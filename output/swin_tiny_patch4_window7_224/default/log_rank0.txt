[2024-12-02 11:38:26 swin_tiny_patch4_window7_224] (main.py 372): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 11:38:26 swin_tiny_patch4_window7_224] (main.py 373): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 11:38:26 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 11:38:26 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=1000, bias=True)
)
[2024-12-02 11:38:26 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1385002
[2024-12-02 11:38:26 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 11:38:26 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 11:38:26 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 11:38:26 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 1000
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 11:44:06 swin_tiny_patch4_window7_224] (main.py 372): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 11:44:06 swin_tiny_patch4_window7_224] (main.py 373): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 11:44:06 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 11:44:06 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 11:44:06 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 11:44:06 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 11:44:06 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 11:44:06 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 11:44:06 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 11:49:00 swin_tiny_patch4_window7_224] (main.py 372): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 11:49:00 swin_tiny_patch4_window7_224] (main.py 373): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 11:49:00 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 11:49:00 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 11:49:00 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 11:49:00 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 11:49:00 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 11:49:00 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 11:49:00 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 11:51:36 swin_tiny_patch4_window7_224] (main.py 373): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 11:51:36 swin_tiny_patch4_window7_224] (main.py 374): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 11:51:36 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 11:51:36 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 11:51:36 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 11:51:36 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 11:51:36 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 11:51:36 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 11:51:36 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 11:53:44 swin_tiny_patch4_window7_224] (main.py 373): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 11:53:44 swin_tiny_patch4_window7_224] (main.py 374): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 11:53:44 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 11:53:44 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 11:53:44 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 11:53:44 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 11:53:44 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 11:53:44 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 11:53:44 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 11:57:19 swin_tiny_patch4_window7_224] (main.py 374): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 11:57:19 swin_tiny_patch4_window7_224] (main.py 375): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 11:57:19 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 11:57:19 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 11:57:19 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 11:57:19 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 11:57:19 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 11:57:19 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 11:57:19 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 11:57:48 swin_tiny_patch4_window7_224] (main.py 374): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 11:57:48 swin_tiny_patch4_window7_224] (main.py 375): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 11:57:48 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 11:57:48 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 11:57:48 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 11:57:48 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 11:57:48 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 11:57:48 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 11:57:48 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 11:59:17 swin_tiny_patch4_window7_224] (main.py 376): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 11:59:17 swin_tiny_patch4_window7_224] (main.py 377): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 11:59:17 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 11:59:17 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 11:59:17 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 11:59:17 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 11:59:17 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 11:59:17 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 11:59:17 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:01:21 swin_tiny_patch4_window7_224] (main.py 377): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:01:21 swin_tiny_patch4_window7_224] (main.py 378): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:01:21 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:01:21 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:01:21 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:01:21 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:01:21 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:01:21 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:01:21 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:04:04 swin_tiny_patch4_window7_224] (main.py 377): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:04:04 swin_tiny_patch4_window7_224] (main.py 378): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:04:04 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:04:04 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:04:04 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:04:04 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:04:04 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:04:04 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:04:04 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:04:35 swin_tiny_patch4_window7_224] (main.py 377): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:04:35 swin_tiny_patch4_window7_224] (main.py 378): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:04:35 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:04:35 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:04:35 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:04:35 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:04:35 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:04:35 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:04:35 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:05:19 swin_tiny_patch4_window7_224] (main.py 377): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:05:19 swin_tiny_patch4_window7_224] (main.py 378): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:05:19 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:05:19 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:05:19 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:05:19 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:05:19 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:05:19 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:05:19 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:07:08 swin_tiny_patch4_window7_224] (main.py 377): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:07:08 swin_tiny_patch4_window7_224] (main.py 378): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:07:08 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:07:08 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:07:08 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:07:08 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:07:08 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:07:08 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:07:08 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:07:31 swin_tiny_patch4_window7_224] (main.py 377): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:07:31 swin_tiny_patch4_window7_224] (main.py 378): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:07:31 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:07:31 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:07:31 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:07:31 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:07:31 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:07:31 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:07:31 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:07:45 swin_tiny_patch4_window7_224] (main.py 377): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:07:45 swin_tiny_patch4_window7_224] (main.py 378): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:07:45 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:07:45 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:07:45 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:07:45 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:07:45 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:07:45 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:07:45 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:08:29 swin_tiny_patch4_window7_224] (main.py 379): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:08:29 swin_tiny_patch4_window7_224] (main.py 380): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:08:29 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:08:29 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:08:29 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:08:29 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:08:29 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:08:29 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:08:29 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:09:08 swin_tiny_patch4_window7_224] (main.py 379): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:09:08 swin_tiny_patch4_window7_224] (main.py 380): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:09:08 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:09:08 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:09:08 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:09:08 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:09:08 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:09:08 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:09:08 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:09:40 swin_tiny_patch4_window7_224] (main.py 379): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:09:40 swin_tiny_patch4_window7_224] (main.py 380): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:09:40 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:09:40 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:09:40 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:09:40 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:09:40 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:09:40 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:09:40 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:12:54 swin_tiny_patch4_window7_224] (main.py 380): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:12:54 swin_tiny_patch4_window7_224] (main.py 381): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:12:54 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:12:54 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:12:54 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:12:54 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:12:54 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:12:54 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:12:54 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:15:22 swin_tiny_patch4_window7_224] (main.py 380): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:15:22 swin_tiny_patch4_window7_224] (main.py 381): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:15:22 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:15:22 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:15:22 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:15:22 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:15:22 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:15:22 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:15:22 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:17:38 swin_tiny_patch4_window7_224] (main.py 380): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:17:38 swin_tiny_patch4_window7_224] (main.py 381): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:17:38 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:17:38 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:17:38 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:17:38 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:17:38 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:17:38 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:17:38 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:17:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3154 (0.3154)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:17:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.2178 (0.1998)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:17:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2686 (0.2007)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:17:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2460 (0.2180)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:17:46 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:07
[2024-12-02 12:18:50 swin_tiny_patch4_window7_224] (main.py 380): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:18:50 swin_tiny_patch4_window7_224] (main.py 381): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:18:50 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:18:50 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:18:50 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:18:50 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:18:50 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:18:50 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:18:50 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:18:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][0/34]	eta 0:00:09 lr 0.000000	 wd 0.0500	time 0.2705 (0.2705)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:18:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1765 (0.1869)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:18:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1732 (0.1817)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:18:55 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1673 (0.1796)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:18:56 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 12:20:05 swin_tiny_patch4_window7_224] (main.py 380): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:20:05 swin_tiny_patch4_window7_224] (main.py 381): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:20:05 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:20:05 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:20:05 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:20:05 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:20:05 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:20:05 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:20:05 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:20:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][0/34]	eta 0:00:08 lr 0.000000	 wd 0.0500	time 0.2639 (0.2639)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:20:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1684 (0.1933)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:20:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2717 (0.1973)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:20:11 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2473 (0.2120)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:20:12 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:07
[2024-12-02 12:21:19 swin_tiny_patch4_window7_224] (main.py 380): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:21:19 swin_tiny_patch4_window7_224] (main.py 381): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:21:19 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:21:19 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:21:19 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:21:19 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:21:19 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:21:19 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:21:19 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:21:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][0/34]	eta 0:00:09 lr 0.000000	 wd 0.0500	time 0.2679 (0.2679)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:21:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.2087 (0.1937)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:21:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2255 (0.2128)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:21:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1880 (0.2124)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:21:27 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:07
[2024-12-02 12:23:55 swin_tiny_patch4_window7_224] (main.py 382): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:23:55 swin_tiny_patch4_window7_224] (main.py 383): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:23:55 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:23:55 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:23:55 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:23:55 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:23:55 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:23:55 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:23:55 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:23:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3180 (0.3180)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:23:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1862 (0.2198)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:24:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2386 (0.2099)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:24:02 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2363 (0.2207)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:24:03 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:07
[2024-12-02 12:42:13 swin_tiny_patch4_window7_224] (main.py 382): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:42:13 swin_tiny_patch4_window7_224] (main.py 383): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:42:13 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:42:13 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:42:13 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:42:13 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:42:13 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:42:13 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:42:13 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:42:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3091 (0.3091)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:42:15 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1808 (0.1932)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:42:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1695 (0.1861)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:42:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1601 (0.1805)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:42:19 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 12:42:39 swin_tiny_patch4_window7_224] (main.py 382): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:42:39 swin_tiny_patch4_window7_224] (main.py 383): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:42:39 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:42:39 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:42:39 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:42:39 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:42:39 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:42:39 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:42:39 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:42:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3017 (0.3017)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:42:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1680 (0.1957)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:42:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1879 (0.1861)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:42:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1796 (0.1822)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:42:45 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 12:45:00 swin_tiny_patch4_window7_224] (main.py 382): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:45:00 swin_tiny_patch4_window7_224] (main.py 383): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:45:00 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:45:00 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:45:00 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:45:00 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:45:00 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:45:00 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:45:00 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:45:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][0/34]	eta 0:00:15 lr 0.000000	 wd 0.0500	time 0.4575 (0.4575)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1717 (0.2234)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1634 (0.1990)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1882 (0.1927)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:07 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 12:45:28 swin_tiny_patch4_window7_224] (main.py 382): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:45:28 swin_tiny_patch4_window7_224] (main.py 383): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:45:28 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:45:28 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:45:28 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:45:28 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:45:28 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:45:28 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:45:28 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:45:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3026 (0.3026)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1721 (0.2030)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1620 (0.1872)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1674 (0.1866)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:34 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 12:45:35 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:45:35 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:45:35 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:45:35 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:45:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/300][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3455 (0.3455)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2387 (0.2397)	loss 1.2106 (1.1857)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2119 (0.2417)	loss 1.3177 (1.1705)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:42 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2025 (0.2226)	loss 1.0078 (1.1956)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:43 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 1 training takes 0:00:07
[2024-12-02 12:45:44 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:45:44 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:45:44 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:45:44 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:45:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/300][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3129 (0.3129)	loss 0.9030 (0.9030)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1865 (0.2097)	loss 1.3133 (1.1674)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1770 (0.1971)	loss 1.1163 (1.1561)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1798 (0.1885)	loss 1.3294 (1.1946)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:50 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 2 training takes 0:00:06
[2024-12-02 12:45:51 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:45:51 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:45:51 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:45:51 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:45:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/300][0/34]	eta 0:00:16 lr 0.000000	 wd 0.0500	time 0.4776 (0.4776)	loss 1.2180 (1.2180)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/300][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.1760 (0.2638)	loss 0.8115 (1.1970)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1709 (0.2199)	loss 1.2076 (1.2151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1808 (0.2068)	loss 1.2020 (1.1984)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:58 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 3 training takes 0:00:06
[2024-12-02 12:45:59 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:45:59 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:45:59 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:45:59 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:45:59 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/300][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3216 (0.3216)	loss 1.4127 (1.4127)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1844 (0.2060)	loss 1.1205 (1.1524)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1713 (0.1905)	loss 1.4133 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2636 (0.2010)	loss 1.0023 (1.1951)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:06 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 4 training takes 0:00:06
[2024-12-02 12:46:07 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:46:07 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:46:07 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:46:07 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:46:08 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/300][0/34]	eta 0:00:14 lr 0.000000	 wd 0.0500	time 0.4398 (0.4398)	loss 1.0050 (1.0050)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1875 (0.2127)	loss 1.3082 (1.1669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:12 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1748 (0.1926)	loss 1.4345 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1691 (0.1851)	loss 1.1244 (1.1977)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:14 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 5 training takes 0:00:06
[2024-12-02 12:46:15 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:46:15 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:46:15 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:46:15 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:46:15 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/300][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3208 (0.3208)	loss 1.2188 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1810 (0.2091)	loss 0.8230 (1.1925)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2686 (0.2208)	loss 1.2182 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1652 (0.2252)	loss 1.2178 (1.1813)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:22 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 6 training takes 0:00:07
[2024-12-02 12:46:23 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:46:23 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:46:23 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:46:23 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:46:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/300][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3549 (0.3549)	loss 1.0111 (1.0111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:25 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1678 (0.2019)	loss 1.0072 (1.1654)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:27 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2069 (0.1913)	loss 0.9054 (1.1399)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:29 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1727 (0.1859)	loss 1.2147 (1.1798)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:29 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 7 training takes 0:00:06
[2024-12-02 12:46:30 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:46:30 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:46:30 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:46:30 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:46:31 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/300][0/34]	eta 0:00:13 lr 0.000000	 wd 0.0500	time 0.3826 (0.3826)	loss 1.1182 (1.1182)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:33 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/300][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.2633 (0.2697)	loss 1.0214 (1.2186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1633 (0.2489)	loss 1.2093 (1.2085)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1705 (0.2229)	loss 1.0152 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:38 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 8 training takes 0:00:07
[2024-12-02 12:46:39 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:46:39 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:46:39 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:46:39 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:46:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/300][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3269 (0.3269)	loss 1.0264 (1.0264)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1760 (0.1993)	loss 1.3252 (1.1444)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1775 (0.1920)	loss 1.5173 (1.1804)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1684 (0.1854)	loss 1.5330 (1.1794)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:45 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 9 training takes 0:00:06
[2024-12-02 12:46:47 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:46:47 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:46:47 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:46:47 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:46:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/300][0/34]	eta 0:00:16 lr 0.000000	 wd 0.0500	time 0.4846 (0.4846)	loss 1.3284 (1.3284)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/300][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.1696 (0.2661)	loss 1.1036 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1638 (0.2241)	loss 1.2124 (1.1887)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1805 (0.2083)	loss 1.1163 (1.1807)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:54 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 10 training takes 0:00:07
[2024-12-02 12:46:55 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:46:55 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:46:55 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:46:55 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:46:55 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/300][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3584 (0.3584)	loss 1.4163 (1.4163)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:57 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1778 (0.1934)	loss 0.8097 (1.2118)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1706 (0.1825)	loss 1.3154 (1.2331)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2678 (0.2007)	loss 0.7169 (1.1948)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:02 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 11 training takes 0:00:07
[2024-12-02 12:47:03 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:47:03 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:47:03 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:47:03 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:47:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/300][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3681 (0.3681)	loss 1.1152 (1.1152)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1887 (0.2067)	loss 1.3062 (1.2064)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1864 (0.1935)	loss 1.0982 (1.2008)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1659 (0.1881)	loss 1.4206 (1.1763)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:09 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 12 training takes 0:00:06
[2024-12-02 12:47:10 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:47:10 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:47:10 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:47:10 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:47:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/300][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3330 (0.3330)	loss 1.2212 (1.2212)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:12 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1899 (0.2080)	loss 1.2048 (1.1112)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:15 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2862 (0.2268)	loss 1.3212 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1906 (0.2270)	loss 1.3129 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:18 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 13 training takes 0:00:07
[2024-12-02 12:47:19 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:47:19 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:47:19 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:47:19 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:47:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/300][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3552 (0.3552)	loss 1.3150 (1.3150)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:21 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1690 (0.2056)	loss 0.9079 (1.0414)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1661 (0.1875)	loss 1.5214 (1.1916)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1736 (0.1860)	loss 1.2292 (1.1842)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:25 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 14 training takes 0:00:06
[2024-12-02 12:47:26 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:47:26 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:47:26 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:47:26 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:47:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/300][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3530 (0.3530)	loss 0.8971 (0.8971)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:29 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/300][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.2440 (0.2696)	loss 1.4212 (1.1306)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:31 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1711 (0.2396)	loss 1.3204 (1.1848)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:33 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1634 (0.2170)	loss 1.3373 (1.1890)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:33 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 15 training takes 0:00:07
[2024-12-02 12:47:34 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:47:34 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:47:34 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:47:34 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:47:35 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/300][0/34]	eta 0:00:13 lr 0.000000	 wd 0.0500	time 0.3867 (0.3867)	loss 1.0005 (1.0005)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1785 (0.2016)	loss 1.2136 (1.1193)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1748 (0.1928)	loss 0.8986 (1.1694)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2197 (0.1884)	loss 1.3288 (1.1791)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:41 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 16 training takes 0:00:06
[2024-12-02 12:47:42 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:47:42 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:47:42 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:47:42 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:47:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/300][0/34]	eta 0:00:16 lr 0.000000	 wd 0.0500	time 0.4970 (0.4970)	loss 1.4139 (1.4139)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1757 (0.2327)	loss 1.3061 (1.2603)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2002 (0.2085)	loss 1.2102 (1.1890)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1857 (0.1995)	loss 1.0017 (1.1820)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:49 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 17 training takes 0:00:06
[2024-12-02 12:47:50 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:47:50 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:47:50 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:47:50 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:47:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/300][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3379 (0.3379)	loss 1.3049 (1.3049)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1685 (0.2020)	loss 1.1154 (1.1879)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2365 (0.1982)	loss 1.4091 (1.1868)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:57 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2319 (0.2161)	loss 1.0122 (1.1849)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:57 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 18 training takes 0:00:07
[2024-12-02 12:47:58 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:47:58 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:47:58 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:47:58 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:47:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/300][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3316 (0.3316)	loss 1.0286 (1.0286)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1746 (0.1940)	loss 1.1265 (1.2362)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:02 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1845 (0.1892)	loss 0.9085 (1.1835)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:04 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1798 (0.1864)	loss 1.2118 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:04 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 19 training takes 0:00:06
[2024-12-02 12:48:05 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:48:05 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:48:05 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:48:05 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:48:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/300][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3521 (0.3521)	loss 1.3092 (1.3092)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:08 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2387 (0.2173)	loss 1.3186 (1.2343)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2540 (0.2314)	loss 0.9077 (1.2009)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:12 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1921 (0.2163)	loss 1.1030 (1.2027)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:13 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 20 training takes 0:00:07
[2024-12-02 12:48:14 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:48:14 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:48:14 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:48:14 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:48:14 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/300][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3681 (0.3681)	loss 1.0226 (1.0226)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1653 (0.2021)	loss 1.2127 (1.1962)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1773 (0.1975)	loss 1.6450 (1.1826)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1601 (0.1905)	loss 1.4221 (1.1872)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:20 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 21 training takes 0:00:06
[2024-12-02 12:48:21 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:48:21 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:48:21 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:48:21 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:48:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/300][0/34]	eta 0:00:17 lr 0.000000	 wd 0.0500	time 0.5173 (0.5173)	loss 1.4136 (1.4136)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/300][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.1859 (0.2666)	loss 1.1175 (1.1990)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1642 (0.2230)	loss 1.4164 (1.2163)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1810 (0.2061)	loss 1.3064 (1.1859)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:28 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 22 training takes 0:00:06
[2024-12-02 12:48:29 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:48:29 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:48:29 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:48:29 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:48:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/300][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3571 (0.3571)	loss 1.1186 (1.1186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1744 (0.2072)	loss 0.8045 (1.1530)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:33 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1803 (0.1892)	loss 1.4216 (1.1972)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2296 (0.2039)	loss 1.1113 (1.1729)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:36 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 23 training takes 0:00:07
[2024-12-02 12:48:38 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:48:38 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:48:38 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:48:38 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:48:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/300][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3379 (0.3379)	loss 1.2105 (1.2105)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1875 (0.1981)	loss 1.1162 (1.1744)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:42 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1951 (0.1926)	loss 1.2089 (1.1896)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1648 (0.1876)	loss 1.3081 (1.2048)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:44 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 24 training takes 0:00:06
[2024-12-02 12:48:45 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:48:45 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:48:45 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:48:45 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:48:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/300][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3740 (0.3740)	loss 1.2229 (1.2229)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1872 (0.2151)	loss 1.5144 (1.2567)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2475 (0.2294)	loss 1.1144 (1.1926)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1905 (0.2219)	loss 1.3066 (1.1866)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:52 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 25 training takes 0:00:07
[2024-12-02 12:48:53 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:48:53 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:48:53 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:48:53 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:48:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/300][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3412 (0.3412)	loss 1.3199 (1.3199)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1590 (0.1921)	loss 1.0294 (1.1535)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:57 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1861 (0.1890)	loss 1.2143 (1.1770)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:59 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1702 (0.1855)	loss 1.0025 (1.1751)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:00 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 26 training takes 0:00:06
[2024-12-02 12:49:01 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:49:01 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:49:01 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:49:01 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:49:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/300][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3697 (0.3697)	loss 1.4119 (1.4119)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:04 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/300][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.2708 (0.2711)	loss 1.5333 (1.1610)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1881 (0.2379)	loss 1.4040 (1.1913)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1702 (0.2192)	loss 1.4108 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:08 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 27 training takes 0:00:07
[2024-12-02 12:49:09 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:49:09 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:49:09 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:49:09 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:49:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/300][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3448 (0.3448)	loss 1.3144 (1.3144)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:11 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1744 (0.2005)	loss 1.2006 (1.1132)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1611 (0.1866)	loss 1.4167 (1.1531)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:15 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2476 (0.1920)	loss 1.1021 (1.1701)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:16 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 28 training takes 0:00:06
[2024-12-02 12:49:17 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:49:17 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:49:17 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:49:17 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:49:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/300][0/34]	eta 0:00:16 lr 0.000000	 wd 0.0500	time 0.4965 (0.4965)	loss 1.3227 (1.3227)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1971 (0.2274)	loss 1.0086 (1.2451)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:21 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1687 (0.1997)	loss 1.0040 (1.2303)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1656 (0.1927)	loss 1.2243 (1.2024)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:23 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 29 training takes 0:00:06
[2024-12-02 12:49:25 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:49:25 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:49:25 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:49:25 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:49:25 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/300][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3316 (0.3316)	loss 1.1026 (1.1026)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:27 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1858 (0.2067)	loss 1.1117 (1.1223)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:29 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2450 (0.2186)	loss 1.1088 (1.1668)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1983 (0.2260)	loss 1.4201 (1.1742)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:32 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 30 training takes 0:00:07
[2024-12-02 12:49:33 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:49:33 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:49:33 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:49:33 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:49:33 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/300][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3186 (0.3186)	loss 1.3124 (1.3124)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:35 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1933 (0.2050)	loss 1.3106 (1.2149)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1647 (0.1872)	loss 1.2093 (1.1914)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1830 (0.1855)	loss 0.7156 (1.1797)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:39 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 31 training takes 0:00:06
[2024-12-02 12:49:40 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:49:40 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:49:40 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:49:40 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:49:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/300][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3122 (0.3122)	loss 1.0058 (1.0058)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2407 (0.2498)	loss 1.0125 (1.2167)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1893 (0.2482)	loss 1.0123 (1.1377)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1982 (0.2271)	loss 1.4166 (1.1854)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:48 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 32 training takes 0:00:07
[2024-12-02 12:49:49 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:49:49 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:49:49 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:49:49 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:49:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [33/300][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3593 (0.3593)	loss 1.1313 (1.1313)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [33/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1883 (0.2095)	loss 0.6049 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:50:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [36/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1911 (0.1904)	loss 1.0131 (1.1773)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:50:20 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 36 training takes 0:00:06
[2024-12-02 12:50:21 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:50:21 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:50:21 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:50:21 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:50:21 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/300][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3289 (0.3289)	loss 1.3151 (1.3151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:50:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2409 (0.2201)	loss 1.1040 (1.2517)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:50:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2192 (0.2264)	loss 0.7092 (1.2056)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:50:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1744 (0.2180)	loss 1.1129 (1.1746)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:50:28 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 37 training takes 0:00:07
[2024-12-02 12:55:43 swin_tiny_patch4_window7_224] (main.py 382): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:55:43 swin_tiny_patch4_window7_224] (main.py 383): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:55:43 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:55:43 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:55:43 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:55:43 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:55:43 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:55:43 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:55:43 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:55:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3092 (0.3092)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:55:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1838 (0.1922)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:55:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1690 (0.1804)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:55:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1626 (0.1760)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:55:49 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 12:55:50 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:55:50 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:55:50 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:55:50 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:55:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][0/34]	eta 0:00:14 lr 0.000000	 wd 0.0500	time 0.4290 (0.4290)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:56:48 swin_tiny_patch4_window7_224] (main.py 382): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:56:48 swin_tiny_patch4_window7_224] (main.py 383): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:56:48 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:56:48 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:56:48 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:56:48 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:56:48 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:56:48 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:56:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3402 (0.3402)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:56:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2671 (0.2097)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:56:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2432 (0.2224)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:56:55 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1664 (0.2191)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:56:56 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:07
[2024-12-02 12:56:57 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:56:57 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:56:57 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:56:57 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3233 (0.3233)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:56:59 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1869 (0.2017)	loss 1.2106 (1.1857)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1645 (0.1853)	loss 1.3177 (1.1705)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:02 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1616 (0.1788)	loss 1.0078 (1.1956)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:03 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 1 training takes 0:00:06
[2024-12-02 12:57:04 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:57:04 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:57:04 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:57:04 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3614 (0.3614)	loss 0.9030 (0.9030)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.2489 (0.2734)	loss 1.3133 (1.1674)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1713 (0.2369)	loss 1.1163 (1.1561)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1915 (0.2159)	loss 1.3294 (1.1946)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:11 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 2 training takes 0:00:07
[2024-12-02 12:57:12 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:57:12 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:57:12 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:57:12 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3247 (0.3247)	loss 1.2180 (1.2180)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:14 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1835 (0.2027)	loss 0.8115 (1.1970)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1724 (0.1930)	loss 1.2076 (1.2151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1777 (0.1901)	loss 1.2020 (1.1984)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:18 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 3 training takes 0:00:06
[2024-12-02 12:57:20 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:57:20 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:57:20 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:57:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][0/34]	eta 0:00:16 lr 0.000000	 wd 0.0500	time 0.4940 (0.4940)	loss 1.4127 (1.4127)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1575 (0.2419)	loss 1.1205 (1.1524)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1868 (0.2076)	loss 1.4133 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1721 (0.1941)	loss 1.0023 (1.1951)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:26 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 4 training takes 0:00:06
[2024-12-02 12:57:27 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:57:27 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:57:27 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:57:27 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3145 (0.3145)	loss 1.0050 (1.0050)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:29 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1632 (0.1976)	loss 1.3082 (1.1669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:31 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1787 (0.1865)	loss 1.4345 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:33 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2486 (0.2015)	loss 1.1244 (1.1977)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:34 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 5 training takes 0:00:06
[2024-12-02 12:57:35 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:57:35 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:57:35 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:57:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3546 (0.3546)	loss 1.2188 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1720 (0.1960)	loss 0.8230 (1.1925)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1713 (0.1808)	loss 1.2182 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1704 (0.1788)	loss 1.2178 (1.1813)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:41 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 6 training takes 0:00:06
[2024-12-02 12:57:42 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:57:42 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:57:42 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:57:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3436 (0.3436)	loss 1.0111 (1.0111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1728 (0.1938)	loss 1.0072 (1.1654)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2595 (0.1996)	loss 0.9054 (1.1399)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2187 (0.2144)	loss 1.2147 (1.1798)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:50 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 7 training takes 0:00:07
[2024-12-02 12:57:50 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:57:50 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:57:50 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:57:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3604 (0.3604)	loss 1.1182 (1.1182)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1920 (0.2116)	loss 1.0214 (1.2186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:55 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1770 (0.1984)	loss 1.2093 (1.2085)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1779 (0.1925)	loss 1.0152 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:57 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 8 training takes 0:00:06
[2024-12-02 12:57:58 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:57:58 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:57:58 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:57:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3339 (0.3339)	loss 1.0264 (1.0264)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2502 (0.2489)	loss 1.3252 (1.1444)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2158 (0.2469)	loss 1.5173 (1.1804)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1826 (0.2245)	loss 1.5330 (1.1794)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:05 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 9 training takes 0:00:07
[2024-12-02 12:58:06 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:58:06 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:58:06 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:58:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3242 (0.3242)	loss 1.3284 (1.3284)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1778 (0.1973)	loss 1.1036 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1568 (0.1827)	loss 1.2124 (1.1887)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:12 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1765 (0.1786)	loss 1.1163 (1.1807)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:12 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 10 training takes 0:00:06
[2024-12-02 12:58:14 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:58:14 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:58:14 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:58:14 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][0/34]	eta 0:00:15 lr 0.000000	 wd 0.0500	time 0.4682 (0.4682)	loss 1.4163 (1.4163)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.2189 (0.2739)	loss 0.8097 (1.2118)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1819 (0.2317)	loss 1.3154 (1.2331)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1900 (0.2141)	loss 0.7169 (1.1948)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:21 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 11 training takes 0:00:07
[2024-12-02 12:58:22 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:58:22 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:58:22 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:58:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3428 (0.3428)	loss 1.1152 (1.1152)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1815 (0.2025)	loss 1.3062 (1.2064)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1708 (0.1870)	loss 1.0982 (1.2008)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2488 (0.1919)	loss 1.4206 (1.1763)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:29 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 12 training takes 0:00:06
[2024-12-02 12:58:30 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:58:30 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:58:30 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:58:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][0/34]	eta 0:00:15 lr 0.000000	 wd 0.0500	time 0.4652 (0.4652)	loss 1.2212 (1.2212)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1941 (0.2099)	loss 1.2048 (1.1112)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1897 (0.1945)	loss 1.3212 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1628 (0.1862)	loss 1.3129 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:36 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 13 training takes 0:00:06
[2024-12-02 12:58:37 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:58:37 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:58:37 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:58:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3278 (0.3278)	loss 1.3150 (1.3150)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1770 (0.1998)	loss 0.9079 (1.0414)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2521 (0.2047)	loss 1.5214 (1.1916)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2076 (0.2157)	loss 1.2292 (1.1842)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:44 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 14 training takes 0:00:07
[2024-12-02 12:58:45 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:58:45 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:58:45 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:58:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3294 (0.3294)	loss 0.8971 (0.8971)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1831 (0.2068)	loss 1.4212 (1.1306)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1953 (0.1935)	loss 1.3204 (1.1848)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1826 (0.1875)	loss 1.3373 (1.1890)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:52 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 15 training takes 0:00:06
[2024-12-02 12:58:53 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:58:53 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:58:53 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:58:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3689 (0.3689)	loss 1.0005 (1.0005)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:55 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2606 (0.2442)	loss 1.2136 (1.1193)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2396 (0.2457)	loss 0.8986 (1.1694)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1623 (0.2233)	loss 1.3288 (1.1791)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:00 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 16 training takes 0:00:07
[2024-12-02 12:59:01 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:59:01 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:59:01 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:59:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3503 (0.3503)	loss 1.4139 (1.4139)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1865 (0.2029)	loss 1.3061 (1.2603)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1678 (0.1889)	loss 1.2102 (1.1890)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1752 (0.1851)	loss 1.0017 (1.1820)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:07 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 17 training takes 0:00:06
[2024-12-02 12:59:08 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:59:08 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:59:08 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:59:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][0/34]	eta 0:00:16 lr 0.000000	 wd 0.0500	time 0.4823 (0.4823)	loss 1.3049 (1.3049)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:11 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.2393 (0.2759)	loss 1.1154 (1.1879)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1617 (0.2292)	loss 1.4091 (1.1868)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:15 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1645 (0.2100)	loss 1.0122 (1.1849)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:15 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 18 training takes 0:00:07
[2024-12-02 12:59:16 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:59:16 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:59:16 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:59:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3608 (0.3608)	loss 1.0286 (1.0286)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1643 (0.2109)	loss 1.1265 (1.2362)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:21 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1724 (0.1969)	loss 0.9085 (1.1835)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2402 (0.1990)	loss 1.2118 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:23 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 19 training takes 0:00:06
[2024-12-02 12:59:25 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:59:25 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:59:25 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:59:25 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][0/34]	eta 0:00:17 lr 0.000000	 wd 0.0500	time 0.5050 (0.5050)	loss 1.3092 (1.3092)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:27 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1707 (0.2193)	loss 1.3186 (1.2343)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:29 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1791 (0.2014)	loss 0.9077 (1.2009)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:31 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1793 (0.1931)	loss 1.1030 (1.2027)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:31 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 20 training takes 0:00:06
[2024-12-02 12:59:32 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:59:32 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:59:32 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:59:33 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][0/34]	eta 0:00:13 lr 0.000000	 wd 0.0500	time 0.3844 (0.3844)	loss 1.0226 (1.0226)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1632 (0.1961)	loss 1.2127 (1.1962)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2471 (0.1989)	loss 1.6450 (1.1826)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2608 (0.2135)	loss 1.4221 (1.1872)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:40 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 21 training takes 0:00:07
[2024-12-02 12:59:41 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:59:41 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:59:41 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:59:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3214 (0.3214)	loss 1.4136 (1.4136)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1616 (0.1926)	loss 1.1175 (1.1990)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1714 (0.1799)	loss 1.4164 (1.2163)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1746 (0.1760)	loss 1.3064 (1.1859)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:47 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 22 training takes 0:00:05
[2024-12-02 12:59:47 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:59:47 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:59:47 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:59:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3140 (0.3140)	loss 1.1186 (1.1186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2576 (0.2277)	loss 0.8045 (1.1530)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2456 (0.2358)	loss 1.4216 (1.1972)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1895 (0.2231)	loss 1.1113 (1.1729)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:55 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 23 training takes 0:00:07
[2024-12-02 12:59:56 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:59:56 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:59:56 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:59:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3130 (0.3130)	loss 1.2105 (1.2105)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1950 (0.2009)	loss 1.1162 (1.1744)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2355 (0.2086)	loss 1.2089 (1.1896)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2333 (0.2134)	loss 1.3081 (1.2048)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:03 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 24 training takes 0:00:07
[2024-12-02 13:00:05 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:00:05 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:00:05 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:00:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][0/34]	eta 0:00:16 lr 0.000000	 wd 0.0500	time 0.4725 (0.4725)	loss 1.2229 (1.2229)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.1703 (0.2693)	loss 1.5144 (1.2567)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1853 (0.2222)	loss 1.1144 (1.1926)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:11 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1776 (0.2089)	loss 1.3066 (1.1866)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:12 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 25 training takes 0:00:07
[2024-12-02 13:00:12 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:00:12 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:00:12 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:00:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3452 (0.3452)	loss 1.3199 (1.3199)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:15 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1739 (0.2102)	loss 1.0294 (1.1535)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1851 (0.1933)	loss 1.2143 (1.1770)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2425 (0.2030)	loss 1.0025 (1.1751)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:20 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 26 training takes 0:00:07
[2024-12-02 13:00:21 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:00:21 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:00:21 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:00:21 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][0/34]	eta 0:00:15 lr 0.000000	 wd 0.0500	time 0.4468 (0.4468)	loss 1.4119 (1.4119)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1671 (0.2090)	loss 1.5333 (1.1610)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:25 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1590 (0.1882)	loss 1.4040 (1.1913)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1608 (0.1819)	loss 1.4108 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:27 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 27 training takes 0:00:06
[2024-12-02 13:00:28 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:00:28 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:00:28 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:00:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3220 (0.3220)	loss 1.3144 (1.3144)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1823 (0.1910)	loss 1.2006 (1.1132)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2400 (0.1963)	loss 1.4167 (1.1531)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2360 (0.2099)	loss 1.1021 (1.1701)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:35 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 28 training takes 0:00:07
[2024-12-02 13:00:36 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:00:36 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:00:36 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:00:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3642 (0.3642)	loss 1.3227 (1.3227)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1675 (0.2057)	loss 1.0086 (1.2451)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1827 (0.2051)	loss 1.0040 (1.2303)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:42 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1834 (0.2009)	loss 1.2243 (1.2024)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:43 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 29 training takes 0:00:06
[2024-12-02 13:00:44 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:00:44 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:00:44 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:00:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3651 (0.3651)	loss 1.1026 (1.1026)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][10/34]	eta 0:00:08 lr 0.000000	 wd 0.0500	time 0.2559 (0.3428)	loss 1.1117 (1.1223)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][20/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1816 (0.3120)	loss 1.1088 (1.1668)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][30/34]	eta 0:00:01 lr 0.000000	 wd 0.0500	time 0.1657 (0.2674)	loss 1.4201 (1.1742)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:53 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 30 training takes 0:00:08
[2024-12-02 13:00:54 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:00:54 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:00:54 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:00:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3600 (0.3600)	loss 1.3124 (1.3124)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:16 swin_tiny_patch4_window7_224] (main.py 382): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 13:01:16 swin_tiny_patch4_window7_224] (main.py 383): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 13:01:16 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:01:16 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 13:01:16 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 13:01:16 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 13:01:16 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:01:16 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:01:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][0/34]	eta 0:00:08 lr 0.000000	 wd 0.0500	time 0.2579 (0.2579)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1574 (0.1791)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1579 (0.1767)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1651 (0.1769)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:22 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:05
[2024-12-02 13:01:23 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:01:23 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:01:23 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:01:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3088 (0.3088)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2477 (0.2391)	loss 1.2106 (1.1857)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1643 (0.2335)	loss 1.3177 (1.1705)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1722 (0.2116)	loss 1.0078 (1.1956)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:30 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 1 training takes 0:00:07
[2024-12-02 13:01:31 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:01:31 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:01:31 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:01:31 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3103 (0.3103)	loss 0.9030 (0.9030)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:33 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1635 (0.1990)	loss 1.3133 (1.1674)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:35 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1597 (0.1873)	loss 1.1163 (1.1561)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1643 (0.1789)	loss 1.3294 (1.1946)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:37 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 2 training takes 0:00:06
[2024-12-02 13:01:38 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:01:38 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:01:38 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:01:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][0/34]	eta 0:00:16 lr 0.000000	 wd 0.0500	time 0.4938 (0.4938)	loss 1.2180 (1.2180)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.2360 (0.2790)	loss 0.8115 (1.1970)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1642 (0.2273)	loss 1.2076 (1.2151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1612 (0.2059)	loss 1.2020 (1.1984)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:45 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 3 training takes 0:00:06
[2024-12-02 13:01:46 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:01:46 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:01:46 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:01:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3595 (0.3595)	loss 1.4127 (1.4127)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1669 (0.1906)	loss 1.1205 (1.1524)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1600 (0.1772)	loss 1.4133 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2474 (0.1788)	loss 1.0023 (1.1951)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:52 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 4 training takes 0:00:06
[2024-12-02 13:01:54 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:01:54 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:01:54 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:01:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][0/34]	eta 0:00:14 lr 0.000000	 wd 0.0500	time 0.4377 (0.4377)	loss 1.0050 (1.0050)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1594 (0.2097)	loss 1.3082 (1.1669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1945 (0.1920)	loss 1.4345 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:59 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1629 (0.1875)	loss 1.1244 (1.1977)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:00 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 5 training takes 0:00:06
[2024-12-02 13:02:01 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:02:01 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:02:01 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:02:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3098 (0.3098)	loss 1.2188 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1867 (0.1943)	loss 0.8230 (1.1925)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1566 (0.1836)	loss 1.2182 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2405 (0.2008)	loss 1.2178 (1.1813)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:08 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 6 training takes 0:00:06
[2024-12-02 13:02:09 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:02:09 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:02:09 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:02:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3168 (0.3168)	loss 1.0111 (1.0111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:11 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1810 (0.1961)	loss 1.0072 (1.1654)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1738 (0.1829)	loss 0.9054 (1.1399)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:14 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1693 (0.1814)	loss 1.2147 (1.1798)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:15 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 7 training takes 0:00:06
[2024-12-02 13:02:16 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:02:16 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:02:16 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:02:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3416 (0.3416)	loss 1.1182 (1.1182)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1727 (0.1941)	loss 1.0214 (1.2186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2345 (0.2147)	loss 1.2093 (1.2085)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1617 (0.2135)	loss 1.0152 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:23 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 8 training takes 0:00:07
[2024-12-02 13:02:24 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:02:24 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:02:24 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:02:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3422 (0.3422)	loss 1.0264 (1.0264)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1580 (0.1880)	loss 1.3252 (1.1444)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1799 (0.1806)	loss 1.5173 (1.1804)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1695 (0.1786)	loss 1.5330 (1.1794)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:30 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 9 training takes 0:00:06
[2024-12-02 13:02:31 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:02:31 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:02:31 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:02:31 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3106 (0.3106)	loss 1.3284 (1.3284)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2535 (0.2464)	loss 1.1036 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1626 (0.2375)	loss 1.2124 (1.1887)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1631 (0.2144)	loss 1.1163 (1.1807)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:38 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 10 training takes 0:00:07
[2024-12-02 13:02:39 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:02:39 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:02:39 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:02:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3495 (0.3495)	loss 1.4163 (1.4163)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:42 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1609 (0.2012)	loss 0.8097 (1.2118)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1831 (0.1913)	loss 1.3154 (1.2331)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1656 (0.1826)	loss 0.7169 (1.1948)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:46 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 11 training takes 0:00:06
[2024-12-02 13:02:47 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:02:47 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:02:47 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:02:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][0/34]	eta 0:00:18 lr 0.000000	 wd 0.0500	time 0.5361 (0.5361)	loss 1.1152 (1.1152)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.1590 (0.2588)	loss 1.3062 (1.2064)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1657 (0.2158)	loss 1.0982 (1.2008)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1763 (0.2008)	loss 1.4206 (1.1763)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:54 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 12 training takes 0:00:06
[2024-12-02 13:02:55 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:02:55 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:02:55 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:02:55 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.2998 (0.2998)	loss 1.2212 (1.2212)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:57 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1710 (0.1847)	loss 1.2048 (1.1112)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1746 (0.1834)	loss 1.3212 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2366 (0.1888)	loss 1.3129 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:01 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 13 training takes 0:00:06
[2024-12-02 13:03:02 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:03:02 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:03:02 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:03:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3617 (0.3617)	loss 1.3150 (1.3150)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1725 (0.2020)	loss 0.9079 (1.0414)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1762 (0.1891)	loss 1.5214 (1.1916)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:08 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1648 (0.1868)	loss 1.2292 (1.1842)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:09 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 14 training takes 0:00:06
[2024-12-02 13:03:10 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:03:10 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:03:10 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:03:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3041 (0.3041)	loss 0.8971 (0.8971)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:12 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1767 (0.1887)	loss 1.4212 (1.1306)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:14 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2766 (0.1965)	loss 1.3204 (1.1848)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2503 (0.2092)	loss 1.3373 (1.1890)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:17 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 15 training takes 0:00:07
[2024-12-02 13:03:18 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:03:18 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:03:18 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:03:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3064 (0.3064)	loss 1.0005 (1.0005)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1736 (0.2055)	loss 1.2136 (1.1193)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1728 (0.1951)	loss 0.8986 (1.1694)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1646 (0.1889)	loss 1.3288 (1.1791)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:24 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 16 training takes 0:00:06
[2024-12-02 13:03:25 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:03:25 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:03:25 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:03:25 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3477 (0.3477)	loss 1.4139 (1.4139)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2747 (0.2300)	loss 1.3061 (1.2603)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1661 (0.2358)	loss 1.2102 (1.1890)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1901 (0.2169)	loss 1.0017 (1.1820)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:32 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 17 training takes 0:00:07
[2024-12-02 13:03:33 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:03:33 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:03:33 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:03:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3026 (0.3026)	loss 1.3049 (1.3049)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:35 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1662 (0.1855)	loss 1.1154 (1.1879)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1846 (0.1811)	loss 1.4091 (1.1868)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1845 (0.1794)	loss 1.0122 (1.1849)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:39 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 18 training takes 0:00:06
[2024-12-02 13:03:41 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:03:41 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:03:41 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:03:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][0/34]	eta 0:00:16 lr 0.000000	 wd 0.0500	time 0.4812 (0.4812)	loss 1.0286 (1.0286)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.1682 (0.2579)	loss 1.1265 (1.2362)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1610 (0.2130)	loss 0.9085 (1.1835)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1661 (0.1997)	loss 1.2118 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:47 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 19 training takes 0:00:06
[2024-12-02 13:03:48 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:03:48 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:03:48 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:03:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3040 (0.3040)	loss 1.3092 (1.3092)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1547 (0.1833)	loss 1.3186 (1.2343)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1605 (0.1745)	loss 0.9077 (1.2009)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2315 (0.1736)	loss 1.1030 (1.2027)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:54 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 20 training takes 0:00:06
[2024-12-02 13:03:56 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:03:56 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:03:56 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:03:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][0/34]	eta 0:00:14 lr 0.000000	 wd 0.0500	time 0.4247 (0.4247)	loss 1.0226 (1.0226)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1613 (0.2052)	loss 1.2127 (1.1962)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1654 (0.1894)	loss 1.6450 (1.1826)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1746 (0.1818)	loss 1.4221 (1.1872)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:02 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 21 training takes 0:00:06
[2024-12-02 13:04:03 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:04:03 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:04:03 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:04:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3003 (0.3003)	loss 1.4136 (1.4136)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1691 (0.2002)	loss 1.1175 (1.1990)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2190 (0.1905)	loss 1.4164 (1.2163)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2067 (0.2032)	loss 1.3064 (1.1859)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:10 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 22 training takes 0:00:07
[2024-12-02 13:04:11 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:04:11 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:04:11 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:04:11 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3426 (0.3426)	loss 1.1186 (1.1186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1636 (0.1879)	loss 0.8045 (1.1530)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:14 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1572 (0.1758)	loss 1.4216 (1.1972)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1585 (0.1709)	loss 1.1113 (1.1729)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:17 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 23 training takes 0:00:05
[2024-12-02 13:04:17 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:04:17 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:04:17 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:04:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3288 (0.3288)	loss 1.2105 (1.2105)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1740 (0.1899)	loss 1.1162 (1.1744)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2392 (0.2043)	loss 1.2089 (1.1896)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1625 (0.2082)	loss 1.3081 (1.2048)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:24 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 24 training takes 0:00:06
[2024-12-02 13:04:25 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:04:25 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:04:25 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:04:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3161 (0.3161)	loss 1.2229 (1.2229)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:27 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1627 (0.1932)	loss 1.5144 (1.2567)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:29 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1900 (0.1877)	loss 1.1144 (1.1926)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:31 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1594 (0.1798)	loss 1.3066 (1.1866)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:31 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 25 training takes 0:00:06
[2024-12-02 13:04:32 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:04:32 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:04:32 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:04:33 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3529 (0.3529)	loss 1.3199 (1.3199)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:35 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2359 (0.2314)	loss 1.0294 (1.1535)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1611 (0.2255)	loss 1.2143 (1.1770)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1815 (0.2110)	loss 1.0025 (1.1751)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:40 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 26 training takes 0:00:07
[2024-12-02 13:04:41 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:04:41 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:04:41 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:04:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3578 (0.3578)	loss 1.4119 (1.4119)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1672 (0.1975)	loss 1.5333 (1.1610)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1720 (0.1824)	loss 1.4040 (1.1913)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1682 (0.1812)	loss 1.4108 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:47 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 27 training takes 0:00:06
[2024-12-02 13:04:48 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:04:48 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:04:48 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:04:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][0/34]	eta 0:00:15 lr 0.000000	 wd 0.0500	time 0.4512 (0.4512)	loss 1.3144 (1.3144)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.1775 (0.2635)	loss 1.2006 (1.1132)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1632 (0.2200)	loss 1.4167 (1.1531)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1709 (0.2016)	loss 1.1021 (1.1701)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:55 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 28 training takes 0:00:06
[2024-12-02 13:04:56 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:04:56 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:04:56 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:04:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3424 (0.3424)	loss 1.3227 (1.3227)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1590 (0.1872)	loss 1.0086 (1.2451)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1652 (0.1811)	loss 1.0040 (1.2303)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:02 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2341 (0.1864)	loss 1.2243 (1.2024)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:02 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 29 training takes 0:00:06
[2024-12-02 13:05:04 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:05:04 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:05:04 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:05:04 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][0/34]	eta 0:00:15 lr 0.000000	 wd 0.0500	time 0.4616 (0.4616)	loss 1.1026 (1.1026)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1901 (0.2010)	loss 1.1117 (1.1223)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1633 (0.1846)	loss 1.1088 (1.1668)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1687 (0.1805)	loss 1.4201 (1.1742)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:10 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 30 training takes 0:00:06
[2024-12-02 13:05:11 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:05:11 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:05:11 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:05:11 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3500 (0.3500)	loss 1.3124 (1.3124)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1826 (0.2034)	loss 1.3106 (1.2149)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:15 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2409 (0.1970)	loss 1.2093 (1.1914)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2403 (0.2116)	loss 0.7156 (1.1797)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:18 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 31 training takes 0:00:07
[2024-12-02 13:05:19 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:05:19 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:05:19 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:05:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3202 (0.3202)	loss 1.0058 (1.0058)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:21 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1696 (0.1943)	loss 1.0125 (1.2167)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1595 (0.1803)	loss 1.0123 (1.1377)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1726 (0.1779)	loss 1.4166 (1.1854)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:25 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 32 training takes 0:00:06
[2024-12-02 13:05:26 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:05:26 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:05:26 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:05:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [33/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3059 (0.3059)	loss 1.1313 (1.1313)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [33/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.2505 (0.2037)	loss 0.6049 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [33/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2515 (0.2225)	loss 1.3294 (1.1954)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [33/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1605 (0.2101)	loss 1.0163 (1.1927)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:33 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 33 training takes 0:00:07
[2024-12-02 13:05:34 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:05:34 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:05:34 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:05:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [34/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3523 (0.3523)	loss 1.1084 (1.1084)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [34/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1883 (0.2021)	loss 1.3212 (1.1620)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [34/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1645 (0.1845)	loss 1.3186 (1.1931)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [34/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1725 (0.1808)	loss 0.9284 (1.1845)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:40 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 34 training takes 0:00:06
[2024-12-02 13:05:41 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:05:41 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:05:41 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:05:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [35/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3148 (0.3148)	loss 1.1111 (1.1111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [35/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2363 (0.2431)	loss 0.8124 (1.1889)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [35/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1628 (0.2299)	loss 0.9057 (1.1603)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [35/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1613 (0.2088)	loss 1.6174 (1.1775)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:48 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 35 training takes 0:00:06
[2024-12-02 13:05:49 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:05:49 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:05:49 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:05:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [36/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3648 (0.3648)	loss 1.4135 (1.4135)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [36/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1651 (0.2027)	loss 1.3019 (1.1401)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [36/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1838 (0.1849)	loss 1.1178 (1.1869)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [36/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1752 (0.1841)	loss 1.0131 (1.1773)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:55 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 36 training takes 0:00:06
[2024-12-02 13:05:56 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:05:56 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:05:56 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:05:57 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/50][0/34]	eta 0:00:14 lr 0.000000	 wd 0.0500	time 0.4166 (0.4166)	loss 1.3151 (1.3151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:59 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1638 (0.2309)	loss 1.1040 (1.2517)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1895 (0.2058)	loss 0.7092 (1.2056)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:02 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1663 (0.1965)	loss 1.1129 (1.1746)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:03 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 37 training takes 0:00:06
[2024-12-02 13:06:04 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:06:04 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:06:04 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:06:04 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [38/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3521 (0.3521)	loss 0.9028 (0.9028)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [38/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1808 (0.1983)	loss 1.2352 (1.1704)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:08 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [38/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1869 (0.1914)	loss 1.4207 (1.1830)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [38/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2322 (0.2067)	loss 1.0141 (1.1747)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:11 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 38 training takes 0:00:07
[2024-12-02 13:06:12 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:06:12 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:06:12 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:06:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [39/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3666 (0.3666)	loss 0.9233 (0.9233)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:14 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [39/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1671 (0.2074)	loss 1.3170 (1.2329)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [39/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1642 (0.1887)	loss 1.3231 (1.2046)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [39/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1604 (0.1841)	loss 0.9093 (1.2043)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:18 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 39 training takes 0:00:06
[2024-12-02 13:06:19 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:06:19 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:06:19 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:06:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [40/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3114 (0.3114)	loss 1.1246 (1.1246)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [40/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1638 (0.1946)	loss 1.2323 (1.1760)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [40/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2423 (0.2137)	loss 1.1203 (1.2085)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [40/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1634 (0.2135)	loss 1.0112 (1.2018)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:27 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 40 training takes 0:00:07
[2024-12-02 13:06:28 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:06:28 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:06:28 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:06:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [41/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3126 (0.3126)	loss 1.0274 (1.0274)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [41/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1712 (0.1962)	loss 1.1096 (1.2295)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:31 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [41/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1736 (0.1874)	loss 1.1239 (1.2008)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:33 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [41/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1630 (0.1800)	loss 1.2138 (1.2016)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:34 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 41 training takes 0:00:06
[2024-12-02 13:06:35 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:06:35 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:06:35 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:06:35 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [42/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3381 (0.3381)	loss 0.9176 (0.9176)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [42/50][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.2586 (0.2513)	loss 1.3111 (1.1131)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [42/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1639 (0.2309)	loss 1.1106 (1.1564)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [42/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1777 (0.2134)	loss 1.0226 (1.1715)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:42 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 42 training takes 0:00:07
[2024-12-02 13:06:43 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:06:43 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:06:43 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:06:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [43/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3333 (0.3333)	loss 1.3139 (1.3139)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [43/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1660 (0.2037)	loss 0.7032 (1.1111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [43/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1671 (0.1881)	loss 1.0167 (1.1435)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [43/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1766 (0.1853)	loss 1.3263 (1.1784)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:49 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 43 training takes 0:00:06
[2024-12-02 13:06:50 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:06:50 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:06:50 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:06:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [44/50][0/34]	eta 0:00:15 lr 0.000000	 wd 0.0500	time 0.4540 (0.4540)	loss 1.2082 (1.2082)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [44/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1704 (0.2465)	loss 1.1141 (1.1958)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:55 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [44/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1647 (0.2133)	loss 1.0141 (1.2047)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:57 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [44/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1693 (0.2013)	loss 1.4171 (1.2017)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:57 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 44 training takes 0:00:06
[2024-12-02 13:06:58 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:06:58 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:06:58 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:06:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [45/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3104 (0.3104)	loss 1.0091 (1.0091)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [45/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1644 (0.1895)	loss 1.0239 (1.1648)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:02 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [45/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1725 (0.1783)	loss 1.0019 (1.1559)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:04 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [45/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2397 (0.1921)	loss 1.2294 (1.1755)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:05 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 45 training takes 0:00:06
[2024-12-02 13:07:06 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:07:06 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:07:06 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:07:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [46/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3386 (0.3386)	loss 1.0175 (1.0175)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:08 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [46/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1602 (0.1924)	loss 1.2075 (1.2443)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [46/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1784 (0.1836)	loss 1.4277 (1.2311)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:12 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [46/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1703 (0.1782)	loss 1.1107 (1.1996)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:12 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 46 training takes 0:00:06
[2024-12-02 13:07:13 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:07:13 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:07:13 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:07:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [47/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3066 (0.3066)	loss 1.3101 (1.3101)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:15 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [47/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1657 (0.1919)	loss 1.1094 (1.1374)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [47/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2454 (0.1991)	loss 1.1018 (1.1581)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [47/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2072 (0.2078)	loss 1.3091 (1.1700)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:20 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 47 training takes 0:00:06
[2024-12-02 13:07:21 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:07:21 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:07:21 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:07:21 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [48/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3064 (0.3064)	loss 1.1175 (1.1175)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [48/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1562 (0.1849)	loss 0.9134 (1.1412)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:25 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [48/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1832 (0.1779)	loss 1.2073 (1.2090)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [48/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1599 (0.1756)	loss 1.2137 (1.1842)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:27 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 48 training takes 0:00:05
[2024-12-02 13:07:28 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:07:28 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:07:28 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:07:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [49/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3014 (0.3014)	loss 1.1293 (1.1293)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [49/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.2077 (0.1859)	loss 1.1128 (1.2068)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [49/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2239 (0.2077)	loss 1.0198 (1.1625)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [49/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1593 (0.2009)	loss 1.2172 (1.1699)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:35 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 49 training takes 0:00:06
[2024-12-02 13:07:35 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:07:35 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:07:35 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:07:36 swin_tiny_patch4_window7_224] (main.py 175): INFO Training time 0:06:19
[2024-12-02 13:14:11 swin_tiny_patch4_window7_224] (main.py 382): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 3.125e-06
  WEIGHT_DECAY: 0.05

[2024-12-02 13:14:11 swin_tiny_patch4_window7_224] (main.py 383): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 13:14:11 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:14:11 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 13:14:11 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 13:14:11 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 13:14:11 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:14:11 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:14:12 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][0/34]	eta 0:00:09 lr 0.000003	 wd 0.0500	time 0.2794 (0.2794)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1583 (0.1794)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:15 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1692 (0.1700)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2440 (0.1757)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:17 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 13:14:19 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:14:19 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:14:19 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:14:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][0/34]	eta 0:00:17 lr 0.000003	 wd 0.0500	time 0.5050 (0.5050)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:21 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1792 (0.2257)	loss 1.2106 (1.1857)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1714 (0.2015)	loss 1.3177 (1.1705)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:25 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1703 (0.1928)	loss 1.0078 (1.1956)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:25 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 1 training takes 0:00:06
[2024-12-02 13:14:26 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:14:26 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:14:26 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:14:27 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3452 (0.3452)	loss 0.9030 (0.9030)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1729 (0.2001)	loss 1.3133 (1.1674)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2139 (0.1849)	loss 1.1163 (1.1561)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2363 (0.2010)	loss 1.3294 (1.1946)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:33 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 2 training takes 0:00:06
[2024-12-02 13:14:34 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:14:34 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:14:34 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:14:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3061 (0.3061)	loss 1.2180 (1.2180)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1725 (0.1848)	loss 0.8115 (1.1970)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1628 (0.1789)	loss 1.2076 (1.2151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1727 (0.1749)	loss 1.2020 (1.1984)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:40 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 3 training takes 0:00:05
[2024-12-02 13:14:41 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:14:41 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:14:41 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:14:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3335 (0.3335)	loss 1.4127 (1.4127)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1699 (0.1952)	loss 1.1205 (1.1524)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2457 (0.2038)	loss 1.4133 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1773 (0.2093)	loss 1.0023 (1.1951)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:48 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 4 training takes 0:00:07
[2024-12-02 13:14:49 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:14:49 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:14:49 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:14:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3062 (0.3062)	loss 1.0050 (1.0050)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1605 (0.1928)	loss 1.3082 (1.1669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1599 (0.1789)	loss 1.4345 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1729 (0.1748)	loss 1.1244 (1.1977)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:55 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 5 training takes 0:00:06
[2024-12-02 13:14:56 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:14:56 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:14:56 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:14:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3397 (0.3397)	loss 1.2188 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:59 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.2340 (0.2398)	loss 0.8230 (1.1925)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2328 (0.2385)	loss 1.2182 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1607 (0.2199)	loss 1.2178 (1.1813)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:03 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 6 training takes 0:00:07
[2024-12-02 13:15:04 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:15:04 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:15:04 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:15:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3451 (0.3451)	loss 1.0111 (1.0111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1612 (0.1871)	loss 1.0072 (1.1654)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:08 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1805 (0.1842)	loss 0.9054 (1.1399)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1643 (0.1787)	loss 1.2147 (1.1798)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:10 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 7 training takes 0:00:06
[2024-12-02 13:15:11 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:15:11 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:15:11 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:15:12 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][0/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4225 (0.4225)	loss 1.1182 (1.1182)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:14 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2263 (0.2680)	loss 1.0214 (1.2186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1582 (0.2209)	loss 1.2093 (1.2085)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1864 (0.2027)	loss 1.0152 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:18 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 8 training takes 0:00:06
[2024-12-02 13:15:19 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:15:19 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:15:19 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:15:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3071 (0.3071)	loss 1.0264 (1.0264)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:21 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1626 (0.1901)	loss 1.3252 (1.1444)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1620 (0.1759)	loss 1.5173 (1.1804)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1875 (0.1728)	loss 1.5330 (1.1794)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:25 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 9 training takes 0:00:06
[2024-12-02 13:15:27 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:15:27 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:15:27 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:15:27 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][0/34]	eta 0:00:17 lr 0.000003	 wd 0.0500	time 0.5040 (0.5040)	loss 1.3284 (1.3284)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:29 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1581 (0.2222)	loss 1.1036 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:31 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1566 (0.1971)	loss 1.2124 (1.1887)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1712 (0.1881)	loss 1.1163 (1.1807)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:33 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 10 training takes 0:00:06
[2024-12-02 13:15:34 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:15:34 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:15:34 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:15:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3440 (0.3440)	loss 1.4163 (1.4163)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1718 (0.1956)	loss 0.8097 (1.2118)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1771 (0.1817)	loss 1.3154 (1.2331)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2620 (0.1991)	loss 0.7169 (1.1948)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:41 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 11 training takes 0:00:06
[2024-12-02 13:15:42 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:15:42 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:15:42 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:15:42 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][0/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4294 (0.4294)	loss 1.1152 (1.1152)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1723 (0.1993)	loss 1.3062 (1.2064)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1837 (0.1843)	loss 1.0982 (1.2008)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1609 (0.1786)	loss 1.4206 (1.1763)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:48 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 12 training takes 0:00:06
[2024-12-02 13:15:49 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:15:49 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:15:49 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:15:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3680 (0.3680)	loss 1.2212 (1.2212)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1578 (0.1885)	loss 1.2048 (1.1112)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2403 (0.2069)	loss 1.3212 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1698 (0.2118)	loss 1.3129 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:56 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 13 training takes 0:00:07
[2024-12-02 13:15:57 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:15:57 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:15:57 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:15:57 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3484 (0.3484)	loss 1.3150 (1.3150)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:59 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1611 (0.2003)	loss 0.9079 (1.0414)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1658 (0.1832)	loss 1.5214 (1.1916)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1594 (0.1802)	loss 1.2292 (1.1842)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:03 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 14 training takes 0:00:06
[2024-12-02 13:16:04 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:16:04 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:16:04 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:16:04 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3717 (0.3717)	loss 0.8971 (0.8971)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.2322 (0.2467)	loss 1.4212 (1.1306)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1739 (0.2371)	loss 1.3204 (1.1848)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:11 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1753 (0.2168)	loss 1.3373 (1.1890)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:11 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 15 training takes 0:00:07
[2024-12-02 13:16:12 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:16:12 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:16:12 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:16:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3337 (0.3337)	loss 1.0005 (1.0005)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:14 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1663 (0.1976)	loss 1.2136 (1.1193)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1678 (0.1854)	loss 0.8986 (1.1694)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1788 (0.1806)	loss 1.3288 (1.1791)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:18 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 16 training takes 0:00:06
[2024-12-02 13:16:20 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:16:20 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:16:20 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:16:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.4050 (0.4050)	loss 1.4139 (1.4139)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.1694 (0.2513)	loss 1.3061 (1.2603)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1746 (0.2158)	loss 1.2102 (1.1890)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1581 (0.2027)	loss 1.0017 (1.1820)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:27 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 17 training takes 0:00:06
[2024-12-02 13:16:28 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:16:28 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:16:28 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:16:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3484 (0.3484)	loss 1.3049 (1.3049)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1540 (0.1895)	loss 1.1154 (1.1879)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:31 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1698 (0.1786)	loss 1.4091 (1.1868)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:33 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2317 (0.1898)	loss 1.0122 (1.1849)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:34 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 18 training takes 0:00:06
[2024-12-02 13:16:35 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:16:35 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:16:35 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:16:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3040 (0.3040)	loss 1.0286 (1.0286)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1708 (0.1881)	loss 1.1265 (1.2362)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1820 (0.1763)	loss 0.9085 (1.1835)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1700 (0.1744)	loss 1.2118 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:41 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 19 training takes 0:00:05
[2024-12-02 13:16:42 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:16:42 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:16:42 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:16:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3250 (0.3250)	loss 1.3092 (1.3092)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1770 (0.1843)	loss 1.3186 (1.2343)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2467 (0.1846)	loss 0.9077 (1.2009)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2305 (0.2052)	loss 1.1030 (1.2027)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:49 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 20 training takes 0:00:06
[2024-12-02 13:16:50 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:16:50 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:16:50 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:16:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3517 (0.3517)	loss 1.0226 (1.0226)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1637 (0.1994)	loss 1.2127 (1.1962)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1687 (0.1859)	loss 1.6450 (1.1826)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1703 (0.1845)	loss 1.4221 (1.1872)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:57 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 21 training takes 0:00:06
[2024-12-02 13:16:58 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:16:58 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:16:58 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:16:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3124 (0.3124)	loss 1.4136 (1.4136)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.2546 (0.2235)	loss 1.1175 (1.1990)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:02 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2179 (0.2322)	loss 1.4164 (1.2163)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:04 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1784 (0.2206)	loss 1.3064 (1.1859)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:05 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 22 training takes 0:00:07
[2024-12-02 13:17:06 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:17:06 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:17:06 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:17:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3434 (0.3434)	loss 1.1186 (1.1186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:08 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1860 (0.2076)	loss 0.8045 (1.1530)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1706 (0.1923)	loss 1.4216 (1.1972)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:12 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1692 (0.1843)	loss 1.1113 (1.1729)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:12 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 23 training takes 0:00:06
[2024-12-02 13:17:14 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:17:14 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:17:14 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:17:14 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][0/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4310 (0.4310)	loss 1.2105 (1.2105)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1696 (0.2402)	loss 1.1162 (1.1744)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1815 (0.2111)	loss 1.2089 (1.1896)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1743 (0.1991)	loss 1.3081 (1.2048)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:20 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 24 training takes 0:00:06
[2024-12-02 13:17:21 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:17:21 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:17:21 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:17:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3488 (0.3488)	loss 1.2229 (1.2229)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1716 (0.1941)	loss 1.5144 (1.2567)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:25 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1776 (0.1873)	loss 1.1144 (1.1926)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2656 (0.2055)	loss 1.3066 (1.1866)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:29 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 25 training takes 0:00:07
[2024-12-02 13:17:30 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:17:30 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:17:30 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:17:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3514 (0.3514)	loss 1.3199 (1.3199)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1589 (0.1872)	loss 1.0294 (1.1535)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1631 (0.1851)	loss 1.2143 (1.1770)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:35 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1573 (0.1775)	loss 1.0025 (1.1751)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:36 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 26 training takes 0:00:06
[2024-12-02 13:17:37 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:17:37 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:17:37 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:17:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3371 (0.3371)	loss 1.4119 (1.4119)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1586 (0.1911)	loss 1.5333 (1.1610)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2580 (0.2125)	loss 1.4040 (1.1913)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1565 (0.2112)	loss 1.4108 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:44 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 27 training takes 0:00:07
[2024-12-02 13:17:45 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:17:45 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:17:45 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:17:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3292 (0.3292)	loss 1.3144 (1.3144)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1591 (0.1877)	loss 1.2006 (1.1132)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1643 (0.1768)	loss 1.4167 (1.1531)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1956 (0.1761)	loss 1.1021 (1.1701)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:51 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 28 training takes 0:00:06
[2024-12-02 13:17:52 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:17:52 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:17:52 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:17:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3650 (0.3650)	loss 1.3227 (1.3227)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:55 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2393 (0.2638)	loss 1.0086 (1.2451)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:57 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1812 (0.2424)	loss 1.0040 (1.2303)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:59 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1669 (0.2232)	loss 1.2243 (1.2024)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:59 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 29 training takes 0:00:07
[2024-12-02 13:18:00 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:18:00 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:18:00 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:18:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3748 (0.3748)	loss 1.1026 (1.1026)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.2140 (0.2174)	loss 1.1117 (1.1223)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:04 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1627 (0.1979)	loss 1.1088 (1.1668)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1827 (0.1909)	loss 1.4201 (1.1742)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:07 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 30 training takes 0:00:06
[2024-12-02 13:18:08 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:18:08 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:18:08 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:18:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/50][0/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4306 (0.4306)	loss 1.3124 (1.3124)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:11 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1817 (0.2314)	loss 1.3106 (1.2149)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1767 (0.2071)	loss 1.2093 (1.1914)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:14 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1684 (0.1936)	loss 0.7156 (1.1797)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:15 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 31 training takes 0:00:06
[2024-12-02 13:18:16 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:18:16 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:18:16 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:18:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3138 (0.3138)	loss 1.0058 (1.0058)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1795 (0.1918)	loss 1.0125 (1.2167)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2277 (0.1854)	loss 1.0123 (1.1377)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2544 (0.2078)	loss 1.4166 (1.1854)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:23 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 32 training takes 0:00:07
[2024-12-02 13:18:24 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:18:24 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:18:24 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:18:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [33/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3462 (0.3462)	loss 1.1313 (1.1313)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [33/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1618 (0.1976)	loss 0.6049 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [33/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1734 (0.1855)	loss 1.3294 (1.1954)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:29 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [33/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1740 (0.1801)	loss 1.0163 (1.1927)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:30 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 33 training takes 0:00:06
[2024-12-02 13:18:31 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:18:31 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:18:31 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:18:31 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [34/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3139 (0.3139)	loss 1.1084 (1.1084)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:33 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [34/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.2489 (0.2040)	loss 1.3212 (1.1620)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [34/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2388 (0.2250)	loss 1.3186 (1.1931)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [34/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1708 (0.2085)	loss 0.9284 (1.1845)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:38 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 34 training takes 0:00:07
[2024-12-02 13:18:39 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:18:39 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:18:39 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:18:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [35/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3530 (0.3530)	loss 1.1111 (1.1111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [35/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1608 (0.1939)	loss 0.8124 (1.1889)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [35/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1598 (0.1785)	loss 0.9057 (1.1603)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [35/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1739 (0.1772)	loss 1.6174 (1.1775)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:45 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 35 training takes 0:00:06
[2024-12-02 13:18:46 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:18:46 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:18:46 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:18:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [36/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.3867 (0.3867)	loss 1.4135 (1.4135)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [36/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2241 (0.2614)	loss 1.3019 (1.1401)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [36/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1741 (0.2280)	loss 1.1178 (1.1869)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [36/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1565 (0.2070)	loss 1.0131 (1.1773)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:53 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 36 training takes 0:00:06
[2024-12-02 13:18:54 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:18:54 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:18:54 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:18:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3275 (0.3275)	loss 1.3151 (1.3151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1702 (0.1947)	loss 1.1040 (1.2517)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:57 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1637 (0.1800)	loss 0.7092 (1.2056)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:59 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1750 (0.1744)	loss 1.1129 (1.1746)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:00 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 37 training takes 0:00:06
[2024-12-02 13:19:01 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:19:01 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:19:01 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:19:02 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [38/50][0/34]	eta 0:00:16 lr 0.000003	 wd 0.0500	time 0.4940 (0.4940)	loss 0.9028 (0.9028)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:04 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [38/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1749 (0.2350)	loss 1.2352 (1.1704)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [38/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1706 (0.2082)	loss 1.4207 (1.1830)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [38/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1797 (0.1984)	loss 1.0141 (1.1747)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:08 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 38 training takes 0:00:06
[2024-12-02 13:19:09 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:19:09 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:19:09 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:19:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [39/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3104 (0.3104)	loss 0.9233 (0.9233)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:11 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [39/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1621 (0.1902)	loss 1.3170 (1.2329)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [39/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1666 (0.1772)	loss 1.3231 (1.2046)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:15 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [39/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2489 (0.1929)	loss 0.9093 (1.2043)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:16 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 39 training takes 0:00:06
[2024-12-02 13:19:17 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:19:17 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:19:17 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:19:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [40/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3223 (0.3223)	loss 1.1246 (1.1246)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [40/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1768 (0.1943)	loss 1.2323 (1.1760)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:21 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [40/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1804 (0.1858)	loss 1.1203 (1.2085)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [40/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1659 (0.1821)	loss 1.0112 (1.2018)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:23 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 40 training takes 0:00:06
[2024-12-02 13:19:24 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:19:24 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:19:24 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:19:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [41/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3488 (0.3488)	loss 1.0274 (1.0274)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [41/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.2150 (0.2079)	loss 1.1096 (1.2295)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:29 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [41/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2664 (0.2265)	loss 1.1239 (1.2008)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [41/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1728 (0.2149)	loss 1.2138 (1.2016)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:31 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 41 training takes 0:00:07
[2024-12-02 13:19:32 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:19:32 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:19:32 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:19:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [42/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3030 (0.3030)	loss 0.9176 (0.9176)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [42/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1707 (0.1927)	loss 1.3111 (1.1131)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [42/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1599 (0.1816)	loss 1.1106 (1.1564)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [42/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1612 (0.1754)	loss 1.0226 (1.1715)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:38 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 42 training takes 0:00:05
[2024-12-02 13:19:39 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:19:39 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:19:39 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:19:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [43/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3377 (0.3377)	loss 1.3139 (1.3139)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:42 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [43/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2663 (0.2541)	loss 0.7032 (1.1111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [43/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1588 (0.2266)	loss 1.0167 (1.1435)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [43/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1892 (0.2096)	loss 1.3263 (1.1784)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:46 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 43 training takes 0:00:07
[2024-12-02 13:19:47 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:19:47 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:19:47 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:19:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [44/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3551 (0.3551)	loss 1.2082 (1.2082)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [44/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1669 (0.1973)	loss 1.1141 (1.1958)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [44/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1739 (0.1869)	loss 1.0141 (1.2047)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [44/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2021 (0.1855)	loss 1.4171 (1.2017)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:53 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 44 training takes 0:00:06
[2024-12-02 13:19:55 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:19:55 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:19:55 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:19:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [45/50][0/34]	eta 0:00:16 lr 0.000003	 wd 0.0500	time 0.4885 (0.4885)	loss 1.0091 (1.0091)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [45/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1762 (0.2262)	loss 1.0239 (1.1648)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:59 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [45/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1587 (0.1992)	loss 1.0019 (1.1559)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [45/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1689 (0.1911)	loss 1.2294 (1.1755)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:02 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 45 training takes 0:00:06
[2024-12-02 13:20:03 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:20:03 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:20:03 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:20:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [46/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3364 (0.3364)	loss 1.0175 (1.0175)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:23 swin_tiny_patch4_window7_224] (main.py 382): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 3.125e-06
  WEIGHT_DECAY: 0.05

[2024-12-02 13:20:23 swin_tiny_patch4_window7_224] (main.py 383): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 13:20:23 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:20:23 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 13:20:23 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 13:20:23 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 13:20:23 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:20:23 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:20:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][0/34]	eta 0:00:09 lr 0.000003	 wd 0.0500	time 0.2934 (0.2934)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:25 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1582 (0.1858)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:27 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1733 (0.1815)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1675 (0.1787)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:29 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 13:20:30 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:20:30 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:20:30 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:20:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3160 (0.3160)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.2331 (0.2075)	loss 1.2106 (1.1857)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2287 (0.2193)	loss 1.3177 (1.1705)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1707 (0.2048)	loss 1.0078 (1.1956)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:37 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 1 training takes 0:00:06
[2024-12-02 13:20:38 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:20:38 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:20:38 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:20:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3552 (0.3552)	loss 0.9030 (0.9030)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1702 (0.1939)	loss 1.3133 (1.1674)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:42 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1627 (0.1846)	loss 1.1163 (1.1561)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1932 (0.1806)	loss 1.3294 (1.1946)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:44 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 2 training takes 0:00:06
[2024-12-02 13:20:45 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:20:45 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:20:45 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:20:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][0/34]	eta 0:00:16 lr 0.000003	 wd 0.0500	time 0.4892 (0.4892)	loss 1.2180 (1.2180)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:23 swin_tiny_patch4_window7_224] (main.py 382): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 3.125e-06
  WEIGHT_DECAY: 0.05

[2024-12-02 13:22:23 swin_tiny_patch4_window7_224] (main.py 383): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 13:22:23 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:22:23 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 13:22:23 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 13:22:23 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:22:23 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:22:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.3870 (0.3870)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:25 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1559 (0.1870)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1912 (0.1775)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1765 (0.1796)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:29 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 13:22:30 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:22:30 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:22:30 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:22:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3404 (0.3404)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1743 (0.1920)	loss 1.2106 (1.1857)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2502 (0.1908)	loss 1.3177 (1.1705)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2335 (0.2098)	loss 1.0078 (1.1956)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:37 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 1 training takes 0:00:07
[2024-12-02 13:22:38 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:22:38 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:22:38 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:22:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3178 (0.3178)	loss 0.9030 (0.9030)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1862 (0.2023)	loss 1.3133 (1.1674)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:42 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1844 (0.1897)	loss 1.1163 (1.1561)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1741 (0.1855)	loss 1.3294 (1.1946)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:44 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 2 training takes 0:00:06
[2024-12-02 13:22:45 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:22:45 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:22:45 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:22:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3158 (0.3158)	loss 1.2180 (1.2180)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.2259 (0.2072)	loss 0.8115 (1.1970)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2386 (0.2213)	loss 1.2076 (1.2151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1558 (0.2028)	loss 1.2020 (1.1984)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:52 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 3 training takes 0:00:06
[2024-12-02 13:22:53 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:22:53 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:22:53 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:22:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3458 (0.3458)	loss 1.4127 (1.4127)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:55 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1710 (0.1902)	loss 1.1205 (1.1524)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1862 (0.1835)	loss 1.4133 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1596 (0.1801)	loss 1.0023 (1.1951)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:59 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 4 training takes 0:00:06
[2024-12-02 13:23:00 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:23:00 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:23:00 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:23:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][0/34]	eta 0:00:15 lr 0.000003	 wd 0.0500	time 0.4617 (0.4617)	loss 1.0050 (1.0050)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2333 (0.2822)	loss 1.3082 (1.1669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1564 (0.2282)	loss 1.4345 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1676 (0.2095)	loss 1.1244 (1.1977)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:07 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 5 training takes 0:00:07
[2024-12-02 13:23:08 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:23:08 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:23:08 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:23:08 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3254 (0.3254)	loss 1.2188 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1653 (0.1905)	loss 0.8230 (1.1925)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:12 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1726 (0.1830)	loss 1.2182 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2155 (0.1792)	loss 1.2178 (1.1813)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:14 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 6 training takes 0:00:06
[2024-12-02 13:23:15 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:23:15 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:23:15 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:23:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][0/34]	eta 0:00:16 lr 0.000003	 wd 0.0500	time 0.4800 (0.4800)	loss 1.0111 (1.0111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1566 (0.2091)	loss 1.0072 (1.1654)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1615 (0.1861)	loss 0.9054 (1.1399)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:21 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1579 (0.1775)	loss 1.2147 (1.1798)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:21 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 7 training takes 0:00:06
[2024-12-02 13:23:22 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:23:22 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:23:22 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:23:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3218 (0.3218)	loss 1.1182 (1.1182)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1788 (0.1899)	loss 1.0214 (1.2186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1685 (0.1796)	loss 1.2093 (1.2085)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2387 (0.1957)	loss 1.0152 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:29 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 8 training takes 0:00:06
[2024-12-02 13:23:30 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:23:30 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:23:30 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:23:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3022 (0.3022)	loss 1.0264 (1.0264)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1594 (0.1818)	loss 1.3252 (1.1444)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1685 (0.1727)	loss 1.5173 (1.1804)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:35 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1718 (0.1710)	loss 1.5330 (1.1794)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:36 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 9 training takes 0:00:05
[2024-12-02 13:23:37 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:23:37 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:23:37 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:23:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3398 (0.3398)	loss 1.3284 (1.3284)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1793 (0.1941)	loss 1.1036 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2488 (0.2077)	loss 1.2124 (1.1887)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1606 (0.2061)	loss 1.1163 (1.1807)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:44 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 10 training takes 0:00:06
[2024-12-02 13:23:45 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:23:45 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:23:45 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:23:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3026 (0.3026)	loss 1.4163 (1.4163)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1727 (0.1905)	loss 0.8097 (1.2118)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1661 (0.1819)	loss 1.3154 (1.2331)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1848 (0.1834)	loss 0.7169 (1.1948)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:51 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 11 training takes 0:00:06
[2024-12-02 13:23:53 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:23:53 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:23:53 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:23:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.4046 (0.4046)	loss 1.1152 (1.1152)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:24:38 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:24:38 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 13:24:38 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 13:24:38 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:24:38 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:24:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][0/34]	eta 0:00:09 lr 0.000003	 wd 0.0500	time 0.2687 (0.2687)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:24:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1709 (0.1824)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:24:42 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2567 (0.1858)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:24:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2644 (0.2041)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:24:45 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:07
[2024-12-02 13:24:46 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:24:46 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:24:46 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:24:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3354 (0.3354)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:24:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1870 (0.2003)	loss 1.2106 (1.1857)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:24:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1820 (0.1899)	loss 1.3177 (1.1705)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:24:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1840 (0.1868)	loss 1.0078 (1.1956)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:24:53 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 1 training takes 0:00:06
[2024-12-02 13:24:54 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:24:54 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:24:54 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:24:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3298 (0.3298)	loss 0.9030 (0.9030)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:24:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.2138 (0.2109)	loss 1.3133 (1.1674)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:24:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2340 (0.2260)	loss 1.1163 (1.1561)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1758 (0.2134)	loss 1.3294 (1.1946)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:01 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 2 training takes 0:00:07
[2024-12-02 13:25:02 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:25:02 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:25:02 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:25:02 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3153 (0.3153)	loss 1.2180 (1.2180)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:04 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1673 (0.1879)	loss 0.8115 (1.1970)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1814 (0.1815)	loss 1.2076 (1.2151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1651 (0.1769)	loss 1.2020 (1.1984)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:08 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 3 training takes 0:00:06
[2024-12-02 13:25:09 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:25:09 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:25:09 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:25:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3129 (0.3129)	loss 1.4127 (1.4127)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:11 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2596 (0.2643)	loss 1.1205 (1.1524)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1794 (0.2333)	loss 1.4133 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:15 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1670 (0.2119)	loss 1.0023 (1.1951)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:16 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 4 training takes 0:00:07
[2024-12-02 13:25:17 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:25:17 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:25:17 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:25:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3062 (0.3062)	loss 1.0050 (1.0050)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1634 (0.1837)	loss 1.3082 (1.1669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1628 (0.1746)	loss 1.4345 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1784 (0.1739)	loss 1.1244 (1.1977)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:22 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 5 training takes 0:00:05
[2024-12-02 13:25:24 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:25:24 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:25:24 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:25:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][0/34]	eta 0:00:15 lr 0.000003	 wd 0.0500	time 0.4642 (0.4642)	loss 1.2188 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:27 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1740 (0.2445)	loss 0.8230 (1.1925)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1815 (0.2152)	loss 1.2182 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1709 (0.2045)	loss 1.2178 (1.1813)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:31 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 6 training takes 0:00:06
[2024-12-02 13:25:32 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:25:32 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:25:32 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:25:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3468 (0.3468)	loss 1.0111 (1.0111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1672 (0.1967)	loss 1.0072 (1.1654)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1775 (0.1885)	loss 0.9054 (1.1399)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2577 (0.2101)	loss 1.2147 (1.1798)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:39 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 7 training takes 0:00:07
[2024-12-02 13:25:40 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:25:40 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:25:40 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:25:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3538 (0.3538)	loss 1.1182 (1.1182)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:42 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1674 (0.2012)	loss 1.0214 (1.2186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1820 (0.1902)	loss 1.2093 (1.2085)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1832 (0.1889)	loss 1.0152 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:46 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 8 training takes 0:00:06
[2024-12-02 13:25:47 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:25:47 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:25:47 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:25:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3755 (0.3755)	loss 1.0264 (1.0264)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.2259 (0.2208)	loss 1.3252 (1.1444)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2529 (0.2310)	loss 1.5173 (1.1804)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1859 (0.2186)	loss 1.5330 (1.1794)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:55 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 9 training takes 0:00:07
[2024-12-02 13:25:56 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:25:56 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:25:56 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:25:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3436 (0.3436)	loss 1.3284 (1.3284)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1830 (0.2014)	loss 1.1036 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:26:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1660 (0.1898)	loss 1.2124 (1.1887)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:26:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1943 (0.1867)	loss 1.1163 (1.1807)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:26:02 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 10 training takes 0:00:06
[2024-12-02 13:26:03 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:26:03 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:26:03 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:26:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][0/34]	eta 0:00:16 lr 0.000003	 wd 0.0500	time 0.4960 (0.4960)	loss 1.4163 (1.4163)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:26:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2228 (0.2891)	loss 0.8097 (1.2118)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:26:08 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1844 (0.2353)	loss 1.3154 (1.2331)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:26:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1683 (0.2139)	loss 0.7169 (1.1948)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:31:19 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:31:19 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 13:31:19 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 13:31:19 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:31:19 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:33:10 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:33:10 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 13:33:10 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 13:33:10 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:33:10 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:33:11 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [0/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.3889 (0.3889)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:13 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [0/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2168 (0.2603)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:15 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [0/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1752 (0.2279)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:17 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1789 (0.2100)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:17 swin_tiny_patch4_window7_224] (main.py 257): INFO EPOCH 0 training takes 0:00:07
[2024-12-02 13:33:18 swin_tiny_patch4_window7_224] (main.py 306): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:33:18 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:33:18 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:33:19 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [1/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3546 (0.3546)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:20 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [1/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1741 (0.1969)	loss 1.2106 (1.1857)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:22 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [1/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1597 (0.1852)	loss 1.3177 (1.1705)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:24 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1672 (0.1817)	loss 1.0078 (1.1956)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:25 swin_tiny_patch4_window7_224] (main.py 257): INFO EPOCH 1 training takes 0:00:06
[2024-12-02 13:33:26 swin_tiny_patch4_window7_224] (main.py 306): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:33:26 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:33:26 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:33:27 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [2/50][0/34]	eta 0:00:16 lr 0.000003	 wd 0.0500	time 0.4936 (0.4936)	loss 0.9030 (0.9030)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:29 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [2/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1680 (0.2348)	loss 1.3133 (1.1674)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:30 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [2/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1653 (0.2034)	loss 1.1163 (1.1561)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:32 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1655 (0.1943)	loss 1.3294 (1.1946)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:33 swin_tiny_patch4_window7_224] (main.py 257): INFO EPOCH 2 training takes 0:00:06
[2024-12-02 13:33:34 swin_tiny_patch4_window7_224] (main.py 306): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:33:34 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:33:34 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:33:34 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [3/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3426 (0.3426)	loss 1.2180 (1.2180)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:36 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [3/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1686 (0.2157)	loss 0.8115 (1.1970)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:38 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [3/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2353 (0.2024)	loss 1.2076 (1.2151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:40 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [3/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2237 (0.2156)	loss 1.2020 (1.1984)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:41 swin_tiny_patch4_window7_224] (main.py 257): INFO EPOCH 3 training takes 0:00:07
[2024-12-02 13:33:42 swin_tiny_patch4_window7_224] (main.py 306): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:33:42 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:33:42 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:33:42 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [4/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3715 (0.3715)	loss 1.4127 (1.4127)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:50 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:33:50 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 13:33:50 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 13:33:50 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:33:50 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:33:51 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [0/50][0/34]	eta 0:00:09 lr 0.000003	 wd 0.0500	time 0.2737 (0.2737)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:53 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [0/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.2182 (0.2387)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:55 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [0/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1783 (0.2264)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:57 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1726 (0.2112)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:57 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 0 training takes 0:00:07
[2024-12-02 13:33:58 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:33:58 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:33:58 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:33:59 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [1/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3098 (0.3098)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:00 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [1/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1759 (0.1892)	loss 1.2106 (1.1857)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:02 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [1/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1599 (0.1777)	loss 1.3177 (1.1705)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:04 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1616 (0.1761)	loss 1.0078 (1.1956)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:04 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 1 training takes 0:00:06
[2024-12-02 13:34:06 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:34:06 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:34:06 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:34:06 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [2/50][0/34]	eta 0:00:16 lr 0.000003	 wd 0.0500	time 0.4722 (0.4722)	loss 0.9030 (0.9030)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:08 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [2/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1695 (0.2472)	loss 1.3133 (1.1674)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:10 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [2/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1689 (0.2133)	loss 1.1163 (1.1561)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:12 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1709 (0.2012)	loss 1.3294 (1.1946)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:12 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 2 training takes 0:00:06
[2024-12-02 13:34:13 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:34:13 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:34:13 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:34:14 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [3/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3240 (0.3240)	loss 1.2180 (1.2180)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:15 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [3/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1675 (0.1919)	loss 0.8115 (1.1970)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:17 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [3/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1776 (0.1868)	loss 1.2076 (1.2151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:20 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [3/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2403 (0.2040)	loss 1.2020 (1.1984)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:20 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 3 training takes 0:00:07
[2024-12-02 13:34:21 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:34:21 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:34:21 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:34:22 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [4/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3389 (0.3389)	loss 1.4127 (1.4127)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:24 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [4/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1763 (0.1993)	loss 1.1205 (1.1524)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:25 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [4/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1864 (0.1901)	loss 1.4133 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:27 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [4/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1728 (0.1836)	loss 1.0023 (1.1951)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:28 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 4 training takes 0:00:06
[2024-12-02 13:34:29 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:34:29 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:34:29 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:34:29 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [5/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3375 (0.3375)	loss 1.0050 (1.0050)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:31 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [5/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.2148 (0.2106)	loss 1.3082 (1.1669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:34 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [5/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2552 (0.2303)	loss 1.4345 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:35 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [5/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1716 (0.2184)	loss 1.1244 (1.1977)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:36 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 5 training takes 0:00:07
[2024-12-02 13:34:37 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:34:37 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:34:37 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:34:37 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [6/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3145 (0.3145)	loss 1.2188 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:39 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [6/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1802 (0.1949)	loss 0.8230 (1.1925)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:41 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [6/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1824 (0.1875)	loss 1.2182 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:43 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [6/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1747 (0.1849)	loss 1.2178 (1.1813)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:43 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 6 training takes 0:00:06
[2024-12-02 13:34:44 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:34:44 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:34:44 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:34:45 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [7/50][0/34]	eta 0:00:16 lr 0.000003	 wd 0.0500	time 0.4918 (0.4918)	loss 1.0111 (1.0111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:47 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [7/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2446 (0.2808)	loss 1.0072 (1.1654)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:49 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [7/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1803 (0.2367)	loss 0.9054 (1.1399)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:51 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [7/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1766 (0.2177)	loss 1.2147 (1.1798)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:52 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 7 training takes 0:00:07
[2024-12-02 13:34:53 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:34:53 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:34:53 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:34:53 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [8/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3237 (0.3237)	loss 1.1182 (1.1182)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:55 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [8/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1768 (0.1885)	loss 1.0214 (1.2186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:56 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [8/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1578 (0.1813)	loss 1.2093 (1.2085)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:58 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [8/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2160 (0.1828)	loss 1.0152 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:59 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 8 training takes 0:00:06
[2024-12-02 13:35:00 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:35:00 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:35:00 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:35:01 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [9/50][0/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4408 (0.4408)	loss 1.0264 (1.0264)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:35:03 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [9/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1608 (0.2147)	loss 1.3252 (1.1444)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:35:04 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [9/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1757 (0.1944)	loss 1.5173 (1.1804)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:35:06 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [9/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1899 (0.1899)	loss 1.5330 (1.1794)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:35:07 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 9 training takes 0:00:06
[2024-12-02 13:35:08 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:35:08 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:35:08 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:35:08 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [10/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3159 (0.3159)	loss 1.3284 (1.3284)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:35:10 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [10/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1745 (0.1910)	loss 1.1036 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:36:04 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:36:04 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 13:36:04 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 13:36:04 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:36:04 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:36:04 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [0/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3095 (0.3095)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:36:06 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [0/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1644 (0.1904)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:37:18 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:37:18 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 13:37:18 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 13:37:18 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:37:18 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:37:19 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [0/50][0/34]	eta 0:00:25 lr 0.000003	 wd 0.0500	time 0.7443 (0.7443)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:37:25 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [0/50][10/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.6175 (0.6094)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:37:31 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [0/50][20/34]	eta 0:00:08 lr 0.000003	 wd 0.0500	time 0.5018 (0.6023)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:37:37 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [0/50][30/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.6188 (0.5961)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:37:39 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 0 training takes 0:00:20
[2024-12-02 13:37:40 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:37:40 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:37:40 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:37:41 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [1/50][0/34]	eta 0:00:28 lr 0.000003	 wd 0.0500	time 0.8325 (0.8325)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:37:47 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [1/50][10/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.6303 (0.6235)	loss 1.2106 (1.1857)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:37:53 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [1/50][20/34]	eta 0:00:08 lr 0.000003	 wd 0.0500	time 0.6245 (0.6123)	loss 1.3177 (1.1705)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:37:59 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [1/50][30/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.6150 (0.6033)	loss 1.0078 (1.1956)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:38:01 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 1 training takes 0:00:20
[2024-12-02 13:38:01 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:38:01 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:38:01 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:38:02 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [2/50][0/34]	eta 0:00:23 lr 0.000003	 wd 0.0500	time 0.6797 (0.6797)	loss 0.9030 (0.9030)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:38:08 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [2/50][10/34]	eta 0:00:15 lr 0.000003	 wd 0.0500	time 0.6137 (0.6335)	loss 1.3133 (1.1674)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:38:14 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [2/50][20/34]	eta 0:00:08 lr 0.000003	 wd 0.0500	time 0.5222 (0.6057)	loss 1.1163 (1.1561)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:38:20 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [2/50][30/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.6142 (0.6024)	loss 1.3294 (1.1946)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:38:22 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 2 training takes 0:00:20
[2024-12-02 13:38:23 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:38:23 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:38:23 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:38:24 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [3/50][0/34]	eta 0:00:24 lr 0.000003	 wd 0.0500	time 0.7196 (0.7196)	loss 1.2180 (1.2180)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:38:29 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [3/50][10/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.6168 (0.5962)	loss 0.8115 (1.1970)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:38:36 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [3/50][20/34]	eta 0:00:08 lr 0.000003	 wd 0.0500	time 0.5205 (0.6017)	loss 1.2076 (1.2151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:38:41 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [3/50][30/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.6135 (0.5895)	loss 1.2020 (1.1984)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:38:43 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 3 training takes 0:00:20
[2024-12-02 13:38:44 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:38:45 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:38:45 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:38:45 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [4/50][0/34]	eta 0:00:31 lr 0.000003	 wd 0.0500	time 0.9320 (0.9320)	loss 1.4127 (1.4127)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:38:51 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [4/50][10/34]	eta 0:00:15 lr 0.000003	 wd 0.0500	time 0.5104 (0.6318)	loss 1.1205 (1.1524)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:38:57 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [4/50][20/34]	eta 0:00:08 lr 0.000003	 wd 0.0500	time 0.6083 (0.5854)	loss 1.4133 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:39:03 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [4/50][30/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.6158 (0.5951)	loss 1.0023 (1.1951)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:39:05 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 4 training takes 0:00:20
[2024-12-02 13:39:06 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:39:06 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:39:06 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:39:06 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [5/50][0/34]	eta 0:00:22 lr 0.000003	 wd 0.0500	time 0.6740 (0.6740)	loss 1.0050 (1.0050)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:39:12 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [5/50][10/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.5145 (0.6042)	loss 1.3082 (1.1669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:39:18 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [5/50][20/34]	eta 0:00:08 lr 0.000003	 wd 0.0500	time 0.6093 (0.5993)	loss 1.4345 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:39:24 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [5/50][30/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.7147 (0.6015)	loss 1.1244 (1.1977)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:39:26 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 5 training takes 0:00:20
[2024-12-02 13:39:27 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:39:27 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:39:27 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:39:28 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [6/50][0/34]	eta 0:00:25 lr 0.000003	 wd 0.0500	time 0.7548 (0.7548)	loss 1.2188 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:39:34 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [6/50][10/34]	eta 0:00:15 lr 0.000003	 wd 0.0500	time 0.6094 (0.6361)	loss 0.8230 (1.1925)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:39:40 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [6/50][20/34]	eta 0:00:08 lr 0.000003	 wd 0.0500	time 0.6140 (0.6222)	loss 1.2182 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:37 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:55:37 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 13:55:37 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 13:55:37 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:55:37 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:55:38 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][0/34]	eta 0:00:15 lr 0.000003	 wd 0.0500	time 0.4615 (0.4615)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:40 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2632 (0.2733)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:42 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1695 (0.2277)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:44 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1616 (0.2075)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:44 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 13:55:45 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:55:45 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:55:45 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:55:46 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3288 (0.3288)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:47 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1634 (0.1855)	loss 1.2106 (1.1857)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:49 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1579 (0.1758)	loss 1.3177 (1.1705)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:51 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1860 (0.1742)	loss 1.0078 (1.1956)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:51 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 1 training takes 0:00:06
[2024-12-02 13:55:53 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:55:53 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:55:53 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:55:53 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][0/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4226 (0.4226)	loss 0.9030 (0.9030)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:55 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1749 (0.2222)	loss 1.3133 (1.1674)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:57 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1773 (0.2008)	loss 1.1163 (1.1561)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:59 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1626 (0.1948)	loss 1.3294 (1.1946)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:59 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 2 training takes 0:00:06
[2024-12-02 13:56:00 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:56:00 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:56:00 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:56:00 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3254 (0.3254)	loss 1.2180 (1.2180)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:02 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1776 (0.2011)	loss 0.8115 (1.1970)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:04 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2386 (0.1937)	loss 1.2076 (1.2151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:07 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2340 (0.2105)	loss 1.2020 (1.1984)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:07 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 3 training takes 0:00:07
[2024-12-02 13:56:08 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:56:08 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:56:08 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:56:09 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3201 (0.3201)	loss 1.4127 (1.4127)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:10 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1659 (0.1869)	loss 1.1205 (1.1524)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:12 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1631 (0.1780)	loss 1.4133 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:14 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1825 (0.1752)	loss 1.0023 (1.1951)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:14 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 4 training takes 0:00:05
[2024-12-02 13:56:15 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:56:15 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:56:15 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:56:16 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3271 (0.3271)	loss 1.0050 (1.0050)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:17 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1799 (0.1881)	loss 1.3082 (1.1669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:20 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2458 (0.2077)	loss 1.4345 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:22 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1720 (0.2066)	loss 1.1244 (1.1977)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:22 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 5 training takes 0:00:06
[2024-12-02 13:56:23 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:56:23 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:56:23 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:56:24 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3445 (0.3445)	loss 1.2188 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:25 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1644 (0.1982)	loss 0.8230 (1.1925)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:27 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1680 (0.1829)	loss 1.2182 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:29 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1752 (0.1804)	loss 1.2178 (1.1813)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:29 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 6 training takes 0:00:06
[2024-12-02 13:56:30 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:56:30 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:56:30 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:56:31 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [7/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3110 (0.3110)	loss 1.0111 (1.0111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:33 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [7/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2811 (0.2615)	loss 1.0072 (1.1654)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:35 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [7/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1616 (0.2380)	loss 0.9054 (1.1399)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:37 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [7/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1628 (0.2142)	loss 1.2147 (1.1798)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:38 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 7 training takes 0:00:07
[2024-12-02 13:56:38 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:56:38 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:56:38 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:56:39 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [8/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3519 (0.3519)	loss 1.1182 (1.1182)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:41 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [8/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1724 (0.2020)	loss 1.0214 (1.2186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:43 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [8/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1786 (0.1945)	loss 1.2093 (1.2085)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:44 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [8/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1651 (0.1903)	loss 1.0152 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:45 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 8 training takes 0:00:06
[2024-12-02 13:56:46 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:56:46 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:56:46 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:56:47 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [9/50][0/34]	eta 0:00:16 lr 0.000003	 wd 0.0500	time 0.4733 (0.4733)	loss 1.0264 (1.0264)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:49 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [9/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1730 (0.2444)	loss 1.3252 (1.1444)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:51 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [9/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1744 (0.2105)	loss 1.5173 (1.1804)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:52 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [9/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1975 (0.1974)	loss 1.5330 (1.1794)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:53 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 9 training takes 0:00:06
[2024-12-02 13:56:54 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:56:54 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:56:54 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:56:54 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [10/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3596 (0.3596)	loss 1.3284 (1.3284)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:56 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [10/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1612 (0.2021)	loss 1.1036 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:58 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [10/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1667 (0.1925)	loss 1.2124 (1.1887)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:00 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [10/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2707 (0.2091)	loss 1.1163 (1.1807)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:01 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 10 training takes 0:00:07
[2024-12-02 13:57:02 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:57:02 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:57:02 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:57:03 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [11/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3376 (0.3376)	loss 1.4163 (1.4163)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:04 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [11/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1785 (0.1952)	loss 0.8097 (1.2118)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:06 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [11/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1807 (0.1904)	loss 1.3154 (1.2331)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:08 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [11/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1716 (0.1883)	loss 0.7169 (1.1948)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:09 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 11 training takes 0:00:06
[2024-12-02 13:57:09 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:57:09 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:57:09 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:57:10 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [12/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3064 (0.3064)	loss 1.1152 (1.1152)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:12 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [12/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1708 (0.1880)	loss 1.3062 (1.2064)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:14 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [12/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2238 (0.2175)	loss 1.0982 (1.2008)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:16 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [12/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1667 (0.2106)	loss 1.4206 (1.1763)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:17 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 12 training takes 0:00:07
[2024-12-02 13:57:17 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:57:17 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:57:17 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:57:18 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [13/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3056 (0.3056)	loss 1.2212 (1.2212)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:20 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [13/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1968 (0.1919)	loss 1.2048 (1.1112)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:21 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [13/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1855 (0.1854)	loss 1.3212 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:23 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [13/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1766 (0.1851)	loss 1.3129 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:24 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 13 training takes 0:00:06
[2024-12-02 13:57:25 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:57:25 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:57:25 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:57:25 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [14/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3514 (0.3514)	loss 1.3150 (1.3150)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:28 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [14/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2934 (0.2704)	loss 0.9079 (1.0414)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:30 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [14/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1775 (0.2465)	loss 1.5214 (1.1916)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:32 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [14/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1693 (0.2218)	loss 1.2292 (1.1842)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:32 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 14 training takes 0:00:07
[2024-12-02 13:57:33 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:57:33 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:57:33 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:57:33 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [15/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3184 (0.3184)	loss 0.8971 (0.8971)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:35 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [15/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1740 (0.1916)	loss 1.4212 (1.1306)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:58:02 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:58:02 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 932368
[2024-12-02 13:58:02 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.064430944
[2024-12-02 13:58:02 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:58:02 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:59:02 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:59:02 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 2084144
[2024-12-02 13:59:02 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.141317952
[2024-12-02 13:59:02 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:59:02 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:59:02 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][0/34]	eta 0:00:15 lr 0.000003	 wd 0.0500	time 0.4673 (0.4673)	loss 1.2547 (1.2547)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:05 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][10/34]	eta 0:00:07 lr 0.000003	 wd 0.0500	time 0.2908 (0.2917)	loss 1.0736 (1.0871)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:08 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2117 (0.2763)	loss 1.0678 (1.0528)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:10 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][30/34]	eta 0:00:01 lr 0.000003	 wd 0.0500	time 0.2140 (0.2527)	loss 1.1589 (1.0432)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:10 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 0 training takes 0:00:08
[2024-12-02 13:59:11 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:59:11 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:59:11 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:59:12 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][0/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4230 (0.4230)	loss 1.2463 (1.2463)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:14 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1957 (0.2423)	loss 1.0759 (1.1097)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:16 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2143 (0.2227)	loss 1.1593 (1.0530)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:19 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2794 (0.2338)	loss 1.0626 (1.0476)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:20 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 1 training takes 0:00:08
[2024-12-02 13:59:21 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:59:21 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:59:21 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:59:21 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3713 (0.3713)	loss 0.7966 (0.7966)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:24 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.2317 (0.2445)	loss 0.8903 (1.0130)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:26 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2164 (0.2294)	loss 0.7086 (1.0191)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:28 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1991 (0.2240)	loss 1.0663 (1.0413)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:29 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 2 training takes 0:00:07
[2024-12-02 13:59:30 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:59:30 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:59:30 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:59:30 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.3907 (0.3907)	loss 0.8912 (0.8912)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:33 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][10/34]	eta 0:00:07 lr 0.000003	 wd 0.0500	time 0.2964 (0.3091)	loss 0.9796 (1.0458)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:36 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1976 (0.2799)	loss 1.1585 (1.0320)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:38 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][30/34]	eta 0:00:01 lr 0.000003	 wd 0.0500	time 0.2308 (0.2561)	loss 0.8080 (1.0410)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:38 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 3 training takes 0:00:08
[2024-12-02 13:59:39 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:59:39 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:59:39 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:59:40 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3726 (0.3726)	loss 1.1704 (1.1704)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:00:54 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:02:16 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:02:16 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 2087504
[2024-12-02 14:02:16 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.15238176
[2024-12-02 14:02:16 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:02:16 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:02:16 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3140 (0.3140)	loss 1.1433 (1.1433)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:18 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1936 (0.1927)	loss 0.8821 (1.0330)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:20 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2467 (0.2083)	loss 1.2331 (1.0198)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:23 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1613 (0.2178)	loss 0.9722 (1.0234)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:23 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 0 training takes 0:00:07
[2024-12-02 14:02:24 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:02:24 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:02:24 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:02:25 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.4007 (0.4007)	loss 0.7903 (0.7903)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:27 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1782 (0.2275)	loss 0.9707 (1.0090)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:29 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1580 (0.1994)	loss 0.7930 (1.0609)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:30 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1902 (0.1917)	loss 0.8810 (1.0397)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:31 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 1 training takes 0:00:06
[2024-12-02 14:02:32 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:02:32 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:02:32 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:02:32 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][0/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4170 (0.4170)	loss 1.0604 (1.0604)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:35 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.3004 (0.2907)	loss 0.9719 (1.0647)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:37 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1909 (0.2614)	loss 1.1456 (1.0404)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:39 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1621 (0.2319)	loss 1.1440 (1.0395)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:40 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 2 training takes 0:00:07
[2024-12-02 14:02:41 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:02:41 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:02:41 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:02:41 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3612 (0.3612)	loss 1.0531 (1.0531)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:43 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1591 (0.1950)	loss 1.2340 (0.9926)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:44 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1609 (0.1798)	loss 1.1475 (1.0145)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:46 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1767 (0.1800)	loss 0.8800 (1.0370)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:47 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 3 training takes 0:00:06
[2024-12-02 14:02:48 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:02:48 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:02:48 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:02:49 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][0/34]	eta 0:00:18 lr 0.000003	 wd 0.0500	time 0.5482 (0.5482)	loss 0.7950 (0.7950)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:51 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.1826 (0.2511)	loss 1.0584 (1.0254)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:53 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1736 (0.2216)	loss 0.9674 (1.0320)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:55 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1815 (0.2064)	loss 0.8863 (1.0265)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:55 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 4 training takes 0:00:06
[2024-12-02 14:02:56 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:02:56 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:02:56 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:02:57 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][0/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4143 (0.4143)	loss 1.2266 (1.2266)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:58 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1594 (0.2026)	loss 1.0533 (1.0571)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:00 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2848 (0.1946)	loss 1.1440 (1.0492)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:03 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2593 (0.2178)	loss 0.9711 (1.0345)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:04 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 5 training takes 0:00:07
[2024-12-02 14:03:05 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:03:05 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:03:05 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:03:05 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.4111 (0.4111)	loss 1.0567 (1.0567)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:07 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1995 (0.2251)	loss 1.4112 (1.0577)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:09 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1802 (0.2074)	loss 0.9705 (1.0447)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:11 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1830 (0.2004)	loss 1.0579 (1.0343)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:11 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 6 training takes 0:00:06
[2024-12-02 14:03:31 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:03:31 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 2087504
[2024-12-02 14:03:31 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.15238176
[2024-12-02 14:03:31 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:03:31 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:03:32 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3620 (0.3620)	loss 1.1433 (1.1433)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:34 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1715 (0.2071)	loss 0.8821 (1.0330)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:35 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1619 (0.1875)	loss 1.2331 (1.0198)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:37 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1635 (0.1828)	loss 0.9722 (1.0234)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:38 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 14:03:39 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:03:39 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:03:39 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:03:40 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][0/34]	eta 0:00:17 lr 0.000003	 wd 0.0500	time 0.5015 (0.5015)	loss 0.7903 (0.7903)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:42 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1799 (0.2342)	loss 0.9707 (1.0090)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:44 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1624 (0.2040)	loss 0.7930 (1.0609)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:45 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1747 (0.1927)	loss 0.8810 (1.0397)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:46 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 1 training takes 0:00:06
[2024-12-02 14:03:47 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:03:47 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:03:47 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:03:47 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.3847 (0.3847)	loss 1.0604 (1.0604)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:49 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1778 (0.2138)	loss 0.9719 (1.0647)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:51 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2652 (0.2050)	loss 1.1456 (1.0404)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:54 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2542 (0.2291)	loss 1.1440 (1.0395)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:20 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:04:20 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 2087504
[2024-12-02 14:04:20 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.15238176
[2024-12-02 14:04:20 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:04:20 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:04:21 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3231 (0.3231)	loss 1.1433 (1.1433)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:22 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1788 (0.1900)	loss 0.8821 (1.0330)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:24 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1885 (0.1886)	loss 1.2331 (1.0198)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:26 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1790 (0.1881)	loss 0.9722 (1.0234)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:27 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 14:04:28 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:04:28 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:04:28 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:04:28 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3730 (0.3730)	loss 0.7903 (0.7903)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:30 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.2478 (0.2333)	loss 0.9707 (1.0090)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:33 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2854 (0.2539)	loss 0.7930 (1.0609)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:35 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1839 (0.2337)	loss 0.8810 (1.0397)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:36 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 1 training takes 0:00:07
[2024-12-02 14:04:37 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:04:37 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:04:37 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:04:37 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.3999 (0.3999)	loss 1.0604 (1.0604)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:39 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1969 (0.2255)	loss 0.9719 (1.0647)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:41 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2035 (0.2118)	loss 1.1456 (1.0404)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:43 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1742 (0.2057)	loss 1.1440 (1.0395)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:44 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 2 training takes 0:00:07
[2024-12-02 14:04:45 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:04:45 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:04:45 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:04:46 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][0/34]	eta 0:00:20 lr 0.000003	 wd 0.0500	time 0.5893 (0.5893)	loss 1.0531 (1.0531)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:48 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1641 (0.2448)	loss 1.2340 (0.9926)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:50 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1980 (0.2168)	loss 1.1475 (1.0145)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:52 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1818 (0.2057)	loss 0.8800 (1.0370)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:52 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 3 training takes 0:00:06
[2024-12-02 14:04:53 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:04:53 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:04:53 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:04:54 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.4072 (0.4072)	loss 0.7950 (0.7950)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:56 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1671 (0.2161)	loss 1.0584 (1.0254)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:58 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2495 (0.2106)	loss 0.9674 (1.0320)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:00 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2688 (0.2287)	loss 0.8863 (1.0265)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:01 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 4 training takes 0:00:07
[2024-12-02 14:05:02 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:05:02 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:05:02 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:05:02 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][0/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4236 (0.4236)	loss 1.2266 (1.2266)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:04 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1887 (0.2129)	loss 1.0533 (1.0571)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:06 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1806 (0.1940)	loss 1.1440 (1.0492)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:08 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1817 (0.1935)	loss 0.9711 (1.0345)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:09 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 5 training takes 0:00:06
[2024-12-02 14:05:10 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:05:10 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:05:10 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:05:10 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][0/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4137 (0.4137)	loss 1.0567 (1.0567)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:13 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2525 (0.2787)	loss 1.4112 (1.0577)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:15 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2222 (0.2531)	loss 0.9705 (1.0447)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:17 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1934 (0.2306)	loss 1.0579 (1.0343)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:17 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 6 training takes 0:00:07
[2024-12-02 14:05:19 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:05:19 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:05:19 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:05:19 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [7/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.3943 (0.3943)	loss 0.9673 (0.9673)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:21 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [7/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.2088 (0.2191)	loss 1.0532 (1.0878)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:23 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [7/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1753 (0.1983)	loss 1.0546 (1.0612)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:12:42 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:12:43 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 33097328
[2024-12-02 14:12:43 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 2.213553408
[2024-12-02 14:12:43 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:12:43 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:12:45 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][0/34]	eta 0:01:28 lr 0.000003	 wd 0.0500	time 2.5953 (2.5953)	loss 1.0855 (1.0855)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:13:01 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][10/34]	eta 0:00:40 lr 0.000003	 wd 0.0500	time 1.3936 (1.6810)	loss 1.1843 (1.1228)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:13:16 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][20/34]	eta 0:00:22 lr 0.000003	 wd 0.0500	time 1.3147 (1.5902)	loss 0.9865 (1.0646)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:13:31 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][30/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 1.3608 (1.5549)	loss 0.9035 (1.0670)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:13:35 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 0 training takes 0:00:52
[2024-12-02 14:13:43 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:13:43 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:13:43 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:13:45 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][0/34]	eta 0:01:08 lr 0.000003	 wd 0.0500	time 2.0192 (2.0192)	loss 0.9955 (0.9955)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:14:01 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][10/34]	eta 0:00:38 lr 0.000003	 wd 0.0500	time 1.4162 (1.5969)	loss 1.0919 (1.0669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:14:16 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][20/34]	eta 0:00:21 lr 0.000003	 wd 0.0500	time 1.3667 (1.5489)	loss 1.1782 (1.0572)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:14:31 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][30/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 1.2971 (1.5331)	loss 1.0761 (1.0571)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:14:36 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 1 training takes 0:00:52
[2024-12-02 14:14:43 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:14:43 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:14:43 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:14:45 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][0/34]	eta 0:01:05 lr 0.000003	 wd 0.0500	time 1.9126 (1.9126)	loss 0.6413 (0.6413)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:15:01 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][10/34]	eta 0:00:39 lr 0.000003	 wd 0.0500	time 2.1980 (1.6515)	loss 1.1778 (1.0326)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:15:54 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:15:54 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 33093968
[2024-12-02 14:15:54 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 2.169298176
[2024-12-02 14:15:54 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:15:54 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:15:56 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][0/34]	eta 0:01:03 lr 0.000003	 wd 0.0500	time 1.8636 (1.8636)	loss 1.0172 (1.0172)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:16:13 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][10/34]	eta 0:00:41 lr 0.000003	 wd 0.0500	time 1.4495 (1.7265)	loss 0.7282 (1.0100)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:16:30 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][20/34]	eta 0:00:23 lr 0.000003	 wd 0.0500	time 1.6189 (1.6855)	loss 1.3203 (1.0919)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:16:48 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][30/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 1.8877 (1.7118)	loss 1.0182 (1.0872)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:16:52 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 0 training takes 0:00:57
[2024-12-02 14:17:01 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:17:01 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:17:01 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:17:03 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][0/34]	eta 0:01:08 lr 0.000003	 wd 0.0500	time 2.0139 (2.0139)	loss 1.0932 (1.0932)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:17:19 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][10/34]	eta 0:00:40 lr 0.000003	 wd 0.0500	time 1.4603 (1.6868)	loss 0.9209 (1.0959)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:17:36 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][20/34]	eta 0:00:23 lr 0.000003	 wd 0.0500	time 1.5230 (1.6666)	loss 0.7312 (1.1031)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:17:53 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][30/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 2.2995 (1.6854)	loss 0.9296 (1.0890)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:17:58 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 1 training takes 0:00:57
[2024-12-02 14:18:06 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:18:06 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:18:06 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:18:09 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][0/34]	eta 0:01:27 lr 0.000003	 wd 0.0500	time 2.5799 (2.5799)	loss 1.1311 (1.1311)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:18:25 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][10/34]	eta 0:00:41 lr 0.000003	 wd 0.0500	time 1.4599 (1.7352)	loss 0.8617 (1.0170)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:18:42 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][20/34]	eta 0:00:23 lr 0.000003	 wd 0.0500	time 1.5391 (1.6746)	loss 1.1192 (1.0790)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:18:58 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][30/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 1.5188 (1.6676)	loss 0.9964 (1.0860)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:19:04 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 2 training takes 0:00:57
[2024-12-02 14:19:11 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:19:11 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:19:11 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:19:14 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][0/34]	eta 0:01:40 lr 0.000003	 wd 0.0500	time 2.9573 (2.9573)	loss 1.2001 (1.2001)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:19:31 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][10/34]	eta 0:00:43 lr 0.000003	 wd 0.0500	time 1.5469 (1.7997)	loss 0.9975 (1.0888)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:19:48 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][20/34]	eta 0:00:24 lr 0.000003	 wd 0.0500	time 1.5525 (1.7323)	loss 1.2027 (1.1058)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:20:22 swin_tiny_patch4_window7_224] (main.py 387): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 384
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 14:20:22 swin_tiny_patch4_window7_224] (main.py 388): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 14:20:22 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:20:23 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 33093968
[2024-12-02 14:20:23 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 2.169298176
[2024-12-02 14:20:23 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:20:23 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:20:25 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][0/34]	eta 0:01:04 lr 0.000004	 wd 0.0001	time 1.8863 (1.8863)	loss 1.0172 (1.0172)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:20:41 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][10/34]	eta 0:00:40 lr 0.000004	 wd 0.0001	time 1.5662 (1.6819)	loss 0.7282 (1.0100)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:20:58 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][20/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 1.5246 (1.6580)	loss 1.3203 (1.0919)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:21:15 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 2.0374 (1.6975)	loss 1.0182 (1.0872)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:21:20 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 0 training takes 0:00:57
[2024-12-02 14:21:29 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:21:29 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:21:29 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:21:31 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][0/34]	eta 0:01:13 lr 0.000004	 wd 0.0001	time 2.1631 (2.1631)	loss 1.0932 (1.0932)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:21:47 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][10/34]	eta 0:00:40 lr 0.000004	 wd 0.0001	time 1.5409 (1.6963)	loss 0.9209 (1.0959)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:22:07 swin_tiny_patch4_window7_224] (main.py 387): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 384
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 14
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 14:22:07 swin_tiny_patch4_window7_224] (main.py 388): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 14:22:07 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:22:08 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 33097328
[2024-12-02 14:22:08 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 2.213553408
[2024-12-02 14:22:08 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:22:08 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:22:10 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][0/34]	eta 0:01:10 lr 0.000004	 wd 0.0001	time 2.0774 (2.0774)	loss 1.0855 (1.0855)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:22:25 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][10/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.3279 (1.5678)	loss 1.1843 (1.1228)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:22:40 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.4116 (1.5179)	loss 0.9865 (1.0646)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:22:54 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3579 (1.5069)	loss 0.9035 (1.0670)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:22:58 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 0 training takes 0:00:50
[2024-12-02 14:23:06 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:23:06 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:23:06 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:23:08 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][0/34]	eta 0:01:04 lr 0.000004	 wd 0.0001	time 1.8869 (1.8869)	loss 0.9955 (0.9955)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:23:24 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][10/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.2967 (1.5572)	loss 1.0919 (1.0669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:23:38 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.3497 (1.5043)	loss 1.1782 (1.0572)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:23:53 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][30/34]	eta 0:00:05 lr 0.000004	 wd 0.0001	time 1.3750 (1.4949)	loss 1.0761 (1.0571)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:23:58 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 1 training takes 0:00:51
[2024-12-02 14:24:05 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:24:05 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:24:05 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:24:07 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][0/34]	eta 0:01:03 lr 0.000004	 wd 0.0001	time 1.8703 (1.8703)	loss 0.6413 (0.6413)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:24:23 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][10/34]	eta 0:00:38 lr 0.000004	 wd 0.0001	time 2.0407 (1.6169)	loss 1.1778 (1.0326)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:24:38 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][20/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 1.8845 (1.5806)	loss 1.2703 (1.0401)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:24:53 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3588 (1.5479)	loss 0.9743 (1.0522)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:24:57 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 2 training takes 0:00:52
[2024-12-02 14:25:05 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:25:05 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:25:05 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:25:07 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][0/34]	eta 0:01:05 lr 0.000004	 wd 0.0001	time 1.9355 (1.9355)	loss 1.0090 (1.0090)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:25:22 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][10/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.2839 (1.5582)	loss 0.8220 (0.9971)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:25:37 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.3366 (1.5168)	loss 1.3722 (1.0442)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:25:52 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3962 (1.5012)	loss 1.1834 (1.0703)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:25:56 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 3 training takes 0:00:50
[2024-12-02 14:26:04 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:26:04 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:26:04 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:26:06 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][0/34]	eta 0:01:02 lr 0.000004	 wd 0.0001	time 1.8411 (1.8411)	loss 0.9931 (0.9931)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:26:21 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][10/34]	eta 0:00:38 lr 0.000004	 wd 0.0001	time 1.3022 (1.5847)	loss 0.8166 (1.0769)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:26:37 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.3689 (1.5538)	loss 1.0840 (1.0796)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:26:53 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 2.2055 (1.5746)	loss 0.7354 (1.0622)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:26:57 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 4 training takes 0:00:53
[2024-12-02 14:27:05 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:27:05 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:27:05 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:27:07 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][0/34]	eta 0:01:37 lr 0.000004	 wd 0.0001	time 2.8764 (2.8764)	loss 1.1726 (1.1726)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:27:23 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][10/34]	eta 0:00:39 lr 0.000004	 wd 0.0001	time 1.4300 (1.6663)	loss 1.0808 (1.0423)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:27:38 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][20/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 1.3167 (1.5742)	loss 1.0906 (1.0516)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:27:49 swin_tiny_patch4_window7_224] (main.py 387): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 8
    EMBED_DIM: 128
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 4
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 14
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 14
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 14:27:49 swin_tiny_patch4_window7_224] (main.py 388): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 14:27:49 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:27:49 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 7264962
[2024-12-02 14:27:49 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.518428352
[2024-12-02 14:27:49 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:27:49 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:29:28 swin_tiny_patch4_window7_224] (main.py 387): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 8
    EMBED_DIM: 128
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 14
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 14
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 14:29:28 swin_tiny_patch4_window7_224] (main.py 388): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 14:29:28 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:29:29 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 7262046
[2024-12-02 14:29:29 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.517813696
[2024-12-02 14:29:29 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:29:29 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:29:49 swin_tiny_patch4_window7_224] (main.py 387): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 128
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 14
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 14
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 14:29:49 swin_tiny_patch4_window7_224] (main.py 388): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 14:29:49 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:29:49 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 3698032
[2024-12-02 14:29:49 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.262199904
[2024-12-02 14:29:49 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:29:49 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:30:10 swin_tiny_patch4_window7_224] (main.py 387): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 128
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 14
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 14:30:10 swin_tiny_patch4_window7_224] (main.py 388): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 14:30:10 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:30:10 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 3698032
[2024-12-02 14:30:10 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.262199904
[2024-12-02 14:30:10 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:30:10 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:30:32 swin_tiny_patch4_window7_224] (main.py 387): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 384
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 14
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 14:30:32 swin_tiny_patch4_window7_224] (main.py 388): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 14:30:32 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:30:32 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 33097328
[2024-12-02 14:30:32 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 2.213553408
[2024-12-02 14:30:32 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:30:32 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:30:34 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][0/34]	eta 0:01:02 lr 0.000004	 wd 0.0001	time 1.8303 (1.8303)	loss 1.0855 (1.0855)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:30:51 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][10/34]	eta 0:00:39 lr 0.000004	 wd 0.0001	time 2.1992 (1.6582)	loss 1.1843 (1.1228)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:31:06 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][20/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 1.6966 (1.6097)	loss 0.9865 (1.0646)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:31:21 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.4004 (1.5774)	loss 0.9035 (1.0670)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:31:25 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 0 training takes 0:00:53
[2024-12-02 14:31:34 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:31:34 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:31:34 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:31:36 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][0/34]	eta 0:01:06 lr 0.000004	 wd 0.0001	time 1.9683 (1.9683)	loss 0.9955 (0.9955)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:31:51 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][10/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.3759 (1.5720)	loss 1.0919 (1.0669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:32:06 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.3470 (1.5326)	loss 1.1782 (1.0572)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:32:21 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3113 (1.5205)	loss 1.0761 (1.0571)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:32:26 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 1 training takes 0:00:52
[2024-12-02 14:32:33 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:32:33 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:32:33 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:32:35 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][0/34]	eta 0:01:08 lr 0.000004	 wd 0.0001	time 2.0122 (2.0122)	loss 0.6413 (0.6413)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:32:51 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][10/34]	eta 0:00:38 lr 0.000004	 wd 0.0001	time 1.4149 (1.5850)	loss 1.1778 (1.0326)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:33:06 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][20/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 2.0865 (1.5838)	loss 1.2703 (1.0401)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:32:00 swin_tiny_patch4_window7_224] (main.py 387): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 384
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 14
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 15:32:00 swin_tiny_patch4_window7_224] (main.py 388): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 15:32:00 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 15:32:01 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 33097328
[2024-12-02 15:32:01 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 2.213553408
[2024-12-02 15:32:01 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 15:32:01 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 15:32:04 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][0/34]	eta 0:01:18 lr 0.000004	 wd 0.0001	time 2.3109 (2.3109)	loss 1.0855 (1.0855)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:32:20 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][10/34]	eta 0:00:40 lr 0.000004	 wd 0.0001	time 1.3863 (1.6733)	loss 1.1843 (1.1228)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:32:37 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][20/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 1.3164 (1.6782)	loss 0.9865 (1.0646)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:32:51 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3817 (1.6167)	loss 0.9035 (1.0670)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:32:57 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 0 training takes 0:00:55
[2024-12-02 15:33:05 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 15:33:05 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 15:33:05 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 15:33:07 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][0/34]	eta 0:01:20 lr 0.000004	 wd 0.0001	time 2.3670 (2.3670)	loss 0.9955 (0.9955)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:33:23 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][10/34]	eta 0:00:40 lr 0.000004	 wd 0.0001	time 1.5761 (1.6870)	loss 1.0919 (1.0669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:34:02 swin_tiny_patch4_window7_224] (main.py 387): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 384
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 14
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 15:34:02 swin_tiny_patch4_window7_224] (main.py 388): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 15:34:02 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 15:34:03 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 33097328
[2024-12-02 15:34:03 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 2.213553408
[2024-12-02 15:34:03 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 15:34:03 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 15:34:04 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][0/34]	eta 0:00:55 lr 0.000004	 wd 0.0001	time 1.6445 (1.6445)	loss 1.0855 (1.0855)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:34:20 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][10/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.3305 (1.5616)	loss 1.1843 (1.1228)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:34:35 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.3098 (1.5249)	loss 0.9865 (1.0646)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:34:50 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3841 (1.5119)	loss 0.9035 (1.0670)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:34:55 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 0 training takes 0:00:52
[2024-12-02 15:35:01 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 15:35:01 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 15:35:01 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 15:35:03 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][0/34]	eta 0:01:07 lr 0.000004	 wd 0.0001	time 1.9776 (1.9776)	loss 0.9955 (0.9955)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:35:20 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][10/34]	eta 0:00:39 lr 0.000004	 wd 0.0001	time 2.1569 (1.6475)	loss 1.0919 (1.0669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:35:35 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][20/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 1.8689 (1.5946)	loss 1.1782 (1.0572)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:35:50 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3684 (1.5528)	loss 1.0761 (1.0571)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:35:54 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 1 training takes 0:00:52
[2024-12-02 15:36:02 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 15:36:02 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 15:36:02 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 15:36:04 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][0/34]	eta 0:01:05 lr 0.000004	 wd 0.0001	time 1.9219 (1.9219)	loss 0.6413 (0.6413)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:36:19 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][10/34]	eta 0:00:36 lr 0.000004	 wd 0.0001	time 1.3131 (1.5341)	loss 1.1778 (1.0326)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:36:33 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.3538 (1.5102)	loss 1.2703 (1.0401)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:36:50 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3953 (1.5448)	loss 0.9743 (1.0522)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:36:55 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 2 training takes 0:00:53
[2024-12-02 15:37:02 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 15:37:02 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 15:37:02 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 15:37:04 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][0/34]	eta 0:01:03 lr 0.000004	 wd 0.0001	time 1.8777 (1.8777)	loss 1.0090 (1.0090)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:37:19 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][10/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.4257 (1.5680)	loss 0.8220 (0.9971)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:37:35 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 2.2641 (1.5679)	loss 1.3722 (1.0442)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:37:50 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.7470 (1.5581)	loss 1.1834 (1.0703)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:37:54 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 3 training takes 0:00:52
[2024-12-02 15:38:02 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 15:38:02 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 15:38:02 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 15:38:04 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][0/34]	eta 0:01:13 lr 0.000004	 wd 0.0001	time 2.1604 (2.1604)	loss 0.9931 (0.9931)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:38:19 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][10/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.3642 (1.5738)	loss 0.8166 (1.0769)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:38:34 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.3390 (1.5297)	loss 1.0840 (1.0796)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:38:49 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3587 (1.5167)	loss 0.7354 (1.0622)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:38:53 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 4 training takes 0:00:51
[2024-12-02 15:39:01 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 15:39:01 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 15:39:01 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 15:39:03 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][0/34]	eta 0:01:05 lr 0.000004	 wd 0.0001	time 1.9322 (1.9322)	loss 1.1726 (1.1726)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:39:19 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][10/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.4031 (1.5635)	loss 1.0808 (1.0423)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:39:33 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.3958 (1.5142)	loss 1.0906 (1.0516)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:39:49 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.8325 (1.5216)	loss 1.3398 (1.0448)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:39:54 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 5 training takes 0:00:52
[2024-12-02 15:40:01 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 15:40:01 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 15:40:01 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 15:40:04 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][0/34]	eta 0:01:38 lr 0.000004	 wd 0.0001	time 2.9002 (2.9002)	loss 1.0040 (1.0040)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:40:19 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][10/34]	eta 0:00:40 lr 0.000004	 wd 0.0001	time 1.4587 (1.6968)	loss 1.1713 (1.1394)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:40:34 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][20/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 1.3399 (1.5987)	loss 1.0901 (1.0770)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:40:49 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.4083 (1.5625)	loss 1.0077 (1.0444)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:40:53 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 6 training takes 0:00:52
[2024-12-02 15:41:01 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 15:41:01 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 15:41:01 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 15:41:03 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [7/50][0/34]	eta 0:01:07 lr 0.000004	 wd 0.0001	time 1.9843 (1.9843)	loss 1.1839 (1.1839)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:41:23 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [7/50][10/34]	eta 0:00:47 lr 0.000004	 wd 0.0001	time 1.4634 (1.9588)	loss 1.0938 (1.0275)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:41:40 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [7/50][20/34]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 2.0614 (1.8596)	loss 0.9914 (1.0582)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:41:58 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [7/50][30/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 2.3389 (1.8352)	loss 1.1679 (1.0450)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:42:03 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 7 training takes 0:01:01
[2024-12-02 15:42:11 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 15:42:11 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 15:42:11 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 15:42:13 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [8/50][0/34]	eta 0:01:09 lr 0.000004	 wd 0.0001	time 2.0577 (2.0577)	loss 1.2868 (1.2868)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 15:42:52 swin_tiny_patch4_window7_224] (main.py 388): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 384
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 14
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 15:42:52 swin_tiny_patch4_window7_224] (main.py 389): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 15:42:52 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 15:42:53 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 33097328
[2024-12-02 15:42:53 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 2.213553408
[2024-12-02 15:42:53 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 15:42:53 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 15:42:55 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [0/50][0/34]	eta 0:01:10 lr 0.000004	 wd 0.0001	time 2.0861 (2.0861)	loss 1.0855 (1.0855)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-02 15:43:11 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [0/50][10/34]	eta 0:00:40 lr 0.000004	 wd 0.0001	time 2.1125 (1.6853)	loss 1.1843 (1.1228)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-02 15:43:26 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [0/50][20/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 1.4819 (1.5951)	loss 0.9865 (1.0646)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.641
[2024-12-02 15:43:41 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [0/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3398 (1.5614)	loss 0.9035 (1.0670)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-02 15:43:45 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 0 training takes 0:00:52
[2024-12-02 15:43:54 swin_tiny_patch4_window7_224] (main.py 311): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 15:43:54 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 15:43:54 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 15:43:55 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [1/50][0/34]	eta 0:01:02 lr 0.000004	 wd 0.0001	time 1.8337 (1.8337)	loss 0.9955 (0.9955)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.664
[2024-12-02 15:44:10 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [1/50][10/34]	eta 0:00:36 lr 0.000004	 wd 0.0001	time 1.3041 (1.5251)	loss 1.0919 (1.0669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-02 15:44:25 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [1/50][20/34]	eta 0:00:20 lr 0.000004	 wd 0.0001	time 1.3205 (1.4965)	loss 1.1782 (1.0572)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-02 15:44:40 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [1/50][30/34]	eta 0:00:05 lr 0.000004	 wd 0.0001	time 1.3286 (1.4908)	loss 1.0761 (1.0571)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-02 15:44:45 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 1 training takes 0:00:51
[2024-12-02 15:44:52 swin_tiny_patch4_window7_224] (main.py 311): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 15:44:52 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 15:44:52 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 15:44:54 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [2/50][0/34]	eta 0:01:02 lr 0.000004	 wd 0.0001	time 1.8506 (1.8506)	loss 0.6413 (0.6413)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-02 15:45:09 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [2/50][10/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.3872 (1.5536)	loss 1.1778 (1.0326)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-02 15:45:24 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [2/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.7682 (1.5325)	loss 1.2703 (1.0401)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.828
[2024-12-02 15:45:40 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [2/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 2.1171 (1.5331)	loss 0.9743 (1.0522)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-02 15:45:44 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 2 training takes 0:00:51
[2024-12-02 15:45:51 swin_tiny_patch4_window7_224] (main.py 311): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 15:45:51 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 15:45:51 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 15:45:54 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [3/50][0/34]	eta 0:01:29 lr 0.000004	 wd 0.0001	time 2.6452 (2.6452)	loss 1.0090 (1.0090)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.664
[2024-12-02 15:46:09 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [3/50][10/34]	eta 0:00:39 lr 0.000004	 wd 0.0001	time 1.3513 (1.6289)	loss 0.8220 (0.9971)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-02 15:46:24 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [3/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.3287 (1.5645)	loss 1.3722 (1.0442)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.883
[2024-12-02 15:46:39 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [3/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.2976 (1.5361)	loss 1.1834 (1.0703)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-02 15:46:43 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 3 training takes 0:00:51
[2024-12-02 15:46:51 swin_tiny_patch4_window7_224] (main.py 311): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 15:46:51 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 15:46:51 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 15:46:53 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [4/50][0/34]	eta 0:01:07 lr 0.000004	 wd 0.0001	time 1.9956 (1.9956)	loss 0.9931 (0.9931)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.664
[2024-12-02 15:47:09 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [4/50][10/34]	eta 0:00:38 lr 0.000004	 wd 0.0001	time 1.3283 (1.6011)	loss 0.8166 (1.0769)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-02 15:47:23 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [4/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.3753 (1.5333)	loss 1.0840 (1.0796)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.719
[2024-12-02 15:47:38 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [4/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.4287 (1.5135)	loss 0.7354 (1.0622)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 15:47:43 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 4 training takes 0:00:52
[2024-12-02 15:47:50 swin_tiny_patch4_window7_224] (main.py 311): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 15:47:50 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 15:47:50 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 15:47:52 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [5/50][0/34]	eta 0:01:15 lr 0.000004	 wd 0.0001	time 2.2293 (2.2293)	loss 1.1726 (1.1726)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.773
[2024-12-02 15:48:09 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [5/50][10/34]	eta 0:00:40 lr 0.000004	 wd 0.0001	time 1.9213 (1.6749)	loss 1.0808 (1.0423)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-02 15:48:23 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [5/50][20/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 1.3217 (1.5796)	loss 1.0906 (1.0516)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.719
[2024-12-02 15:48:39 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [5/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3538 (1.5905)	loss 1.3398 (1.0448)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.883
[2024-12-02 15:48:44 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 5 training takes 0:00:53
[2024-12-02 15:48:52 swin_tiny_patch4_window7_224] (main.py 311): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 15:48:52 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 15:48:52 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 15:48:54 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [6/50][0/34]	eta 0:01:05 lr 0.000004	 wd 0.0001	time 1.9119 (1.9119)	loss 1.0040 (1.0040)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-02 15:49:09 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [6/50][10/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.2958 (1.5827)	loss 1.1713 (1.1394)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.734
[2024-12-02 15:49:25 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [6/50][20/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 1.3045 (1.5769)	loss 1.0901 (1.0770)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-02 15:49:43 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [6/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 2.6924 (1.6531)	loss 1.0077 (1.0444)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.664
[2024-12-02 15:49:48 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 6 training takes 0:00:56
[2024-12-02 15:49:55 swin_tiny_patch4_window7_224] (main.py 311): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 15:49:55 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 15:49:55 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 15:49:58 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [7/50][0/34]	eta 0:01:28 lr 0.000004	 wd 0.0001	time 2.6046 (2.6046)	loss 1.1839 (1.1839)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-02 15:50:14 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [7/50][10/34]	eta 0:00:41 lr 0.000004	 wd 0.0001	time 1.6885 (1.7232)	loss 1.0938 (1.0275)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-02 15:51:19 swin_tiny_patch4_window7_224] (main.py 390): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 384
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 14
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 15:51:19 swin_tiny_patch4_window7_224] (main.py 391): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 15:51:19 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 15:51:20 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 33097328
[2024-12-02 15:51:20 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 2.213553408
[2024-12-02 15:51:20 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 15:51:20 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 15:51:22 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [0/50][0/34]	eta 0:01:00 lr 0.000004	 wd 0.0001	time 1.7794 (1.7794)	loss 1.0855 (1.0855)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-02 15:51:40 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [0/50][10/34]	eta 0:00:42 lr 0.000004	 wd 0.0001	time 3.7131 (1.7799)	loss 1.1843 (1.1228)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-02 15:51:55 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [0/50][20/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 1.4337 (1.6575)	loss 0.9865 (1.0646)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.641
[2024-12-02 15:52:10 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [0/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3590 (1.6102)	loss 0.9035 (1.0670)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-02 15:52:14 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 0 training takes 0:00:54
[2024-12-02 15:52:23 swin_tiny_patch4_window7_224] (main.py 313): INFO  * Accuracy validation@ 0.000 
[2024-12-02 15:52:23 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 15:52:23 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 15:52:25 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [1/50][0/34]	eta 0:01:06 lr 0.000004	 wd 0.0001	time 1.9647 (1.9647)	loss 0.9955 (0.9955)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.664
[2024-12-02 15:52:40 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [1/50][10/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.2951 (1.5740)	loss 1.0919 (1.0669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-02 15:52:54 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [1/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.3570 (1.5209)	loss 1.1782 (1.0572)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-02 15:53:09 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [1/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3705 (1.5030)	loss 1.0761 (1.0571)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-02 15:53:15 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 1 training takes 0:00:52
[2024-12-02 15:53:24 swin_tiny_patch4_window7_224] (main.py 313): INFO  * Accuracy validation@ 0.000 
[2024-12-02 15:53:24 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 15:53:24 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 15:53:29 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [2/50][0/34]	eta 0:02:55 lr 0.000004	 wd 0.0001	time 5.1710 (5.1710)	loss 0.6413 (0.6413)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-02 15:53:46 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [2/50][10/34]	eta 0:00:48 lr 0.000004	 wd 0.0001	time 1.3913 (2.0391)	loss 1.1778 (1.0326)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-02 15:54:05 swin_tiny_patch4_window7_224] (main.py 392): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 384
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 14
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 15:54:05 swin_tiny_patch4_window7_224] (main.py 393): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 15:54:05 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 15:54:06 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 33097328
[2024-12-02 15:54:06 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 2.213553408
[2024-12-02 15:54:06 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 15:54:06 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 15:54:08 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [0/50][0/34]	eta 0:01:31 lr 0.000004	 wd 0.0001	time 2.6870 (2.6870)	loss 1.0855 (1.0855)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-02 15:54:24 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [0/50][10/34]	eta 0:00:39 lr 0.000004	 wd 0.0001	time 1.5250 (1.6404)	loss 1.1843 (1.1228)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-02 15:54:40 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [0/50][20/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 1.3472 (1.6258)	loss 0.9865 (1.0646)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.641
[2024-12-02 15:54:54 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [0/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3555 (1.5763)	loss 0.9035 (1.0670)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-02 15:54:59 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 0 training takes 0:00:52
[2024-12-02 15:55:08 swin_tiny_patch4_window7_224] (main.py 315): INFO  * Accuracy validation@ 0.000 
[2024-12-02 15:55:08 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 15:55:08 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 15:55:10 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [1/50][0/34]	eta 0:01:14 lr 0.000004	 wd 0.0001	time 2.2053 (2.2053)	loss 0.9955 (0.9955)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.664
[2024-12-02 15:55:25 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [1/50][10/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.3423 (1.5540)	loss 1.0919 (1.0669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-02 15:55:40 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [1/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.3610 (1.5198)	loss 1.1782 (1.0572)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-02 15:55:55 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [1/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.7933 (1.5242)	loss 1.0761 (1.0571)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-02 15:56:00 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 1 training takes 0:00:52
[2024-12-02 15:56:07 swin_tiny_patch4_window7_224] (main.py 315): INFO  * Accuracy validation@ 0.000 
[2024-12-02 15:56:07 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 15:56:07 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 15:56:09 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [2/50][0/34]	eta 0:01:28 lr 0.000004	 wd 0.0001	time 2.5891 (2.5891)	loss 0.6413 (0.6413)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-02 15:56:25 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [2/50][10/34]	eta 0:00:40 lr 0.000004	 wd 0.0001	time 1.7427 (1.6729)	loss 1.1778 (1.0326)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-02 15:56:40 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [2/50][20/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 1.3636 (1.5854)	loss 1.2703 (1.0401)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.828
[2024-12-02 15:56:55 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [2/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3054 (1.5521)	loss 0.9743 (1.0522)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-02 15:56:59 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 2 training takes 0:00:52
[2024-12-02 15:57:07 swin_tiny_patch4_window7_224] (main.py 315): INFO  * Accuracy validation@ 0.000 
[2024-12-02 15:57:07 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 15:57:07 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 15:57:09 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [3/50][0/34]	eta 0:01:06 lr 0.000004	 wd 0.0001	time 1.9666 (1.9666)	loss 1.0090 (1.0090)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.664
[2024-12-02 16:03:14 swin_tiny_patch4_window7_224] (main.py 392): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 384
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 14
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 16:03:14 swin_tiny_patch4_window7_224] (main.py 393): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 16:03:14 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 16:03:15 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 33097328
[2024-12-02 16:03:15 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 2.213553408
[2024-12-02 16:03:15 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 16:03:15 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 16:03:16 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [0/50][0/34]	eta 0:00:57 lr 0.000004	 wd 0.0001	time 1.6900 (1.6900)	loss 1.0855 (1.0855)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-02 16:03:31 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [0/50][10/34]	eta 0:00:36 lr 0.000004	 wd 0.0001	time 1.3558 (1.5231)	loss 1.1843 (1.1228)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-02 16:03:46 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [0/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.3913 (1.5009)	loss 0.9865 (1.0646)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.641
[2024-12-02 16:04:01 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [0/50][30/34]	eta 0:00:05 lr 0.000004	 wd 0.0001	time 1.3894 (1.4975)	loss 0.9035 (1.0670)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-02 16:04:05 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 0 training takes 0:00:50
[2024-12-02 16:04:13 swin_tiny_patch4_window7_224] (main.py 315): INFO  * Accuracy validation@ 0.731 
[2024-12-02 16:04:13 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 16:04:13 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 16:04:15 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [1/50][0/34]	eta 0:01:08 lr 0.000004	 wd 0.0001	time 2.0005 (2.0005)	loss 0.9955 (0.9955)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.664
[2024-12-02 16:04:30 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [1/50][10/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.2977 (1.5507)	loss 1.0919 (1.0669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-02 16:04:45 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [1/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.3127 (1.5160)	loss 1.1782 (1.0572)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-02 16:05:00 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [1/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.6828 (1.5109)	loss 1.0761 (1.0571)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-02 16:05:05 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 1 training takes 0:00:51
[2024-12-02 16:05:12 swin_tiny_patch4_window7_224] (main.py 315): INFO  * Accuracy validation@ 0.731 
[2024-12-02 16:05:12 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 16:05:12 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 16:05:15 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [2/50][0/34]	eta 0:01:29 lr 0.000004	 wd 0.0001	time 2.6377 (2.6377)	loss 0.6413 (0.6413)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-02 16:05:30 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [2/50][10/34]	eta 0:00:39 lr 0.000004	 wd 0.0001	time 1.6838 (1.6445)	loss 1.1778 (1.0326)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-02 16:05:45 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [2/50][20/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 1.4975 (1.5942)	loss 1.2703 (1.0401)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.828
[2024-12-02 16:06:01 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [2/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3720 (1.5701)	loss 0.9743 (1.0522)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-02 16:06:05 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 2 training takes 0:00:52
[2024-12-02 16:06:13 swin_tiny_patch4_window7_224] (main.py 315): INFO  * Accuracy validation@ 0.731 
[2024-12-02 16:06:13 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 16:06:13 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 16:06:15 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [3/50][0/34]	eta 0:01:10 lr 0.000004	 wd 0.0001	time 2.0736 (2.0736)	loss 1.0090 (1.0090)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.664
[2024-12-02 16:06:31 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [3/50][10/34]	eta 0:00:39 lr 0.000004	 wd 0.0001	time 1.3745 (1.6482)	loss 0.8220 (0.9971)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-02 16:06:46 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [3/50][20/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 1.3947 (1.5817)	loss 1.3722 (1.0442)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.883
[2024-12-02 16:07:02 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [3/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.9859 (1.5780)	loss 1.1834 (1.0703)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-02 16:07:07 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 3 training takes 0:00:53
[2024-12-02 16:07:14 swin_tiny_patch4_window7_224] (main.py 315): INFO  * Accuracy validation@ 0.731 
[2024-12-02 16:07:14 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 16:07:14 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 16:07:16 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [4/50][0/34]	eta 0:01:30 lr 0.000004	 wd 0.0001	time 2.6694 (2.6694)	loss 0.9931 (0.9931)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.664
[2024-12-02 16:07:32 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [4/50][10/34]	eta 0:00:39 lr 0.000004	 wd 0.0001	time 1.6347 (1.6408)	loss 0.8166 (1.0769)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-02 16:07:46 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [4/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.3631 (1.5655)	loss 1.0840 (1.0796)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.719
[2024-12-02 16:08:01 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [4/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3755 (1.5384)	loss 0.7354 (1.0622)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 16:08:05 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 4 training takes 0:00:51
[2024-12-02 16:08:14 swin_tiny_patch4_window7_224] (main.py 315): INFO  * Accuracy validation@ 0.731 
[2024-12-02 16:08:14 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 16:08:14 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 16:08:16 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [5/50][0/34]	eta 0:01:01 lr 0.000004	 wd 0.0001	time 1.8058 (1.8058)	loss 1.1726 (1.1726)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.773
[2024-12-02 16:08:33 swin_tiny_patch4_window7_224] (main.py 392): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 384
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 14
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 16:08:33 swin_tiny_patch4_window7_224] (main.py 393): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 16:08:33 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 16:08:33 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 33097328
[2024-12-02 16:08:33 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 2.213553408
[2024-12-02 16:08:33 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 16:08:33 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 16:08:35 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [0/50][0/34]	eta 0:01:06 lr 0.000004	 wd 0.0001	time 1.9662 (1.9662)	loss 1.0855 (1.0855)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-02 16:08:52 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [0/50][10/34]	eta 0:00:39 lr 0.000004	 wd 0.0001	time 2.1667 (1.6524)	loss 1.1843 (1.1228)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-02 16:09:06 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [0/50][20/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 1.5468 (1.5734)	loss 0.9865 (1.0646)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.641
[2024-12-02 16:09:21 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [0/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3847 (1.5491)	loss 0.9035 (1.0670)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-02 16:09:25 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 0 training takes 0:00:52
[2024-12-02 16:09:34 swin_tiny_patch4_window7_224] (main.py 315): INFO  * Accuracy validation@ 0.731 
[2024-12-02 16:09:34 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 16:09:34 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 16:09:36 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [1/50][0/34]	eta 0:01:06 lr 0.000004	 wd 0.0001	time 1.9637 (1.9637)	loss 0.9955 (0.9955)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.664
[2024-12-02 16:09:51 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [1/50][10/34]	eta 0:00:38 lr 0.000004	 wd 0.0001	time 1.3504 (1.6010)	loss 1.0919 (1.0669)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-02 16:10:07 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [1/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.4348 (1.5711)	loss 1.1782 (1.0572)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-02 16:10:21 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [1/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3046 (1.5411)	loss 1.0761 (1.0571)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-02 16:10:27 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 1 training takes 0:00:53
[2024-12-02 16:10:34 swin_tiny_patch4_window7_224] (main.py 315): INFO  * Accuracy validation@ 0.731 
[2024-12-02 16:10:34 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 16:10:34 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 16:10:36 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [2/50][0/34]	eta 0:01:09 lr 0.000004	 wd 0.0001	time 2.0329 (2.0329)	loss 0.6413 (0.6413)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-02 16:10:52 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [2/50][10/34]	eta 0:00:40 lr 0.000004	 wd 0.0001	time 2.1580 (1.6698)	loss 1.1778 (1.0326)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-02 16:11:08 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [2/50][20/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 1.8349 (1.6225)	loss 1.2703 (1.0401)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.828
[2024-12-02 16:11:23 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [2/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3138 (1.5729)	loss 0.9743 (1.0522)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-02 16:11:27 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 2 training takes 0:00:52
[2024-12-02 16:11:35 swin_tiny_patch4_window7_224] (main.py 315): INFO  * Accuracy validation@ 0.731 
[2024-12-02 16:11:35 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 16:11:35 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 16:11:37 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [3/50][0/34]	eta 0:01:02 lr 0.000004	 wd 0.0001	time 1.8242 (1.8242)	loss 1.0090 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.664
[2024-12-02 16:11:52 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [3/50][10/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.2909 (1.5481)	loss 0.8220 (0.9971)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-02 16:12:07 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [3/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.3006 (1.5061)	loss 1.3722 (1.0442)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.883
[2024-12-02 16:12:23 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [3/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3964 (1.5408)	loss 1.1834 (1.0703)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-02 16:12:28 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 3 training takes 0:00:53
[2024-12-02 16:12:35 swin_tiny_patch4_window7_224] (main.py 315): INFO  * Accuracy validation@ 0.731 
[2024-12-02 16:12:35 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 16:12:35 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 16:12:37 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [4/50][0/34]	eta 0:01:07 lr 0.000004	 wd 0.0001	time 1.9877 (1.9877)	loss 0.9931 (0.9931)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.664
[2024-12-02 16:12:53 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [4/50][10/34]	eta 0:00:39 lr 0.000004	 wd 0.0001	time 1.9388 (1.6403)	loss 0.8166 (1.0769)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-02 16:13:08 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [4/50][20/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 2.0414 (1.5816)	loss 1.0840 (1.0796)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.719
[2024-12-02 16:13:23 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [4/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.4158 (1.5497)	loss 0.7354 (1.0622)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 16:13:27 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 4 training takes 0:00:52
[2024-12-02 16:13:35 swin_tiny_patch4_window7_224] (main.py 315): INFO  * Accuracy validation@ 0.731 
[2024-12-02 16:13:35 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 16:13:35 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 16:13:37 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [5/50][0/34]	eta 0:01:01 lr 0.000004	 wd 0.0001	time 1.8180 (1.8180)	loss 1.1726 (1.1726)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.773
[2024-12-02 16:13:52 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [5/50][10/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.3659 (1.5457)	loss 1.0808 (1.0423)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-02 16:14:07 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [5/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.3010 (1.5087)	loss 1.0906 (1.0516)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.719
[2024-12-02 16:14:22 swin_tiny_patch4_window7_224] (main.py 253): INFO Train: [5/50][30/34]	eta 0:00:05 lr 0.000004	 wd 0.0001	time 1.3596 (1.4953)	loss 1.3398 (1.0448)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.883
[2024-12-02 16:14:26 swin_tiny_patch4_window7_224] (main.py 262): INFO EPOCH 5 training takes 0:00:50
[2024-12-02 16:16:19 swin_tiny_patch4_window7_224] (main.py 398): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 384
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 14
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 16:16:19 swin_tiny_patch4_window7_224] (main.py 399): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 16:16:19 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 16:16:20 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 33097328
[2024-12-02 16:16:20 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 2.213553408
[2024-12-02 16:16:20 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 16:16:20 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 16:16:25 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][0/34]	eta 0:02:52 lr 0.000004	 wd 0.0001	time 5.0671 (5.0671)	loss 1.0855 (1.0855)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-02 16:17:12 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][10/34]	eta 0:01:54 lr 0.000004	 wd 0.0001	time 5.5139 (4.7789)	loss 1.1368 (1.0901)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.227
[2024-12-02 16:17:59 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][20/34]	eta 0:01:05 lr 0.000004	 wd 0.0001	time 4.2828 (4.7026)	loss 0.9583 (1.0269)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-02 16:18:47 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][30/34]	eta 0:00:18 lr 0.000004	 wd 0.0001	time 4.9615 (4.7457)	loss 0.8699 (1.0292)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-02 16:19:01 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 0 training takes 0:02:40
[2024-12-02 16:19:08 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.308 
[2024-12-02 16:19:08 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-02 16:19:08 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.31%
[2024-12-02 16:19:14 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][0/34]	eta 0:03:24 lr 0.000004	 wd 0.0001	time 6.0236 (6.0236)	loss 0.9538 (0.9538)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.336
[2024-12-02 16:20:01 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][10/34]	eta 0:01:55 lr 0.000004	 wd 0.0001	time 4.3849 (4.8284)	loss 1.0421 (1.0254)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-02 16:20:48 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][20/34]	eta 0:01:06 lr 0.000004	 wd 0.0001	time 4.9678 (4.7664)	loss 1.1268 (1.0161)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 16:21:35 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][30/34]	eta 0:00:19 lr 0.000004	 wd 0.0001	time 4.3400 (4.7514)	loss 1.0401 (1.0156)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-02 16:21:49 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 1 training takes 0:02:41
[2024-12-02 16:21:58 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.423 
[2024-12-02 16:21:58 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 16:21:58 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.42%
[2024-12-02 16:22:03 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][0/34]	eta 0:03:03 lr 0.000004	 wd 0.0001	time 5.4115 (5.4115)	loss 0.6066 (0.6066)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 16:22:50 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][10/34]	eta 0:01:54 lr 0.000004	 wd 0.0001	time 5.0534 (4.7697)	loss 1.1267 (0.9849)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-02 16:23:36 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][20/34]	eta 0:01:05 lr 0.000004	 wd 0.0001	time 4.4085 (4.6816)	loss 1.2148 (0.9947)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.734
[2024-12-02 16:24:24 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][30/34]	eta 0:00:18 lr 0.000004	 wd 0.0001	time 4.2634 (4.7148)	loss 0.9533 (1.0093)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.570
[2024-12-02 16:24:38 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 2 training takes 0:02:40
[2024-12-02 16:24:46 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.308 
[2024-12-02 16:24:46 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-02 16:24:46 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.42%
[2024-12-02 16:24:51 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][0/34]	eta 0:03:05 lr 0.000004	 wd 0.0001	time 5.4632 (5.4632)	loss 0.9532 (0.9532)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.430
[2024-12-02 16:25:40 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][10/34]	eta 0:01:58 lr 0.000004	 wd 0.0001	time 4.1181 (4.9465)	loss 0.7800 (0.9534)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-02 16:26:27 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][20/34]	eta 0:01:07 lr 0.000004	 wd 0.0001	time 4.6404 (4.8004)	loss 1.2998 (0.9987)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-02 16:27:14 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][30/34]	eta 0:00:19 lr 0.000004	 wd 0.0001	time 4.1480 (4.7746)	loss 1.1266 (1.0232)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.227
[2024-12-02 16:27:28 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 3 training takes 0:02:41
[2024-12-02 16:27:36 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.628 
[2024-12-02 16:27:36 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 16:27:36 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-02 16:27:41 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][0/34]	eta 0:03:12 lr 0.000004	 wd 0.0001	time 5.6685 (5.6685)	loss 0.9533 (0.9533)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-02 16:28:28 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][10/34]	eta 0:01:54 lr 0.000004	 wd 0.0001	time 4.4010 (4.7518)	loss 0.7799 (1.0320)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-02 16:29:17 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][20/34]	eta 0:01:07 lr 0.000004	 wd 0.0001	time 4.1627 (4.8243)	loss 1.0400 (1.0316)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 16:30:07 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][30/34]	eta 0:00:19 lr 0.000004	 wd 0.0001	time 5.6098 (4.8784)	loss 0.6933 (1.0148)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 16:30:21 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 4 training takes 0:02:45
[2024-12-02 16:30:28 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.718 
[2024-12-02 16:30:28 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 16:30:28 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 16:30:35 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][0/34]	eta 0:03:38 lr 0.000004	 wd 0.0001	time 6.4288 (6.4288)	loss 1.1265 (1.1265)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.695
[2024-12-02 16:31:22 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][10/34]	eta 0:01:56 lr 0.000004	 wd 0.0001	time 4.3196 (4.8455)	loss 1.0398 (1.0004)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-02 16:32:09 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][20/34]	eta 0:01:07 lr 0.000004	 wd 0.0001	time 5.4445 (4.8139)	loss 1.0398 (1.0069)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-02 16:33:41 swin_tiny_patch4_window7_224] (main.py 398): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 384
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 16:33:41 swin_tiny_patch4_window7_224] (main.py 399): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 16:33:41 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 16:33:42 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 33093968
[2024-12-02 16:33:42 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 2.169298176
[2024-12-02 16:33:42 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 16:33:42 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 16:33:48 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][0/34]	eta 0:03:40 lr 0.000004	 wd 0.0001	time 6.4921 (6.4921)	loss 1.0172 (1.0172)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-02 16:34:40 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][10/34]	eta 0:02:06 lr 0.000004	 wd 0.0001	time 4.6475 (5.2781)	loss 0.6941 (0.9714)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 16:35:30 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][20/34]	eta 0:01:11 lr 0.000004	 wd 0.0001	time 4.4512 (5.1338)	loss 1.2187 (1.0363)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.828
[2024-12-02 16:36:21 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][30/34]	eta 0:00:20 lr 0.000004	 wd 0.0001	time 5.5603 (5.1157)	loss 0.9556 (1.0275)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.641
[2024-12-02 16:36:35 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 0 training takes 0:02:52
[2024-12-02 16:36:43 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.436 
[2024-12-02 16:36:43 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 16:36:43 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.44%
[2024-12-02 16:36:49 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][0/34]	eta 0:03:28 lr 0.000004	 wd 0.0001	time 6.1270 (6.1270)	loss 1.0404 (1.0404)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-02 16:37:39 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][10/34]	eta 0:02:02 lr 0.000004	 wd 0.0001	time 6.0951 (5.0856)	loss 0.8679 (1.0264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-02 16:38:28 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][20/34]	eta 0:01:09 lr 0.000004	 wd 0.0001	time 4.4318 (4.9841)	loss 0.6934 (1.0337)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 16:39:16 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][30/34]	eta 0:00:19 lr 0.000004	 wd 0.0001	time 4.2357 (4.9490)	loss 0.8670 (1.0220)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-02 16:39:31 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 1 training takes 0:02:47
[2024-12-02 16:39:40 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.321 
[2024-12-02 16:39:40 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-02 16:39:40 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.44%
[2024-12-02 16:39:45 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][0/34]	eta 0:03:07 lr 0.000004	 wd 0.0001	time 5.5137 (5.5137)	loss 1.0417 (1.0417)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-02 16:40:35 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][10/34]	eta 0:02:01 lr 0.000004	 wd 0.0001	time 4.5113 (5.0560)	loss 0.7800 (0.9460)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 16:41:25 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][20/34]	eta 0:01:10 lr 0.000004	 wd 0.0001	time 5.0401 (5.0172)	loss 1.0405 (1.0074)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 16:42:15 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][30/34]	eta 0:00:20 lr 0.000004	 wd 0.0001	time 5.5577 (5.0248)	loss 0.9532 (1.0152)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 16:42:30 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 2 training takes 0:02:50
[2024-12-02 16:42:38 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.372 
[2024-12-02 16:42:38 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 16:42:38 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.44%
[2024-12-02 16:42:44 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][0/34]	eta 0:03:36 lr 0.000004	 wd 0.0001	time 6.3609 (6.3609)	loss 1.1271 (1.1271)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-02 16:43:34 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][10/34]	eta 0:02:01 lr 0.000004	 wd 0.0001	time 5.6836 (5.0632)	loss 0.9535 (1.0167)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-02 16:44:22 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][20/34]	eta 0:01:08 lr 0.000004	 wd 0.0001	time 4.4797 (4.9245)	loss 1.1271 (1.0321)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-02 16:45:11 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][30/34]	eta 0:00:19 lr 0.000004	 wd 0.0001	time 4.6294 (4.9227)	loss 1.1269 (1.0067)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-02 16:45:25 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 3 training takes 0:02:47
[2024-12-02 16:45:34 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.731 
[2024-12-02 16:45:34 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 16:45:34 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 16:45:41 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][0/34]	eta 0:03:53 lr 0.000004	 wd 0.0001	time 6.8638 (6.8638)	loss 0.9533 (0.9533)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 16:46:31 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][10/34]	eta 0:02:04 lr 0.000004	 wd 0.0001	time 4.4268 (5.1930)	loss 0.9531 (1.0007)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 16:47:20 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][20/34]	eta 0:01:10 lr 0.000004	 wd 0.0001	time 4.9037 (5.0579)	loss 1.0400 (1.0194)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 16:48:11 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][30/34]	eta 0:00:20 lr 0.000004	 wd 0.0001	time 5.5240 (5.0527)	loss 0.8669 (1.0177)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-02 16:48:26 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 4 training takes 0:02:51
[2024-12-02 16:48:34 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.731 
[2024-12-02 16:48:34 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 16:48:34 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 16:48:40 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][0/34]	eta 0:03:37 lr 0.000004	 wd 0.0001	time 6.3840 (6.3840)	loss 0.8673 (0.8673)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-02 16:49:29 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][10/34]	eta 0:02:01 lr 0.000004	 wd 0.0001	time 5.6328 (5.0639)	loss 1.0400 (1.0321)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-02 16:50:19 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][20/34]	eta 0:01:09 lr 0.000004	 wd 0.0001	time 4.6827 (4.9918)	loss 1.0398 (0.9864)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-02 16:51:08 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][30/34]	eta 0:00:19 lr 0.000004	 wd 0.0001	time 4.5924 (4.9784)	loss 1.0399 (1.0065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 16:51:23 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 5 training takes 0:02:48
[2024-12-02 16:51:31 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.410 
[2024-12-02 16:51:31 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 16:51:31 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 16:51:37 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [6/50][0/34]	eta 0:03:19 lr 0.000004	 wd 0.0001	time 5.8790 (5.8790)	loss 1.2132 (1.2132)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.219
[2024-12-02 17:05:06 swin_tiny_patch4_window7_224] (main.py 398): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 17:05:06 swin_tiny_patch4_window7_224] (main.py 399): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 17:05:06 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 17:05:07 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 27498236
[2024-12-02 17:05:07 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.210060288
[2024-12-02 17:05:07 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 17:05:07 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 17:05:46 swin_tiny_patch4_window7_224] (main.py 398): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 17:05:46 swin_tiny_patch4_window7_224] (main.py 399): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 17:05:46 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 17:05:47 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 27498236
[2024-12-02 17:05:47 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.210060288
[2024-12-02 17:05:47 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 17:05:47 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 17:10:13 swin_tiny_patch4_window7_224] (main.py 398): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 17:10:13 swin_tiny_patch4_window7_224] (main.py 399): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 17:10:14 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 17:10:14 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 27498236
[2024-12-02 17:10:14 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.210060288
[2024-12-02 17:10:14 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 17:10:14 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 17:11:45 swin_tiny_patch4_window7_224] (main.py 398): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 17:11:45 swin_tiny_patch4_window7_224] (main.py 399): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 17:11:45 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 17:11:46 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 27498236
[2024-12-02 17:11:46 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.210060288
[2024-12-02 17:11:46 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 17:11:46 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 17:12:35 swin_tiny_patch4_window7_224] (main.py 398): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 17:12:35 swin_tiny_patch4_window7_224] (main.py 399): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 17:12:35 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 17:12:36 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 27498236
[2024-12-02 17:12:36 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.210060288
[2024-12-02 17:12:36 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 17:12:36 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 17:12:56 swin_tiny_patch4_window7_224] (main.py 398): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 17:12:56 swin_tiny_patch4_window7_224] (main.py 399): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 17:12:56 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 17:12:56 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 17:12:56 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 17:12:56 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 17:12:56 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 17:12:56 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][0/34]	eta 0:00:19 lr 0.000004	 wd 0.0001	time 0.5731 (0.5731)	loss 0.9096 (0.9096)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-02 17:13:01 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][10/34]	eta 0:00:11 lr 0.000004	 wd 0.0001	time 0.5762 (0.4947)	loss 1.0159 (1.0847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-02 17:13:06 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][20/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 0.3876 (0.4625)	loss 0.9576 (1.0601)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-02 17:13:10 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][30/34]	eta 0:00:01 lr 0.000004	 wd 0.0001	time 0.4258 (0.4464)	loss 0.7830 (1.0552)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-02 17:13:11 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 0 training takes 0:00:15
[2024-12-02 17:13:12 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.269 
[2024-12-02 17:13:12 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-02 17:13:12 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.27%
[2024-12-02 17:13:13 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][0/34]	eta 0:00:28 lr 0.000004	 wd 0.0001	time 0.8394 (0.8394)	loss 1.1328 (1.1328)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.266
[2024-12-02 17:13:18 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4233 (0.5284)	loss 1.0429 (1.0148)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-02 17:13:40 swin_tiny_patch4_window7_224] (main.py 398): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 17:13:40 swin_tiny_patch4_window7_224] (main.py 399): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 17:13:40 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 17:13:41 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 27498236
[2024-12-02 17:13:41 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.210060288
[2024-12-02 17:13:41 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 17:13:41 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 17:33:11 swin_tiny_patch4_window7_224] (main.py 398): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 17:33:11 swin_tiny_patch4_window7_224] (main.py 399): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 17:33:11 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 17:33:11 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 5039132
[2024-12-02 17:33:11 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.130737024
[2024-12-02 17:33:11 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 17:33:11 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 17:33:28 swin_tiny_patch4_window7_224] (main.py 398): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 17:33:28 swin_tiny_patch4_window7_224] (main.py 399): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 17:33:28 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 17:33:29 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 2084144
[2024-12-02 17:33:29 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.141317952
[2024-12-02 17:33:29 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 17:33:29 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 17:33:29 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7061 (0.7061)	loss 1.2547 (1.2547)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-02 17:33:35 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.4928 (0.5659)	loss 1.0419 (1.0654)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 17:33:41 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7172 (0.5895)	loss 1.0426 (1.0304)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-02 17:33:46 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5035 (0.5737)	loss 1.1294 (1.0199)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.617
[2024-12-02 17:33:48 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 0 training takes 0:00:19
[2024-12-02 17:33:49 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.667 
[2024-12-02 17:33:49 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 17:33:49 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:33:50 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][0/34]	eta 0:00:28 lr 0.000004	 wd 0.0001	time 0.8359 (0.8359)	loss 1.2139 (1.2139)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.734
[2024-12-02 17:33:56 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.5240 (0.6529)	loss 1.0400 (1.0804)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-02 17:34:02 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5255 (0.6080)	loss 1.1280 (1.0243)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-02 17:34:08 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6289 (0.6070)	loss 1.0399 (1.0184)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-02 17:34:10 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 1 training takes 0:00:20
[2024-12-02 17:34:11 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.564 
[2024-12-02 17:34:11 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 17:34:11 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:34:11 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7209 (0.7209)	loss 0.7801 (0.7801)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-02 17:34:17 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.5275 (0.5373)	loss 0.8670 (0.9852)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:34:23 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5340 (0.5842)	loss 0.6933 (0.9907)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:34:28 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5451 (0.5612)	loss 1.0400 (1.0122)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-02 17:34:30 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 2 training takes 0:00:19
[2024-12-02 17:34:31 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.603 
[2024-12-02 17:34:31 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 17:34:31 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:34:32 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][0/34]	eta 0:00:31 lr 0.000004	 wd 0.0001	time 0.9175 (0.9175)	loss 0.8666 (0.8666)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 17:34:38 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4968 (0.6295)	loss 0.9533 (1.0163)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-02 17:34:43 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5395 (0.5787)	loss 1.1267 (1.0028)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-02 17:34:49 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5380 (0.5980)	loss 0.7799 (1.0120)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 17:34:51 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 3 training takes 0:00:20
[2024-12-02 17:34:52 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.474 
[2024-12-02 17:34:52 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-02 17:34:52 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:34:53 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][0/34]	eta 0:00:28 lr 0.000004	 wd 0.0001	time 0.8382 (0.8382)	loss 1.1268 (1.1268)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-02 17:34:59 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.7097 (0.5788)	loss 0.7799 (1.0084)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-02 17:35:05 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5331 (0.5917)	loss 0.8665 (0.9904)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 17:35:10 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4887 (0.5659)	loss 0.9531 (0.9980)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:35:12 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 4 training takes 0:00:19
[2024-12-02 17:35:13 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.423 
[2024-12-02 17:35:13 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 17:35:13 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:35:14 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][0/34]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.9864 (0.9864)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 17:35:19 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.5369 (0.5685)	loss 0.6065 (0.8981)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:35:25 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.7614 (0.5524)	loss 1.2998 (0.9904)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.773
[2024-12-02 17:35:31 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4946 (0.5691)	loss 1.1265 (1.0007)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:35:32 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 5 training takes 0:00:19
[2024-12-02 17:35:34 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.513 
[2024-12-02 17:35:34 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-02 17:35:34 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:35:34 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [6/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7218 (0.7218)	loss 1.0398 (1.0398)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-02 17:35:40 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [6/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.7362 (0.6297)	loss 0.8665 (0.9847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 17:35:46 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [6/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4963 (0.5872)	loss 0.8665 (0.9862)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:35:51 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [6/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5027 (0.5611)	loss 0.9532 (1.0091)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-02 17:35:53 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 6 training takes 0:00:19
[2024-12-02 17:35:55 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.449 
[2024-12-02 17:35:55 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 17:35:55 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:35:55 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [7/50][0/34]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 0.8166 (0.8166)	loss 1.2132 (1.2132)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.359
[2024-12-02 17:36:01 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [7/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.5217 (0.5855)	loss 1.1264 (1.0083)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.734
[2024-12-02 17:36:07 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [7/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7505 (0.5995)	loss 0.9532 (1.0151)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-02 17:36:12 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [7/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5074 (0.5745)	loss 1.2998 (1.0147)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.719
[2024-12-02 17:36:14 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 7 training takes 0:00:19
[2024-12-02 17:36:15 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.603 
[2024-12-02 17:36:15 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 17:36:15 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:36:16 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [8/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7174 (0.7174)	loss 0.7798 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-02 17:36:23 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [8/50][10/34]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.6712 (0.7492)	loss 1.2997 (1.0555)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-02 17:36:28 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [8/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5314 (0.6425)	loss 1.0398 (1.0522)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-02 17:36:34 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [8/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7432 (0.6230)	loss 0.9531 (1.0286)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-02 17:36:36 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 8 training takes 0:00:21
[2024-12-02 17:36:38 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.372 
[2024-12-02 17:36:38 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 17:36:38 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:36:38 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [9/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7367 (0.7367)	loss 1.3864 (1.3864)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-02 17:36:44 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [9/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.5145 (0.5437)	loss 1.0398 (1.0556)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 17:36:50 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [9/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5738 (0.5818)	loss 1.1264 (1.0192)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-02 17:36:55 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [9/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5293 (0.5624)	loss 1.2131 (1.0035)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-02 17:36:57 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 9 training takes 0:00:18
[2024-12-02 17:36:58 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.385 
[2024-12-02 17:36:58 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 17:36:58 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:36:59 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [10/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7263 (0.7263)	loss 1.2131 (1.2131)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:37:05 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [10/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.5383 (0.6510)	loss 1.1265 (1.0634)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.695
[2024-12-02 17:37:10 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [10/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4884 (0.5821)	loss 0.9531 (1.0439)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-02 17:37:16 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [10/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6521 (0.5909)	loss 0.6932 (1.0202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:37:18 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 10 training takes 0:00:19
[2024-12-02 17:37:19 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.397 
[2024-12-02 17:37:19 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 17:37:19 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:37:20 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [11/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7377 (0.7377)	loss 0.7798 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-02 17:37:25 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [11/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.5132 (0.5319)	loss 1.2131 (0.9847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-02 17:37:31 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [11/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5778 (0.5814)	loss 0.9531 (1.0027)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-02 17:37:36 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [11/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4994 (0.5619)	loss 1.0398 (1.0063)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 17:37:38 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 11 training takes 0:00:19
[2024-12-02 17:37:39 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.436 
[2024-12-02 17:37:39 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 17:37:39 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:37:40 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [12/50][0/34]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 1.0059 (1.0059)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 17:37:46 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [12/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.5456 (0.6555)	loss 1.0398 (0.9689)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:37:52 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [12/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4878 (0.5896)	loss 1.0397 (0.9779)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-02 17:37:58 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [12/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5880 (0.5988)	loss 1.1264 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.695
[2024-12-02 17:37:59 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 12 training takes 0:00:20
[2024-12-02 17:38:01 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.526 
[2024-12-02 17:38:01 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-02 17:38:01 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:38:02 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [13/50][0/34]	eta 0:00:30 lr 0.000004	 wd 0.0001	time 0.9055 (0.9055)	loss 1.2997 (1.2997)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.336
[2024-12-02 17:38:07 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [13/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.7516 (0.5698)	loss 0.7798 (1.0634)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-02 17:38:13 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [13/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5333 (0.5838)	loss 0.9531 (1.0522)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:38:18 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [13/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5253 (0.5637)	loss 1.0398 (1.0202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:38:20 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 13 training takes 0:00:19
[2024-12-02 17:38:22 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.423 
[2024-12-02 17:38:22 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 17:38:22 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:38:23 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [14/50][0/34]	eta 0:00:36 lr 0.000004	 wd 0.0001	time 1.0723 (1.0723)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-02 17:38:28 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [14/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.5886 (0.5971)	loss 1.0398 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-02 17:38:34 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [14/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7492 (0.5881)	loss 1.1264 (1.0068)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-02 17:38:40 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [14/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5372 (0.5918)	loss 1.0398 (1.0006)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.719
[2024-12-02 17:38:42 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 14 training takes 0:00:19
[2024-12-02 17:38:43 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.513 
[2024-12-02 17:38:43 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-02 17:38:43 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:38:44 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [15/50][0/34]	eta 0:00:28 lr 0.000004	 wd 0.0001	time 0.8240 (0.8240)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-02 17:38:50 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [15/50][10/34]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.5356 (0.6740)	loss 1.0398 (1.0240)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 17:38:56 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [15/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5435 (0.6073)	loss 0.8665 (0.9902)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-02 17:39:01 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [15/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7060 (0.5918)	loss 0.9531 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 17:39:03 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 15 training takes 0:00:20
[2024-12-02 17:39:04 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.474 
[2024-12-02 17:39:04 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-02 17:39:04 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:39:05 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [16/50][0/34]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 0.7931 (0.7931)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-02 17:39:10 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [16/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.5250 (0.5419)	loss 0.7798 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-02 17:39:17 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [16/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5328 (0.5848)	loss 1.0397 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-02 17:39:22 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [16/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4976 (0.5625)	loss 0.8665 (1.0118)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:39:23 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 16 training takes 0:00:19
[2024-12-02 17:39:25 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.500 
[2024-12-02 17:39:25 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-02 17:39:25 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:39:25 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [17/50][0/34]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 0.8124 (0.8124)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-02 17:39:32 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [17/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4972 (0.6354)	loss 1.2997 (0.9610)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:39:37 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [17/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5401 (0.5806)	loss 0.8665 (0.9944)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-02 17:39:43 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [17/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7139 (0.5920)	loss 0.9531 (1.0006)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-02 17:39:45 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 17 training takes 0:00:20
[2024-12-02 17:39:46 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.538 
[2024-12-02 17:39:46 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-02 17:39:46 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:39:47 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [18/50][0/34]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 0.8040 (0.8040)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-02 17:39:52 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [18/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.5614 (0.5521)	loss 1.2997 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.664
[2024-12-02 17:39:58 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [18/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4953 (0.5730)	loss 1.1264 (0.9944)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-02 17:40:03 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [18/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5339 (0.5653)	loss 1.1264 (1.0006)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-02 17:40:05 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 18 training takes 0:00:19
[2024-12-02 17:40:06 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.436 
[2024-12-02 17:40:06 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 17:40:06 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:40:07 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [19/50][0/34]	eta 0:00:39 lr 0.000004	 wd 0.0001	time 1.1709 (1.1709)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-02 17:40:13 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [19/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.5033 (0.6437)	loss 1.0397 (0.9689)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-02 17:40:19 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [19/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5652 (0.5931)	loss 1.2997 (0.9944)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.391
[2024-12-02 17:40:25 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [19/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5245 (0.6018)	loss 0.9531 (1.0034)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-02 17:40:27 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 19 training takes 0:00:20
[2024-12-02 17:40:28 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.590 
[2024-12-02 17:40:28 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 17:40:28 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:40:29 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [20/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7280 (0.7280)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 17:40:34 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [20/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.7575 (0.6077)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-02 17:40:40 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [20/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5425 (0.5946)	loss 0.8664 (1.0067)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 17:40:45 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [20/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4985 (0.5699)	loss 1.2130 (1.0202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 17:40:47 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 20 training takes 0:00:19
[2024-12-02 17:40:49 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.462 
[2024-12-02 17:40:49 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-02 17:40:49 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:40:50 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [21/50][0/34]	eta 0:00:28 lr 0.000004	 wd 0.0001	time 0.8408 (0.8408)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-02 17:40:55 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [21/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.5648 (0.5682)	loss 1.1264 (0.9137)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-02 17:41:01 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [21/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7524 (0.5790)	loss 0.8664 (0.9655)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:41:07 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [21/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5169 (0.5737)	loss 1.1264 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-02 17:41:09 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 21 training takes 0:00:19
[2024-12-02 17:41:10 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.679 
[2024-12-02 17:41:10 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 17:41:10 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-02 17:41:10 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [22/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7316 (0.7316)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-02 17:41:17 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [22/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4894 (0.6347)	loss 1.2130 (0.9689)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 17:41:22 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [22/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5268 (0.5721)	loss 0.8664 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-02 17:41:28 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [22/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7835 (0.5813)	loss 1.2130 (1.0230)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-02 17:41:30 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 22 training takes 0:00:20
[2024-12-02 17:41:31 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.308 
[2024-12-02 17:41:31 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-02 17:41:31 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-02 17:41:32 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [23/50][0/34]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 0.7718 (0.7718)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-02 17:41:37 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [23/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.5612 (0.5553)	loss 0.7798 (0.9767)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-02 17:41:43 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [23/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5674 (0.5908)	loss 1.1264 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-02 17:41:48 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [23/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5619 (0.5700)	loss 1.0398 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-02 17:41:50 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 23 training takes 0:00:19
[2024-12-02 17:41:51 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.564 
[2024-12-02 17:41:51 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 17:41:51 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-02 17:41:52 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [24/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7355 (0.7355)	loss 0.7798 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-02 17:41:58 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [24/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.5735 (0.6577)	loss 1.0397 (1.0004)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-02 17:42:04 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [24/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7177 (0.6331)	loss 1.2130 (1.0109)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-02 17:42:11 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [24/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5494 (0.6281)	loss 0.9531 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 17:42:12 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 24 training takes 0:00:21
[2024-12-02 17:42:13 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.679 
[2024-12-02 17:42:13 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 17:42:13 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-02 17:42:14 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [25/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7596 (0.7596)	loss 1.2130 (1.2130)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.734
[2024-12-02 17:42:19 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [25/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.5822 (0.5357)	loss 1.1264 (1.0555)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.617
[2024-12-02 17:42:25 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [25/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.5503 (0.5709)	loss 1.1264 (1.0315)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-02 17:42:31 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [25/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5288 (0.5587)	loss 0.9531 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 17:42:32 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 25 training takes 0:00:18
[2024-12-02 17:42:34 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.513 
[2024-12-02 17:42:34 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-02 17:42:34 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-02 17:42:35 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [26/50][0/34]	eta 0:00:36 lr 0.000004	 wd 0.0001	time 1.0863 (1.0863)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-02 17:42:41 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [26/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.5084 (0.5830)	loss 1.0397 (1.0003)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-02 17:42:46 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [26/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.6334 (0.5662)	loss 1.1264 (0.9655)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-02 17:42:52 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [26/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5555 (0.5915)	loss 1.1264 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-02 17:42:54 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 26 training takes 0:00:20
[2024-12-02 17:42:55 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.615 
[2024-12-02 17:42:55 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 17:42:55 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-02 17:42:56 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [27/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7274 (0.7274)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:43:02 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [27/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.7346 (0.6442)	loss 1.1264 (0.9610)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.695
[2024-12-02 17:43:08 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [27/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5561 (0.5876)	loss 0.9531 (0.9985)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-02 17:43:13 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [27/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7392 (0.5751)	loss 1.2130 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 17:43:15 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 27 training takes 0:00:20
[2024-12-02 17:43:17 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.410 
[2024-12-02 17:43:17 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 17:43:17 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-02 17:43:17 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [28/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7575 (0.7575)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:43:22 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [28/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4718 (0.5379)	loss 0.5199 (1.0082)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-02 17:43:29 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [28/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7259 (0.5780)	loss 1.1264 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.734
[2024-12-02 17:43:34 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [28/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4812 (0.5599)	loss 0.8665 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:43:36 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 28 training takes 0:00:19
[2024-12-02 17:43:37 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.615 
[2024-12-02 17:43:37 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 17:43:37 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-02 17:43:38 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [29/50][0/34]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 0.7878 (0.7878)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 17:43:44 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [29/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4865 (0.6225)	loss 1.0397 (1.0240)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 17:43:49 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [29/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5493 (0.5769)	loss 1.0397 (0.9820)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 17:43:55 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [29/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7336 (0.5917)	loss 1.2130 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.641
[2024-12-02 17:43:57 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 29 training takes 0:00:20
[2024-12-02 17:43:58 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.385 
[2024-12-02 17:43:58 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 17:43:58 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-02 17:43:59 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [30/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7540 (0.7540)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 17:44:04 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [30/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.5032 (0.5473)	loss 0.6065 (0.9373)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 17:44:10 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [30/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5412 (0.5814)	loss 1.0397 (0.9613)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 17:44:16 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [30/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5381 (0.5673)	loss 1.0398 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-02 17:44:17 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 30 training takes 0:00:19
[2024-12-02 17:44:19 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.718 
[2024-12-02 17:44:19 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 17:44:19 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 17:44:20 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [31/50][0/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.1015 (1.1015)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-02 17:44:26 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [31/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.5426 (0.6502)	loss 1.2997 (1.0161)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:44:31 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [31/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5563 (0.5891)	loss 1.0397 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 17:44:37 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [31/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5050 (0.6035)	loss 0.8664 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-02 17:44:39 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 31 training takes 0:00:20
[2024-12-02 17:44:40 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.397 
[2024-12-02 17:44:40 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 17:44:40 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 17:44:41 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [32/50][0/34]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 0.8096 (0.8096)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.430
[2024-12-02 17:44:46 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [32/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.7267 (0.5873)	loss 0.8664 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 17:44:52 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [32/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5392 (0.5858)	loss 1.0397 (0.9902)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-02 17:44:58 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [32/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5549 (0.5680)	loss 0.9531 (1.0118)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-02 17:44:59 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 32 training takes 0:00:19
[2024-12-02 17:45:01 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.551 
[2024-12-02 17:45:01 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 17:45:01 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 17:45:02 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [33/50][0/34]	eta 0:00:31 lr 0.000004	 wd 0.0001	time 0.9298 (0.9298)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:45:08 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [33/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.5737 (0.5772)	loss 0.9531 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-02 17:45:13 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [33/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7547 (0.5779)	loss 0.8664 (0.9943)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-02 17:45:19 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [33/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5097 (0.5729)	loss 0.7798 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:45:21 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 33 training takes 0:00:19
[2024-12-02 17:45:22 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.641 
[2024-12-02 17:45:22 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 17:45:22 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 17:45:23 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [34/50][0/34]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 0.8123 (0.8123)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-02 17:45:29 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [34/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.5436 (0.6496)	loss 0.8664 (1.0555)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 17:45:34 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [34/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5019 (0.5973)	loss 0.9531 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.570
[2024-12-02 17:45:40 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [34/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7203 (0.5839)	loss 0.6931 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:45:42 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 34 training takes 0:00:20
[2024-12-02 17:45:43 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.436 
[2024-12-02 17:45:43 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 17:45:43 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 17:45:44 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [35/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7504 (0.7504)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-02 17:45:50 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [35/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.5261 (0.5723)	loss 0.9531 (0.9846)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-02 17:45:56 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [35/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5383 (0.5938)	loss 1.0397 (0.9861)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 17:46:01 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [35/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5549 (0.5739)	loss 1.0397 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:46:03 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 35 training takes 0:00:19
[2024-12-02 17:46:04 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.333 
[2024-12-02 17:46:04 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-02 17:46:04 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 17:46:05 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [36/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7528 (0.7528)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-02 17:46:11 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [36/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4974 (0.6365)	loss 1.1264 (1.0712)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-02 17:46:16 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [36/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5226 (0.5857)	loss 0.7798 (1.0232)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-02 17:46:23 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [36/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5045 (0.6015)	loss 0.9531 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:46:24 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 36 training takes 0:00:20
[2024-12-02 17:46:25 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.462 
[2024-12-02 17:46:25 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-02 17:46:25 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 17:46:26 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [37/50][0/34]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 0.8017 (0.8017)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-02 17:46:32 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [37/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.5410 (0.5726)	loss 1.2130 (1.0003)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-02 17:46:38 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [37/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4898 (0.5982)	loss 0.9531 (1.0067)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.430
[2024-12-02 17:46:43 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [37/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5321 (0.5702)	loss 1.2130 (1.0118)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.359
[2024-12-02 17:46:45 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 37 training takes 0:00:19
[2024-12-02 17:46:46 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.577 
[2024-12-02 17:46:46 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 17:46:46 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 17:46:47 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [38/50][0/34]	eta 0:00:36 lr 0.000004	 wd 0.0001	time 1.0612 (1.0612)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-02 17:46:53 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [38/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.5003 (0.5997)	loss 1.1264 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-02 17:46:58 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [38/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.5441 (0.5667)	loss 0.9531 (1.0026)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-02 17:47:04 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [38/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4994 (0.5825)	loss 0.7798 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-02 17:47:06 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 38 training takes 0:00:19
[2024-12-02 17:47:07 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.590 
[2024-12-02 17:47:07 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 17:47:07 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 17:47:07 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [39/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7206 (0.7206)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-02 17:47:13 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [39/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.7918 (0.5515)	loss 0.7798 (0.9452)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 17:47:19 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [39/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.5004 (0.5646)	loss 1.0397 (1.0067)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-02 17:47:24 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [39/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4965 (0.5422)	loss 1.0397 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:47:25 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 39 training takes 0:00:18
[2024-12-02 17:47:27 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.410 
[2024-12-02 17:47:27 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 17:47:27 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 17:47:28 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [40/50][0/34]	eta 0:00:36 lr 0.000004	 wd 0.0001	time 1.0844 (1.0844)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:47:33 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [40/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.5518 (0.5986)	loss 0.9531 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-02 17:47:39 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [40/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7833 (0.5814)	loss 1.0397 (1.0356)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-02 17:47:45 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [40/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5499 (0.5875)	loss 0.7798 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 17:47:47 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 40 training takes 0:00:19
[2024-12-02 17:47:48 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.679 
[2024-12-02 17:47:48 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 17:47:48 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 17:47:49 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [41/50][0/34]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 0.7692 (0.7692)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 17:47:55 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [41/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.5992 (0.6460)	loss 1.1264 (1.0240)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-02 17:48:00 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [41/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5552 (0.5902)	loss 0.8664 (0.9861)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-02 17:48:06 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [41/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.8078 (0.5842)	loss 1.0397 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:48:08 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 41 training takes 0:00:20
[2024-12-02 17:48:09 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.731 
[2024-12-02 17:48:09 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 17:48:09 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 17:48:10 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [42/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7518 (0.7518)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.617
[2024-12-02 17:48:15 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [42/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.5598 (0.5372)	loss 1.1264 (1.0082)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-02 17:48:22 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [42/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.6505 (0.5873)	loss 0.8664 (1.0026)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 17:48:27 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [42/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5426 (0.5669)	loss 0.9531 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 17:48:29 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 42 training takes 0:00:19
[2024-12-02 17:48:30 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.654 
[2024-12-02 17:48:30 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 17:48:30 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 17:48:31 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [43/50][0/34]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 0.7791 (0.7791)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-02 17:48:37 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [43/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4906 (0.6389)	loss 1.1264 (0.9767)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.617
[2024-12-02 17:48:42 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [43/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4890 (0.5766)	loss 1.2130 (1.0191)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.781
[2024-12-02 17:48:48 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [43/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7941 (0.5964)	loss 1.1264 (1.0118)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.734
[2024-12-02 17:48:50 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 43 training takes 0:00:20
[2024-12-02 17:48:51 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.321 
[2024-12-02 17:48:51 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-02 17:48:51 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 17:50:53 swin_tiny_patch4_window7_224] (main.py 398): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 17:50:53 swin_tiny_patch4_window7_224] (main.py 399): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 17:50:53 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 17:50:53 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 2084144
[2024-12-02 17:50:53 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.141317952
[2024-12-02 17:50:53 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 17:50:53 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 17:50:54 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][0/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 0.6546 (0.6546)	loss 1.2547 (1.2547)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-02 17:51:00 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.6837 (0.6340)	loss 1.0419 (1.0654)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 17:51:05 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5005 (0.5800)	loss 1.0426 (1.0304)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-02 17:51:11 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6784 (0.5577)	loss 1.1294 (1.0199)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.617
[2024-12-02 17:51:13 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 0 training takes 0:00:19
[2024-12-02 17:51:14 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.667 
[2024-12-02 17:51:14 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 17:51:14 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:51:15 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7417 (0.7417)	loss 1.2139 (1.2139)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.734
[2024-12-02 17:51:20 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4906 (0.5332)	loss 1.0400 (1.0804)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-02 17:51:26 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.7394 (0.5497)	loss 1.1280 (1.0243)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-02 17:51:31 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5615 (0.5496)	loss 1.0399 (1.0184)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-02 17:51:33 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 1 training takes 0:00:18
[2024-12-02 17:51:34 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.564 
[2024-12-02 17:51:34 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 17:51:34 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:51:35 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][0/34]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 0.7887 (0.7887)	loss 0.7801 (0.7801)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-02 17:51:41 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4903 (0.6532)	loss 0.8670 (0.9852)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:51:47 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5302 (0.5989)	loss 0.6933 (0.9907)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:51:53 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7688 (0.6078)	loss 1.0400 (1.0122)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-02 17:51:55 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 2 training takes 0:00:20
[2024-12-02 17:51:56 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.603 
[2024-12-02 17:51:56 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 17:51:56 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:51:57 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7234 (0.7234)	loss 0.8666 (0.8666)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 17:52:02 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.5645 (0.5723)	loss 0.9533 (1.0163)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-02 17:52:09 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5184 (0.6056)	loss 1.1267 (1.0028)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-02 17:52:14 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4816 (0.5806)	loss 0.7799 (1.0120)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 17:52:15 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 3 training takes 0:00:19
[2024-12-02 17:52:17 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.474 
[2024-12-02 17:52:17 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-02 17:52:17 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:52:18 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][0/34]	eta 0:00:36 lr 0.000004	 wd 0.0001	time 1.0870 (1.0870)	loss 1.1268 (1.1268)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-02 17:52:24 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.5294 (0.6601)	loss 0.7799 (1.0084)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-02 17:52:29 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4908 (0.5994)	loss 0.8665 (0.9904)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 17:52:36 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4880 (0.6133)	loss 0.9531 (0.9980)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:52:37 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 4 training takes 0:00:20
[2024-12-02 17:52:38 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.423 
[2024-12-02 17:52:38 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 17:52:38 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:52:39 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7355 (0.7355)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 17:52:45 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.7929 (0.6041)	loss 0.6065 (0.8981)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:52:51 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5103 (0.5876)	loss 1.2998 (0.9904)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.773
[2024-12-02 17:52:56 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5592 (0.5748)	loss 1.1265 (1.0007)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:52:58 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 5 training takes 0:00:19
[2024-12-02 17:53:00 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.513 
[2024-12-02 17:53:00 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-02 17:53:00 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:53:01 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [6/50][0/34]	eta 0:00:28 lr 0.000004	 wd 0.0001	time 0.8461 (0.8461)	loss 1.0398 (1.0398)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-02 17:53:06 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [6/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.4887 (0.5787)	loss 0.8665 (0.9847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 17:53:12 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [6/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.8328 (0.5901)	loss 0.8665 (0.9862)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:53:18 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [6/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5873 (0.5905)	loss 0.9532 (1.0091)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-02 17:53:20 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 6 training takes 0:00:19
[2024-12-02 17:53:21 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.449 
[2024-12-02 17:53:21 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 17:53:21 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:53:22 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [7/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7363 (0.7363)	loss 1.2132 (1.2132)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.359
[2024-12-02 17:53:28 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [7/50][10/34]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.5588 (0.6800)	loss 1.1264 (1.0083)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.734
[2024-12-02 17:53:34 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [7/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5570 (0.6227)	loss 0.9532 (1.0151)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-02 17:53:40 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [7/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7426 (0.6218)	loss 1.2998 (1.0147)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.719
[2024-12-02 17:53:42 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 7 training takes 0:00:20
[2024-12-02 17:53:43 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.603 
[2024-12-02 17:53:43 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 17:53:43 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:53:44 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [8/50][0/34]	eta 0:00:40 lr 0.000004	 wd 0.0001	time 1.1955 (1.1955)	loss 0.7798 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-02 17:53:51 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [8/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.6328 (0.6642)	loss 1.2997 (1.0555)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-02 17:53:57 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [8/50][20/34]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.5361 (0.6554)	loss 1.0398 (1.0522)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-02 17:54:02 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [8/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5161 (0.6167)	loss 0.9531 (1.0286)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-02 17:54:04 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 8 training takes 0:00:20
[2024-12-02 17:54:06 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.372 
[2024-12-02 17:54:06 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 17:54:06 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:54:07 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [9/50][0/34]	eta 0:00:38 lr 0.000004	 wd 0.0001	time 1.1372 (1.1372)	loss 1.3864 (1.3864)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-02 17:54:12 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [9/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.5138 (0.6022)	loss 1.0398 (1.0556)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 17:54:18 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [9/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7745 (0.5878)	loss 1.1264 (1.0192)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-02 17:54:24 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [9/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5088 (0.5918)	loss 1.2131 (1.0035)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-02 17:54:26 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 9 training takes 0:00:20
[2024-12-02 17:54:27 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.385 
[2024-12-02 17:54:27 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 17:54:27 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:54:28 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [10/50][0/34]	eta 0:00:29 lr 0.000004	 wd 0.0001	time 0.8647 (0.8647)	loss 1.2131 (1.2131)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:54:34 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [10/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.7063 (0.6571)	loss 1.1265 (1.0634)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.695
[2024-12-02 17:54:40 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [10/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5791 (0.6084)	loss 0.9531 (1.0439)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-02 17:54:46 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [10/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.8409 (0.6084)	loss 0.6932 (1.0202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:54:48 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 10 training takes 0:00:20
[2024-12-02 17:54:49 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.397 
[2024-12-02 17:54:49 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 17:54:49 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:54:50 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [11/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7431 (0.7431)	loss 0.7798 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-02 17:54:55 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [11/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.5098 (0.5503)	loss 1.2131 (0.9847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-02 17:55:01 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [11/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5187 (0.5917)	loss 0.9531 (1.0027)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-02 17:55:07 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [11/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5064 (0.5790)	loss 1.0398 (1.0063)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 17:55:09 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 11 training takes 0:00:19
[2024-12-02 17:55:10 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.436 
[2024-12-02 17:55:10 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 17:55:10 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:55:10 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [12/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7533 (0.7533)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 17:55:17 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [12/50][10/34]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.5250 (0.6810)	loss 1.0398 (0.9689)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:55:23 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [12/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5894 (0.6249)	loss 1.0397 (0.9779)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-02 17:55:29 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [12/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5057 (0.6343)	loss 1.1264 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.695
[2024-12-02 17:55:31 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 12 training takes 0:00:21
[2024-12-02 17:55:32 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.526 
[2024-12-02 17:55:32 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-02 17:55:32 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:55:33 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [13/50][0/34]	eta 0:00:28 lr 0.000004	 wd 0.0001	time 0.8454 (0.8454)	loss 1.2997 (1.2997)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.336
[2024-12-02 17:55:39 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [13/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.7315 (0.6086)	loss 0.7798 (1.0634)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-02 17:55:45 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [13/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4945 (0.6060)	loss 0.9531 (1.0522)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:55:50 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [13/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5496 (0.5847)	loss 1.0398 (1.0202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:55:53 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 13 training takes 0:00:20
[2024-12-02 17:55:54 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.423 
[2024-12-02 17:55:54 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 17:55:54 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:55:55 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [14/50][0/34]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 0.7943 (0.7943)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-02 17:56:01 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [14/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.6042 (0.5821)	loss 1.0398 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-02 17:56:07 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [14/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.8323 (0.5929)	loss 1.1264 (1.0068)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-02 17:56:12 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [14/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5548 (0.5856)	loss 1.0398 (1.0006)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.719
[2024-12-02 17:56:14 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 14 training takes 0:00:19
[2024-12-02 17:56:15 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.513 
[2024-12-02 17:56:15 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-02 17:56:15 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:56:16 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [15/50][0/34]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 0.8173 (0.8173)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-02 17:56:22 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [15/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.5384 (0.6644)	loss 1.0398 (1.0240)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 17:56:28 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [15/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4905 (0.5935)	loss 0.8665 (0.9902)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-02 17:56:34 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [15/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7701 (0.5978)	loss 0.9531 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 17:56:36 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 15 training takes 0:00:20
[2024-12-02 17:56:37 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.474 
[2024-12-02 17:56:37 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-02 17:56:37 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:56:38 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [16/50][0/34]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 0.7851 (0.7851)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-02 17:56:43 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [16/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.5281 (0.5767)	loss 0.7798 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-02 17:56:50 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [16/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5425 (0.6159)	loss 1.0397 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-02 17:56:55 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [16/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5216 (0.5956)	loss 0.8665 (1.0118)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:56:57 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 16 training takes 0:00:20
[2024-12-02 17:56:58 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.500 
[2024-12-02 17:56:58 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-02 17:56:58 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:56:59 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [17/50][0/34]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.9799 (0.9799)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-02 17:57:05 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [17/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.5704 (0.6353)	loss 1.2997 (0.9610)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:57:10 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [17/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5247 (0.5887)	loss 0.8665 (0.9944)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-02 17:57:17 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [17/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5311 (0.6015)	loss 0.9531 (1.0006)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-02 17:57:18 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 17 training takes 0:00:20
[2024-12-02 17:57:20 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.538 
[2024-12-02 17:57:20 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-02 17:57:20 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:57:20 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [18/50][0/34]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 0.8168 (0.8168)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-02 17:57:26 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [18/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.7805 (0.6002)	loss 1.2997 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.664
[2024-12-02 17:57:32 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [18/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5616 (0.5893)	loss 1.1264 (0.9944)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-02 17:57:37 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [18/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5634 (0.5756)	loss 1.1264 (1.0006)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-02 17:57:40 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 18 training takes 0:00:20
[2024-12-02 17:57:41 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.436 
[2024-12-02 17:57:41 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 17:57:41 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:57:42 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [19/50][0/34]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 0.7792 (0.7792)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-02 17:57:48 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [19/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.5247 (0.5895)	loss 1.0397 (0.9689)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-02 17:57:54 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [19/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7401 (0.5923)	loss 1.2997 (0.9944)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.391
[2024-12-02 17:57:59 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [19/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5935 (0.5841)	loss 0.9531 (1.0034)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-02 17:58:01 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 19 training takes 0:00:19
[2024-12-02 17:58:02 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.590 
[2024-12-02 17:58:02 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 17:58:02 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:58:03 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [20/50][0/34]	eta 0:00:28 lr 0.000004	 wd 0.0001	time 0.8407 (0.8407)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 17:58:10 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [20/50][10/34]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.5427 (0.7024)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-02 17:58:16 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [20/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4900 (0.6204)	loss 0.8664 (1.0067)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 17:58:22 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [20/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7871 (0.6245)	loss 1.2130 (1.0202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 17:58:23 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 20 training takes 0:00:20
[2024-12-02 17:58:25 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.462 
[2024-12-02 17:58:25 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-02 17:58:25 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-02 17:58:25 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [21/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7525 (0.7525)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-02 17:58:31 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [21/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4989 (0.5411)	loss 1.1264 (0.9137)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-02 17:58:37 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [21/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5491 (0.5969)	loss 0.8664 (0.9655)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 17:58:43 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [21/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5859 (0.5814)	loss 1.1264 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-02 17:58:44 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 21 training takes 0:00:19
[2024-12-02 17:58:46 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.679 
[2024-12-02 17:58:46 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 17:58:46 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-02 17:58:47 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [22/50][0/34]	eta 0:00:39 lr 0.000004	 wd 0.0001	time 1.1558 (1.1558)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-02 17:58:53 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [22/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.5620 (0.6585)	loss 1.2130 (0.9689)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 17:58:58 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [22/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5477 (0.6060)	loss 0.8664 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-02 17:59:05 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [22/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5589 (0.6181)	loss 1.2130 (1.0230)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-02 17:59:06 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 22 training takes 0:00:20
[2024-12-02 17:59:08 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.308 
[2024-12-02 17:59:08 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-02 17:59:08 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-02 17:59:08 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [23/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7595 (0.7595)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-02 17:59:14 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [23/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.7848 (0.6174)	loss 0.7798 (0.9767)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-02 17:59:20 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [23/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5572 (0.6050)	loss 1.1264 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-02 17:59:26 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [23/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5396 (0.5802)	loss 1.0398 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-02 17:59:28 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 23 training takes 0:00:20
[2024-12-02 17:59:30 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.564 
[2024-12-02 17:59:30 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 17:59:30 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-02 17:59:31 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [24/50][0/34]	eta 0:00:35 lr 0.000004	 wd 0.0001	time 1.0535 (1.0535)	loss 0.7798 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-02 17:59:37 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [24/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4955 (0.6141)	loss 1.0397 (1.0004)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-02 17:59:43 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [24/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.8367 (0.6121)	loss 1.2130 (1.0109)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-02 17:59:48 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [24/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5159 (0.5909)	loss 0.9531 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 17:59:50 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 24 training takes 0:00:19
[2024-12-02 17:59:51 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.679 
[2024-12-02 17:59:51 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 17:59:51 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-02 17:59:52 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [25/50][0/34]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 0.8228 (0.8228)	loss 1.2130 (1.2130)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.734
[2024-12-02 17:59:58 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [25/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.5727 (0.6491)	loss 1.1264 (1.0555)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.617
[2024-12-02 18:00:04 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [25/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5497 (0.6346)	loss 1.1264 (1.0315)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-02 18:00:11 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [25/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5676 (0.6451)	loss 0.9531 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 18:00:13 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 25 training takes 0:00:21
[2024-12-02 18:00:14 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.513 
[2024-12-02 18:00:14 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-02 18:00:14 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-02 18:00:15 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [26/50][0/34]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 0.8033 (0.8033)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-02 18:00:20 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [26/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.5391 (0.5564)	loss 1.0397 (1.0003)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-02 18:00:26 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [26/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5559 (0.5913)	loss 1.1264 (0.9655)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-02 18:00:32 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [26/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5586 (0.5723)	loss 1.1264 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-02 18:00:33 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 26 training takes 0:00:19
[2024-12-02 18:00:35 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.615 
[2024-12-02 18:00:35 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 18:00:35 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-02 18:00:36 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [27/50][0/34]	eta 0:00:40 lr 0.000004	 wd 0.0001	time 1.1996 (1.1996)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 18:00:42 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [27/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.5598 (0.6114)	loss 1.1264 (0.9610)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.695
[2024-12-02 18:00:47 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [27/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7384 (0.5871)	loss 0.9531 (0.9985)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-02 18:00:54 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [27/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5345 (0.5997)	loss 1.2130 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 18:00:55 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 27 training takes 0:00:20
[2024-12-02 18:00:57 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.410 
[2024-12-02 18:00:57 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 18:00:57 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-02 18:00:57 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [28/50][0/34]	eta 0:00:28 lr 0.000004	 wd 0.0001	time 0.8407 (0.8407)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 18:01:04 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [28/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.6577 (0.6326)	loss 0.5199 (1.0082)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-02 18:01:09 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [28/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5715 (0.5913)	loss 1.1264 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.734
[2024-12-02 18:01:15 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [28/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7270 (0.5868)	loss 0.8665 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 18:01:17 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 28 training takes 0:00:20
[2024-12-02 18:01:18 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.615 
[2024-12-02 18:01:18 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 18:01:18 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-02 18:01:19 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [29/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7575 (0.7575)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 18:01:24 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [29/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.5519 (0.5641)	loss 1.0397 (1.0240)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 18:01:31 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [29/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5367 (0.6117)	loss 1.0397 (0.9820)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 18:01:37 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [29/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5150 (0.5906)	loss 1.2130 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.641
[2024-12-02 18:01:38 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 29 training takes 0:00:20
[2024-12-02 18:01:40 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.385 
[2024-12-02 18:01:40 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 18:01:40 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-02 18:01:40 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [30/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7267 (0.7267)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 18:01:47 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [30/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.5445 (0.6547)	loss 0.6065 (0.9373)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 18:01:52 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [30/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5101 (0.5846)	loss 1.0397 (0.9613)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 18:01:58 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [30/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5999 (0.6106)	loss 1.0398 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-02 18:02:00 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 30 training takes 0:00:20
[2024-12-02 18:02:01 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.718 
[2024-12-02 18:02:01 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 18:02:01 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 18:02:02 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [31/50][0/34]	eta 0:00:28 lr 0.000004	 wd 0.0001	time 0.8431 (0.8431)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-02 18:02:08 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [31/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.8182 (0.6296)	loss 1.2997 (1.0161)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 18:02:15 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [31/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5434 (0.6249)	loss 1.0397 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 18:02:20 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [31/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5358 (0.5959)	loss 0.8664 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-02 18:02:22 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 31 training takes 0:00:20
[2024-12-02 18:02:23 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.397 
[2024-12-02 18:02:23 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 18:02:23 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 18:02:25 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [32/50][0/34]	eta 0:00:35 lr 0.000004	 wd 0.0001	time 1.0316 (1.0316)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.430
[2024-12-02 18:02:30 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [32/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.5962 (0.5878)	loss 0.8664 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 18:02:36 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [32/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.8306 (0.5894)	loss 1.0397 (0.9902)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-02 18:02:42 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [32/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6009 (0.5970)	loss 0.9531 (1.0118)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-02 18:02:44 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 32 training takes 0:00:20
[2024-12-02 18:02:45 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.551 
[2024-12-02 18:02:45 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 18:02:45 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 18:02:46 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [33/50][0/34]	eta 0:00:28 lr 0.000004	 wd 0.0001	time 0.8357 (0.8357)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 18:02:52 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [33/50][10/34]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.5143 (0.6815)	loss 0.9531 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-02 18:02:58 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [33/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5568 (0.6160)	loss 0.8664 (0.9943)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-02 18:03:04 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [33/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7683 (0.6187)	loss 0.7798 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 18:03:06 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 33 training takes 0:00:20
[2024-12-02 18:03:07 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.641 
[2024-12-02 18:03:07 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 18:03:07 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 18:03:08 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [34/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7499 (0.7499)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-02 18:03:13 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [34/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.4890 (0.5547)	loss 0.8664 (1.0555)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 18:03:20 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [34/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4961 (0.5986)	loss 0.9531 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.570
[2024-12-02 18:03:25 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [34/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4851 (0.5697)	loss 0.6931 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 18:03:26 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 34 training takes 0:00:19
[2024-12-02 18:03:27 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.436 
[2024-12-02 18:03:27 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 18:03:27 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 18:03:28 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [35/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7378 (0.7378)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-02 18:03:35 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [35/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.5541 (0.6595)	loss 0.9531 (0.9846)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-02 18:03:40 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [35/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5346 (0.5912)	loss 1.0397 (0.9861)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 18:03:46 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [35/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5067 (0.6055)	loss 1.0397 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 18:03:48 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 35 training takes 0:00:20
[2024-12-02 18:03:49 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.333 
[2024-12-02 18:03:49 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-02 18:03:49 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 18:03:50 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [36/50][0/34]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 0.7991 (0.7991)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-02 18:03:55 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [36/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.5385 (0.5610)	loss 1.1264 (1.0712)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-02 18:04:01 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [36/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5027 (0.5957)	loss 0.7798 (1.0232)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-02 18:04:07 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [36/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4912 (0.5709)	loss 0.9531 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 18:04:08 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 36 training takes 0:00:19
[2024-12-02 18:04:10 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.462 
[2024-12-02 18:04:10 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-02 18:04:10 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 18:04:11 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [37/50][0/34]	eta 0:00:38 lr 0.000004	 wd 0.0001	time 1.1442 (1.1442)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-02 18:04:17 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [37/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.5052 (0.6156)	loss 1.2130 (1.0003)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-02 18:04:22 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [37/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4846 (0.5700)	loss 0.9531 (1.0067)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.430
[2024-12-02 18:04:28 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [37/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5057 (0.5889)	loss 1.2130 (1.0118)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.359
[2024-12-02 18:04:30 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 37 training takes 0:00:19
[2024-12-02 18:04:31 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.577 
[2024-12-02 18:04:31 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 18:04:31 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 18:04:32 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [38/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7458 (0.7458)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-02 18:04:38 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [38/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.8553 (0.6199)	loss 1.1264 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-02 18:04:44 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [38/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5692 (0.5942)	loss 0.9531 (1.0026)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-02 18:04:49 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [38/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5670 (0.5771)	loss 0.7798 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-02 18:04:51 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 38 training takes 0:00:20
[2024-12-02 18:04:53 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.590 
[2024-12-02 18:04:53 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-02 18:04:53 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 18:04:54 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [39/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7492 (0.7492)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-02 18:04:59 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [39/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.5407 (0.5592)	loss 0.7798 (0.9452)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-02 18:05:05 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [39/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.8910 (0.6049)	loss 1.0397 (1.0067)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-02 18:05:12 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [39/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5189 (0.6186)	loss 1.0397 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 18:05:14 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 39 training takes 0:00:20
[2024-12-02 18:05:15 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.410 
[2024-12-02 18:05:15 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-02 18:05:15 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 18:05:16 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [40/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7609 (0.7609)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 18:05:22 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [40/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4897 (0.6538)	loss 0.9531 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-02 18:05:28 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [40/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.6115 (0.6060)	loss 1.0397 (1.0356)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-02 18:05:34 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [40/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5176 (0.6126)	loss 0.7798 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 18:05:35 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 40 training takes 0:00:20
[2024-12-02 18:05:37 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.679 
[2024-12-02 18:05:37 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 18:05:37 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-02 18:05:37 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [41/50][0/34]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 0.7778 (0.7778)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-02 18:05:43 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [41/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.5196 (0.5649)	loss 1.1264 (1.0240)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-02 18:05:49 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [41/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4990 (0.6027)	loss 0.8664 (0.9861)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-02 18:05:55 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [41/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5092 (0.5828)	loss 1.0397 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-02 18:05:56 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 41 training takes 0:00:19
[2024-12-02 18:05:58 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.731 
[2024-12-02 18:05:58 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 18:05:58 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 18:05:59 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [42/50][0/34]	eta 0:00:36 lr 0.000004	 wd 0.0001	time 1.0839 (1.0839)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.617
[2024-12-02 18:06:05 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [42/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.5261 (0.6023)	loss 1.1264 (1.0082)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-02 18:06:10 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [42/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.6132 (0.5772)	loss 0.8664 (1.0026)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 18:06:16 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [42/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5455 (0.5912)	loss 0.9531 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-02 18:06:18 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 42 training takes 0:00:19
[2024-12-02 18:06:19 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.654 
[2024-12-02 18:06:19 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-02 18:06:19 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-02 18:06:20 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [43/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7320 (0.7320)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-02 18:06:26 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [43/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.8100 (0.6515)	loss 1.1264 (0.9767)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.617
[2024-12-02 18:06:32 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [43/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5507 (0.6057)	loss 1.2130 (1.0191)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.781
[2024-12-02 18:06:37 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [43/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7307 (0.5872)	loss 1.1264 (1.0118)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.734
[2024-12-02 18:06:40 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 43 training takes 0:00:20
[2024-12-02 18:06:41 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.321 
[2024-12-02 18:06:41 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-02 18:06:41 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:21:00 swin_tiny_patch4_window7_224] (main.py 398): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-07 10:21:00 swin_tiny_patch4_window7_224] (main.py 399): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 10:21:00 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 10:21:01 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 2084144
[2024-12-07 10:21:01 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.141317952
[2024-12-07 10:21:01 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-07 10:21:01 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-07 10:21:02 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][0/34]	eta 0:00:40 lr 0.000004	 wd 0.0001	time 1.2028 (1.2028)	loss 1.2547 (1.2547)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 10:21:07 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.4703 (0.5773)	loss 1.0419 (1.0654)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 10:21:12 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4690 (0.5243)	loss 1.0426 (1.0304)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-07 10:21:17 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4568 (0.5377)	loss 1.1294 (1.0199)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.617
[2024-12-07 10:21:19 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 0 training takes 0:00:18
[2024-12-07 10:21:20 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.667 
[2024-12-07 10:21:20 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 10:21:20 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:21:20 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6918 (0.6918)	loss 1.2139 (1.2139)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.734
[2024-12-07 10:21:25 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][10/34]	eta 0:00:11 lr 0.000004	 wd 0.0001	time 0.4643 (0.4943)	loss 1.0400 (1.0804)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-07 10:21:31 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4712 (0.5280)	loss 1.1280 (1.0243)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 10:21:36 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4726 (0.5096)	loss 1.0399 (1.0184)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-07 10:21:37 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 1 training takes 0:00:17
[2024-12-07 10:21:38 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.564 
[2024-12-07 10:21:38 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:21:38 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:21:39 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6811 (0.6811)	loss 0.7801 (0.7801)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 10:21:44 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.4564 (0.5793)	loss 0.8670 (0.9852)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:21:49 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4608 (0.5276)	loss 0.6933 (0.9907)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:21:54 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6988 (0.5248)	loss 1.0400 (1.0122)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 10:21:56 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 2 training takes 0:00:18
[2024-12-07 10:21:57 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.603 
[2024-12-07 10:21:57 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:21:57 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:21:58 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][0/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 0.6742 (0.6742)	loss 0.8666 (0.8666)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:22:02 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][10/34]	eta 0:00:11 lr 0.000004	 wd 0.0001	time 0.4674 (0.4907)	loss 0.9533 (1.0163)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 10:22:08 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.7600 (0.5378)	loss 1.1267 (1.0028)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-07 10:22:14 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4517 (0.5431)	loss 0.7799 (1.0120)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 10:22:15 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 3 training takes 0:00:18
[2024-12-07 10:22:16 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.474 
[2024-12-07 10:22:16 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 10:22:16 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:22:17 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][0/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 0.6691 (0.6691)	loss 1.1268 (1.1268)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 10:22:22 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.6898 (0.5362)	loss 0.7799 (1.0084)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 10:22:27 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4574 (0.5280)	loss 0.8665 (0.9904)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:22:32 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4592 (0.5109)	loss 0.9531 (0.9980)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:22:34 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 4 training takes 0:00:17
[2024-12-07 10:22:35 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.423 
[2024-12-07 10:22:35 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:22:35 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:22:36 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][0/34]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.9749 (0.9749)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 10:22:41 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4538 (0.5414)	loss 0.6065 (0.8981)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:22:46 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4780 (0.5093)	loss 1.2998 (0.9904)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.773
[2024-12-07 10:22:51 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4669 (0.5279)	loss 1.1265 (1.0007)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:22:53 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 5 training takes 0:00:17
[2024-12-07 10:22:54 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.513 
[2024-12-07 10:22:54 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 10:22:54 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:22:55 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [6/50][0/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 0.6652 (0.6652)	loss 1.0398 (1.0398)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 10:22:59 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [6/50][10/34]	eta 0:00:11 lr 0.000004	 wd 0.0001	time 0.4530 (0.4865)	loss 0.8665 (0.9847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 10:23:05 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [6/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4580 (0.5272)	loss 0.8665 (0.9862)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:23:10 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [6/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4617 (0.5093)	loss 0.9532 (1.0091)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 10:23:11 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 6 training takes 0:00:17
[2024-12-07 10:23:12 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.449 
[2024-12-07 10:23:12 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:23:12 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:23:13 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [7/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6853 (0.6853)	loss 1.2132 (1.2132)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.359
[2024-12-07 10:23:19 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [7/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4775 (0.5885)	loss 1.1264 (1.0083)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.734
[2024-12-07 10:23:23 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [7/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4716 (0.5333)	loss 0.9532 (1.0151)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 10:23:29 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [7/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6876 (0.5352)	loss 1.2998 (1.0147)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.719
[2024-12-07 10:23:30 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 7 training takes 0:00:18
[2024-12-07 10:23:31 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.603 
[2024-12-07 10:23:31 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:23:31 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:23:32 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [8/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7274 (0.7274)	loss 0.7798 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 10:23:37 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [8/50][10/34]	eta 0:00:11 lr 0.000004	 wd 0.0001	time 0.4802 (0.4999)	loss 1.2997 (1.0555)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-07 10:23:43 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [8/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.6742 (0.5286)	loss 1.0398 (1.0522)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 10:23:47 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [8/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4695 (0.5117)	loss 0.9531 (1.0286)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 10:23:49 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 8 training takes 0:00:17
[2024-12-07 10:23:50 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.372 
[2024-12-07 10:23:50 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:23:50 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:23:50 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [9/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6858 (0.6858)	loss 1.3864 (1.3864)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-07 10:23:56 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [9/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.5758 (0.5872)	loss 1.0398 (1.0556)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 10:24:01 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [9/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4691 (0.5282)	loss 1.1264 (1.0192)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 10:24:06 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [9/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4783 (0.5097)	loss 1.2131 (1.0035)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 10:24:07 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 9 training takes 0:00:17
[2024-12-07 10:24:09 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.385 
[2024-12-07 10:24:09 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:24:09 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:24:10 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [10/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6809 (0.6809)	loss 1.2131 (1.2131)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:24:14 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [10/50][10/34]	eta 0:00:11 lr 0.000004	 wd 0.0001	time 0.4745 (0.4996)	loss 1.1265 (1.0634)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.695
[2024-12-07 10:24:19 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [10/50][20/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 0.6030 (0.4912)	loss 0.9531 (1.0439)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 10:24:25 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [10/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4450 (0.5112)	loss 0.6932 (1.0202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:24:26 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 10 training takes 0:00:17
[2024-12-07 10:24:27 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.397 
[2024-12-07 10:24:27 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:24:27 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:24:28 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [11/50][0/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 0.6715 (0.6715)	loss 0.7798 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 10:24:33 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [11/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.7056 (0.5415)	loss 1.2131 (0.9847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 10:24:38 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [11/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4575 (0.5362)	loss 0.9531 (1.0027)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 10:24:43 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [11/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4783 (0.5136)	loss 1.0398 (1.0063)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 10:24:45 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 11 training takes 0:00:17
[2024-12-07 10:24:46 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.436 
[2024-12-07 10:24:46 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:24:46 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:24:47 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [12/50][0/34]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.9712 (0.9712)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 10:24:52 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [12/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.4605 (0.5652)	loss 1.0398 (0.9689)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:24:57 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [12/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4897 (0.5198)	loss 1.0397 (0.9779)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 10:25:05 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [12/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4788 (0.6158)	loss 1.1264 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.695
[2024-12-07 10:25:06 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 12 training takes 0:00:20
[2024-12-07 10:25:07 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.526 
[2024-12-07 10:25:07 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 10:25:07 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:25:08 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [13/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6975 (0.6975)	loss 1.2997 (1.2997)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.336
[2024-12-07 10:25:13 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [13/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.6612 (0.5282)	loss 0.7798 (1.0634)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 10:25:19 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [13/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4873 (0.5343)	loss 0.9531 (1.0522)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:25:24 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [13/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4818 (0.5476)	loss 1.0398 (1.0202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:25:26 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 13 training takes 0:00:18
[2024-12-07 10:25:27 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.423 
[2024-12-07 10:25:27 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:25:27 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:25:28 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [14/50][0/34]	eta 0:00:31 lr 0.000004	 wd 0.0001	time 0.9374 (0.9374)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 10:25:33 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [14/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.5263 (0.5226)	loss 1.0398 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-07 10:25:38 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [14/50][20/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 0.4736 (0.4983)	loss 1.1264 (1.0068)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 10:25:44 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [14/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4771 (0.5251)	loss 1.0398 (1.0006)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.719
[2024-12-07 10:25:45 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 14 training takes 0:00:17
[2024-12-07 10:25:46 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.513 
[2024-12-07 10:25:46 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 10:25:46 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:25:47 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [15/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7045 (0.7045)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 10:25:52 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [15/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.6666 (0.5228)	loss 1.0398 (1.0240)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 10:25:58 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [15/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4551 (0.5391)	loss 0.8665 (0.9902)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 10:26:02 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [15/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4700 (0.5180)	loss 0.9531 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:26:04 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 15 training takes 0:00:17
[2024-12-07 10:26:05 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.474 
[2024-12-07 10:26:05 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 10:26:05 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:26:06 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [16/50][0/34]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.9725 (0.9725)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 10:26:11 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [16/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.4537 (0.5711)	loss 0.7798 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 10:26:16 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [16/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4795 (0.5246)	loss 1.0397 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 10:26:22 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [16/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4664 (0.5411)	loss 0.8665 (1.0118)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:26:23 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 16 training takes 0:00:18
[2024-12-07 10:26:24 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.500 
[2024-12-07 10:26:24 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 10:26:24 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:26:25 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [17/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7120 (0.7120)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 10:26:30 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [17/50][10/34]	eta 0:00:11 lr 0.000004	 wd 0.0001	time 0.4726 (0.4943)	loss 1.2997 (0.9610)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:26:35 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [17/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4646 (0.5331)	loss 0.8665 (0.9944)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 10:26:40 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [17/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4577 (0.5118)	loss 0.9531 (1.0006)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 10:26:41 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 17 training takes 0:00:17
[2024-12-07 10:26:43 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.538 
[2024-12-07 10:26:43 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 10:26:43 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:26:43 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [18/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7256 (0.7256)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 10:26:49 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [18/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4792 (0.5902)	loss 1.2997 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.664
[2024-12-07 10:26:54 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [18/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4683 (0.5332)	loss 1.1264 (0.9944)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 10:26:59 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [18/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7081 (0.5269)	loss 1.1264 (1.0006)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 10:27:01 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 18 training takes 0:00:18
[2024-12-07 10:27:02 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.436 
[2024-12-07 10:27:02 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:27:02 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:27:03 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [19/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6835 (0.6835)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 10:27:07 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [19/50][10/34]	eta 0:00:11 lr 0.000004	 wd 0.0001	time 0.4534 (0.4891)	loss 1.0397 (0.9689)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 10:27:13 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [19/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.7011 (0.5127)	loss 1.2997 (0.9944)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.391
[2024-12-07 10:27:18 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [19/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4601 (0.5095)	loss 0.9531 (1.0034)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 10:27:19 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 19 training takes 0:00:17
[2024-12-07 10:27:20 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.590 
[2024-12-07 10:27:20 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:27:20 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:27:21 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [20/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6793 (0.6793)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 10:27:27 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [20/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.7004 (0.5819)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 10:27:31 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [20/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4534 (0.5289)	loss 0.8664 (1.0067)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 10:27:36 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [20/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4802 (0.5111)	loss 1.2130 (1.0202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:27:38 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 20 training takes 0:00:17
[2024-12-07 10:27:39 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.462 
[2024-12-07 10:27:39 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 10:27:39 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:27:40 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [21/50][0/34]	eta 0:00:28 lr 0.000004	 wd 0.0001	time 0.8405 (0.8405)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-07 10:27:45 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [21/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4818 (0.5061)	loss 1.1264 (0.9137)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 10:27:50 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [21/50][20/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 0.4572 (0.4883)	loss 0.8664 (0.9655)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:27:55 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [21/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4635 (0.5161)	loss 1.1264 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 10:27:57 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 21 training takes 0:00:17
[2024-12-07 10:27:58 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.679 
[2024-12-07 10:27:58 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 10:27:58 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-07 10:27:58 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [22/50][0/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 0.6718 (0.6718)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 10:28:03 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [22/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.5854 (0.5002)	loss 1.2130 (0.9689)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:28:09 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [22/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4600 (0.5282)	loss 0.8664 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 10:28:14 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [22/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4792 (0.5082)	loss 1.2130 (1.0230)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 10:28:15 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 22 training takes 0:00:17
[2024-12-07 10:28:16 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.308 
[2024-12-07 10:28:16 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 10:28:16 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-07 10:28:17 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [23/50][0/34]	eta 0:00:30 lr 0.000004	 wd 0.0001	time 0.9098 (0.9098)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 10:28:22 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [23/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4659 (0.5905)	loss 0.7798 (0.9767)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 10:28:27 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [23/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4643 (0.5344)	loss 1.1264 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-07 10:28:33 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [23/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4848 (0.5459)	loss 1.0398 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 10:28:35 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 23 training takes 0:00:18
[2024-12-07 10:28:36 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.564 
[2024-12-07 10:28:36 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:28:36 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-07 10:28:37 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [24/50][0/34]	eta 0:00:31 lr 0.000004	 wd 0.0001	time 0.9158 (0.9158)	loss 0.7798 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 10:28:42 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [24/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4611 (0.5160)	loss 1.0397 (1.0004)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 10:28:48 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [24/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4750 (0.5419)	loss 1.2130 (1.0109)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 10:28:52 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [24/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4629 (0.5183)	loss 0.9531 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:28:54 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 24 training takes 0:00:17
[2024-12-07 10:28:55 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.679 
[2024-12-07 10:28:55 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 10:28:55 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-07 10:28:55 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [25/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6930 (0.6930)	loss 1.2130 (1.2130)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.734
[2024-12-07 10:29:01 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [25/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4664 (0.5854)	loss 1.1264 (1.0555)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.617
[2024-12-07 10:29:06 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [25/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4829 (0.5327)	loss 1.1264 (1.0315)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-07 10:29:12 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [25/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6806 (0.5432)	loss 0.9531 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:29:13 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 25 training takes 0:00:18
[2024-12-07 10:29:14 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.513 
[2024-12-07 10:29:14 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 10:29:14 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-07 10:29:15 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [26/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6798 (0.6798)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 10:29:20 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [26/50][10/34]	eta 0:00:11 lr 0.000004	 wd 0.0001	time 0.4662 (0.4995)	loss 1.0397 (1.0003)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 10:29:25 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [26/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4842 (0.5334)	loss 1.1264 (0.9655)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 10:29:30 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [26/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4666 (0.5134)	loss 1.1264 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 10:29:31 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 26 training takes 0:00:17
[2024-12-07 10:29:32 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.615 
[2024-12-07 10:29:32 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:29:32 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-07 10:29:33 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [27/50][0/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 0.6664 (0.6664)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:29:39 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [27/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4726 (0.5910)	loss 1.1264 (0.9610)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.695
[2024-12-07 10:29:44 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [27/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4812 (0.5360)	loss 0.9531 (0.9985)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 10:29:49 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [27/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6958 (0.5218)	loss 1.2130 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:29:51 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 27 training takes 0:00:18
[2024-12-07 10:29:52 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.410 
[2024-12-07 10:29:52 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:29:52 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-07 10:29:53 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [28/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6912 (0.6912)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:29:57 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [28/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4572 (0.5088)	loss 0.5199 (1.0082)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 10:30:03 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [28/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.7254 (0.5225)	loss 1.1264 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.734
[2024-12-07 10:30:08 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [28/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4716 (0.5219)	loss 0.8665 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:30:10 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 28 training takes 0:00:17
[2024-12-07 10:30:11 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.615 
[2024-12-07 10:30:11 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:30:11 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-07 10:30:11 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [29/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6829 (0.6829)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:30:17 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [29/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.6802 (0.6045)	loss 1.0397 (1.0240)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 10:30:22 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [29/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4699 (0.5448)	loss 1.0397 (0.9820)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 10:30:27 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [29/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4786 (0.5252)	loss 1.2130 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.641
[2024-12-07 10:30:29 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 29 training takes 0:00:18
[2024-12-07 10:30:30 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.385 
[2024-12-07 10:30:30 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:30:30 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.68%
[2024-12-07 10:30:31 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [30/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7016 (0.7016)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 10:30:36 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [30/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.5091 (0.5022)	loss 0.6065 (0.9373)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 10:30:41 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [30/50][20/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 0.6494 (0.4949)	loss 1.0397 (0.9613)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 10:30:46 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [30/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4679 (0.5172)	loss 1.0398 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-07 10:30:48 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 30 training takes 0:00:17
[2024-12-07 10:30:49 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.718 
[2024-12-07 10:30:49 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 10:30:49 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-07 10:30:50 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [31/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6961 (0.6961)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 10:30:55 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [31/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.7333 (0.5639)	loss 1.2997 (1.0161)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:31:00 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [31/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4707 (0.5397)	loss 1.0397 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 10:31:05 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [31/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4695 (0.5175)	loss 0.8664 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 10:31:06 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 31 training takes 0:00:17
[2024-12-07 10:31:08 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.397 
[2024-12-07 10:31:08 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:31:08 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-07 10:31:09 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [32/50][0/34]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.9931 (0.9931)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.430
[2024-12-07 10:31:14 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [32/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.4672 (0.5510)	loss 0.8664 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 10:31:19 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [32/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4923 (0.5125)	loss 1.0397 (0.9902)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 10:31:24 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [32/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4595 (0.5307)	loss 0.9531 (1.0118)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 10:31:26 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 32 training takes 0:00:17
[2024-12-07 10:31:27 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.551 
[2024-12-07 10:31:27 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:31:27 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-07 10:31:27 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [33/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6767 (0.6767)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:31:32 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [33/50][10/34]	eta 0:00:11 lr 0.000004	 wd 0.0001	time 0.4675 (0.4919)	loss 0.9531 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 10:31:38 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [33/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4626 (0.5323)	loss 0.8664 (0.9943)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 10:31:43 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [33/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4700 (0.5129)	loss 0.7798 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:31:44 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 33 training takes 0:00:17
[2024-12-07 10:31:45 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.641 
[2024-12-07 10:31:45 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:31:45 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-07 10:31:46 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [34/50][0/34]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 0.7995 (0.7995)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 10:31:53 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [34/50][10/34]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.6224 (0.6844)	loss 0.8664 (1.0555)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 10:31:57 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [34/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4659 (0.5845)	loss 0.9531 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.570
[2024-12-07 10:32:03 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [34/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4626 (0.5797)	loss 0.6931 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:32:05 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 34 training takes 0:00:19
[2024-12-07 10:32:06 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.436 
[2024-12-07 10:32:06 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:32:06 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-07 10:32:06 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [35/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6774 (0.6774)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 10:32:11 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [35/50][10/34]	eta 0:00:11 lr 0.000004	 wd 0.0001	time 0.4602 (0.4941)	loss 0.9531 (0.9846)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 10:32:17 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [35/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4652 (0.5294)	loss 1.0397 (0.9861)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 10:32:21 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [35/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4683 (0.5115)	loss 1.0397 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:32:23 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 35 training takes 0:00:17
[2024-12-07 10:32:24 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.333 
[2024-12-07 10:32:24 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 10:32:24 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-07 10:32:25 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [36/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6834 (0.6834)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 10:32:30 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [36/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4771 (0.5865)	loss 1.1264 (1.0712)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-07 10:32:35 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [36/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4545 (0.5307)	loss 0.7798 (1.0232)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 10:32:41 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [36/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6953 (0.5410)	loss 0.9531 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:32:42 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 36 training takes 0:00:18
[2024-12-07 10:32:43 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.462 
[2024-12-07 10:32:43 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 10:32:43 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-07 10:32:44 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [37/50][0/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 0.6739 (0.6739)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 10:32:49 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [37/50][10/34]	eta 0:00:11 lr 0.000004	 wd 0.0001	time 0.4822 (0.4991)	loss 1.2130 (1.0003)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 10:32:55 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [37/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.5499 (0.5319)	loss 0.9531 (1.0067)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.430
[2024-12-07 10:32:59 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [37/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4686 (0.5119)	loss 1.2130 (1.0118)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.359
[2024-12-07 10:33:01 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 37 training takes 0:00:17
[2024-12-07 10:33:02 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.577 
[2024-12-07 10:33:02 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:33:02 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-07 10:33:02 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [38/50][0/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 0.6704 (0.6704)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 10:33:08 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [38/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4686 (0.5866)	loss 1.1264 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-07 10:33:13 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [38/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4698 (0.5313)	loss 0.9531 (1.0026)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 10:33:18 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [38/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4796 (0.5123)	loss 0.7798 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 10:33:20 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 38 training takes 0:00:18
[2024-12-07 10:33:21 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.590 
[2024-12-07 10:33:21 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:33:21 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-07 10:33:22 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [39/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6938 (0.6938)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 10:33:27 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [39/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4842 (0.5135)	loss 0.7798 (0.9452)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 10:33:32 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [39/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.7147 (0.5174)	loss 1.0397 (1.0067)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 10:33:37 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [39/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4873 (0.5218)	loss 1.0397 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:33:39 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 39 training takes 0:00:17
[2024-12-07 10:33:40 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.410 
[2024-12-07 10:33:40 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:33:40 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-07 10:33:40 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [40/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6910 (0.6910)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:33:46 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [40/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.6904 (0.5673)	loss 0.9531 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 10:33:51 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [40/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4645 (0.5334)	loss 1.0397 (1.0356)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-07 10:33:56 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [40/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4778 (0.5123)	loss 0.7798 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 10:33:57 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 40 training takes 0:00:17
[2024-12-07 10:33:59 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.679 
[2024-12-07 10:33:59 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 10:33:59 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.72%
[2024-12-07 10:34:00 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [41/50][0/34]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.9843 (0.9843)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 10:34:05 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [41/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.4955 (0.5508)	loss 1.1264 (1.0240)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 10:34:10 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [41/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4725 (0.5262)	loss 0.8664 (0.9861)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 10:34:15 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [41/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4713 (0.5410)	loss 1.0397 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:34:17 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 41 training takes 0:00:18
[2024-12-07 10:34:18 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.731 
[2024-12-07 10:34:18 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 10:34:18 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:34:19 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [42/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6792 (0.6792)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.617
[2024-12-07 10:34:24 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [42/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.6824 (0.5228)	loss 1.1264 (1.0082)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 10:34:29 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [42/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4662 (0.5331)	loss 0.8664 (1.0026)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:34:34 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [42/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4755 (0.5141)	loss 0.9531 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:34:35 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 42 training takes 0:00:17
[2024-12-07 10:34:36 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.654 
[2024-12-07 10:34:36 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 10:34:36 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:34:37 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [43/50][0/34]	eta 0:00:32 lr 0.000004	 wd 0.0001	time 0.9630 (0.9630)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 10:34:43 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [43/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.4631 (0.5717)	loss 1.1264 (0.9767)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.617
[2024-12-07 10:34:47 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [43/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4677 (0.5246)	loss 1.2130 (1.0191)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.781
[2024-12-07 10:34:53 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [43/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4809 (0.5407)	loss 1.1264 (1.0118)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.734
[2024-12-07 10:34:55 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 43 training takes 0:00:18
[2024-12-07 10:34:56 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.321 
[2024-12-07 10:34:56 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 10:34:56 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:37:07 swin_tiny_patch4_window7_224] (main.py 398): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-07 10:37:07 swin_tiny_patch4_window7_224] (main.py 399): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 10:37:07 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 10:37:07 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 2084144
[2024-12-07 10:37:07 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.141317952
[2024-12-07 10:37:07 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-07 10:37:07 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-07 10:37:08 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][0/34]	eta 0:00:28 lr 0.000004	 wd 0.0001	time 0.8305 (0.8305)	loss 0.9830 (0.9830)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 10:37:14 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.7643 (0.5883)	loss 1.3025 (1.0092)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.391
[2024-12-07 10:37:19 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4720 (0.5529)	loss 0.9546 (0.9969)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 10:37:24 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4743 (0.5290)	loss 1.2162 (1.0198)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 10:37:25 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 0 training takes 0:00:17
[2024-12-07 10:37:27 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.615 
[2024-12-07 10:37:27 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:37:27 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.62%
[2024-12-07 10:37:28 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][0/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.1004 (1.1004)	loss 1.1272 (1.1272)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.695
[2024-12-07 10:37:33 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.4795 (0.5548)	loss 1.2135 (1.0565)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-07 10:37:38 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4795 (0.5194)	loss 1.2146 (1.0200)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:37:43 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4611 (0.5410)	loss 0.6936 (1.0099)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:37:45 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 1 training takes 0:00:18
[2024-12-07 10:37:46 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.526 
[2024-12-07 10:37:46 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 10:37:46 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.62%
[2024-12-07 10:37:47 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6810 (0.6810)	loss 1.0400 (1.0400)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 10:37:52 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4905 (0.5013)	loss 1.0404 (1.0483)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 10:37:57 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4697 (0.5370)	loss 1.0400 (1.0155)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 10:38:02 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4724 (0.5167)	loss 0.6937 (0.9926)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:38:04 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 2 training takes 0:00:17
[2024-12-07 10:38:05 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.628 
[2024-12-07 10:38:05 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:38:05 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 10:38:05 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][0/34]	eta 0:00:30 lr 0.000004	 wd 0.0001	time 0.9022 (0.9022)	loss 1.2133 (1.2133)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.641
[2024-12-07 10:38:11 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4806 (0.5956)	loss 0.9533 (1.0794)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 10:38:16 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4682 (0.5355)	loss 0.9534 (1.0276)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:38:22 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7298 (0.5683)	loss 0.8665 (1.0176)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:38:24 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 3 training takes 0:00:19
[2024-12-07 10:38:25 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.308 
[2024-12-07 10:38:25 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 10:38:25 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 10:38:26 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6975 (0.6975)	loss 1.0402 (1.0402)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 10:38:31 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][10/34]	eta 0:00:11 lr 0.000004	 wd 0.0001	time 0.4747 (0.4977)	loss 1.1265 (0.9690)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 10:38:37 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4761 (0.5384)	loss 0.9532 (0.9821)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:38:41 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4813 (0.5218)	loss 1.0398 (1.0175)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 10:38:43 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 4 training takes 0:00:17
[2024-12-07 10:38:44 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.385 
[2024-12-07 10:38:44 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:38:44 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 10:38:45 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7140 (0.7140)	loss 0.7799 (0.7799)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 10:38:51 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4670 (0.5975)	loss 0.8665 (1.0635)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 10:38:55 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4773 (0.5390)	loss 1.0398 (1.0151)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 10:39:01 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7377 (0.5368)	loss 1.1265 (1.0091)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 10:39:02 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 5 training takes 0:00:18
[2024-12-07 10:39:04 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.513 
[2024-12-07 10:39:04 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 10:39:04 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 10:39:04 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [6/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6803 (0.6803)	loss 1.0399 (1.0399)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 10:39:09 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [6/50][10/34]	eta 0:00:11 lr 0.000004	 wd 0.0001	time 0.4728 (0.4982)	loss 1.1266 (1.0477)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-07 10:39:15 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [6/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.6993 (0.5336)	loss 0.7799 (1.0316)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 10:39:20 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [6/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4694 (0.5191)	loss 0.8665 (1.0258)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 10:39:21 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 6 training takes 0:00:17
[2024-12-07 10:39:22 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.462 
[2024-12-07 10:39:22 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 10:39:22 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 10:39:23 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [7/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6897 (0.6897)	loss 1.2998 (1.2998)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.336
[2024-12-07 10:39:29 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [7/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4950 (0.5914)	loss 0.7799 (0.9926)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 10:39:33 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [7/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4778 (0.5369)	loss 0.8665 (1.0109)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 10:39:38 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [7/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4874 (0.5197)	loss 1.0398 (1.0119)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 10:39:40 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 7 training takes 0:00:18
[2024-12-07 10:39:42 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.603 
[2024-12-07 10:39:42 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:39:42 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 10:39:42 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [8/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7056 (0.7056)	loss 1.0398 (1.0398)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 10:39:47 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [8/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4726 (0.5045)	loss 1.0398 (1.0241)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 10:39:52 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [8/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.6880 (0.5083)	loss 0.9531 (1.0357)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:39:58 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [8/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4756 (0.5192)	loss 0.7799 (1.0035)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 10:39:59 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 8 training takes 0:00:17
[2024-12-07 10:40:00 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.372 
[2024-12-07 10:40:00 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:40:00 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 10:40:01 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [9/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6886 (0.6886)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:40:07 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [9/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.6932 (0.5636)	loss 1.0398 (1.0083)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 10:40:12 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [9/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4754 (0.5425)	loss 1.1264 (1.0109)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 10:40:17 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [9/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4763 (0.5211)	loss 1.0398 (1.0202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:40:18 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 9 training takes 0:00:17
[2024-12-07 10:40:20 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.385 
[2024-12-07 10:40:20 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:40:20 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 10:40:21 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [10/50][0/34]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.9911 (0.9911)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 10:40:25 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [10/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4897 (0.5395)	loss 1.2131 (1.0004)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.734
[2024-12-07 10:40:30 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [10/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4703 (0.5085)	loss 1.1264 (1.0109)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 10:40:36 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [10/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4795 (0.5308)	loss 1.1264 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 10:40:37 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 10 training takes 0:00:17
[2024-12-07 10:40:39 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.449 
[2024-12-07 10:40:39 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:40:39 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 10:40:39 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [11/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7144 (0.7144)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 10:40:44 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [11/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4929 (0.5117)	loss 0.8665 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:40:50 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [11/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4853 (0.5438)	loss 0.8665 (1.0233)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 10:40:55 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [11/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4836 (0.5216)	loss 1.1264 (1.0118)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 10:40:56 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 11 training takes 0:00:17
[2024-12-07 10:40:57 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.474 
[2024-12-07 10:40:57 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 10:40:57 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 10:40:58 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [12/50][0/34]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 1.0035 (1.0035)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 10:41:04 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [12/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4665 (0.5932)	loss 0.8665 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 10:41:08 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [12/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4960 (0.5380)	loss 1.1264 (1.0026)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 10:41:14 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [12/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4709 (0.5526)	loss 1.2131 (1.0006)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 10:41:16 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 12 training takes 0:00:18
[2024-12-07 10:41:17 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.538 
[2024-12-07 10:41:17 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 10:41:17 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 10:41:18 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [13/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7058 (0.7058)	loss 1.3864 (1.3864)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 10:41:22 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [13/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4704 (0.5058)	loss 1.0397 (1.1028)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:41:28 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [13/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4749 (0.5407)	loss 0.8665 (1.0439)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:41:33 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [13/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4603 (0.5186)	loss 0.7798 (1.0118)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 10:41:34 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 13 training takes 0:00:17
[2024-12-07 10:41:36 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.423 
[2024-12-07 10:41:36 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:41:36 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 10:41:37 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [14/50][0/34]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 1.0194 (1.0194)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 10:41:43 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [14/50][10/34]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.4749 (0.6965)	loss 1.0397 (1.0319)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 10:41:48 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [14/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4889 (0.5939)	loss 1.0397 (1.0356)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 10:41:53 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [14/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7119 (0.5776)	loss 0.9531 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:41:55 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 14 training takes 0:00:19
[2024-12-07 10:41:56 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.513 
[2024-12-07 10:41:56 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 10:41:56 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 10:41:57 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [15/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7046 (0.7046)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 10:42:02 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [15/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4901 (0.5038)	loss 1.2130 (1.0319)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.359
[2024-12-07 10:42:08 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [15/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.6992 (0.5385)	loss 1.0397 (1.0191)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 10:42:12 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [15/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4768 (0.5201)	loss 1.2131 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 10:42:14 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 15 training takes 0:00:17
[2024-12-07 10:42:15 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.615 
[2024-12-07 10:42:15 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:42:15 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 10:42:16 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [16/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7100 (0.7100)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 10:42:22 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [16/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4987 (0.5952)	loss 1.2130 (1.0634)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 10:42:26 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [16/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4644 (0.5371)	loss 0.9531 (1.0026)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:42:31 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [16/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6069 (0.5224)	loss 0.8665 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:42:33 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 16 training takes 0:00:18
[2024-12-07 10:42:35 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.564 
[2024-12-07 10:42:35 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:42:35 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 10:42:35 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [17/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7009 (0.7009)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 10:42:40 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [17/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4804 (0.5009)	loss 1.1264 (1.0161)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 10:42:45 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [17/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.7012 (0.5124)	loss 0.9532 (1.0274)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 10:42:51 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [17/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4847 (0.5197)	loss 1.1264 (1.0202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 10:42:52 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 17 training takes 0:00:17
[2024-12-07 10:42:53 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.436 
[2024-12-07 10:42:53 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:42:53 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 10:42:54 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [18/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6923 (0.6923)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:42:59 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [18/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.7000 (0.5695)	loss 0.8665 (0.9689)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 10:43:04 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [18/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4765 (0.5360)	loss 1.1264 (0.9737)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 10:43:09 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [18/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4975 (0.5177)	loss 1.2998 (0.9978)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-07 10:43:11 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 18 training takes 0:00:17
[2024-12-07 10:43:12 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.474 
[2024-12-07 10:43:12 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 10:43:12 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 10:43:13 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [19/50][0/34]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.9934 (0.9934)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.570
[2024-12-07 10:43:18 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [19/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4682 (0.5286)	loss 0.9531 (1.0476)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 10:43:23 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [19/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4822 (0.5053)	loss 0.8665 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 10:43:29 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [19/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4728 (0.5282)	loss 0.8665 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 10:43:30 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 19 training takes 0:00:17
[2024-12-07 10:43:31 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.615 
[2024-12-07 10:43:31 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:43:31 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 10:43:32 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [20/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7081 (0.7081)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 10:43:37 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [20/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.6675 (0.5227)	loss 0.7798 (1.0004)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 10:43:43 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [20/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4734 (0.5445)	loss 1.2131 (1.0521)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:43:48 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [20/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4909 (0.5231)	loss 1.2130 (1.0258)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:43:49 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 20 training takes 0:00:17
[2024-12-07 10:43:50 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.654 
[2024-12-07 10:43:50 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 10:43:50 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.65%
[2024-12-07 10:43:51 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [21/50][0/34]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 1.0046 (1.0046)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 10:43:56 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [21/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.4548 (0.5653)	loss 0.6932 (0.9452)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:44:01 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [21/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4837 (0.5222)	loss 1.2130 (0.9861)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:44:07 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [21/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4689 (0.5390)	loss 1.0397 (0.9894)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 10:44:08 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 21 training takes 0:00:18
[2024-12-07 10:44:09 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.667 
[2024-12-07 10:44:09 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 10:44:09 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:44:10 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [22/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6840 (0.6840)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:44:15 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [22/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4765 (0.5026)	loss 0.9531 (1.0082)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:44:21 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [22/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4843 (0.5397)	loss 1.2130 (1.0315)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:44:26 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [22/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4778 (0.5200)	loss 0.6065 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 10:44:27 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 22 training takes 0:00:17
[2024-12-07 10:44:28 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.269 
[2024-12-07 10:44:28 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 10:44:28 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:44:29 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [23/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6847 (0.6847)	loss 0.7799 (0.7799)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 10:44:35 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [23/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4947 (0.5959)	loss 1.1264 (1.0398)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-07 10:44:39 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [23/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4860 (0.5413)	loss 1.1264 (1.0398)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 10:44:45 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [23/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6968 (0.5531)	loss 1.0397 (1.0202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 10:44:47 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 23 training takes 0:00:18
[2024-12-07 10:44:48 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.474 
[2024-12-07 10:44:48 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 10:44:48 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.67%
[2024-12-07 10:44:48 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [24/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6939 (0.6939)	loss 1.0398 (1.0398)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 10:44:54 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [24/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.5134 (0.6003)	loss 1.1264 (1.0476)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 10:45:00 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [24/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4641 (0.5888)	loss 0.8665 (1.0026)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 10:45:05 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [24/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4936 (0.5553)	loss 1.2997 (1.0202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-07 10:45:06 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 24 training takes 0:00:18
[2024-12-07 10:45:08 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.731 
[2024-12-07 10:45:08 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 10:45:08 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:45:08 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [25/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7037 (0.7037)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 10:45:14 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [25/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4753 (0.6002)	loss 0.8665 (1.0161)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 10:45:19 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [25/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4932 (0.5455)	loss 0.8664 (1.0232)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 10:45:25 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [25/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6978 (0.5557)	loss 0.9531 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:45:26 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 25 training takes 0:00:18
[2024-12-07 10:45:27 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.333 
[2024-12-07 10:45:27 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 10:45:27 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:45:28 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [26/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7068 (0.7068)	loss 0.7798 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 10:45:33 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [26/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4800 (0.5030)	loss 0.9531 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 10:45:39 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [26/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4675 (0.5399)	loss 0.8665 (0.9943)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 10:45:43 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [26/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4721 (0.5209)	loss 1.0397 (1.0006)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 10:45:45 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 26 training takes 0:00:17
[2024-12-07 10:45:46 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.603 
[2024-12-07 10:45:46 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:45:46 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:45:47 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [27/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6935 (0.6935)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 10:45:53 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [27/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4774 (0.5971)	loss 0.7798 (1.0634)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:45:57 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [27/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4790 (0.5382)	loss 1.2130 (1.0232)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.641
[2024-12-07 10:46:03 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [27/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7090 (0.5316)	loss 1.2130 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 10:46:05 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 27 training takes 0:00:18
[2024-12-07 10:46:06 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.590 
[2024-12-07 10:46:06 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:46:06 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:46:06 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [28/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6946 (0.6946)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 10:46:11 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [28/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4692 (0.5031)	loss 0.8664 (1.0634)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:46:17 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [28/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.7151 (0.5280)	loss 1.2130 (1.0562)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.734
[2024-12-07 10:46:22 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [28/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4816 (0.5184)	loss 0.7798 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 10:46:23 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 28 training takes 0:00:17
[2024-12-07 10:46:24 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.526 
[2024-12-07 10:46:24 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 10:46:24 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:46:25 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [29/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7252 (0.7252)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 10:46:31 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [29/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.5862 (0.6007)	loss 0.6932 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:46:36 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [29/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4688 (0.5408)	loss 0.8664 (0.9902)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 10:46:40 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [29/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4866 (0.5202)	loss 1.1264 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 10:46:42 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 29 training takes 0:00:18
[2024-12-07 10:46:44 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.462 
[2024-12-07 10:46:44 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 10:46:44 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:46:45 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [30/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7086 (0.7086)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:46:49 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [30/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4794 (0.5030)	loss 1.1264 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 10:46:54 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [30/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.6668 (0.5021)	loss 1.1264 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 10:47:00 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [30/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4942 (0.5211)	loss 1.1264 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-07 10:47:01 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 30 training takes 0:00:17
[2024-12-07 10:47:03 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.731 
[2024-12-07 10:47:03 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 10:47:03 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:47:03 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [31/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7035 (0.7035)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 10:47:09 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [31/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.7089 (0.5515)	loss 1.1264 (1.0791)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 10:47:14 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [31/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.5094 (0.5406)	loss 1.1264 (1.0232)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-07 10:47:19 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [31/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4883 (0.5211)	loss 1.1264 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 10:47:20 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 31 training takes 0:00:17
[2024-12-07 10:47:22 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.269 
[2024-12-07 10:47:22 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 10:47:22 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:47:23 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [32/50][0/34]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 1.0025 (1.0025)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.391
[2024-12-07 10:47:28 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [32/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4793 (0.5352)	loss 1.2130 (1.0555)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.359
[2024-12-07 10:47:32 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [32/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4879 (0.5067)	loss 1.2130 (1.0067)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:47:38 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [32/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4758 (0.5304)	loss 1.0397 (1.0034)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 10:47:40 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 32 training takes 0:00:17
[2024-12-07 10:47:41 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.603 
[2024-12-07 10:47:41 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:47:41 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:47:41 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [33/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6892 (0.6892)	loss 0.7798 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:47:46 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [33/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.5246 (0.5134)	loss 0.9531 (1.0319)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.570
[2024-12-07 10:47:52 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [33/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4865 (0.5400)	loss 1.1264 (0.9985)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:47:57 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [33/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4728 (0.5192)	loss 1.0397 (1.0006)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 10:47:58 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 33 training takes 0:00:17
[2024-12-07 10:47:59 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.551 
[2024-12-07 10:47:59 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:47:59 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:48:00 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [34/50][0/34]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 1.0219 (1.0219)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 10:48:06 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [34/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4843 (0.5924)	loss 1.0397 (1.0634)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 10:48:12 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [34/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4745 (0.5862)	loss 1.0397 (1.0315)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 10:48:17 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [34/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4635 (0.5835)	loss 0.9531 (1.0286)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 10:48:19 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 34 training takes 0:00:19
[2024-12-07 10:48:20 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.449 
[2024-12-07 10:48:20 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:48:20 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:48:21 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [35/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7098 (0.7098)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:48:26 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [35/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4763 (0.5076)	loss 1.0397 (1.0161)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:48:31 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [35/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4625 (0.5394)	loss 1.0397 (1.0026)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 10:48:36 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [35/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4741 (0.5200)	loss 1.0397 (0.9950)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 10:48:38 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 35 training takes 0:00:17
[2024-12-07 10:48:39 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.346 
[2024-12-07 10:48:39 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 10:48:39 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:48:40 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [36/50][0/34]	eta 0:00:30 lr 0.000004	 wd 0.0001	time 0.9082 (0.9082)	loss 1.2997 (1.2997)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.336
[2024-12-07 10:48:45 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [36/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4827 (0.5951)	loss 0.7798 (1.0319)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 10:48:50 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [36/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4765 (0.5387)	loss 1.1264 (1.0356)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.617
[2024-12-07 10:48:56 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [36/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4862 (0.5517)	loss 0.7798 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:48:57 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 36 training takes 0:00:18
[2024-12-07 10:48:58 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.333 
[2024-12-07 10:48:58 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 10:48:58 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:48:59 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [37/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7006 (0.7006)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 10:49:04 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [37/50][10/34]	eta 0:00:11 lr 0.000004	 wd 0.0001	time 0.4924 (0.4992)	loss 1.2130 (0.9610)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.641
[2024-12-07 10:49:10 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [37/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4780 (0.5345)	loss 1.2997 (0.9820)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-07 10:49:14 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [37/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4834 (0.5157)	loss 0.8664 (1.0034)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 10:49:16 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 37 training takes 0:00:17
[2024-12-07 10:49:17 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.423 
[2024-12-07 10:49:17 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:49:17 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:49:18 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [38/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7047 (0.7047)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 10:49:23 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [38/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4876 (0.5960)	loss 1.2997 (1.0240)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.445
[2024-12-07 10:49:28 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [38/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4640 (0.5389)	loss 1.0397 (1.0274)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 10:49:34 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [38/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6769 (0.5420)	loss 0.7798 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 10:49:35 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 38 training takes 0:00:18
[2024-12-07 10:49:36 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.474 
[2024-12-07 10:49:36 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 10:49:36 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:49:37 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [39/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6946 (0.6946)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 10:49:42 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [39/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4671 (0.5027)	loss 0.8664 (1.0319)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 10:49:48 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [39/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.6872 (0.5407)	loss 0.9531 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.664
[2024-12-07 10:49:53 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [39/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4820 (0.5214)	loss 1.0397 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 10:49:54 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 39 training takes 0:00:17
[2024-12-07 10:49:55 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.397 
[2024-12-07 10:49:55 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:49:55 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:49:56 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [40/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7006 (0.7006)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 10:50:02 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [40/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4846 (0.5941)	loss 1.1264 (0.9767)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 10:50:07 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [40/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4705 (0.5414)	loss 0.8664 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 10:50:11 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [40/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6326 (0.5258)	loss 1.1264 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 10:50:14 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 40 training takes 0:00:18
[2024-12-07 10:50:15 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.705 
[2024-12-07 10:50:15 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 10:50:15 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:50:16 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [41/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7020 (0.7020)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 10:50:20 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [41/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4641 (0.5010)	loss 1.0397 (1.0161)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 10:50:26 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [41/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.6932 (0.5140)	loss 0.7798 (1.0232)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 10:50:31 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [41/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4733 (0.5190)	loss 0.8664 (1.0230)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:50:32 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 41 training takes 0:00:17
[2024-12-07 10:50:33 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.731 
[2024-12-07 10:50:33 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 10:50:33 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:50:34 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [42/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7308 (0.7308)	loss 1.2130 (1.2130)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.781
[2024-12-07 10:50:40 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [42/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.7325 (0.5851)	loss 1.1264 (1.1342)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:50:45 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [42/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4840 (0.5409)	loss 0.8664 (1.0521)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:50:50 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [42/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4780 (0.5217)	loss 0.9531 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 10:50:51 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 42 training takes 0:00:17
[2024-12-07 10:50:53 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.731 
[2024-12-07 10:50:53 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 10:50:53 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:50:54 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [43/50][0/34]	eta 0:00:29 lr 0.000004	 wd 0.0001	time 0.8586 (0.8586)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 10:50:59 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [43/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4543 (0.5171)	loss 0.6932 (1.0161)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:51:03 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [43/50][20/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 0.4683 (0.4985)	loss 0.8664 (1.0067)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 10:51:09 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [43/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4710 (0.5268)	loss 1.1264 (1.0230)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 10:51:11 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 43 training takes 0:00:17
[2024-12-07 10:51:12 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.333 
[2024-12-07 10:51:12 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 10:51:12 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:51:12 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [44/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6912 (0.6912)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 10:51:18 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [44/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.6937 (0.5323)	loss 0.8664 (0.9767)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 10:51:23 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [44/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4790 (0.5413)	loss 0.9531 (0.9985)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:51:29 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [44/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4781 (0.5535)	loss 1.1264 (1.0202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 10:51:31 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 44 training takes 0:00:18
[2024-12-07 10:51:32 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.615 
[2024-12-07 10:51:32 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:51:32 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:51:33 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [45/50][0/34]	eta 0:00:30 lr 0.000004	 wd 0.0001	time 0.9105 (0.9105)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 10:51:38 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [45/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4944 (0.5214)	loss 1.0397 (0.9373)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-07 10:51:43 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [45/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4724 (0.5018)	loss 0.9531 (0.9820)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 10:51:49 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [45/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4684 (0.5286)	loss 1.1264 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-07 10:51:50 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 45 training takes 0:00:17
[2024-12-07 10:51:51 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.615 
[2024-12-07 10:51:51 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:51:51 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:51:52 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [46/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7036 (0.7036)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:51:57 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [46/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.6890 (0.5194)	loss 1.2130 (1.0003)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 10:52:02 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [46/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4656 (0.5372)	loss 0.7798 (0.9778)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 10:52:07 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [46/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4689 (0.5180)	loss 1.1264 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 10:52:09 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 46 training takes 0:00:17
[2024-12-07 10:52:10 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.423 
[2024-12-07 10:52:10 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 10:52:10 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:52:11 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [47/50][0/34]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 1.0190 (1.0190)	loss 1.2130 (1.2130)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:52:16 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [47/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.5085 (0.5779)	loss 0.9531 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 10:52:21 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [47/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4888 (0.5298)	loss 1.1264 (1.0191)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 10:52:27 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [47/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4924 (0.5454)	loss 1.1264 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 10:52:28 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 47 training takes 0:00:18
[2024-12-07 10:52:29 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.628 
[2024-12-07 10:52:29 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 10:52:29 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:52:30 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [48/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7287 (0.7287)	loss 1.2997 (1.2997)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.336
[2024-12-07 10:52:35 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [48/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4803 (0.5035)	loss 1.0397 (1.0476)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 10:52:41 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [48/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4867 (0.5406)	loss 1.1264 (0.9902)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 10:52:45 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [48/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4866 (0.5205)	loss 1.1264 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-07 10:52:47 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 48 training takes 0:00:17
[2024-12-07 10:52:48 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.679 
[2024-12-07 10:52:48 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 10:52:48 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:52:49 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [49/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7240 (0.7240)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.570
[2024-12-07 10:52:54 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [49/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4748 (0.5898)	loss 1.2130 (0.9058)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.266
[2024-12-07 10:52:59 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [49/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4794 (0.5361)	loss 1.2997 (0.9820)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.172
[2024-12-07 10:53:05 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [49/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6549 (0.5502)	loss 1.2130 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 10:53:06 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 49 training takes 0:00:18
[2024-12-07 10:53:08 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.538 
[2024-12-07 10:53:08 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 10:53:08 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.73%
[2024-12-07 10:53:08 swin_tiny_patch4_window7_224] (main.py 175): INFO Training time 0:16:00
[2024-12-07 12:08:05 swin_tiny_patch4_window7_224] (main.py 398): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-07 12:08:05 swin_tiny_patch4_window7_224] (main.py 399): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 12:08:05 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 12:08:05 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 2084144
[2024-12-07 12:08:05 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.141317952
[2024-12-07 12:08:05 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-07 12:08:05 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-07 12:08:06 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][0/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.0938 (1.0938)	loss 0.9830 (0.9830)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 12:08:12 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4747 (0.6248)	loss 1.3025 (1.0092)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.391
[2024-12-07 12:08:17 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4694 (0.5521)	loss 0.9546 (0.9969)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 12:08:23 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [0/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4671 (0.5611)	loss 1.2162 (1.0198)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 12:08:24 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 0 training takes 0:00:18
[2024-12-07 12:08:25 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.615 
[2024-12-07 12:08:25 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 12:08:25 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.62%
[2024-12-07 12:08:26 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][0/34]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 0.7946 (0.7946)	loss 1.1272 (1.1272)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.695
[2024-12-07 12:08:31 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4799 (0.5138)	loss 1.2135 (1.0565)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-07 12:08:37 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4983 (0.5458)	loss 1.2146 (1.0200)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:08:41 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [1/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4899 (0.5235)	loss 0.6936 (1.0099)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:08:43 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 1 training takes 0:00:17
[2024-12-07 12:08:44 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.526 
[2024-12-07 12:08:44 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 12:08:44 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.62%
[2024-12-07 12:08:45 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7068 (0.7068)	loss 1.0400 (1.0400)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 12:08:50 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4820 (0.6031)	loss 1.0404 (1.0483)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 12:08:57 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][20/34]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4808 (0.6455)	loss 1.0400 (1.0155)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 12:09:03 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [2/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4505 (0.6235)	loss 0.6937 (0.9926)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:09:05 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 2 training takes 0:00:20
[2024-12-07 12:09:06 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.628 
[2024-12-07 12:09:06 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 12:09:06 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 12:09:06 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7042 (0.7042)	loss 1.2133 (1.2133)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.641
[2024-12-07 12:09:11 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.5121 (0.5079)	loss 0.9533 (1.0794)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 12:09:17 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4751 (0.5404)	loss 0.9534 (1.0276)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:09:24 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [3/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.8082 (0.5738)	loss 0.8665 (1.0176)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:09:25 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 3 training takes 0:00:19
[2024-12-07 12:09:28 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.308 
[2024-12-07 12:09:28 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 12:09:28 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 12:09:29 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][0/34]	eta 0:00:30 lr 0.000004	 wd 0.0001	time 0.8917 (0.8917)	loss 1.0402 (1.0402)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 12:09:34 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4850 (0.5213)	loss 1.1265 (0.9690)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 12:09:39 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.7115 (0.5264)	loss 0.9532 (0.9821)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 12:09:45 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [4/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4778 (0.5399)	loss 1.0398 (1.0175)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 12:09:46 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 4 training takes 0:00:18
[2024-12-07 12:09:47 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.385 
[2024-12-07 12:09:47 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 12:09:47 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 12:09:48 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7107 (0.7107)	loss 0.7799 (0.7799)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 12:09:56 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][10/34]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.6237 (0.7380)	loss 0.8665 (1.0635)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 12:10:01 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4829 (0.6317)	loss 1.0398 (1.0151)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 12:10:06 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [5/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5606 (0.5854)	loss 1.1265 (1.0091)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 12:10:08 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 5 training takes 0:00:20
[2024-12-07 12:10:09 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.513 
[2024-12-07 12:10:09 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 12:10:09 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 12:10:10 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [6/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6964 (0.6964)	loss 1.0399 (1.0399)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 12:10:15 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [6/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.4921 (0.5538)	loss 1.1266 (1.0477)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-07 12:10:22 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [6/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.6754 (0.5964)	loss 0.7799 (1.0316)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 12:10:27 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [6/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4871 (0.5682)	loss 0.8665 (1.0258)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 12:10:28 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 6 training takes 0:00:19
[2024-12-07 12:10:29 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.462 
[2024-12-07 12:10:29 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 12:10:29 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 12:10:30 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [7/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7340 (0.7340)	loss 1.2998 (1.2998)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.336
[2024-12-07 12:10:36 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [7/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.5051 (0.6292)	loss 0.7799 (0.9926)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 12:10:41 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [7/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4744 (0.5589)	loss 0.8665 (1.0109)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 12:10:46 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [7/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6949 (0.5454)	loss 1.0398 (1.0119)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 12:10:49 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 7 training takes 0:00:19
[2024-12-07 12:10:50 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.603 
[2024-12-07 12:10:50 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 12:10:50 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 12:10:50 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [8/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7037 (0.7037)	loss 1.0398 (1.0398)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 12:10:56 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [8/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.9067 (0.5836)	loss 1.0398 (1.0241)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 12:11:09 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [8/50][20/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 1.4159 (0.9286)	loss 0.9531 (1.0357)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:11:21 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [8/50][30/34]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.9148 (1.0261)	loss 0.7799 (1.0035)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 12:11:23 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 8 training takes 0:00:33
[2024-12-07 12:11:24 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.372 
[2024-12-07 12:11:24 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 12:11:24 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 12:11:25 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [9/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7195 (0.7195)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:11:31 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [9/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.7265 (0.6058)	loss 1.0398 (1.0083)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 12:11:36 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [9/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4906 (0.5503)	loss 1.1264 (1.0109)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 12:11:41 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [9/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7505 (0.5415)	loss 1.0398 (1.0202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:11:46 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 9 training takes 0:00:22
[2024-12-07 12:11:49 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.385 
[2024-12-07 12:11:49 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 12:11:49 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 12:11:51 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [10/50][0/34]	eta 0:00:50 lr 0.000004	 wd 0.0001	time 1.4918 (1.4918)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 12:11:56 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [10/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.8482 (0.6226)	loss 1.2131 (1.0004)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.734
[2024-12-07 12:12:04 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [10/50][20/34]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4899 (0.7053)	loss 1.1264 (1.0109)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 12:12:13 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [10/50][30/34]	eta 0:00:03 lr 0.000004	 wd 0.0001	time 1.2089 (0.7723)	loss 1.1264 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 12:12:15 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 10 training takes 0:00:26
[2024-12-07 12:12:17 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.449 
[2024-12-07 12:12:17 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 12:12:17 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 12:12:18 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [11/50][0/34]	eta 0:00:35 lr 0.000004	 wd 0.0001	time 1.0552 (1.0552)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 12:12:25 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [11/50][10/34]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7165 (0.7171)	loss 0.8665 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:12:30 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [11/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4686 (0.6125)	loss 0.8665 (1.0233)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 12:12:36 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [11/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6793 (0.6017)	loss 1.1264 (1.0118)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 12:12:40 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 11 training takes 0:00:22
[2024-12-07 12:12:41 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.474 
[2024-12-07 12:12:41 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 12:12:41 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 12:12:42 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [12/50][0/34]	eta 0:00:39 lr 0.000004	 wd 0.0001	time 1.1756 (1.1756)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 12:12:49 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [12/50][10/34]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.7369 (0.6774)	loss 0.8665 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 12:12:56 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [12/50][20/34]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4802 (0.6938)	loss 1.1264 (1.0026)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 12:13:01 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [12/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4840 (0.6254)	loss 1.2131 (1.0006)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 12:13:02 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 12 training takes 0:00:20
[2024-12-07 12:13:03 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.538 
[2024-12-07 12:13:03 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 12:13:03 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 12:13:04 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [13/50][0/34]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 1.0292 (1.0292)	loss 1.3864 (1.3864)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 12:13:10 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [13/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4866 (0.5952)	loss 1.0397 (1.1028)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:13:15 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [13/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4808 (0.5424)	loss 0.8665 (1.0439)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 12:13:20 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [13/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4861 (0.5574)	loss 0.7798 (1.0118)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 12:13:22 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 13 training takes 0:00:18
[2024-12-07 12:13:23 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.423 
[2024-12-07 12:13:23 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 12:13:23 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 12:13:24 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [14/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7119 (0.7119)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 12:13:29 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [14/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4786 (0.5414)	loss 1.0397 (1.0319)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 12:13:37 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [14/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7065 (0.6419)	loss 1.0397 (1.0356)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 12:13:44 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [14/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 1.3928 (0.6871)	loss 0.9531 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 12:13:48 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 14 training takes 0:00:24
[2024-12-07 12:13:49 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.513 
[2024-12-07 12:13:49 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 12:13:49 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 12:13:50 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [15/50][0/34]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 0.7738 (0.7738)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 12:13:55 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [15/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4899 (0.5166)	loss 1.2130 (1.0319)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.359
[2024-12-07 12:14:03 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [15/50][20/34]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4884 (0.6488)	loss 1.0397 (1.0191)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 12:14:08 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [15/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4945 (0.6065)	loss 1.2131 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 12:14:09 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 15 training takes 0:00:20
[2024-12-07 12:14:10 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.615 
[2024-12-07 12:14:10 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 12:14:10 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 12:14:11 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [16/50][0/34]	eta 0:00:29 lr 0.000004	 wd 0.0001	time 0.8586 (0.8586)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 12:14:17 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [16/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.8316 (0.6417)	loss 1.2130 (1.0634)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 12:14:24 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [16/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4844 (0.6422)	loss 0.9531 (1.0026)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 12:14:31 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [16/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4697 (0.6691)	loss 0.8665 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:14:33 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 16 training takes 0:00:22
[2024-12-07 12:14:34 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.564 
[2024-12-07 12:14:34 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 12:14:34 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 12:14:35 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [17/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7050 (0.7050)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 12:14:39 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [17/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4794 (0.5120)	loss 1.1264 (1.0161)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 12:14:45 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [17/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4946 (0.5521)	loss 0.9532 (1.0274)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 12:14:50 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [17/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4862 (0.5309)	loss 1.1264 (1.0202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 12:14:52 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 17 training takes 0:00:17
[2024-12-07 12:14:53 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.436 
[2024-12-07 12:14:53 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 12:14:53 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 12:14:54 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [18/50][0/34]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.9942 (0.9942)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:15:01 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [18/50][10/34]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7175 (0.7221)	loss 0.8665 (0.9689)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 12:15:06 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [18/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.5202 (0.6238)	loss 1.1264 (0.9737)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 12:15:12 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [18/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4866 (0.6131)	loss 1.2998 (0.9978)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-07 12:15:13 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 18 training takes 0:00:20
[2024-12-07 12:15:15 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.474 
[2024-12-07 12:15:15 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 12:15:15 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 12:15:15 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [19/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7181 (0.7181)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.570
[2024-12-07 12:15:22 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [19/50][10/34]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 1.0924 (0.6713)	loss 0.9531 (1.0476)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 12:15:30 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [19/50][20/34]	eta 0:00:10 lr 0.000004	 wd 0.0001	time 0.4692 (0.7201)	loss 0.8665 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 12:15:35 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [19/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7099 (0.6663)	loss 0.8665 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 12:15:37 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 19 training takes 0:00:22
[2024-12-07 12:15:38 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.615 
[2024-12-07 12:15:38 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 12:15:38 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.63%
[2024-12-07 12:15:39 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [20/50][0/34]	eta 0:00:35 lr 0.000004	 wd 0.0001	time 1.0528 (1.0528)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 12:15:50 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [20/50][10/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 1.1633 (1.0703)	loss 0.7798 (1.0004)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 12:15:57 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [20/50][20/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.6924 (0.8957)	loss 1.2131 (1.0521)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:16:05 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [20/50][30/34]	eta 0:00:03 lr 0.000004	 wd 0.0001	time 0.7725 (0.8607)	loss 1.2130 (1.0258)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 12:16:06 swin_tiny_patch4_window7_224] (main.py 268): INFO EPOCH 20 training takes 0:00:28
[2024-12-07 12:16:07 swin_tiny_patch4_window7_224] (main.py 321): INFO  * Accuracy validation@ 0.654 
[2024-12-07 12:16:07 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 12:16:07 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 0.65%
[2024-12-07 12:16:08 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [21/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7436 (0.7436)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 12:16:13 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [21/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4722 (0.5204)	loss 0.6932 (0.9452)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:16:19 swin_tiny_patch4_window7_224] (main.py 259): INFO Train: [21/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4958 (0.5550)	loss 1.2130 (0.9861)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 12:16:31 swin_tiny_patch4_window7_224] (main.py 434): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-07 12:16:31 swin_tiny_patch4_window7_224] (main.py 435): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 12:16:31 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 12:16:31 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 2084144
[2024-12-07 12:16:31 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.141317952
[2024-12-07 12:16:31 swin_tiny_patch4_window7_224] (main.py 139): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-07 12:16:31 swin_tiny_patch4_window7_224] (main.py 157): INFO Start training
[2024-12-07 12:16:31 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][0/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 0.6218 (0.6218)	loss 0.9830 (0.9830)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 12:16:36 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][10/34]	eta 0:00:11 lr 0.000004	 wd 0.0001	time 0.4863 (0.4925)	loss 1.3025 (1.0092)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.391
[2024-12-07 12:16:41 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][20/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 0.6889 (0.4982)	loss 0.9546 (0.9969)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 12:16:47 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4867 (0.5314)	loss 1.2162 (1.0198)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 12:16:49 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 0 training takes 0:00:17
[2024-12-07 12:16:50 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.615 
[2024-12-07 12:16:50 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 12:16:50 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.62%
[2024-12-07 12:16:51 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [1/50][0/34]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 0.7863 (0.7863)	loss 1.1272 (1.1272)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.695
[2024-12-07 12:16:56 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [1/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.7002 (0.5505)	loss 1.2135 (1.0565)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-07 12:17:02 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [1/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4831 (0.5690)	loss 1.2146 (1.0200)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:17:06 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [1/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4670 (0.5381)	loss 0.6936 (1.0099)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:17:08 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 1 training takes 0:00:18
[2024-12-07 12:17:09 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.526 
[2024-12-07 12:17:09 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 12:17:09 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.62%
[2024-12-07 12:17:10 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [2/50][0/34]	eta 0:00:30 lr 0.000004	 wd 0.0001	time 0.8989 (0.8989)	loss 1.0400 (1.0400)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 12:17:16 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [2/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4779 (0.6421)	loss 1.0404 (1.0483)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 12:17:21 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [2/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4822 (0.5631)	loss 1.0400 (1.0155)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 12:17:28 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [2/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6867 (0.6078)	loss 0.6937 (0.9926)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:17:30 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 2 training takes 0:00:20
[2024-12-07 12:17:31 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.628 
[2024-12-07 12:17:31 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 12:17:31 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:17:31 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [3/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7332 (0.7332)	loss 1.2133 (1.2133)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.641
[2024-12-07 12:17:36 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [3/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4656 (0.5045)	loss 0.9533 (1.0794)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 12:17:42 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [3/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.7062 (0.5432)	loss 0.9534 (1.0276)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:17:47 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [3/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4690 (0.5354)	loss 0.8665 (1.0176)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:17:49 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 3 training takes 0:00:18
[2024-12-07 12:17:51 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.308 
[2024-12-07 12:17:51 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 12:17:51 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:17:52 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [4/50][0/34]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 1.0223 (1.0223)	loss 1.0402 (1.0402)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 12:17:58 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [4/50][10/34]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.4944 (0.6989)	loss 1.1265 (0.9690)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 12:18:03 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [4/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4879 (0.5922)	loss 0.9532 (0.9821)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 12:18:09 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [4/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7349 (0.5959)	loss 1.0398 (1.0175)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 12:18:11 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 4 training takes 0:00:20
[2024-12-07 12:18:12 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.385 
[2024-12-07 12:18:12 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 12:18:12 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:18:13 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [5/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6936 (0.6936)	loss 0.7799 (0.7799)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 12:18:18 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [5/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4671 (0.5087)	loss 0.8665 (1.0635)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 12:18:23 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [5/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.6972 (0.5181)	loss 1.0398 (1.0151)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 12:18:29 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [5/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4927 (0.5317)	loss 1.1265 (1.0091)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 12:18:30 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 5 training takes 0:00:17
[2024-12-07 12:18:31 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.513 
[2024-12-07 12:18:31 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 12:18:31 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:18:32 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [6/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7112 (0.7112)	loss 1.0399 (1.0399)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 12:18:38 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [6/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.7449 (0.5648)	loss 1.1266 (1.0477)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-07 12:18:43 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [6/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4841 (0.5642)	loss 0.7799 (1.0316)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 12:18:48 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [6/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4681 (0.5390)	loss 0.8665 (1.0258)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 12:18:50 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 6 training takes 0:00:18
[2024-12-07 12:18:51 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.462 
[2024-12-07 12:18:51 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 12:18:51 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:18:52 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [7/50][0/34]	eta 0:00:35 lr 0.000004	 wd 0.0001	time 1.0398 (1.0398)	loss 1.2998 (1.2998)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.336
[2024-12-07 12:18:58 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [7/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4575 (0.6044)	loss 0.7799 (0.9926)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 12:19:03 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [7/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4687 (0.5459)	loss 0.8665 (1.0109)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 12:19:09 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [7/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7210 (0.5647)	loss 1.0398 (1.0119)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 12:19:10 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 7 training takes 0:00:19
[2024-12-07 12:19:11 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.603 
[2024-12-07 12:19:11 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 12:19:11 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:19:12 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [8/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7025 (0.7025)	loss 1.0398 (1.0398)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 12:19:17 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [8/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.4686 (0.5527)	loss 1.0398 (1.0241)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 12:19:24 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [8/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.6992 (0.5813)	loss 0.9531 (1.0357)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:19:29 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [8/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5661 (0.5580)	loss 0.7799 (1.0035)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 12:19:31 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 8 training takes 0:00:19
[2024-12-07 12:19:33 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.372 
[2024-12-07 12:19:33 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 12:19:33 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:19:35 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [9/50][0/34]	eta 0:00:59 lr 0.000004	 wd 0.0001	time 1.7409 (1.7409)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:19:43 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [9/50][10/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 0.9588 (0.9004)	loss 1.0398 (1.0083)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 12:19:57 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [9/50][20/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4876 (1.1314)	loss 1.1264 (1.0109)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 12:20:02 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [9/50][30/34]	eta 0:00:03 lr 0.000004	 wd 0.0001	time 0.4688 (0.9213)	loss 1.0398 (1.0202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:20:03 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 9 training takes 0:00:30
[2024-12-07 12:20:04 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.385 
[2024-12-07 12:20:04 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 12:20:04 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:20:06 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [10/50][0/34]	eta 0:00:35 lr 0.000004	 wd 0.0001	time 1.0453 (1.0453)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 12:20:18 swin_tiny_patch4_window7_224] (main.py 434): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-07 12:20:18 swin_tiny_patch4_window7_224] (main.py 435): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 12:20:18 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 12:20:18 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 2084144
[2024-12-07 12:20:18 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.141317952
[2024-12-07 12:20:18 swin_tiny_patch4_window7_224] (main.py 139): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-07 12:20:18 swin_tiny_patch4_window7_224] (main.py 157): INFO Start training
[2024-12-07 12:20:19 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][0/34]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.9825 (0.9825)	loss 0.9830 (0.9830)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 12:20:25 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.5071 (0.6175)	loss 1.3025 (1.0092)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.391
[2024-12-07 12:20:30 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4611 (0.5483)	loss 0.9546 (0.9969)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 12:20:36 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7155 (0.5641)	loss 1.2162 (1.0198)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 12:20:37 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 0 training takes 0:00:19
[2024-12-07 12:20:38 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.615 
[2024-12-07 12:20:38 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 12:20:38 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.62%
[2024-12-07 12:20:38 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4960, Recall: 0.4962, F1: 0.4957
[2024-12-07 12:20:39 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [1/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6995 (0.6995)	loss 1.1272 (1.1272)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.695
[2024-12-07 12:20:44 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [1/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4795 (0.5023)	loss 1.2135 (1.0565)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-07 12:20:50 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [1/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.7412 (0.5500)	loss 1.2146 (1.0200)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:20:55 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [1/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4688 (0.5303)	loss 0.6936 (1.0099)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:20:56 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 1 training takes 0:00:17
[2024-12-07 12:20:57 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.526 
[2024-12-07 12:20:57 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 12:20:57 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.62%
[2024-12-07 12:20:57 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4571, Recall: 0.4499, F1: 0.4496
[2024-12-07 12:20:58 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [2/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6940 (0.6940)	loss 1.0400 (1.0400)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 12:21:04 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [2/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.7151 (0.6149)	loss 1.0404 (1.0483)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 12:21:09 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [2/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4715 (0.5604)	loss 1.0400 (1.0155)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 12:21:14 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [2/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4787 (0.5326)	loss 0.6937 (0.9926)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:21:16 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 2 training takes 0:00:18
[2024-12-07 12:21:17 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.628 
[2024-12-07 12:21:17 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 12:21:17 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:21:17 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5341, Recall: 0.5351, F1: 0.5345
[2024-12-07 12:21:19 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [3/50][0/34]	eta 0:00:43 lr 0.000004	 wd 0.0001	time 1.2683 (1.2683)	loss 1.2133 (1.2133)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.641
[2024-12-07 12:21:25 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [3/50][10/34]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.4751 (0.6787)	loss 0.9533 (1.0794)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 12:21:30 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [3/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4735 (0.6009)	loss 0.9534 (1.0276)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:21:36 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [3/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6845 (0.5954)	loss 0.8665 (1.0176)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:21:38 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 3 training takes 0:00:20
[2024-12-07 12:21:39 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.308 
[2024-12-07 12:21:39 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 12:21:39 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:21:39 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4450, Recall: 0.4662, F1: 0.2961
[2024-12-07 12:21:39 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [4/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7014 (0.7014)	loss 1.0402 (1.0402)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 12:21:44 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [4/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4807 (0.5048)	loss 1.1265 (0.9690)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 12:21:50 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [4/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.6905 (0.5417)	loss 0.9532 (0.9821)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 12:21:55 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [4/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4875 (0.5362)	loss 1.0398 (1.0175)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 12:21:57 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 4 training takes 0:00:18
[2024-12-07 12:21:58 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.385 
[2024-12-07 12:21:58 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 12:21:58 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:21:58 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.3962, Recall: 0.3684, F1: 0.3576
[2024-12-07 12:21:59 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [5/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6882 (0.6882)	loss 0.7799 (0.7799)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 12:22:04 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [5/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.7162 (0.5836)	loss 0.8665 (1.0635)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 12:22:10 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [5/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4806 (0.5552)	loss 1.0398 (1.0151)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 12:22:14 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [5/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4698 (0.5284)	loss 1.1265 (1.0091)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 12:22:16 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 5 training takes 0:00:17
[2024-12-07 12:22:17 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.513 
[2024-12-07 12:22:17 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 12:22:17 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:22:17 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5495, Recall: 0.5614, F1: 0.5010
[2024-12-07 12:22:18 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [6/50][0/34]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 1.0089 (1.0089)	loss 1.0399 (1.0399)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 12:22:24 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [6/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4839 (0.6025)	loss 1.1266 (1.0477)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-07 12:22:29 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [6/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4556 (0.5410)	loss 0.7799 (1.0316)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 12:22:35 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [6/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7152 (0.5587)	loss 0.8665 (1.0258)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 12:22:36 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 6 training takes 0:00:19
[2024-12-07 12:22:37 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.462 
[2024-12-07 12:22:37 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 12:22:37 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:22:37 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5222, Recall: 0.5263, F1: 0.4558
[2024-12-07 12:22:38 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [7/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7095 (0.7095)	loss 1.2998 (1.2998)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.336
[2024-12-07 12:22:43 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [7/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4867 (0.5041)	loss 0.7799 (0.9926)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 12:22:49 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [7/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.6945 (0.5480)	loss 0.8665 (1.0109)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 12:22:54 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [7/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4679 (0.5368)	loss 1.0398 (1.0119)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 12:22:55 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 7 training takes 0:00:18
[2024-12-07 12:22:57 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.603 
[2024-12-07 12:22:57 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 12:22:57 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:22:57 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5288, Recall: 0.5326, F1: 0.5280
[2024-12-07 12:22:57 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [8/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7006 (0.7006)	loss 1.0398 (1.0398)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 12:23:03 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [8/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.6951 (0.5893)	loss 1.0398 (1.0241)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 12:23:08 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [8/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4615 (0.5582)	loss 0.9531 (1.0357)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:23:14 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [8/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7529 (0.5587)	loss 0.7799 (1.0035)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 12:23:16 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 8 training takes 0:00:19
[2024-12-07 12:23:17 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.372 
[2024-12-07 12:23:17 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 12:23:17 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:23:17 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4208, Recall: 0.4048, F1: 0.3633
[2024-12-07 12:23:18 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [9/50][0/34]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.9932 (0.9932)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:23:23 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [9/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4743 (0.5394)	loss 1.0398 (1.0083)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 12:23:28 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [9/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4745 (0.5104)	loss 1.1264 (1.0109)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 12:23:34 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [9/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4792 (0.5464)	loss 1.0398 (1.0202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:23:36 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 9 training takes 0:00:18
[2024-12-07 12:23:37 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.385 
[2024-12-07 12:23:37 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 12:23:37 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:23:37 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.3962, Recall: 0.3684, F1: 0.3576
[2024-12-07 12:23:37 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [10/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7018 (0.7018)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 12:23:42 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [10/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4991 (0.5022)	loss 1.2131 (1.0004)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.734
[2024-12-07 12:23:49 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [10/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4953 (0.5605)	loss 1.1264 (1.0109)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 12:23:53 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [10/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4681 (0.5356)	loss 1.1264 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 12:23:55 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 10 training takes 0:00:18
[2024-12-07 12:23:56 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.449 
[2024-12-07 12:23:56 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 12:23:56 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:23:56 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5609, Recall: 0.5627, F1: 0.4486
[2024-12-07 12:23:57 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [11/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7326 (0.7326)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 12:24:03 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [11/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4754 (0.6442)	loss 0.8665 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:24:08 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [11/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4640 (0.5668)	loss 0.8665 (1.0233)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 12:24:13 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [11/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7255 (0.5508)	loss 1.1264 (1.0118)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 12:24:15 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 11 training takes 0:00:19
[2024-12-07 12:24:16 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.474 
[2024-12-07 12:24:16 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 12:24:16 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:24:16 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5292, Recall: 0.5351, F1: 0.4673
[2024-12-07 12:24:17 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [12/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7064 (0.7064)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 12:24:22 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [12/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4767 (0.5084)	loss 0.8665 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 12:24:27 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [12/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.7171 (0.5211)	loss 1.1264 (1.0026)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 12:24:33 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [12/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4773 (0.5320)	loss 1.2131 (1.0006)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 12:24:34 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 12 training takes 0:00:18
[2024-12-07 12:24:35 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.538 
[2024-12-07 12:24:35 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 12:24:35 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:24:35 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4491, Recall: 0.4436, F1: 0.4451
[2024-12-07 12:24:36 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [13/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7328 (0.7328)	loss 1.3864 (1.3864)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 12:24:43 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [13/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.7813 (0.6436)	loss 1.0397 (1.1028)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:24:49 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [13/50][20/34]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4944 (0.6436)	loss 0.8665 (1.0439)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 12:24:54 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [13/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4645 (0.5922)	loss 0.7798 (1.0118)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 12:24:55 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 13 training takes 0:00:19
[2024-12-07 12:24:56 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.423 
[2024-12-07 12:24:56 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 12:24:56 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:24:56 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4633, Recall: 0.4549, F1: 0.4114
[2024-12-07 12:24:57 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [14/50][0/34]	eta 0:00:28 lr 0.000004	 wd 0.0001	time 0.8323 (0.8323)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 12:25:03 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [14/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4811 (0.6327)	loss 1.0397 (1.0319)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 12:25:08 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [14/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4845 (0.5628)	loss 1.0397 (1.0356)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 12:25:14 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [14/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7008 (0.5654)	loss 0.9531 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 12:25:16 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 14 training takes 0:00:19
[2024-12-07 12:25:17 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.513 
[2024-12-07 12:25:17 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 12:25:17 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:25:17 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4357, Recall: 0.4261, F1: 0.4282
[2024-12-07 12:25:18 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [15/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7180 (0.7180)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 12:25:23 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [15/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4849 (0.5130)	loss 1.2130 (1.0319)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.359
[2024-12-07 12:25:28 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [15/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.6859 (0.5426)	loss 1.0397 (1.0191)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 12:25:34 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [15/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4962 (0.5396)	loss 1.2131 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 12:25:35 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 15 training takes 0:00:18
[2024-12-07 12:25:36 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.615 
[2024-12-07 12:25:36 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 12:25:36 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:25:36 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5113, Recall: 0.5113, F1: 0.5113
[2024-12-07 12:25:37 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [16/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7261 (0.7261)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 12:25:43 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [16/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.7066 (0.5893)	loss 1.2130 (1.0634)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 12:25:48 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [16/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4805 (0.5643)	loss 0.9531 (1.0026)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 12:25:53 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [16/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4617 (0.5404)	loss 0.8665 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:25:55 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 16 training takes 0:00:18
[2024-12-07 12:25:56 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.564 
[2024-12-07 12:25:56 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 12:25:56 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:25:56 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4632, Recall: 0.4612, F1: 0.4619
[2024-12-07 12:25:57 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [17/50][0/34]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 1.0130 (1.0130)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 12:26:03 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [17/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4733 (0.5841)	loss 1.1264 (1.0161)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 12:26:08 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [17/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4833 (0.5373)	loss 0.9532 (1.0274)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 12:26:14 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [17/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5104 (0.5644)	loss 1.1264 (1.0202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 12:26:15 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 17 training takes 0:00:18
[2024-12-07 12:26:16 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.436 
[2024-12-07 12:26:16 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 12:26:16 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:26:16 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4476, Recall: 0.4336, F1: 0.4111
[2024-12-07 12:26:17 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [18/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7259 (0.7259)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:26:22 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [18/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4855 (0.5139)	loss 0.8665 (0.9689)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 12:26:28 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [18/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.5527 (0.5647)	loss 1.1264 (0.9737)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 12:26:33 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [18/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4930 (0.5381)	loss 1.2998 (0.9978)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-07 12:26:34 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 18 training takes 0:00:18
[2024-12-07 12:26:36 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.474 
[2024-12-07 12:26:36 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 12:26:36 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:26:36 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4563, Recall: 0.4449, F1: 0.4333
[2024-12-07 12:26:36 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [19/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6998 (0.6998)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.570
[2024-12-07 12:26:43 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [19/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.5372 (0.6366)	loss 0.9531 (1.0476)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 12:26:47 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [19/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4599 (0.5626)	loss 0.8665 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 12:26:52 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [19/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4795 (0.5378)	loss 0.8665 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 12:26:54 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 19 training takes 0:00:18
[2024-12-07 12:26:56 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.615 
[2024-12-07 12:26:56 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 12:26:56 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.63%
[2024-12-07 12:26:56 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5113, Recall: 0.5113, F1: 0.5113
[2024-12-07 12:26:57 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [20/50][0/34]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 0.7873 (0.7873)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 12:27:02 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [20/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4864 (0.5139)	loss 0.7798 (1.0004)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 12:27:06 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [20/50][20/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 0.5253 (0.4989)	loss 1.2131 (1.0521)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:27:13 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [20/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4809 (0.5363)	loss 1.2130 (1.0258)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 12:27:14 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 20 training takes 0:00:18
[2024-12-07 12:27:15 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.654 
[2024-12-07 12:27:15 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 12:27:15 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.65%
[2024-12-07 12:27:15 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.3542, Recall: 0.4474, F1: 0.3953
[2024-12-07 12:27:16 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [21/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7221 (0.7221)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 12:27:21 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [21/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.5083 (0.5087)	loss 0.6932 (0.9452)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:27:27 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [21/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4792 (0.5613)	loss 1.2130 (0.9861)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 12:27:32 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [21/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5006 (0.5336)	loss 1.0397 (0.9894)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 12:27:33 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 21 training takes 0:00:18
[2024-12-07 12:27:34 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.667 
[2024-12-07 12:27:34 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 12:27:34 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.67%
[2024-12-07 12:27:34 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5231, Recall: 0.5163, F1: 0.5111
[2024-12-07 12:27:35 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [22/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7021 (0.7021)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 12:27:41 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [22/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4868 (0.6335)	loss 0.9531 (1.0082)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 12:27:46 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [22/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4762 (0.5606)	loss 1.2130 (1.0315)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:27:51 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [22/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6887 (0.5521)	loss 0.6065 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 12:27:54 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 22 training takes 0:00:19
[2024-12-07 12:27:55 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.269 
[2024-12-07 12:27:55 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 12:27:55 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.67%
[2024-12-07 12:27:55 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.1346, Recall: 0.5000, F1: 0.2121
[2024-12-07 12:27:55 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [23/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6919 (0.6919)	loss 0.7799 (0.7799)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 12:28:00 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [23/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4725 (0.5022)	loss 1.1264 (1.0398)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-07 12:28:06 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [23/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.7278 (0.5203)	loss 1.1264 (1.0398)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 12:28:13 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [23/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4716 (0.5858)	loss 1.0397 (1.0202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 12:28:14 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 23 training takes 0:00:19
[2024-12-07 12:28:15 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.474 
[2024-12-07 12:28:15 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 12:28:15 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.67%
[2024-12-07 12:28:15 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5577, Recall: 0.5652, F1: 0.4722
[2024-12-07 12:28:16 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [24/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7102 (0.7102)	loss 1.0398 (1.0398)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 12:28:21 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [24/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.7498 (0.5394)	loss 1.1264 (1.0476)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 12:28:27 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [24/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4829 (0.5739)	loss 0.8665 (1.0026)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 12:28:32 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [24/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.5167 (0.5464)	loss 1.2997 (1.0202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-07 12:28:34 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 24 training takes 0:00:18
[2024-12-07 12:28:35 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.731 
[2024-12-07 12:28:35 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 12:28:35 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:28:35 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 12:28:36 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [25/50][0/34]	eta 0:00:29 lr 0.000004	 wd 0.0001	time 0.8778 (0.8778)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 12:28:42 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [25/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4862 (0.6370)	loss 0.8665 (1.0161)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 12:28:47 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [25/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4809 (0.5639)	loss 0.8664 (1.0232)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 12:28:52 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [25/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7050 (0.5638)	loss 0.9531 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 12:28:55 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 25 training takes 0:00:19
[2024-12-07 12:28:56 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.333 
[2024-12-07 12:28:56 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 12:28:56 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:28:56 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4769, Recall: 0.4837, F1: 0.3262
[2024-12-07 12:28:56 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [26/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6869 (0.6869)	loss 0.7798 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 12:29:01 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [26/50][10/34]	eta 0:00:11 lr 0.000004	 wd 0.0001	time 0.4726 (0.4991)	loss 0.9531 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 12:29:07 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [26/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.7106 (0.5251)	loss 0.8665 (0.9943)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 12:29:12 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [26/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4970 (0.5341)	loss 1.0397 (1.0006)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 12:29:14 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 26 training takes 0:00:18
[2024-12-07 12:29:15 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.603 
[2024-12-07 12:29:15 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 12:29:15 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:29:15 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5967, Recall: 0.6228, F1: 0.5775
[2024-12-07 12:29:15 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [27/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7152 (0.7152)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 12:29:21 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [27/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.6846 (0.5616)	loss 0.7798 (1.0634)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 12:29:27 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [27/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4811 (0.5629)	loss 1.2130 (1.0232)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.641
[2024-12-07 12:29:31 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [27/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4741 (0.5348)	loss 1.2130 (1.0174)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 12:29:33 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 27 training takes 0:00:18
[2024-12-07 12:29:34 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.590 
[2024-12-07 12:29:34 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 12:29:34 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:29:34 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.3846, Recall: 0.4185, F1: 0.3983
[2024-12-07 12:29:35 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [28/50][0/34]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 1.0263 (1.0263)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 12:29:41 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [28/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4708 (0.6246)	loss 0.8664 (1.0634)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:29:46 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [28/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4926 (0.5581)	loss 1.2130 (1.0562)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.734
[2024-12-07 12:29:52 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [28/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7058 (0.5697)	loss 0.7798 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 12:29:54 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 28 training takes 0:00:19
[2024-12-07 12:29:55 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.526 
[2024-12-07 12:29:55 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 12:29:55 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:29:55 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4960, Recall: 0.4950, F1: 0.4805
[2024-12-07 12:29:55 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [29/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7026 (0.7026)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 12:30:00 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [29/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4842 (0.5115)	loss 0.6932 (0.9925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:30:06 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [29/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.6722 (0.5505)	loss 0.8664 (0.9902)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 12:30:12 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [29/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4892 (0.5420)	loss 1.1264 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 12:30:13 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 29 training takes 0:00:18
[2024-12-07 12:30:14 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.462 
[2024-12-07 12:30:14 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 12:30:14 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:30:14 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4733, Recall: 0.4662, F1: 0.4379
[2024-12-07 12:30:15 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [30/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7309 (0.7309)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 12:30:21 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [30/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.7420 (0.6233)	loss 1.1264 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 12:30:26 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [30/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.4792 (0.5748)	loss 1.1264 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 12:30:31 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [30/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4803 (0.5447)	loss 1.1264 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-07 12:30:33 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 30 training takes 0:00:18
[2024-12-07 12:30:34 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.731 
[2024-12-07 12:30:34 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 12:30:34 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:30:34 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.6184, Recall: 0.5150, F1: 0.4645
[2024-12-07 12:30:35 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [31/50][0/34]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 1.0272 (1.0272)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 12:30:41 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [31/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.4740 (0.5636)	loss 1.1264 (1.0791)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 12:30:45 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [31/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4729 (0.5230)	loss 1.1264 (1.0232)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-07 12:30:51 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [31/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4856 (0.5519)	loss 1.1264 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 12:30:53 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 31 training takes 0:00:18
[2024-12-07 12:30:54 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.269 
[2024-12-07 12:30:54 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 12:30:54 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:30:54 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.1346, Recall: 0.5000, F1: 0.2121
[2024-12-07 12:30:55 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [32/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7145 (0.7145)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.391
[2024-12-07 12:31:00 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [32/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4869 (0.5035)	loss 1.2130 (1.0555)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.359
[2024-12-07 12:31:06 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [32/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4871 (0.5596)	loss 1.2130 (1.0067)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 12:31:11 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [32/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4721 (0.5328)	loss 1.0397 (1.0034)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 12:31:12 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 32 training takes 0:00:18
[2024-12-07 12:31:13 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.603 
[2024-12-07 12:31:13 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 12:31:13 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:31:13 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4486, Recall: 0.4574, F1: 0.4508
[2024-12-07 12:31:14 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [33/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7147 (0.7147)	loss 0.7798 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:31:20 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [33/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4884 (0.6362)	loss 0.9531 (1.0319)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.570
[2024-12-07 12:31:25 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [33/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4822 (0.5648)	loss 1.1264 (0.9985)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:31:30 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [33/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6029 (0.5406)	loss 1.0397 (1.0006)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 12:31:32 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 33 training takes 0:00:18
[2024-12-07 12:31:34 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.551 
[2024-12-07 12:31:34 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 12:31:34 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:31:34 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4560, Recall: 0.4524, F1: 0.4535
[2024-12-07 12:31:35 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [34/50][0/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.0961 (1.0961)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 12:31:41 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [34/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4756 (0.6306)	loss 1.0397 (1.0634)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 12:31:46 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [34/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7127 (0.5902)	loss 1.0397 (1.0315)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 12:31:52 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [34/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4802 (0.5810)	loss 0.9531 (1.0286)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 12:31:53 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 34 training takes 0:00:19
[2024-12-07 12:31:54 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.449 
[2024-12-07 12:31:54 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 12:31:54 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:31:54 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5021, Recall: 0.5025, F1: 0.4413
[2024-12-07 12:31:55 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [35/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7254 (0.7254)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:32:01 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [35/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.7130 (0.5608)	loss 1.0397 (1.0161)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:32:06 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [35/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4737 (0.5589)	loss 1.0397 (1.0026)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 12:32:11 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [35/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4673 (0.5317)	loss 1.0397 (0.9950)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 12:32:12 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 35 training takes 0:00:17
[2024-12-07 12:32:14 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.346 
[2024-12-07 12:32:14 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 12:32:14 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:32:14 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4583, Recall: 0.4624, F1: 0.3452
[2024-12-07 12:32:15 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [36/50][0/34]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 1.0201 (1.0201)	loss 1.2997 (1.2997)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.336
[2024-12-07 12:32:20 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [36/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4794 (0.6060)	loss 0.7798 (1.0319)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 12:32:25 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [36/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4714 (0.5469)	loss 1.1264 (1.0356)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.617
[2024-12-07 12:32:31 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [36/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6866 (0.5605)	loss 0.7798 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 12:32:33 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 36 training takes 0:00:19
[2024-12-07 12:32:34 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.333 
[2024-12-07 12:32:34 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 12:32:34 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:32:34 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4980, Recall: 0.4987, F1: 0.3222
[2024-12-07 12:32:35 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [37/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7074 (0.7074)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 12:32:39 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [37/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4765 (0.5004)	loss 1.2130 (0.9610)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.641
[2024-12-07 12:32:45 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [37/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.7063 (0.5417)	loss 1.2997 (0.9820)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-07 12:32:50 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [37/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4836 (0.5332)	loss 0.8664 (1.0034)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 12:32:52 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 37 training takes 0:00:18
[2024-12-07 12:32:53 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.423 
[2024-12-07 12:32:53 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 12:32:53 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:32:53 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5667, Recall: 0.5602, F1: 0.4222
[2024-12-07 12:32:54 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [38/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7053 (0.7053)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 12:33:00 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [38/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.7300 (0.6091)	loss 1.2997 (1.0240)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.445
[2024-12-07 12:33:05 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [38/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4858 (0.5651)	loss 1.0397 (1.0274)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 12:33:10 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [38/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4655 (0.5356)	loss 0.7798 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 12:33:11 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 38 training takes 0:00:18
[2024-12-07 12:33:13 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.474 
[2024-12-07 12:33:13 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 12:33:13 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:33:13 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4684, Recall: 0.4599, F1: 0.4412
[2024-12-07 12:33:14 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [39/50][0/34]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.9960 (0.9960)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 12:33:19 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [39/50][10/34]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.4704 (0.5591)	loss 0.8664 (1.0319)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 12:33:24 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [39/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4753 (0.5211)	loss 0.9531 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.664
[2024-12-07 12:33:30 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [39/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4773 (0.5536)	loss 1.0397 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 12:33:31 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 39 training takes 0:00:18
[2024-12-07 12:33:33 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.397 
[2024-12-07 12:33:33 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 12:33:33 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:33:33 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5306, Recall: 0.5276, F1: 0.3965
[2024-12-07 12:33:33 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [40/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7137 (0.7137)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 12:33:38 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [40/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4811 (0.5058)	loss 1.1264 (0.9767)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 12:33:44 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [40/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4681 (0.5614)	loss 0.8664 (1.0150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 12:33:49 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [40/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4688 (0.5345)	loss 1.1264 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 12:33:51 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 40 training takes 0:00:18
[2024-12-07 12:33:52 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.705 
[2024-12-07 12:33:52 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 12:33:52 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:33:52 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.3618, Recall: 0.4825, F1: 0.4135
[2024-12-07 12:33:52 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [41/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7022 (0.7022)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 12:33:59 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [41/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.5400 (0.6333)	loss 1.0397 (1.0161)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 12:34:03 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [41/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4790 (0.5587)	loss 0.7798 (1.0232)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 12:34:08 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [41/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4633 (0.5319)	loss 0.8664 (1.0230)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:34:10 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 41 training takes 0:00:18
[2024-12-07 12:34:12 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.731 
[2024-12-07 12:34:12 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 12:34:12 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:34:12 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 12:34:13 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [42/50][0/34]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 0.7929 (0.7929)	loss 1.2130 (1.2130)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.781
[2024-12-07 12:34:18 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [42/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4698 (0.5132)	loss 1.1264 (1.1342)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:34:22 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [42/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.5538 (0.5015)	loss 0.8664 (1.0521)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:34:29 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [42/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4818 (0.5380)	loss 0.9531 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 12:34:30 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 42 training takes 0:00:18
[2024-12-07 12:34:31 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.731 
[2024-12-07 12:34:31 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 12:34:31 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:34:31 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.6184, Recall: 0.5150, F1: 0.4645
[2024-12-07 12:34:32 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [43/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7421 (0.7421)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 12:34:37 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [43/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4960 (0.5100)	loss 0.6932 (1.0161)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:34:43 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [43/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4654 (0.5540)	loss 0.8664 (1.0067)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 12:34:48 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [43/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4717 (0.5291)	loss 1.1264 (1.0230)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 12:34:49 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 43 training takes 0:00:17
[2024-12-07 12:34:50 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.333 
[2024-12-07 12:34:50 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 12:34:50 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:34:50 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4134, Recall: 0.4085, F1: 0.3329
[2024-12-07 12:34:51 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [44/50][0/34]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 0.7855 (0.7855)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 12:34:57 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [44/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4596 (0.6392)	loss 0.8664 (0.9767)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 12:35:03 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [44/50][20/34]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7195 (0.6124)	loss 0.9531 (0.9985)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:35:10 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [44/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.7308 (0.6279)	loss 1.1264 (1.0202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 12:35:11 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 44 training takes 0:00:21
[2024-12-07 12:35:12 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.615 
[2024-12-07 12:35:12 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 12:35:12 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:35:12 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4571, Recall: 0.4662, F1: 0.4583
[2024-12-07 12:35:13 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [45/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7107 (0.7107)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 12:35:18 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [45/50][10/34]	eta 0:00:11 lr 0.000004	 wd 0.0001	time 0.4785 (0.4996)	loss 1.0397 (0.9373)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-07 12:35:24 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [45/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.7261 (0.5529)	loss 0.9531 (0.9820)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 12:35:29 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [45/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4697 (0.5340)	loss 1.1264 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-07 12:35:30 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 45 training takes 0:00:18
[2024-12-07 12:35:31 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.615 
[2024-12-07 12:35:31 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 12:35:31 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:35:31 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5374, Recall: 0.5414, F1: 0.5375
[2024-12-07 12:35:32 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [46/50][0/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.7053 (0.7053)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:35:38 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [46/50][10/34]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.7224 (0.6097)	loss 1.2130 (1.0003)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 12:35:43 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [46/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4698 (0.5521)	loss 0.7798 (0.9778)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 12:35:48 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [46/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4884 (0.5286)	loss 1.1264 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 12:35:50 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 46 training takes 0:00:18
[2024-12-07 12:35:51 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.423 
[2024-12-07 12:35:51 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 12:35:51 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:35:51 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4871, Recall: 0.4850, F1: 0.4184
[2024-12-07 12:35:52 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [47/50][0/34]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 1.0163 (1.0163)	loss 1.2130 (1.2130)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 12:35:57 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [47/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4653 (0.5342)	loss 0.9531 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 12:36:02 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [47/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4784 (0.5057)	loss 1.1264 (1.0191)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 12:36:08 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [47/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4888 (0.5423)	loss 1.1264 (1.0090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 12:36:09 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 47 training takes 0:00:18
[2024-12-07 12:36:10 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.628 
[2024-12-07 12:36:10 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 12:36:10 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:36:10 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5341, Recall: 0.5351, F1: 0.5345
[2024-12-07 12:36:11 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [48/50][0/34]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7544 (0.7544)	loss 1.2997 (1.2997)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.336
[2024-12-07 12:36:16 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [48/50][10/34]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.4895 (0.5099)	loss 1.0397 (1.0476)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 12:36:22 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [48/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4824 (0.5632)	loss 1.1264 (0.9902)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 12:36:27 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [48/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.4661 (0.5353)	loss 1.1264 (1.0062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-07 12:36:29 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 48 training takes 0:00:18
[2024-12-07 12:36:30 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.679 
[2024-12-07 12:36:30 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 12:36:30 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:36:30 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5379, Recall: 0.5251, F1: 0.5196
[2024-12-07 12:36:30 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [49/50][0/34]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.7344 (0.7344)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.570
[2024-12-07 12:36:37 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [49/50][10/34]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4726 (0.6363)	loss 1.2130 (0.9058)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.266
[2024-12-07 12:36:41 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [49/50][20/34]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.4787 (0.5593)	loss 1.2997 (0.9820)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.172
[2024-12-07 12:36:46 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [49/50][30/34]	eta 0:00:02 lr 0.000004	 wd 0.0001	time 0.6709 (0.5397)	loss 1.2130 (1.0146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 12:36:49 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 49 training takes 0:00:18
[2024-12-07 12:36:50 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.538 
[2024-12-07 12:36:50 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 12:36:50 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 12:36:50 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4778, Recall: 0.4737, F1: 0.4702
[2024-12-07 12:36:50 swin_tiny_patch4_window7_224] (main.py 176): INFO Training time 0:16:31
[2024-12-07 13:10:37 swin_tiny_patch4_window7_224] (main.py 434): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-07 13:10:37 swin_tiny_patch4_window7_224] (main.py 435): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 13:10:37 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 13:10:37 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 2084144
[2024-12-07 13:10:37 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.141317952
[2024-12-07 13:10:37 swin_tiny_patch4_window7_224] (main.py 139): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-07 13:10:37 swin_tiny_patch4_window7_224] (main.py 157): INFO Start training
[2024-12-07 13:10:38 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][0/49]	eta 0:00:28 lr 0.000004	 wd 0.0001	time 0.5906 (0.5906)	loss 0.4353 (0.4353)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 13:10:43 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][10/49]	eta 0:00:20 lr 0.000004	 wd 0.0001	time 0.6726 (0.5348)	loss 0.5207 (0.6791)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 13:10:48 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][20/49]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4678 (0.5429)	loss 0.8668 (0.6820)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 13:10:53 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4576 (0.5161)	loss 0.7800 (0.6857)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 13:10:59 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.6488 (0.5238)	loss 0.4334 (0.6918)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 13:11:03 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 0 training takes 0:00:25
[2024-12-07 13:11:04 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.526 
[2024-12-07 13:11:04 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 13:11:04 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.53%
[2024-12-07 13:11:04 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4837, Recall: 0.4799, F1: 0.4713
[2024-12-07 13:11:05 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [1/50][0/49]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.6768 (0.6768)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 13:11:09 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [1/50][10/49]	eta 0:00:19 lr 0.000004	 wd 0.0001	time 0.4766 (0.4882)	loss 0.5199 (0.7011)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:11:15 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [1/50][20/49]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.6583 (0.5474)	loss 0.5199 (0.7139)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 13:11:20 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [1/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4583 (0.5216)	loss 0.6066 (0.6765)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 13:11:25 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [1/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4638 (0.5068)	loss 0.8665 (0.6996)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 13:11:30 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 1 training takes 0:00:25
[2024-12-07 13:11:31 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.538 
[2024-12-07 13:11:31 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 13:11:31 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.54%
[2024-12-07 13:11:31 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5385, Recall: 0.5489, F1: 0.5125
[2024-12-07 13:11:32 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [2/50][0/49]	eta 0:00:32 lr 0.000004	 wd 0.0001	time 0.6557 (0.6557)	loss 0.5199 (0.5199)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 13:11:36 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [2/50][10/49]	eta 0:00:18 lr 0.000004	 wd 0.0001	time 0.4479 (0.4803)	loss 0.6932 (0.6696)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:11:41 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [2/50][20/49]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.6764 (0.4915)	loss 0.7798 (0.7303)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 13:11:47 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [2/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4445 (0.5218)	loss 0.4332 (0.7183)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 13:11:52 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [2/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4587 (0.5056)	loss 0.5199 (0.6868)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 13:11:55 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 2 training takes 0:00:24
[2024-12-07 13:11:57 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.282 
[2024-12-07 13:11:57 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 13:11:57 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.54%
[2024-12-07 13:11:57 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4010, Recall: 0.4486, F1: 0.2646
[2024-12-07 13:11:58 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [3/50][0/49]	eta 0:00:45 lr 0.000004	 wd 0.0001	time 0.9293 (0.9293)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 13:12:03 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [3/50][10/49]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 0.4598 (0.5666)	loss 0.4332 (0.6459)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 13:12:08 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [3/50][20/49]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4580 (0.5188)	loss 0.6932 (0.7179)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:12:13 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [3/50][30/49]	eta 0:00:10 lr 0.000004	 wd 0.0001	time 0.6700 (0.5330)	loss 0.5199 (0.6876)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 13:12:18 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [3/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4666 (0.5258)	loss 0.8666 (0.6995)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 13:12:22 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 3 training takes 0:00:25
[2024-12-07 13:12:23 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.526 
[2024-12-07 13:12:23 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 13:12:23 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.54%
[2024-12-07 13:12:23 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4837, Recall: 0.4799, F1: 0.4713
[2024-12-07 13:12:24 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [4/50][0/49]	eta 0:00:32 lr 0.000004	 wd 0.0001	time 0.6733 (0.6733)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:12:30 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [4/50][10/49]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.5117 (0.6292)	loss 0.7798 (0.7247)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 13:12:35 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [4/50][20/49]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4573 (0.5499)	loss 0.7798 (0.7179)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 13:12:39 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [4/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4451 (0.5216)	loss 0.4332 (0.7071)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 13:12:46 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [4/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4522 (0.5447)	loss 0.3466 (0.6953)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-07 13:12:49 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 4 training takes 0:00:26
[2024-12-07 13:12:50 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.436 
[2024-12-07 13:12:50 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 13:12:50 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.54%
[2024-12-07 13:12:50 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4359, Recall: 0.4185, F1: 0.4042
[2024-12-07 13:12:51 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [5/50][0/49]	eta 0:00:32 lr 0.000004	 wd 0.0001	time 0.6630 (0.6630)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:12:56 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [5/50][10/49]	eta 0:00:20 lr 0.000004	 wd 0.0001	time 0.6812 (0.5168)	loss 0.6932 (0.6538)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:13:02 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [5/50][20/49]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4635 (0.5374)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:13:06 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [5/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4665 (0.5120)	loss 0.8665 (0.6876)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 13:13:12 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [5/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.6664 (0.5198)	loss 0.5199 (0.6868)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 13:13:16 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 5 training takes 0:00:25
[2024-12-07 13:13:17 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.385 
[2024-12-07 13:13:17 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 13:13:17 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.54%
[2024-12-07 13:13:17 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5429, Recall: 0.5338, F1: 0.3810
[2024-12-07 13:13:18 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [6/50][0/49]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.6888 (0.6888)	loss 0.4332 (0.4332)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 13:13:22 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [6/50][10/49]	eta 0:00:18 lr 0.000004	 wd 0.0001	time 0.4505 (0.4833)	loss 0.6932 (0.7089)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:13:29 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [6/50][20/49]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.7087 (0.5455)	loss 0.7798 (0.6725)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 13:13:33 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [6/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4460 (0.5192)	loss 0.6066 (0.7071)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 13:13:38 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [6/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.5333 (0.5053)	loss 0.7798 (0.7037)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 13:13:43 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 6 training takes 0:00:25
[2024-12-07 13:13:44 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.513 
[2024-12-07 13:13:44 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 13:13:44 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.54%
[2024-12-07 13:13:44 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5369, Recall: 0.5464, F1: 0.4966
[2024-12-07 13:13:45 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [7/50][0/49]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.6933 (0.6933)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 13:13:50 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [7/50][10/49]	eta 0:00:18 lr 0.000004	 wd 0.0001	time 0.4503 (0.4844)	loss 0.6065 (0.6695)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 13:13:54 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [7/50][20/49]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.6599 (0.4900)	loss 0.4332 (0.6560)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.617
[2024-12-07 13:14:01 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [7/50][30/49]	eta 0:00:10 lr 0.000004	 wd 0.0001	time 0.6683 (0.5520)	loss 0.8665 (0.6708)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 13:14:06 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [7/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4452 (0.5429)	loss 0.5199 (0.6763)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.609
[2024-12-07 13:14:11 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 7 training takes 0:00:27
[2024-12-07 13:14:12 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.269 
[2024-12-07 13:14:12 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 13:14:12 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.54%
[2024-12-07 13:14:12 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.1346, Recall: 0.5000, F1: 0.2121
[2024-12-07 13:14:13 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [8/50][0/49]	eta 0:00:32 lr 0.000004	 wd 0.0001	time 0.6562 (0.6562)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:14:18 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [8/50][10/49]	eta 0:00:18 lr 0.000004	 wd 0.0001	time 0.4531 (0.4786)	loss 0.5199 (0.6380)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 13:14:23 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [8/50][20/49]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.6892 (0.4877)	loss 0.7798 (0.6767)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 13:14:28 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [8/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4831 (0.5169)	loss 0.8665 (0.6820)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 13:14:33 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [8/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4603 (0.5017)	loss 0.6065 (0.6763)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 13:14:37 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 8 training takes 0:00:24
[2024-12-07 13:14:39 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.423 
[2024-12-07 13:14:39 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 13:14:39 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.54%
[2024-12-07 13:14:39 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4871, Recall: 0.4850, F1: 0.4184
[2024-12-07 13:14:39 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [9/50][0/49]	eta 0:00:46 lr 0.000004	 wd 0.0001	time 0.9518 (0.9518)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:14:45 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [9/50][10/49]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 0.4749 (0.5680)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:14:49 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [9/50][20/49]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4468 (0.5138)	loss 0.4332 (0.6643)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 13:14:55 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [9/50][30/49]	eta 0:00:10 lr 0.000004	 wd 0.0001	time 0.6768 (0.5321)	loss 0.5199 (0.6652)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 13:15:00 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [9/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4598 (0.5273)	loss 0.7798 (0.6953)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 13:15:04 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 9 training takes 0:00:25
[2024-12-07 13:15:05 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.397 
[2024-12-07 13:15:05 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 13:15:05 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.54%
[2024-12-07 13:15:05 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5129, Recall: 0.5125, F1: 0.3973
[2024-12-07 13:15:06 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [10/50][0/49]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 0.7029 (0.7029)	loss 0.7798 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 13:15:12 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [10/50][10/49]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.4780 (0.6346)	loss 0.7798 (0.7719)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 13:15:17 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [10/50][20/49]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.4685 (0.5548)	loss 0.9531 (0.7344)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.430
[2024-12-07 13:15:22 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [10/50][30/49]	eta 0:00:10 lr 0.000004	 wd 0.0001	time 0.6611 (0.5398)	loss 0.6931 (0.7183)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:15:28 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [10/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4543 (0.5555)	loss 0.3466 (0.6910)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 13:15:32 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 10 training takes 0:00:26
[2024-12-07 13:15:33 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.308 
[2024-12-07 13:15:33 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 13:15:33 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.54%
[2024-12-07 13:15:33 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4638, Recall: 0.4812, F1: 0.2909
[2024-12-07 13:15:33 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [11/50][0/49]	eta 0:00:32 lr 0.000004	 wd 0.0001	time 0.6706 (0.6706)	loss 0.5199 (0.5199)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 13:15:39 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [11/50][10/49]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 0.6992 (0.5701)	loss 0.6065 (0.7010)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 13:15:44 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [11/50][20/49]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.4542 (0.5525)	loss 0.6065 (0.7014)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 13:15:49 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [11/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4595 (0.5231)	loss 0.9531 (0.6876)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.430
[2024-12-07 13:15:55 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [11/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.7015 (0.5342)	loss 0.8665 (0.7058)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 13:15:59 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 11 training takes 0:00:26
[2024-12-07 13:16:00 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.269 
[2024-12-07 13:16:00 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 13:16:00 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.54%
[2024-12-07 13:16:00 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.1346, Recall: 0.5000, F1: 0.2121
[2024-12-07 13:16:01 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [12/50][0/49]	eta 0:00:32 lr 0.000004	 wd 0.0001	time 0.6645 (0.6645)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 13:16:05 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [12/50][10/49]	eta 0:00:19 lr 0.000004	 wd 0.0001	time 0.4706 (0.4901)	loss 0.7798 (0.7325)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 13:16:11 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [12/50][20/49]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.6096 (0.5528)	loss 0.6065 (0.6973)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 13:16:16 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [12/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4479 (0.5241)	loss 0.4332 (0.7071)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.570
[2024-12-07 13:16:21 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [12/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4615 (0.5087)	loss 0.4332 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 13:16:26 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 12 training takes 0:00:26
[2024-12-07 13:16:27 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.590 
[2024-12-07 13:16:27 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 13:16:27 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.59%
[2024-12-07 13:16:27 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5781, Recall: 0.5990, F1: 0.5609
[2024-12-07 13:16:28 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [13/50][0/49]	eta 0:00:32 lr 0.000004	 wd 0.0001	time 0.6600 (0.6600)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:16:33 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [13/50][10/49]	eta 0:00:19 lr 0.000004	 wd 0.0001	time 0.4681 (0.4878)	loss 0.6065 (0.7089)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 13:16:38 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [13/50][20/49]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.6971 (0.4954)	loss 0.8664 (0.6849)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:16:43 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [13/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4630 (0.5204)	loss 0.6932 (0.7071)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:16:48 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [13/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4747 (0.5077)	loss 0.7798 (0.6995)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 13:16:52 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 13 training takes 0:00:24
[2024-12-07 13:16:54 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.269 
[2024-12-07 13:16:54 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 13:16:54 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.59%
[2024-12-07 13:16:54 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.1346, Recall: 0.5000, F1: 0.2121
[2024-12-07 13:16:55 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [14/50][0/49]	eta 0:00:49 lr 0.000004	 wd 0.0001	time 1.0037 (1.0037)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:16:59 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [14/50][10/49]	eta 0:00:20 lr 0.000004	 wd 0.0001	time 0.4620 (0.5244)	loss 0.5199 (0.7089)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 13:17:04 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [14/50][20/49]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4646 (0.4954)	loss 0.7798 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 13:17:10 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [14/50][30/49]	eta 0:00:10 lr 0.000004	 wd 0.0001	time 0.5096 (0.5325)	loss 0.7798 (0.6764)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 13:17:15 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [14/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4661 (0.5155)	loss 0.6065 (0.6805)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 13:17:19 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 14 training takes 0:00:24
[2024-12-07 13:17:20 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.269 
[2024-12-07 13:17:20 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 13:17:20 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.59%
[2024-12-07 13:17:20 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.1346, Recall: 0.5000, F1: 0.2121
[2024-12-07 13:17:21 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [15/50][0/49]	eta 0:00:47 lr 0.000004	 wd 0.0001	time 0.9624 (0.9624)	loss 0.4332 (0.4332)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.641
[2024-12-07 13:17:27 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [15/50][10/49]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.4676 (0.6195)	loss 0.6932 (0.6538)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:17:31 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [15/50][20/49]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4426 (0.5439)	loss 0.5199 (0.7014)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.391
[2024-12-07 13:17:36 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [15/50][30/49]	eta 0:00:10 lr 0.000004	 wd 0.0001	time 0.6877 (0.5375)	loss 0.7798 (0.6820)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 13:17:44 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [15/50][40/49]	eta 0:00:05 lr 0.000004	 wd 0.0001	time 0.7300 (0.5833)	loss 0.7798 (0.6889)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 13:17:48 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 15 training takes 0:00:27
[2024-12-07 13:17:49 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.269 
[2024-12-07 13:17:49 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 13:17:49 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.59%
[2024-12-07 13:17:49 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.1346, Recall: 0.5000, F1: 0.2121
[2024-12-07 13:17:49 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [16/50][0/49]	eta 0:00:31 lr 0.000004	 wd 0.0001	time 0.6513 (0.6513)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 13:17:55 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [16/50][10/49]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 0.6858 (0.5879)	loss 0.6065 (0.7168)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 13:18:00 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [16/50][20/49]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4615 (0.5451)	loss 0.7798 (0.6849)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 13:18:05 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [16/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4503 (0.5182)	loss 0.5199 (0.6820)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 13:18:11 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [16/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.6922 (0.5383)	loss 0.7798 (0.6910)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 13:18:15 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 16 training takes 0:00:26
[2024-12-07 13:18:16 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.269 
[2024-12-07 13:18:16 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 13:18:16 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.59%
[2024-12-07 13:18:16 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.1346, Recall: 0.5000, F1: 0.2121
[2024-12-07 13:18:16 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [17/50][0/49]	eta 0:00:32 lr 0.000004	 wd 0.0001	time 0.6705 (0.6705)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-07 13:18:21 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [17/50][10/49]	eta 0:00:19 lr 0.000004	 wd 0.0001	time 0.4684 (0.4907)	loss 0.8664 (0.7010)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 13:18:27 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [17/50][20/49]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.4613 (0.5534)	loss 0.8664 (0.6973)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 13:18:32 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [17/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4995 (0.5246)	loss 0.6932 (0.6959)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:18:37 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [17/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.5576 (0.5108)	loss 0.7798 (0.6910)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 13:18:42 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 17 training takes 0:00:26
[2024-12-07 13:18:43 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.295 
[2024-12-07 13:18:43 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 13:18:43 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.59%
[2024-12-07 13:18:43 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.6382, Recall: 0.5175, F1: 0.2504
[2024-12-07 13:18:44 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [18/50][0/49]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.6768 (0.6768)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 13:18:48 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [18/50][10/49]	eta 0:00:18 lr 0.000004	 wd 0.0001	time 0.4565 (0.4837)	loss 0.8664 (0.7247)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 13:18:54 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [18/50][20/49]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.6932 (0.5108)	loss 0.7798 (0.6849)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 13:18:59 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [18/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4540 (0.5213)	loss 0.6065 (0.6904)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 13:19:04 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [18/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4808 (0.5082)	loss 1.0397 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 13:19:08 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 18 training takes 0:00:25
[2024-12-07 13:19:10 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.333 
[2024-12-07 13:19:10 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 13:19:10 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.59%
[2024-12-07 13:19:10 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5266, Recall: 0.5138, F1: 0.3172
[2024-12-07 13:19:11 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [19/50][0/49]	eta 0:00:40 lr 0.000004	 wd 0.0001	time 0.8175 (0.8175)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:19:15 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [19/50][10/49]	eta 0:00:19 lr 0.000004	 wd 0.0001	time 0.4662 (0.5075)	loss 0.7798 (0.6616)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 13:19:20 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [19/50][20/49]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4648 (0.4891)	loss 0.8664 (0.6849)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.391
[2024-12-07 13:19:26 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [19/50][30/49]	eta 0:00:10 lr 0.000004	 wd 0.0001	time 0.4652 (0.5339)	loss 0.7798 (0.6848)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.445
[2024-12-07 13:19:31 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [19/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4623 (0.5153)	loss 0.6931 (0.6889)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:19:35 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 19 training takes 0:00:24
[2024-12-07 13:19:36 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.731 
[2024-12-07 13:19:36 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 13:19:36 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:19:36 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 13:19:37 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [20/50][0/49]	eta 0:00:46 lr 0.000004	 wd 0.0001	time 0.9580 (0.9580)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.445
[2024-12-07 13:19:43 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [20/50][10/49]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.5052 (0.6174)	loss 0.6065 (0.6616)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 13:19:47 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [20/50][20/49]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4500 (0.5437)	loss 0.6065 (0.6601)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 13:19:53 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [20/50][30/49]	eta 0:00:10 lr 0.000004	 wd 0.0001	time 0.7121 (0.5517)	loss 0.8664 (0.6959)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 13:19:58 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [20/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4665 (0.5465)	loss 0.9531 (0.6953)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.430
[2024-12-07 13:20:02 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 20 training takes 0:00:26
[2024-12-07 13:20:03 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.397 
[2024-12-07 13:20:03 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 13:20:03 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:20:03 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4838, Recall: 0.4825, F1: 0.3965
[2024-12-07 13:20:04 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [21/50][0/49]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 0.7078 (0.7078)	loss 0.3466 (0.3466)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 13:20:10 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [21/50][10/49]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.6093 (0.6393)	loss 0.6065 (0.5750)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 13:20:15 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [21/50][20/49]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.4988 (0.5594)	loss 0.7798 (0.6436)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 13:20:19 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [21/50][30/49]	eta 0:00:10 lr 0.000004	 wd 0.0001	time 0.4470 (0.5273)	loss 0.6065 (0.6596)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 13:20:26 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [21/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4761 (0.5522)	loss 0.9531 (0.6847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 13:20:30 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 21 training takes 0:00:26
[2024-12-07 13:20:31 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.269 
[2024-12-07 13:20:31 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 13:20:31 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:20:31 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.1346, Recall: 0.5000, F1: 0.2121
[2024-12-07 13:20:31 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [22/50][0/49]	eta 0:00:32 lr 0.000004	 wd 0.0001	time 0.6587 (0.6587)	loss 0.5199 (0.5199)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 13:20:36 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [22/50][10/49]	eta 0:00:20 lr 0.000004	 wd 0.0001	time 0.6733 (0.5249)	loss 0.5199 (0.6459)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 13:20:42 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [22/50][20/49]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4665 (0.5466)	loss 0.7798 (0.6849)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 13:20:47 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [22/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4674 (0.5219)	loss 0.6932 (0.6987)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:20:52 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [22/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.6833 (0.5287)	loss 0.4332 (0.6847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 13:20:57 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 22 training takes 0:00:26
[2024-12-07 13:20:58 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.346 
[2024-12-07 13:20:58 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 13:20:58 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:20:58 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.6458, Recall: 0.5526, F1: 0.3210
[2024-12-07 13:20:59 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [23/50][0/49]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.6746 (0.6746)	loss 0.7798 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 13:21:03 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [23/50][10/49]	eta 0:00:19 lr 0.000004	 wd 0.0001	time 0.4598 (0.4894)	loss 0.6065 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 13:21:09 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [23/50][20/49]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.6678 (0.5460)	loss 0.4332 (0.6684)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 13:21:14 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [23/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4630 (0.5211)	loss 0.7798 (0.6568)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 13:21:20 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [23/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.8409 (0.5492)	loss 0.9531 (0.6572)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-07 13:21:26 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 23 training takes 0:00:27
[2024-12-07 13:21:27 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.654 
[2024-12-07 13:21:27 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 13:21:27 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:21:27 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5272, Recall: 0.5226, F1: 0.5217
[2024-12-07 13:21:27 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [24/50][0/49]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.6805 (0.6805)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 13:21:32 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [24/50][10/49]	eta 0:00:18 lr 0.000004	 wd 0.0001	time 0.4307 (0.4827)	loss 0.3466 (0.6695)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 13:21:38 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [24/50][20/49]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.6834 (0.5122)	loss 0.6932 (0.6808)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:21:43 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [24/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.5065 (0.5160)	loss 0.9531 (0.6708)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.430
[2024-12-07 13:21:47 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [24/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4491 (0.5022)	loss 0.7798 (0.6678)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 13:21:52 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 24 training takes 0:00:25
[2024-12-07 13:21:53 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.705 
[2024-12-07 13:21:53 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 13:21:53 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:21:53 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.3618, Recall: 0.4825, F1: 0.4135
[2024-12-07 13:21:54 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [25/50][0/49]	eta 0:00:31 lr 0.000004	 wd 0.0001	time 0.6433 (0.6433)	loss 0.4332 (0.4332)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-07 13:21:59 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [25/50][10/49]	eta 0:00:18 lr 0.000004	 wd 0.0001	time 0.4603 (0.4821)	loss 0.7798 (0.6695)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 13:22:03 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [25/50][20/49]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.5054 (0.4748)	loss 0.4332 (0.6395)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 13:22:09 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [25/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4581 (0.5147)	loss 0.8664 (0.6512)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 13:22:14 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [25/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4696 (0.5032)	loss 0.7798 (0.6636)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 13:22:18 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 25 training takes 0:00:24
[2024-12-07 13:22:19 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.256 
[2024-12-07 13:22:19 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 13:22:19 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:22:19 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.1299, Recall: 0.4762, F1: 0.2041
[2024-12-07 13:22:20 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [26/50][0/49]	eta 0:00:46 lr 0.000004	 wd 0.0001	time 0.9524 (0.9524)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 13:22:26 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [26/50][10/49]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 0.4590 (0.5669)	loss 0.6932 (0.6538)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:22:30 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [26/50][20/49]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4580 (0.5151)	loss 0.4332 (0.6643)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.430
[2024-12-07 13:22:36 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [26/50][30/49]	eta 0:00:10 lr 0.000004	 wd 0.0001	time 0.6745 (0.5374)	loss 0.5199 (0.6792)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 13:22:41 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [26/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4423 (0.5269)	loss 0.5199 (0.6784)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 13:22:45 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 26 training takes 0:00:25
[2024-12-07 13:22:46 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.269 
[2024-12-07 13:22:46 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 13:22:46 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:22:46 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.1346, Recall: 0.5000, F1: 0.2121
[2024-12-07 13:22:47 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [27/50][0/49]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 0.7001 (0.7001)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 13:22:53 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [27/50][10/49]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.4774 (0.6341)	loss 0.4332 (0.6774)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.641
[2024-12-07 13:22:58 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [27/50][20/49]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4500 (0.5496)	loss 0.6931 (0.6684)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:23:02 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [27/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4698 (0.5216)	loss 0.8664 (0.6959)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 13:23:08 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [27/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4615 (0.5454)	loss 0.9531 (0.7058)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 13:23:12 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 27 training takes 0:00:26
[2024-12-07 13:23:13 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.333 
[2024-12-07 13:23:13 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 13:23:13 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:23:13 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4980, Recall: 0.4987, F1: 0.3222
[2024-12-07 13:23:14 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [28/50][0/49]	eta 0:00:35 lr 0.000004	 wd 0.0001	time 0.7260 (0.7260)	loss 0.5199 (0.5199)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 13:23:19 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [28/50][10/49]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 0.7082 (0.5518)	loss 0.6065 (0.7404)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 13:23:25 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [28/50][20/49]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.4671 (0.5519)	loss 0.9531 (0.7344)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 13:23:29 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [28/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4682 (0.5224)	loss 0.7798 (0.7155)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 13:23:35 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [28/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.6583 (0.5268)	loss 0.6065 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 13:23:39 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 28 training takes 0:00:25
[2024-12-07 13:23:40 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.590 
[2024-12-07 13:23:40 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 13:23:40 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:23:40 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5443, Recall: 0.5539, F1: 0.5385
[2024-12-07 13:23:41 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [29/50][0/49]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.6812 (0.6812)	loss 0.7798 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 13:23:46 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [29/50][10/49]	eta 0:00:19 lr 0.000004	 wd 0.0001	time 0.4665 (0.4923)	loss 0.6931 (0.6774)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:23:52 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [29/50][20/49]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.6540 (0.5501)	loss 0.9531 (0.6643)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.570
[2024-12-07 13:23:56 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [29/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4636 (0.5210)	loss 0.6065 (0.6596)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 13:24:01 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [29/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4385 (0.5062)	loss 0.5199 (0.6593)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 13:24:06 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 29 training takes 0:00:26
[2024-12-07 13:24:07 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.449 
[2024-12-07 13:24:07 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 13:24:07 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:24:07 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5150, Recall: 0.5175, F1: 0.4442
[2024-12-07 13:24:08 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [30/50][0/49]	eta 0:00:32 lr 0.000004	 wd 0.0001	time 0.6684 (0.6684)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 13:24:13 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [30/50][10/49]	eta 0:00:19 lr 0.000004	 wd 0.0001	time 0.4617 (0.4893)	loss 0.9531 (0.7247)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 13:24:18 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [30/50][20/49]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.6675 (0.4956)	loss 0.7798 (0.7138)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 13:24:23 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [30/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4536 (0.5180)	loss 0.6065 (0.7015)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 13:24:28 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [30/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4850 (0.5032)	loss 1.0397 (0.6826)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 13:24:32 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 30 training takes 0:00:24
[2024-12-07 13:24:34 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.423 
[2024-12-07 13:24:34 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 13:24:34 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:24:34 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5139, Recall: 0.5150, F1: 0.4222
[2024-12-07 13:24:35 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [31/50][0/49]	eta 0:00:47 lr 0.000004	 wd 0.0001	time 0.9692 (0.9692)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:24:39 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [31/50][10/49]	eta 0:00:20 lr 0.000004	 wd 0.0001	time 0.4594 (0.5131)	loss 0.6932 (0.7168)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:24:44 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [31/50][20/49]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4842 (0.4866)	loss 0.7798 (0.6973)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 13:24:50 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [31/50][30/49]	eta 0:00:10 lr 0.000004	 wd 0.0001	time 0.4679 (0.5302)	loss 0.8664 (0.7071)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 13:24:55 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [31/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4530 (0.5127)	loss 0.4332 (0.6953)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.336
[2024-12-07 13:24:59 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 31 training takes 0:00:24
[2024-12-07 13:25:00 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.423 
[2024-12-07 13:25:00 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 13:25:00 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:25:00 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.6205, Recall: 0.5902, F1: 0.4184
[2024-12-07 13:25:02 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [32/50][0/49]	eta 0:00:54 lr 0.000004	 wd 0.0001	time 1.1205 (1.1205)	loss 0.4332 (0.4332)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 13:25:08 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [32/50][10/49]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 0.4499 (0.6862)	loss 0.4332 (0.6380)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:25:13 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [32/50][20/49]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.4526 (0.5782)	loss 0.6932 (0.6519)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:25:18 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [32/50][30/49]	eta 0:00:10 lr 0.000004	 wd 0.0001	time 0.6634 (0.5550)	loss 0.8664 (0.6876)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 13:25:23 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [32/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4454 (0.5552)	loss 0.6065 (0.6784)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 13:25:27 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 32 training takes 0:00:26
[2024-12-07 13:25:28 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.731 
[2024-12-07 13:25:28 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 13:25:28 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:25:28 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 13:25:29 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [33/50][0/49]	eta 0:00:32 lr 0.000004	 wd 0.0001	time 0.6677 (0.6677)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 13:25:35 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [33/50][10/49]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6803 (0.5980)	loss 0.6065 (0.7089)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 13:25:39 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [33/50][20/49]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4545 (0.5393)	loss 0.5199 (0.6519)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 13:25:44 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [33/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4609 (0.5130)	loss 0.7798 (0.6624)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 13:25:50 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [33/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.5059 (0.5399)	loss 0.7798 (0.6784)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 13:25:54 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 33 training takes 0:00:25
[2024-12-07 13:25:55 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.372 
[2024-12-07 13:25:55 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 13:25:55 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:25:55 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.6500, Recall: 0.5702, F1: 0.3538
[2024-12-07 13:25:56 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [34/50][0/49]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.6813 (0.6813)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-07 13:26:00 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [34/50][10/49]	eta 0:00:19 lr 0.000004	 wd 0.0001	time 0.6350 (0.4980)	loss 0.7798 (0.7640)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 13:26:06 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [34/50][20/49]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4590 (0.5459)	loss 0.6932 (0.7550)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:26:11 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [34/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4584 (0.5170)	loss 0.8664 (0.7323)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 13:26:16 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [34/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.6933 (0.5138)	loss 0.5199 (0.7016)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 13:26:21 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 34 training takes 0:00:25
[2024-12-07 13:26:22 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.718 
[2024-12-07 13:26:22 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 13:26:22 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:26:22 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.3636, Recall: 0.4912, F1: 0.4179
[2024-12-07 13:26:23 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [35/50][0/49]	eta 0:00:32 lr 0.000004	 wd 0.0001	time 0.6664 (0.6664)	loss 0.5199 (0.5199)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 13:26:27 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [35/50][10/49]	eta 0:00:19 lr 0.000004	 wd 0.0001	time 0.4520 (0.4889)	loss 0.7798 (0.7010)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 13:26:33 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [35/50][20/49]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.6773 (0.5263)	loss 0.5199 (0.7097)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 13:26:38 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [35/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4428 (0.5208)	loss 0.4332 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 13:26:43 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [35/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4802 (0.5071)	loss 1.0397 (0.7122)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-07 13:26:47 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 35 training takes 0:00:25
[2024-12-07 13:26:49 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.269 
[2024-12-07 13:26:49 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 13:26:49 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:26:49 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.1346, Recall: 0.5000, F1: 0.2121
[2024-12-07 13:26:50 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [36/50][0/49]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.6747 (0.6747)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 13:26:54 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [36/50][10/49]	eta 0:00:19 lr 0.000004	 wd 0.0001	time 0.4721 (0.4924)	loss 0.7798 (0.7010)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-07 13:26:59 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [36/50][20/49]	eta 0:00:13 lr 0.000004	 wd 0.0001	time 0.5563 (0.4821)	loss 0.6931 (0.6849)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:27:05 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [36/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4650 (0.5228)	loss 0.7798 (0.6904)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 13:27:10 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [36/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4783 (0.5090)	loss 0.8664 (0.6953)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.391
[2024-12-07 13:27:14 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 36 training takes 0:00:24
[2024-12-07 13:27:15 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.372 
[2024-12-07 13:27:15 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 13:27:15 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:27:15 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5121, Recall: 0.5100, F1: 0.3692
[2024-12-07 13:27:16 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [37/50][0/49]	eta 0:00:45 lr 0.000004	 wd 0.0001	time 0.9324 (0.9324)	loss 0.4332 (0.4332)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 13:27:22 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [37/50][10/49]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.4785 (0.6071)	loss 0.8664 (0.7404)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 13:27:26 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [37/50][20/49]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4537 (0.5371)	loss 0.7798 (0.7055)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 13:27:32 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [37/50][30/49]	eta 0:00:10 lr 0.000004	 wd 0.0001	time 0.6736 (0.5497)	loss 0.6932 (0.6764)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:27:37 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [37/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4588 (0.5381)	loss 1.0397 (0.6847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-07 13:27:41 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 37 training takes 0:00:25
[2024-12-07 13:27:42 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.474 
[2024-12-07 13:27:42 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 13:27:42 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:27:42 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5040, Recall: 0.5050, F1: 0.4593
[2024-12-07 13:27:43 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [38/50][0/49]	eta 0:00:32 lr 0.000004	 wd 0.0001	time 0.6676 (0.6676)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:27:49 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [38/50][10/49]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.4823 (0.6317)	loss 0.6065 (0.5986)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.445
[2024-12-07 13:27:53 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [38/50][20/49]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4477 (0.5501)	loss 0.6931 (0.6189)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:27:58 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [38/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4606 (0.5212)	loss 0.7798 (0.6512)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 13:28:04 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [38/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4537 (0.5453)	loss 0.6065 (0.6847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-07 13:28:08 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 38 training takes 0:00:26
[2024-12-07 13:28:09 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.269 
[2024-12-07 13:28:09 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 13:28:09 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:28:09 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.3816, Recall: 0.4850, F1: 0.2231
[2024-12-07 13:28:10 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [39/50][0/49]	eta 0:00:35 lr 0.000004	 wd 0.0001	time 0.7185 (0.7185)	loss 0.7798 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 13:28:15 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [39/50][10/49]	eta 0:00:20 lr 0.000004	 wd 0.0001	time 0.6950 (0.5283)	loss 0.7798 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 13:28:21 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [39/50][20/49]	eta 0:00:15 lr 0.000004	 wd 0.0001	time 0.4721 (0.5504)	loss 0.6931 (0.6725)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:28:25 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [39/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4617 (0.5219)	loss 0.8664 (0.6876)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 13:28:31 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [39/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.6858 (0.5236)	loss 0.6065 (0.6974)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 13:28:35 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 39 training takes 0:00:26
[2024-12-07 13:28:36 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.731 
[2024-12-07 13:28:36 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 13:28:36 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:28:36 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 13:28:37 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [40/50][0/49]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 0.6982 (0.6982)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 13:28:43 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [40/50][10/49]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 0.6710 (0.5924)	loss 0.5199 (0.7719)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.609
[2024-12-07 13:28:50 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [40/50][20/49]	eta 0:00:18 lr 0.000004	 wd 0.0001	time 0.5926 (0.6368)	loss 0.6932 (0.7097)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:28:54 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [40/50][30/49]	eta 0:00:11 lr 0.000004	 wd 0.0001	time 0.4567 (0.5819)	loss 0.9531 (0.7323)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.570
[2024-12-07 13:28:59 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [40/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4515 (0.5508)	loss 0.3466 (0.7079)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 13:29:04 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 40 training takes 0:00:27
[2024-12-07 13:29:05 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.667 
[2024-12-07 13:29:05 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 13:29:05 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:29:05 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5397, Recall: 0.5313, F1: 0.5306
[2024-12-07 13:29:06 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [41/50][0/49]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.6853 (0.6853)	loss 1.0397 (1.0397)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 13:29:11 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [41/50][10/49]	eta 0:00:19 lr 0.000004	 wd 0.0001	time 0.4577 (0.4931)	loss 0.6932 (0.7640)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:29:16 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [41/50][20/49]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.6538 (0.4969)	loss 0.3466 (0.7097)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-07 13:29:21 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [41/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4477 (0.5210)	loss 0.7798 (0.7211)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.445
[2024-12-07 13:29:26 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [41/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4865 (0.5054)	loss 0.9531 (0.6953)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.570
[2024-12-07 13:29:30 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 41 training takes 0:00:24
[2024-12-07 13:29:32 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.641 
[2024-12-07 13:29:32 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 13:29:32 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:29:32 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4769, Recall: 0.4837, F1: 0.4735
[2024-12-07 13:29:33 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [42/50][0/49]	eta 0:00:47 lr 0.000004	 wd 0.0001	time 0.9611 (0.9611)	loss 0.5199 (0.5199)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 13:29:38 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [42/50][10/49]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 0.4572 (0.5562)	loss 0.6065 (0.7247)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 13:29:42 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [42/50][20/49]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4623 (0.5142)	loss 0.6931 (0.7220)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:29:48 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [42/50][30/49]	eta 0:00:10 lr 0.000004	 wd 0.0001	time 0.7063 (0.5437)	loss 0.9531 (0.6959)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.336
[2024-12-07 13:29:53 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [42/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4683 (0.5291)	loss 0.6065 (0.6847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 13:29:57 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 42 training takes 0:00:25
[2024-12-07 13:29:58 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.513 
[2024-12-07 13:29:58 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 13:29:58 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:29:58 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4504, Recall: 0.4411, F1: 0.4408
[2024-12-07 13:29:59 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [43/50][0/49]	eta 0:00:32 lr 0.000004	 wd 0.0001	time 0.6641 (0.6641)	loss 0.5199 (0.5199)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 13:30:05 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [43/50][10/49]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.4617 (0.6359)	loss 0.6932 (0.7325)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:30:10 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [43/50][20/49]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.4672 (0.5549)	loss 0.5199 (0.7055)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 13:30:15 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [43/50][30/49]	eta 0:00:10 lr 0.000004	 wd 0.0001	time 0.5631 (0.5300)	loss 1.0397 (0.7043)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 13:30:21 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [43/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4844 (0.5496)	loss 0.7798 (0.6974)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 13:30:24 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 43 training takes 0:00:26
[2024-12-07 13:30:26 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.667 
[2024-12-07 13:30:26 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 13:30:26 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:30:26 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4306, Recall: 0.4712, F1: 0.4342
[2024-12-07 13:30:26 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [44/50][0/49]	eta 0:00:31 lr 0.000004	 wd 0.0001	time 0.6396 (0.6396)	loss 0.2599 (0.2599)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-07 13:30:32 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [44/50][10/49]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 0.6924 (0.5776)	loss 0.5199 (0.6695)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 13:30:37 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [44/50][20/49]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.4596 (0.5555)	loss 0.2599 (0.6725)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 13:30:42 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [44/50][30/49]	eta 0:00:09 lr 0.000004	 wd 0.0001	time 0.4495 (0.5259)	loss 0.6065 (0.6764)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 13:30:48 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [44/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.6772 (0.5408)	loss 0.9531 (0.7058)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:30:52 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 44 training takes 0:00:26
[2024-12-07 13:30:53 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.282 
[2024-12-07 13:30:53 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 13:30:53 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:30:53 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.6364, Recall: 0.5088, F1: 0.2315
[2024-12-07 13:30:54 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [45/50][0/49]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 0.7062 (0.7062)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 13:30:59 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [45/50][10/49]	eta 0:00:19 lr 0.000004	 wd 0.0001	time 0.4592 (0.4947)	loss 0.5199 (0.7483)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:31:05 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [45/50][20/49]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.5309 (0.5580)	loss 0.4332 (0.7303)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.359
[2024-12-07 13:31:09 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [45/50][30/49]	eta 0:00:10 lr 0.000004	 wd 0.0001	time 0.4808 (0.5289)	loss 0.7798 (0.7239)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 13:31:14 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [45/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4601 (0.5130)	loss 0.8664 (0.6953)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 13:31:19 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 45 training takes 0:00:26
[2024-12-07 13:31:21 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.731 
[2024-12-07 13:31:21 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 13:31:21 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:31:21 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 13:31:22 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [46/50][0/49]	eta 0:00:35 lr 0.000004	 wd 0.0001	time 0.7169 (0.7169)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:31:26 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [46/50][10/49]	eta 0:00:19 lr 0.000004	 wd 0.0001	time 0.4766 (0.5020)	loss 0.7798 (0.7640)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 13:31:32 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [46/50][20/49]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.7012 (0.5120)	loss 0.7798 (0.7138)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 13:31:37 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [46/50][30/49]	eta 0:00:10 lr 0.000004	 wd 0.0001	time 0.4468 (0.5330)	loss 0.5199 (0.7267)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 13:31:42 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [46/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4616 (0.5155)	loss 0.6065 (0.7185)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 13:31:46 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 46 training takes 0:00:25
[2024-12-07 13:31:47 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.538 
[2024-12-07 13:31:47 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 13:31:47 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:31:47 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5628, Recall: 0.5789, F1: 0.5231
[2024-12-07 13:31:48 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [47/50][0/49]	eta 0:00:45 lr 0.000004	 wd 0.0001	time 0.9378 (0.9378)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 13:31:54 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [47/50][10/49]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 0.4613 (0.5518)	loss 0.6065 (0.6459)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 13:31:58 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [47/50][20/49]	eta 0:00:14 lr 0.000004	 wd 0.0001	time 0.4587 (0.5124)	loss 0.7798 (0.6766)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 13:32:04 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [47/50][30/49]	eta 0:00:10 lr 0.000004	 wd 0.0001	time 0.6608 (0.5393)	loss 1.0397 (0.6652)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 13:32:09 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [47/50][40/49]	eta 0:00:04 lr 0.000004	 wd 0.0001	time 0.4858 (0.5313)	loss 0.8664 (0.6847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 13:32:13 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 47 training takes 0:00:25
[2024-12-07 13:32:14 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.410 
[2024-12-07 13:32:14 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 13:32:14 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:32:14 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5593, Recall: 0.5514, F1: 0.4087
[2024-12-07 13:32:15 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [48/50][0/49]	eta 0:00:35 lr 0.000004	 wd 0.0001	time 0.7152 (0.7152)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-07 13:32:21 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [48/50][10/49]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.4785 (0.6615)	loss 0.5199 (0.6774)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.609
[2024-12-07 13:32:28 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [48/50][20/49]	eta 0:00:18 lr 0.000004	 wd 0.0001	time 0.4713 (0.6488)	loss 0.9531 (0.7262)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.359
[2024-12-07 13:32:33 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [48/50][30/49]	eta 0:00:11 lr 0.000004	 wd 0.0001	time 0.6965 (0.6190)	loss 0.7798 (0.7015)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 13:32:39 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [48/50][40/49]	eta 0:00:05 lr 0.000004	 wd 0.0001	time 0.4598 (0.6024)	loss 0.4332 (0.6868)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.641
[2024-12-07 13:32:43 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 48 training takes 0:00:28
[2024-12-07 13:32:44 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.615 
[2024-12-07 13:32:44 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 13:32:44 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:32:44 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5374, Recall: 0.5414, F1: 0.5375
[2024-12-07 13:32:45 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [49/50][0/49]	eta 0:00:36 lr 0.000004	 wd 0.0001	time 0.7434 (0.7434)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:32:51 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [49/50][10/49]	eta 0:00:24 lr 0.000004	 wd 0.0001	time 0.4724 (0.6353)	loss 0.8664 (0.7010)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 13:32:56 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [49/50][20/49]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.4725 (0.5606)	loss 0.7798 (0.7633)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-07 13:33:00 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [49/50][30/49]	eta 0:00:10 lr 0.000004	 wd 0.0001	time 0.5320 (0.5342)	loss 0.6931 (0.7239)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 13:33:07 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [49/50][40/49]	eta 0:00:05 lr 0.000004	 wd 0.0001	time 0.5206 (0.5579)	loss 0.8664 (0.7079)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 13:33:11 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 49 training takes 0:00:26
[2024-12-07 13:33:12 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.679 
[2024-12-07 13:33:12 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 13:33:12 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.73%
[2024-12-07 13:33:12 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5665, Recall: 0.5551, F1: 0.5571
[2024-12-07 13:33:12 swin_tiny_patch4_window7_224] (main.py 176): INFO Training time 0:22:34
[2024-12-07 14:11:00 swin_tiny_patch4_window7_224] (main.py 434): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 1
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-07 14:11:00 swin_tiny_patch4_window7_224] (main.py 435): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 14:14:55 swin_tiny_patch4_window7_224] (main.py 434): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 1
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-07 14:14:55 swin_tiny_patch4_window7_224] (main.py 435): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 14:15:12 swin_tiny_patch4_window7_224] (main.py 434): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-07 14:15:12 swin_tiny_patch4_window7_224] (main.py 435): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 14:17:35 swin_tiny_patch4_window7_224] (main.py 434): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-07 14:17:35 swin_tiny_patch4_window7_224] (main.py 435): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 14:18:53 swin_tiny_patch4_window7_224] (main.py 434): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-07 14:18:53 swin_tiny_patch4_window7_224] (main.py 435): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 14:19:16 swin_tiny_patch4_window7_224] (main.py 434): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-07 14:19:16 swin_tiny_patch4_window7_224] (main.py 435): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 14:19:17 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 14:19:17 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 14:19:17 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 14:19:17 swin_tiny_patch4_window7_224] (main.py 139): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-07 14:19:17 swin_tiny_patch4_window7_224] (main.py 157): INFO Start training
[2024-12-07 14:19:18 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][0/49]	eta 0:01:02 lr 0.000004	 wd 0.0001	time 1.2703 (1.2703)	loss 1.0671 (1.0671)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-07 14:19:44 swin_tiny_patch4_window7_224] (main.py 434): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-07 14:19:44 swin_tiny_patch4_window7_224] (main.py 435): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 14:21:12 swin_tiny_patch4_window7_224] (main.py 434): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-07 14:21:12 swin_tiny_patch4_window7_224] (main.py 435): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 14:21:13 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 14:21:13 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 14:21:13 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 14:21:13 swin_tiny_patch4_window7_224] (main.py 139): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-07 14:21:13 swin_tiny_patch4_window7_224] (main.py 157): INFO Start training
[2024-12-07 14:21:14 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][0/49]	eta 0:01:08 lr 0.000004	 wd 0.0001	time 1.4029 (1.4029)	loss 0.7833 (0.7833)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 14:21:40 swin_tiny_patch4_window7_224] (main.py 434): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-07 14:21:40 swin_tiny_patch4_window7_224] (main.py 435): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 14:21:41 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 14:21:41 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 14:21:41 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 14:21:41 swin_tiny_patch4_window7_224] (main.py 139): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-07 14:21:41 swin_tiny_patch4_window7_224] (main.py 157): INFO Start training
[2024-12-07 14:21:43 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][0/49]	eta 0:01:09 lr 0.000004	 wd 0.0001	time 1.4224 (1.4224)	loss 0.7312 (0.7312)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:21:53 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][10/49]	eta 0:00:40 lr 0.000004	 wd 0.0001	time 1.2490 (1.0339)	loss 0.9551 (0.7432)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.430
[2024-12-07 14:22:06 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][20/49]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 0.7854 (1.1772)	loss 0.6948 (0.7336)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:22:30 swin_tiny_patch4_window7_224] (main.py 434): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-07 14:22:30 swin_tiny_patch4_window7_224] (main.py 435): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 14:22:31 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 14:22:31 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 14:22:31 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 14:22:31 swin_tiny_patch4_window7_224] (main.py 139): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-07 14:22:31 swin_tiny_patch4_window7_224] (main.py 157): INFO Start training
[2024-12-07 14:22:32 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][0/49]	eta 0:00:45 lr 0.000004	 wd 0.0001	time 0.9216 (0.9216)	loss 0.7216 (0.7216)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:22:40 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][10/49]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 1.1536 (0.8754)	loss 0.4336 (0.6821)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 14:22:49 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][20/49]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7886 (0.8660)	loss 0.5220 (0.6638)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 14:22:58 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][30/49]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.8496 (0.8838)	loss 1.0402 (0.6821)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 14:23:06 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [0/50][40/49]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.7626 (0.8590)	loss 0.5201 (0.6723)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-07 14:23:14 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 0 training takes 0:00:43
[2024-12-07 14:23:16 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.269 
[2024-12-07 14:23:16 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 14:23:16 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.27%
[2024-12-07 14:23:16 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.3784, Recall: 0.4699, F1: 0.2328
[2024-12-07 14:23:17 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [1/50][0/49]	eta 0:01:19 lr 0.000004	 wd 0.0001	time 1.6277 (1.6277)	loss 0.2602 (0.2602)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.695
[2024-12-07 14:23:27 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [1/50][10/49]	eta 0:00:39 lr 0.000004	 wd 0.0001	time 1.1673 (1.0014)	loss 0.6935 (0.7016)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:23:35 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [1/50][20/49]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 0.7934 (0.9187)	loss 0.8666 (0.6894)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 14:23:44 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [1/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7980 (0.9284)	loss 0.6067 (0.6851)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 14:23:53 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [1/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.9053 (0.9215)	loss 0.8666 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:24:01 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 1 training takes 0:00:45
[2024-12-07 14:24:03 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.410 
[2024-12-07 14:24:03 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 14:24:03 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.41%
[2024-12-07 14:24:03 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4332, Recall: 0.4160, F1: 0.3906
[2024-12-07 14:24:04 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [2/50][0/49]	eta 0:00:55 lr 0.000004	 wd 0.0001	time 1.1310 (1.1310)	loss 0.7799 (0.7799)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 14:24:14 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [2/50][10/49]	eta 0:00:39 lr 0.000004	 wd 0.0001	time 0.7812 (1.0134)	loss 0.6066 (0.7090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 14:24:22 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [2/50][20/49]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 0.7740 (0.9004)	loss 0.6065 (0.6561)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 14:24:32 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [2/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7694 (0.9164)	loss 0.6932 (0.6933)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:24:40 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [2/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 1.1584 (0.8939)	loss 0.8667 (0.6848)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 14:24:47 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 2 training takes 0:00:44
[2024-12-07 14:24:49 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.436 
[2024-12-07 14:24:49 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 14:24:49 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.44%
[2024-12-07 14:24:49 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5736, Recall: 0.5689, F1: 0.4355
[2024-12-07 14:24:50 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [3/50][0/49]	eta 0:00:53 lr 0.000004	 wd 0.0001	time 1.0845 (1.0845)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:25:00 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [3/50][10/49]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 0.7635 (0.9551)	loss 0.6065 (0.7326)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 14:25:08 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [3/50][20/49]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7890 (0.8929)	loss 0.6066 (0.6891)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 14:25:17 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [3/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7926 (0.9133)	loss 0.8664 (0.7044)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 14:25:26 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [3/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 1.1317 (0.9009)	loss 0.5199 (0.6848)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 14:25:33 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 3 training takes 0:00:43
[2024-12-07 14:25:35 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.615 
[2024-12-07 14:25:35 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 14:25:35 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.62%
[2024-12-07 14:25:35 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5249, Recall: 0.5263, F1: 0.5252
[2024-12-07 14:25:36 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [4/50][0/49]	eta 0:00:53 lr 0.000004	 wd 0.0001	time 1.0889 (1.0889)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 14:25:46 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [4/50][10/49]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 0.8040 (0.9635)	loss 0.9531 (0.5908)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 14:25:54 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [4/50][20/49]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 1.2517 (0.9207)	loss 0.7799 (0.6643)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:26:05 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [4/50][30/49]	eta 0:00:18 lr 0.000004	 wd 0.0001	time 0.7766 (0.9615)	loss 0.5199 (0.6988)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 14:26:14 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [4/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 1.2157 (0.9405)	loss 1.0403 (0.7144)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-07 14:26:21 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 4 training takes 0:00:45
[2024-12-07 14:26:22 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.423 
[2024-12-07 14:26:22 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 14:26:22 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.62%
[2024-12-07 14:26:22 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4871, Recall: 0.4850, F1: 0.4184
[2024-12-07 14:26:24 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [5/50][0/49]	eta 0:00:53 lr 0.000004	 wd 0.0001	time 1.0950 (1.0950)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 14:26:33 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [5/50][10/49]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 0.7809 (0.9648)	loss 0.6066 (0.7011)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:26:41 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [5/50][20/49]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7768 (0.8820)	loss 0.5199 (0.7097)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 14:26:50 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [5/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7841 (0.9014)	loss 0.4333 (0.6653)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 14:26:59 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [5/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 1.1878 (0.9011)	loss 0.9532 (0.6869)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.570
[2024-12-07 14:27:06 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 5 training takes 0:00:43
[2024-12-07 14:27:08 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.410 
[2024-12-07 14:27:08 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 14:27:08 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.62%
[2024-12-07 14:27:08 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5841, Recall: 0.5664, F1: 0.4067
[2024-12-07 14:27:09 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [6/50][0/49]	eta 0:00:55 lr 0.000004	 wd 0.0001	time 1.1358 (1.1358)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:27:19 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [6/50][10/49]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 0.8160 (0.9695)	loss 0.5199 (0.6617)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 14:27:27 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [6/50][20/49]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 1.0685 (0.8938)	loss 0.4332 (0.6437)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 14:27:36 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [6/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7853 (0.9025)	loss 0.9531 (0.6764)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 14:27:45 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [6/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 1.1227 (0.9089)	loss 0.2599 (0.6890)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 14:27:55 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 6 training takes 0:00:46
[2024-12-07 14:27:57 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.641 
[2024-12-07 14:27:57 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 14:27:57 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.64%
[2024-12-07 14:27:57 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.6081, Recall: 0.6341, F1: 0.6035
[2024-12-07 14:27:58 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [7/50][0/49]	eta 0:01:15 lr 0.000004	 wd 0.0001	time 1.5440 (1.5440)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:28:07 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [7/50][10/49]	eta 0:00:36 lr 0.000004	 wd 0.0001	time 0.7892 (0.9399)	loss 0.8665 (0.7326)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 14:28:17 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [7/50][20/49]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 0.9719 (0.9435)	loss 0.6065 (0.6849)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 14:28:24 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [7/50][30/49]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.7964 (0.8923)	loss 0.7799 (0.6792)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 14:28:34 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [7/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7983 (0.9070)	loss 0.7799 (0.7016)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 14:28:40 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 7 training takes 0:00:43
[2024-12-07 14:28:42 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.436 
[2024-12-07 14:28:42 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 14:28:42 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.64%
[2024-12-07 14:28:42 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4825, Recall: 0.4787, F1: 0.4265
[2024-12-07 14:28:44 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [8/50][0/49]	eta 0:01:14 lr 0.000004	 wd 0.0001	time 1.5268 (1.5268)	loss 0.5199 (0.5199)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 14:28:53 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [8/50][10/49]	eta 0:00:36 lr 0.000004	 wd 0.0001	time 0.8075 (0.9305)	loss 0.9531 (0.7720)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.430
[2024-12-07 14:29:02 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [8/50][20/49]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 0.8048 (0.9402)	loss 0.4332 (0.7386)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 14:29:10 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [8/50][30/49]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.8028 (0.8919)	loss 0.5199 (0.7100)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 14:29:20 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [8/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.8023 (0.9077)	loss 0.6932 (0.6911)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:29:26 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 8 training takes 0:00:43
[2024-12-07 14:29:29 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.436 
[2024-12-07 14:29:29 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 14:29:29 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.64%
[2024-12-07 14:29:29 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5076, Recall: 0.5088, F1: 0.4325
[2024-12-07 14:29:30 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [9/50][0/49]	eta 0:01:16 lr 0.000004	 wd 0.0001	time 1.5581 (1.5581)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:29:39 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [9/50][10/49]	eta 0:00:36 lr 0.000004	 wd 0.0001	time 0.8107 (0.9435)	loss 0.7799 (0.7404)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 14:30:00 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [9/50][20/49]	eta 0:00:43 lr 0.000004	 wd 0.0001	time 2.3518 (1.4968)	loss 0.6932 (0.7221)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:30:13 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [9/50][30/49]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 1.1423 (1.4374)	loss 0.7798 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 14:30:27 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [9/50][40/49]	eta 0:00:12 lr 0.000004	 wd 0.0001	time 0.7947 (1.4333)	loss 0.6932 (0.6890)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:30:39 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 9 training takes 0:01:09
[2024-12-07 14:30:41 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.410 
[2024-12-07 14:30:41 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 14:30:41 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.64%
[2024-12-07 14:30:41 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4921, Recall: 0.4912, F1: 0.4087
[2024-12-07 14:30:42 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [10/50][0/49]	eta 0:00:59 lr 0.000004	 wd 0.0001	time 1.2059 (1.2059)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:30:53 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [10/50][10/49]	eta 0:00:44 lr 0.000004	 wd 0.0001	time 0.8107 (1.1333)	loss 0.8665 (0.7562)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 14:31:01 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [10/50][20/49]	eta 0:00:28 lr 0.000004	 wd 0.0001	time 0.8917 (0.9770)	loss 0.5199 (0.7344)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 14:31:11 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [10/50][30/49]	eta 0:00:18 lr 0.000004	 wd 0.0001	time 0.7771 (0.9644)	loss 0.5199 (0.6988)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 14:31:20 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [10/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 1.1451 (0.9513)	loss 0.7798 (0.6826)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 14:31:27 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 10 training takes 0:00:46
[2024-12-07 14:31:29 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.551 
[2024-12-07 14:31:29 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 14:31:29 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.64%
[2024-12-07 14:31:29 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4391, Recall: 0.4373, F1: 0.4382
[2024-12-07 14:31:30 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [11/50][0/49]	eta 0:00:54 lr 0.000004	 wd 0.0001	time 1.1076 (1.1076)	loss 0.7798 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 14:31:39 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [11/50][10/49]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 0.7535 (0.9688)	loss 0.3466 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 14:31:48 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [11/50][20/49]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 1.1631 (0.9137)	loss 0.6932 (0.6684)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:31:57 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [11/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7981 (0.9107)	loss 0.6932 (0.6876)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:32:08 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [11/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7841 (0.9691)	loss 0.6932 (0.6890)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:32:17 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 11 training takes 0:00:48
[2024-12-07 14:32:22 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.615 
[2024-12-07 14:32:22 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 14:32:22 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.64%
[2024-12-07 14:32:22 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5374, Recall: 0.5414, F1: 0.5375
[2024-12-07 14:32:23 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [12/50][0/49]	eta 0:01:28 lr 0.000004	 wd 0.0001	time 1.8043 (1.8043)	loss 0.4332 (0.4332)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.430
[2024-12-07 14:32:33 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [12/50][10/49]	eta 0:00:42 lr 0.000004	 wd 0.0001	time 1.2195 (1.0815)	loss 0.7798 (0.7089)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 14:32:46 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [12/50][20/49]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 1.1969 (1.1613)	loss 0.5199 (0.6643)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 14:32:58 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [12/50][30/49]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 0.7613 (1.1792)	loss 0.5199 (0.6848)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 14:33:08 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [12/50][40/49]	eta 0:00:10 lr 0.000004	 wd 0.0001	time 1.0096 (1.1265)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:33:14 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 12 training takes 0:00:52
[2024-12-07 14:33:16 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.410 
[2024-12-07 14:33:16 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 14:33:16 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.64%
[2024-12-07 14:33:16 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4444, Recall: 0.4311, F1: 0.3960
[2024-12-07 14:33:17 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [13/50][0/49]	eta 0:00:54 lr 0.000004	 wd 0.0001	time 1.1164 (1.1164)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 14:33:27 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [13/50][10/49]	eta 0:00:39 lr 0.000004	 wd 0.0001	time 0.7940 (1.0053)	loss 0.7798 (0.7720)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 14:33:37 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [13/50][20/49]	eta 0:00:28 lr 0.000004	 wd 0.0001	time 1.4319 (0.9714)	loss 0.7798 (0.7097)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 14:33:46 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [13/50][30/49]	eta 0:00:18 lr 0.000004	 wd 0.0001	time 1.5476 (0.9710)	loss 0.8665 (0.7072)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 14:33:57 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [13/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.8033 (0.9930)	loss 0.7798 (0.7016)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 14:34:04 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 13 training takes 0:00:47
[2024-12-07 14:34:06 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.590 
[2024-12-07 14:34:06 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 14:34:06 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.64%
[2024-12-07 14:34:06 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5207, Recall: 0.5238, F1: 0.5185
[2024-12-07 14:34:08 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [14/50][0/49]	eta 0:01:16 lr 0.000004	 wd 0.0001	time 1.5686 (1.5686)	loss 0.2599 (0.2599)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 14:34:16 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [14/50][10/49]	eta 0:00:35 lr 0.000004	 wd 0.0001	time 0.8093 (0.9095)	loss 0.9532 (0.6617)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.430
[2024-12-07 14:34:26 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [14/50][20/49]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 0.7904 (0.9535)	loss 0.7798 (0.6437)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 14:34:34 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [14/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7962 (0.9026)	loss 0.6066 (0.6708)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 14:34:44 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [14/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.8438 (0.9184)	loss 0.7799 (0.6890)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 14:34:51 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 14 training takes 0:00:44
[2024-12-07 14:34:53 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.679 
[2024-12-07 14:34:53 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 14:34:53 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.68%
[2024-12-07 14:34:53 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5176, Recall: 0.5100, F1: 0.4968
[2024-12-07 14:34:55 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [15/50][0/49]	eta 0:00:58 lr 0.000004	 wd 0.0001	time 1.2036 (1.2036)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:35:03 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [15/50][10/49]	eta 0:00:32 lr 0.000004	 wd 0.0001	time 0.8078 (0.8403)	loss 0.8665 (0.7720)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 14:35:12 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [15/50][20/49]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7624 (0.8927)	loss 0.5199 (0.7056)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 14:35:21 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [15/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 1.1407 (0.9046)	loss 0.5199 (0.7127)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 14:35:30 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [15/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7762 (0.8936)	loss 0.5199 (0.6995)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 14:35:37 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 15 training takes 0:00:44
[2024-12-07 14:35:39 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.397 
[2024-12-07 14:35:39 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 14:35:39 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.68%
[2024-12-07 14:35:39 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4712, Recall: 0.4674, F1: 0.3949
[2024-12-07 14:35:40 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [16/50][0/49]	eta 0:00:54 lr 0.000004	 wd 0.0001	time 1.1078 (1.1078)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:35:50 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [16/50][10/49]	eta 0:00:36 lr 0.000004	 wd 0.0001	time 1.2277 (0.9341)	loss 0.6065 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 14:35:59 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [16/50][20/49]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 0.8059 (0.9149)	loss 0.7798 (0.7386)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 14:36:08 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [16/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.9725 (0.9261)	loss 0.6065 (0.7183)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 14:36:16 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [16/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.8101 (0.8941)	loss 0.6932 (0.7164)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:36:24 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 16 training takes 0:00:44
[2024-12-07 14:36:26 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.410 
[2024-12-07 14:36:26 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 14:36:26 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.68%
[2024-12-07 14:36:26 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5213, Recall: 0.5213, F1: 0.4103
[2024-12-07 14:36:27 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [17/50][0/49]	eta 0:00:54 lr 0.000004	 wd 0.0001	time 1.1049 (1.1049)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:36:36 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [17/50][10/49]	eta 0:00:36 lr 0.000004	 wd 0.0001	time 1.1753 (0.9283)	loss 0.7798 (0.7247)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 14:36:45 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [17/50][20/49]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.8502 (0.8932)	loss 0.5199 (0.7138)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 14:36:54 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [17/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.8113 (0.9100)	loss 0.8665 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 14:37:02 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [17/50][40/49]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.7936 (0.8813)	loss 0.6065 (0.6974)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 14:37:10 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 17 training takes 0:00:44
[2024-12-07 14:37:12 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.333 
[2024-12-07 14:37:12 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 14:37:12 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.68%
[2024-12-07 14:37:12 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5266, Recall: 0.5138, F1: 0.3172
[2024-12-07 14:37:13 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [18/50][0/49]	eta 0:00:54 lr 0.000004	 wd 0.0001	time 1.1048 (1.1048)	loss 0.7798 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 14:37:22 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [18/50][10/49]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.0533 (0.9718)	loss 0.6065 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 14:37:30 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [18/50][20/49]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7946 (0.8874)	loss 0.9531 (0.7303)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:37:40 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [18/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7825 (0.9042)	loss 0.6932 (0.7044)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:37:50 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [18/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 1.1648 (0.9405)	loss 0.7798 (0.6911)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:37:57 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 18 training takes 0:00:45
[2024-12-07 14:37:59 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.372 
[2024-12-07 14:37:59 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 14:37:59 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.68%
[2024-12-07 14:37:59 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5971, Recall: 0.5551, F1: 0.3590
[2024-12-07 14:38:00 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [19/50][0/49]	eta 0:00:56 lr 0.000004	 wd 0.0001	time 1.1485 (1.1485)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 14:38:10 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [19/50][10/49]	eta 0:00:38 lr 0.000004	 wd 0.0001	time 0.8016 (0.9765)	loss 0.7798 (0.7956)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:38:19 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [19/50][20/49]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 1.1682 (0.9343)	loss 0.8665 (0.7509)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 14:38:28 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [19/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7521 (0.9280)	loss 0.3466 (0.7435)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:38:37 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [19/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 1.0639 (0.9304)	loss 0.8665 (0.7122)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 14:38:43 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 19 training takes 0:00:44
[2024-12-07 14:38:46 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.423 
[2024-12-07 14:38:46 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 14:38:46 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.68%
[2024-12-07 14:38:46 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4405, Recall: 0.4248, F1: 0.4009
[2024-12-07 14:38:47 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [20/50][0/49]	eta 0:00:56 lr 0.000004	 wd 0.0001	time 1.1470 (1.1470)	loss 0.5199 (0.5199)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 14:38:56 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [20/50][10/49]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 0.7736 (0.9679)	loss 0.6065 (0.7562)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 14:39:05 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [20/50][20/49]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 1.1728 (0.9340)	loss 0.8664 (0.7262)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 14:39:14 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [20/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7816 (0.9034)	loss 0.5199 (0.7239)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 14:39:24 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [20/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.8282 (0.9252)	loss 0.6065 (0.7058)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 14:39:30 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 20 training takes 0:00:44
[2024-12-07 14:39:32 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.372 
[2024-12-07 14:39:32 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 14:39:32 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.68%
[2024-12-07 14:39:32 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.6500, Recall: 0.5702, F1: 0.3538
[2024-12-07 14:39:34 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [21/50][0/49]	eta 0:01:36 lr 0.000004	 wd 0.0001	time 1.9635 (1.9635)	loss 0.7798 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 14:39:43 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [21/50][10/49]	eta 0:00:39 lr 0.000004	 wd 0.0001	time 0.7780 (1.0062)	loss 0.6065 (0.6302)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 14:39:53 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [21/50][20/49]	eta 0:00:28 lr 0.000004	 wd 0.0001	time 0.7885 (0.9896)	loss 0.4332 (0.6395)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.570
[2024-12-07 14:40:01 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [21/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7871 (0.9296)	loss 0.6065 (0.6960)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 14:40:11 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [21/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7924 (0.9341)	loss 0.8664 (0.7037)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 14:40:17 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 21 training takes 0:00:44
[2024-12-07 14:40:20 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.590 
[2024-12-07 14:40:20 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 14:40:20 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.68%
[2024-12-07 14:40:20 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4407, Recall: 0.4486, F1: 0.4434
[2024-12-07 14:40:21 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [22/50][0/49]	eta 0:01:17 lr 0.000004	 wd 0.0001	time 1.5754 (1.5754)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 14:40:29 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [22/50][10/49]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 0.7874 (0.8850)	loss 0.6932 (0.7168)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:40:39 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [22/50][20/49]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 0.8130 (0.9216)	loss 0.6932 (0.7344)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:40:47 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [22/50][30/49]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.9919 (0.8878)	loss 0.3466 (0.6792)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 14:40:56 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [22/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7759 (0.9000)	loss 0.5199 (0.6847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 14:41:04 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 22 training takes 0:00:44
[2024-12-07 14:41:06 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.538 
[2024-12-07 14:41:06 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 14:41:06 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.68%
[2024-12-07 14:41:06 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5030, Recall: 0.5038, F1: 0.4902
[2024-12-07 14:41:07 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [23/50][0/49]	eta 0:00:54 lr 0.000004	 wd 0.0001	time 1.1218 (1.1218)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.430
[2024-12-07 14:41:15 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [23/50][10/49]	eta 0:00:32 lr 0.000004	 wd 0.0001	time 0.7732 (0.8329)	loss 0.6932 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:41:25 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [23/50][20/49]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7674 (0.8871)	loss 0.3466 (0.7344)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 14:41:33 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [23/50][30/49]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 1.1551 (0.8756)	loss 0.7798 (0.6960)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 14:41:42 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [23/50][40/49]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.9966 (0.8817)	loss 0.8665 (0.6911)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 14:41:52 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 23 training takes 0:00:45
[2024-12-07 14:41:54 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.615 
[2024-12-07 14:41:54 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 14:41:54 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.68%
[2024-12-07 14:41:54 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4308, Recall: 0.4511, F1: 0.4359
[2024-12-07 14:41:55 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [24/50][0/49]	eta 0:00:58 lr 0.000004	 wd 0.0001	time 1.2012 (1.2012)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 14:42:04 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [24/50][10/49]	eta 0:00:34 lr 0.000004	 wd 0.0001	time 1.1628 (0.8949)	loss 0.5199 (0.6774)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 14:42:14 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [24/50][20/49]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 0.8406 (0.9561)	loss 0.7798 (0.6643)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 14:42:24 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [24/50][30/49]	eta 0:00:18 lr 0.000004	 wd 0.0001	time 0.7960 (0.9549)	loss 0.6932 (0.6820)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:42:31 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [24/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7821 (0.9111)	loss 0.7798 (0.6826)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:42:39 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 24 training takes 0:00:45
[2024-12-07 14:42:41 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.705 
[2024-12-07 14:42:41 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 14:42:41 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:42:41 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.6058, Recall: 0.5877, F1: 0.5926
[2024-12-07 14:42:42 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [25/50][0/49]	eta 0:00:56 lr 0.000004	 wd 0.0001	time 1.1504 (1.1504)	loss 1.2130 (1.2130)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 14:42:52 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [25/50][10/49]	eta 0:00:38 lr 0.000004	 wd 0.0001	time 1.1727 (0.9762)	loss 0.5199 (0.7010)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:43:00 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [25/50][20/49]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.8022 (0.8931)	loss 0.7798 (0.7179)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 14:43:09 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [25/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.8467 (0.9115)	loss 0.9531 (0.7099)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-07 14:43:17 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [25/50][40/49]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.8047 (0.8819)	loss 0.5199 (0.6911)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:43:25 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 25 training takes 0:00:44
[2024-12-07 14:43:27 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.423 
[2024-12-07 14:43:27 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 14:43:27 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:43:27 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5000, Recall: 0.5000, F1: 0.4207
[2024-12-07 14:43:28 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [26/50][0/49]	eta 0:00:54 lr 0.000004	 wd 0.0001	time 1.1100 (1.1100)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:43:38 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [26/50][10/49]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 0.8268 (0.9640)	loss 0.6065 (0.7010)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 14:43:46 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [26/50][20/49]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7956 (0.8803)	loss 0.6932 (0.6725)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:43:55 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [26/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.8027 (0.9017)	loss 0.7798 (0.6680)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 14:44:03 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [26/50][40/49]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 1.2191 (0.8854)	loss 0.7798 (0.6826)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 14:44:11 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 26 training takes 0:00:43
[2024-12-07 14:44:13 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.615 
[2024-12-07 14:44:13 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 14:44:13 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:44:13 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5710, Recall: 0.5865, F1: 0.5673
[2024-12-07 14:44:14 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [27/50][0/49]	eta 0:00:55 lr 0.000004	 wd 0.0001	time 1.1322 (1.1322)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 14:44:23 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [27/50][10/49]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 0.7859 (0.9742)	loss 0.6065 (0.7483)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 14:44:31 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [27/50][20/49]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7843 (0.8811)	loss 0.9531 (0.6808)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-07 14:44:41 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [27/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7735 (0.9008)	loss 0.6065 (0.6904)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 14:44:49 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [27/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 1.1850 (0.8907)	loss 0.6932 (0.6805)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:44:57 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 27 training takes 0:00:43
[2024-12-07 14:44:58 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.513 
[2024-12-07 14:44:58 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 14:44:58 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:44:58 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5369, Recall: 0.5464, F1: 0.4966
[2024-12-07 14:45:00 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [28/50][0/49]	eta 0:00:53 lr 0.000004	 wd 0.0001	time 1.0994 (1.0994)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:45:09 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [28/50][10/49]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 0.7949 (0.9647)	loss 0.7798 (0.6853)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 14:45:17 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [28/50][20/49]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7726 (0.8808)	loss 0.3466 (0.6849)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 14:45:26 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [28/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.8155 (0.9038)	loss 0.6065 (0.6792)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 14:45:35 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [28/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 1.2024 (0.9046)	loss 1.0398 (0.7037)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 14:45:43 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 28 training takes 0:00:44
[2024-12-07 14:45:45 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.603 
[2024-12-07 14:45:45 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 14:45:45 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:45:45 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4871, Recall: 0.4875, F1: 0.4872
[2024-12-07 14:45:47 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [29/50][0/49]	eta 0:01:01 lr 0.000004	 wd 0.0001	time 1.2507 (1.2507)	loss 0.9531 (0.9531)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 14:45:56 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [29/50][10/49]	eta 0:00:38 lr 0.000004	 wd 0.0001	time 0.7817 (0.9823)	loss 0.4332 (0.6301)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.570
[2024-12-07 14:46:05 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [29/50][20/49]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 1.1721 (0.9374)	loss 0.9531 (0.6478)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 14:46:14 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [29/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7797 (0.9092)	loss 0.6932 (0.6680)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:46:23 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [29/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7811 (0.9215)	loss 0.6932 (0.6720)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:46:30 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 29 training takes 0:00:44
[2024-12-07 14:46:32 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.359 
[2024-12-07 14:46:32 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 14:46:32 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:46:32 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4227, Recall: 0.4110, F1: 0.3552
[2024-12-07 14:46:33 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [30/50][0/49]	eta 0:01:00 lr 0.000004	 wd 0.0001	time 1.2277 (1.2277)	loss 0.7798 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 14:46:42 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [30/50][10/49]	eta 0:00:38 lr 0.000004	 wd 0.0001	time 0.7809 (0.9763)	loss 0.6932 (0.7089)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:46:52 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [30/50][20/49]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 1.1902 (0.9567)	loss 0.9531 (0.6973)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-07 14:47:00 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [30/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7505 (0.9090)	loss 0.4332 (0.7099)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.570
[2024-12-07 14:47:09 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [30/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7942 (0.9194)	loss 0.8665 (0.7016)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 14:47:16 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 30 training takes 0:00:43
[2024-12-07 14:47:17 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.474 
[2024-12-07 14:47:17 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 14:47:17 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:47:17 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4563, Recall: 0.4449, F1: 0.4333
[2024-12-07 14:47:19 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [31/50][0/49]	eta 0:01:16 lr 0.000004	 wd 0.0001	time 1.5609 (1.5609)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:47:28 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [31/50][10/49]	eta 0:00:38 lr 0.000004	 wd 0.0001	time 0.7962 (0.9770)	loss 0.6065 (0.7325)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 14:47:37 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [31/50][20/49]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 0.9264 (0.9542)	loss 0.6065 (0.7303)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 14:47:45 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [31/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7951 (0.9000)	loss 0.6932 (0.7015)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:47:55 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [31/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.8043 (0.9115)	loss 0.9531 (0.7122)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.664
[2024-12-07 14:48:01 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 31 training takes 0:00:43
[2024-12-07 14:48:03 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.346 
[2024-12-07 14:48:03 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 14:48:03 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:48:03 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4583, Recall: 0.4624, F1: 0.3452
[2024-12-07 14:48:05 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [32/50][0/49]	eta 0:01:17 lr 0.000004	 wd 0.0001	time 1.5862 (1.5862)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 14:48:13 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [32/50][10/49]	eta 0:00:35 lr 0.000004	 wd 0.0001	time 0.7813 (0.9178)	loss 0.6932 (0.7247)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:48:23 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [32/50][20/49]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 0.8126 (0.9333)	loss 0.7798 (0.6684)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 14:48:31 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [32/50][30/49]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.7806 (0.8865)	loss 0.7798 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 14:48:40 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [32/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7926 (0.9003)	loss 0.6932 (0.6974)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:48:47 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 32 training takes 0:00:43
[2024-12-07 14:48:49 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.564 
[2024-12-07 14:48:49 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 14:48:49 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:48:49 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5053, Recall: 0.5063, F1: 0.4996
[2024-12-07 14:48:51 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [33/50][0/49]	eta 0:01:17 lr 0.000004	 wd 0.0001	time 1.5917 (1.5917)	loss 0.7798 (0.7798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 14:48:59 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [33/50][10/49]	eta 0:00:35 lr 0.000004	 wd 0.0001	time 0.7894 (0.8998)	loss 0.7798 (0.6853)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 14:49:08 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [33/50][20/49]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 0.7888 (0.9193)	loss 0.6065 (0.6560)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 14:49:16 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [33/50][30/49]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 0.7820 (0.8804)	loss 0.6065 (0.6848)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 14:49:26 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [33/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7531 (0.8976)	loss 0.3466 (0.6826)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.656
[2024-12-07 14:49:32 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 33 training takes 0:00:43
[2024-12-07 14:49:35 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.487 
[2024-12-07 14:49:35 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 14:49:35 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:49:35 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5804, Recall: 0.5890, F1: 0.4858
[2024-12-07 14:49:37 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [34/50][0/49]	eta 0:01:12 lr 0.000004	 wd 0.0001	time 1.4868 (1.4868)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 14:49:45 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [34/50][10/49]	eta 0:00:36 lr 0.000004	 wd 0.0001	time 1.1069 (0.9269)	loss 0.1733 (0.6144)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-07 14:49:56 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [34/50][20/49]	eta 0:00:28 lr 0.000004	 wd 0.0001	time 0.8040 (0.9865)	loss 0.9531 (0.6271)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-07 14:50:04 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [34/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 1.1418 (0.9353)	loss 0.7798 (0.6568)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 14:50:13 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [34/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7904 (0.9311)	loss 0.7798 (0.6657)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 14:50:20 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 34 training takes 0:00:45
[2024-12-07 14:50:23 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.321 
[2024-12-07 14:50:23 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 14:50:23 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:50:23 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5107, Recall: 0.5050, F1: 0.3011
[2024-12-07 14:50:24 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [35/50][0/49]	eta 0:00:57 lr 0.000004	 wd 0.0001	time 1.1663 (1.1663)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 14:50:32 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [35/50][10/49]	eta 0:00:32 lr 0.000004	 wd 0.0001	time 0.7880 (0.8286)	loss 0.6932 (0.6538)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:50:42 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [35/50][20/49]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7716 (0.8905)	loss 0.4332 (0.7014)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 14:50:50 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [35/50][30/49]	eta 0:00:16 lr 0.000004	 wd 0.0001	time 1.1733 (0.8780)	loss 0.8664 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 14:50:59 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [35/50][40/49]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.8059 (0.8814)	loss 0.9531 (0.6953)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 14:51:07 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 35 training takes 0:00:43
[2024-12-07 14:51:09 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.641 
[2024-12-07 14:51:09 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 14:51:09 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:51:09 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4984, Recall: 0.4987, F1: 0.4944
[2024-12-07 14:51:10 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [36/50][0/49]	eta 0:00:54 lr 0.000004	 wd 0.0001	time 1.1154 (1.1154)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:51:18 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [36/50][10/49]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 1.1433 (0.8566)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:51:27 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [36/50][20/49]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7643 (0.8858)	loss 0.6065 (0.7303)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 14:51:37 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [36/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 1.1134 (0.9046)	loss 0.7798 (0.7155)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 14:51:45 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [36/50][40/49]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.7902 (0.8760)	loss 0.2599 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.305
[2024-12-07 14:51:52 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 36 training takes 0:00:43
[2024-12-07 14:51:54 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.372 
[2024-12-07 14:51:54 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 14:51:54 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:51:54 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4793, Recall: 0.4799, F1: 0.3717
[2024-12-07 14:51:56 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [37/50][0/49]	eta 0:00:56 lr 0.000004	 wd 0.0001	time 1.1543 (1.1543)	loss 1.1264 (1.1264)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-07 14:52:04 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [37/50][10/49]	eta 0:00:35 lr 0.000004	 wd 0.0001	time 1.1233 (0.9129)	loss 0.3466 (0.6617)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-07 14:52:13 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [37/50][20/49]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7651 (0.8812)	loss 0.6932 (0.6849)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:52:22 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [37/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7797 (0.8967)	loss 0.6932 (0.7155)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:52:30 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [37/50][40/49]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.7683 (0.8704)	loss 0.4332 (0.6910)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 14:52:38 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 37 training takes 0:00:43
[2024-12-07 14:52:40 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.372 
[2024-12-07 14:52:40 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 14:52:40 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:52:40 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5121, Recall: 0.5100, F1: 0.3692
[2024-12-07 14:52:41 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [38/50][0/49]	eta 0:00:54 lr 0.000004	 wd 0.0001	time 1.1144 (1.1144)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 14:52:51 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [38/50][10/49]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.1363 (0.9742)	loss 0.6065 (0.7089)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 14:52:58 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [38/50][20/49]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7910 (0.8872)	loss 0.7798 (0.7220)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 14:53:08 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [38/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.8127 (0.9067)	loss 0.6932 (0.6960)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:53:16 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [38/50][40/49]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 1.0195 (0.8877)	loss 0.5199 (0.6995)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 14:53:24 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 38 training takes 0:00:44
[2024-12-07 14:53:26 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.487 
[2024-12-07 14:53:26 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 14:53:26 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:53:26 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.6190, Recall: 0.6190, F1: 0.4872
[2024-12-07 14:53:27 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [39/50][0/49]	eta 0:00:53 lr 0.000004	 wd 0.0001	time 1.0915 (1.0915)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 14:53:37 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [39/50][10/49]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 0.8253 (0.9688)	loss 0.9531 (0.7089)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:53:44 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [39/50][20/49]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.8070 (0.8811)	loss 0.7798 (0.6849)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 14:53:56 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [39/50][30/49]	eta 0:00:18 lr 0.000004	 wd 0.0001	time 0.8213 (0.9676)	loss 0.7798 (0.7211)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 14:54:04 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [39/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7842 (0.9244)	loss 0.5199 (0.7037)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:54:12 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 39 training takes 0:00:45
[2024-12-07 14:54:14 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.282 
[2024-12-07 14:54:14 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 14:54:14 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:54:14 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4667, Recall: 0.4937, F1: 0.2417
[2024-12-07 14:54:15 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [40/50][0/49]	eta 0:00:53 lr 0.000004	 wd 0.0001	time 1.0979 (1.0979)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:54:24 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [40/50][10/49]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.1543 (0.9563)	loss 0.6065 (0.6617)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 14:54:32 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [40/50][20/49]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7675 (0.8864)	loss 0.5199 (0.6808)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 14:54:42 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [40/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.8029 (0.9080)	loss 0.6932 (0.6876)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:54:50 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [40/50][40/49]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 0.7772 (0.8798)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:54:58 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 40 training takes 0:00:43
[2024-12-07 14:54:59 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.692 
[2024-12-07 14:54:59 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 14:54:59 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:54:59 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5362, Recall: 0.5188, F1: 0.5048
[2024-12-07 14:55:01 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [41/50][0/49]	eta 0:00:54 lr 0.000004	 wd 0.0001	time 1.1043 (1.1043)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:55:10 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [41/50][10/49]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 0.8130 (0.9721)	loss 0.6932 (0.7325)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:55:18 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [41/50][20/49]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.7722 (0.8831)	loss 0.6932 (0.6890)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:55:27 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [41/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7888 (0.9040)	loss 0.8665 (0.6792)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.609
[2024-12-07 14:55:36 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [41/50][40/49]	eta 0:00:07 lr 0.000004	 wd 0.0001	time 1.1459 (0.8871)	loss 0.6065 (0.6826)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 14:55:43 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 41 training takes 0:00:43
[2024-12-07 14:55:45 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.436 
[2024-12-07 14:55:45 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.4%
[2024-12-07 14:55:45 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:55:45 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4113, Recall: 0.3885, F1: 0.3871
[2024-12-07 14:55:46 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [42/50][0/49]	eta 0:00:53 lr 0.000004	 wd 0.0001	time 1.0826 (1.0826)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 14:55:56 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [42/50][10/49]	eta 0:00:38 lr 0.000004	 wd 0.0001	time 0.7959 (0.9819)	loss 0.5199 (0.7483)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 14:56:04 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [42/50][20/49]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.8035 (0.8904)	loss 0.8664 (0.7179)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:56:13 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [42/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7906 (0.9072)	loss 0.8664 (0.6904)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 14:56:22 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [42/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 1.1567 (0.8988)	loss 0.7798 (0.7079)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 14:56:29 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 42 training takes 0:00:44
[2024-12-07 14:56:31 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.551 
[2024-12-07 14:56:31 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 14:56:31 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:56:31 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5572, Recall: 0.5727, F1: 0.5289
[2024-12-07 14:56:32 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [43/50][0/49]	eta 0:00:56 lr 0.000004	 wd 0.0001	time 1.1435 (1.1435)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 14:56:42 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [43/50][10/49]	eta 0:00:38 lr 0.000004	 wd 0.0001	time 0.7967 (0.9781)	loss 0.8664 (0.7168)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 14:56:50 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [43/50][20/49]	eta 0:00:25 lr 0.000004	 wd 0.0001	time 0.8574 (0.8915)	loss 0.7798 (0.6973)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 14:56:59 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [43/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7790 (0.9111)	loss 0.7798 (0.7155)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 14:57:09 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [43/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 1.1409 (0.9117)	loss 0.6065 (0.7143)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 14:57:15 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 43 training takes 0:00:44
[2024-12-07 14:57:17 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.705 
[2024-12-07 14:57:17 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 14:57:17 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:57:17 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4899, Recall: 0.4975, F1: 0.4522
[2024-12-07 14:57:18 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [44/50][0/49]	eta 0:00:55 lr 0.000004	 wd 0.0001	time 1.1337 (1.1337)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 14:57:28 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [44/50][10/49]	eta 0:00:38 lr 0.000004	 wd 0.0001	time 0.7770 (0.9747)	loss 0.6932 (0.6616)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:57:36 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [44/50][20/49]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 1.1509 (0.9015)	loss 0.6932 (0.6725)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:57:45 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [44/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.8317 (0.9080)	loss 1.0397 (0.7183)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 14:57:56 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [44/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.8546 (0.9608)	loss 0.7798 (0.7016)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 14:58:03 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 44 training takes 0:00:45
[2024-12-07 14:58:05 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.577 
[2024-12-07 14:58:05 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 14:58:05 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:58:05 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4861, Recall: 0.4850, F1: 0.4847
[2024-12-07 14:58:06 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [45/50][0/49]	eta 0:00:54 lr 0.000004	 wd 0.0001	time 1.1032 (1.1032)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:58:15 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [45/50][10/49]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 0.7805 (0.9636)	loss 0.6932 (0.6538)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:58:24 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [45/50][20/49]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 1.1420 (0.9331)	loss 0.7798 (0.6767)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 14:58:33 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [45/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7862 (0.9043)	loss 0.6932 (0.7127)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:58:42 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [45/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7658 (0.9169)	loss 0.6065 (0.7080)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 14:58:49 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 45 training takes 0:00:43
[2024-12-07 14:58:50 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.654 
[2024-12-07 14:58:50 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 14:58:50 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:58:50 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.4603, Recall: 0.4774, F1: 0.4565
[2024-12-07 14:58:52 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [46/50][0/49]	eta 0:01:10 lr 0.000004	 wd 0.0001	time 1.4408 (1.4408)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 14:59:01 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [46/50][10/49]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 0.7859 (0.9629)	loss 0.6065 (0.5908)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 14:59:10 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [46/50][20/49]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 1.1046 (0.9525)	loss 0.7798 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 14:59:19 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [46/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.7734 (0.9047)	loss 0.4332 (0.6736)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 14:59:28 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [46/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7826 (0.9180)	loss 0.6932 (0.6889)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 14:59:34 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 46 training takes 0:00:44
[2024-12-07 14:59:36 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.487 
[2024-12-07 14:59:36 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 14:59:36 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 14:59:36 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5360, Recall: 0.5439, F1: 0.4786
[2024-12-07 14:59:38 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [47/50][0/49]	eta 0:01:17 lr 0.000004	 wd 0.0001	time 1.5792 (1.5792)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 14:59:47 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [47/50][10/49]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 0.8151 (0.9613)	loss 0.8665 (0.7089)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 14:59:57 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [47/50][20/49]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 0.8110 (0.9543)	loss 0.3466 (0.7262)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 15:00:05 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [47/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.8161 (0.9050)	loss 0.8664 (0.7071)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 15:00:14 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [47/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7854 (0.9179)	loss 0.5199 (0.6995)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 15:00:21 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 47 training takes 0:00:44
[2024-12-07 15:00:23 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.641 
[2024-12-07 15:00:23 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 15:00:23 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 15:00:23 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.6081, Recall: 0.6341, F1: 0.6035
[2024-12-07 15:00:25 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [48/50][0/49]	eta 0:01:18 lr 0.000004	 wd 0.0001	time 1.6069 (1.6069)	loss 0.8664 (0.8664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 15:00:33 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [48/50][10/49]	eta 0:00:36 lr 0.000004	 wd 0.0001	time 0.7947 (0.9326)	loss 0.6932 (0.7562)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 15:00:43 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [48/50][20/49]	eta 0:00:27 lr 0.000004	 wd 0.0001	time 0.7871 (0.9450)	loss 0.4332 (0.7344)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.359
[2024-12-07 15:00:51 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [48/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 0.8059 (0.8987)	loss 0.6065 (0.7351)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 15:01:00 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [48/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.7779 (0.9121)	loss 0.5199 (0.7227)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 15:01:07 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 48 training takes 0:00:44
[2024-12-07 15:01:10 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.590 
[2024-12-07 15:01:10 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 15:01:10 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 15:01:10 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5079, Recall: 0.5088, F1: 0.5067
[2024-12-07 15:01:11 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [49/50][0/49]	eta 0:00:58 lr 0.000004	 wd 0.0001	time 1.1883 (1.1883)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 15:01:19 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [49/50][10/49]	eta 0:00:33 lr 0.000004	 wd 0.0001	time 0.8517 (0.8464)	loss 0.6065 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 15:01:29 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [49/50][20/49]	eta 0:00:26 lr 0.000004	 wd 0.0001	time 0.8409 (0.9109)	loss 0.6065 (0.7138)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 15:01:38 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [49/50][30/49]	eta 0:00:17 lr 0.000004	 wd 0.0001	time 1.1625 (0.9001)	loss 0.6932 (0.6987)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 15:01:47 swin_tiny_patch4_window7_224] (main.py 260): INFO Train: [49/50][40/49]	eta 0:00:08 lr 0.000004	 wd 0.0001	time 0.8060 (0.8971)	loss 0.7798 (0.6910)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-07 15:01:55 swin_tiny_patch4_window7_224] (main.py 269): INFO EPOCH 49 training takes 0:00:45
[2024-12-07 15:01:58 swin_tiny_patch4_window7_224] (main.py 357): INFO  * Accuracy validation@ 0.705 
[2024-12-07 15:01:58 swin_tiny_patch4_window7_224] (main.py 170): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 15:01:58 swin_tiny_patch4_window7_224] (main.py 172): INFO Max accuracy: 0.71%
[2024-12-07 15:01:58 swin_tiny_patch4_window7_224] (main.py 173): INFO Precision: 0.5347, Recall: 0.5125, F1: 0.4849
[2024-12-07 15:01:58 swin_tiny_patch4_window7_224] (main.py 176): INFO Training time 0:39:27
[2024-12-07 16:29:13 swin_tiny_patch4_window7_224] (main.py 436): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 16:29:13 swin_tiny_patch4_window7_224] (main.py 437): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 16:29:14 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 16:29:15 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 16:29:15 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 16:29:15 swin_tiny_patch4_window7_224] (main.py 159): INFO Start training
[2024-12-07 16:29:16 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][0/49]	eta 0:01:08 lr 0.000000	 wd 0.0000	time 1.3941 (1.3941)	loss 0.7186 (0.7186)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:29:26 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][10/49]	eta 0:00:41 lr 0.000000	 wd 0.0000	time 0.8233 (1.0553)	loss 0.4525 (0.6994)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-07 16:29:35 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 1.2042 (0.9756)	loss 0.5374 (0.6837)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-07 16:29:44 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8509 (0.9640)	loss 1.0715 (0.7030)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 16:29:54 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8209 (0.9703)	loss 0.5386 (0.6918)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-07 16:30:01 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 0 training takes 0:00:46
[2024-12-07 16:30:03 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.731 
[2024-12-07 16:30:03 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 16:30:03 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:30:03 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 16:30:05 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [1/70][0/49]	eta 0:01:36 lr 0.000000	 wd 0.0000	time 1.9780 (1.9780)	loss 0.7890 (0.7890)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 16:30:15 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [1/70][10/49]	eta 0:00:41 lr 0.000000	 wd 0.0000	time 0.8220 (1.0702)	loss 0.4380 (0.6969)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-07 16:30:25 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [1/70][20/49]	eta 0:00:29 lr 0.000000	 wd 0.0000	time 0.8393 (1.0344)	loss 0.6152 (0.7168)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 16:30:33 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [1/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8391 (0.9805)	loss 0.8742 (0.6918)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 16:30:44 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [1/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8716 (0.9934)	loss 1.0509 (0.6981)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.719
[2024-12-07 16:30:52 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 1 training takes 0:00:48
[2024-12-07 16:30:53 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.731 
[2024-12-07 16:30:53 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 16:30:53 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:30:53 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 16:30:55 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [2/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2575 (1.2575)	loss 0.7861 (0.7861)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.555
[2024-12-07 16:31:05 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [2/70][10/49]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 1.2335 (1.0105)	loss 0.6947 (0.7609)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:31:14 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [2/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8532 (0.9628)	loss 0.6964 (0.7302)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:31:24 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [2/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8272 (0.9788)	loss 0.6071 (0.7050)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 16:31:34 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [2/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.2660 (0.9760)	loss 0.9563 (0.6983)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.664
[2024-12-07 16:31:43 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 2 training takes 0:00:49
[2024-12-07 16:31:45 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.718 
[2024-12-07 16:31:45 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 16:31:45 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:31:45 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5333, Recall: 0.5063, F1: 0.4583
[2024-12-07 16:31:46 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [3/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2471 (1.2471)	loss 0.9548 (0.9548)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.617
[2024-12-07 16:31:57 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [3/70][10/49]	eta 0:00:42 lr 0.000000	 wd 0.0000	time 1.4371 (1.0837)	loss 0.8674 (0.6554)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 16:32:07 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [3/70][20/49]	eta 0:00:30 lr 0.000000	 wd 0.0000	time 1.2151 (1.0413)	loss 0.7807 (0.6614)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 16:32:16 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [3/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 1.0680 (0.9832)	loss 0.5202 (0.6888)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 16:32:28 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [3/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.8440 (1.0421)	loss 0.5204 (0.6773)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 16:32:43 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 3 training takes 0:00:57
[2024-12-07 16:32:45 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.679 
[2024-12-07 16:32:45 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 16:32:45 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:32:45 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5536, Recall: 0.5401, F1: 0.5396
[2024-12-07 16:32:47 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [4/70][0/49]	eta 0:01:37 lr 0.000000	 wd 0.0000	time 1.9883 (1.9883)	loss 0.6939 (0.6939)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:33:00 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [4/70][10/49]	eta 0:00:53 lr 0.000000	 wd 0.0000	time 0.8110 (1.3689)	loss 0.4335 (0.7016)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.406
[2024-12-07 16:33:13 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [4/70][20/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8180 (1.3148)	loss 0.5200 (0.6730)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:33:21 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [4/70][30/49]	eta 0:00:22 lr 0.000000	 wd 0.0000	time 1.1314 (1.1704)	loss 0.6935 (0.6825)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:33:31 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [4/70][40/49]	eta 0:00:10 lr 0.000000	 wd 0.0000	time 0.8553 (1.1229)	loss 0.6066 (0.6937)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 16:33:39 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 4 training takes 0:00:53
[2024-12-07 16:33:41 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.551 
[2024-12-07 16:33:41 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 16:33:41 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:33:41 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4979, Recall: 0.4975, F1: 0.4902
[2024-12-07 16:33:43 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [5/70][0/49]	eta 0:01:08 lr 0.000000	 wd 0.0000	time 1.3926 (1.3926)	loss 0.6933 (0.6933)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:33:52 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [5/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 1.2388 (0.9729)	loss 0.3469 (0.7095)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:34:01 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [5/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8049 (0.9496)	loss 0.2601 (0.6854)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 16:34:11 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [5/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8464 (0.9638)	loss 0.6940 (0.6937)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:34:20 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [5/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.9052 (0.9402)	loss 1.2141 (0.7106)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 16:34:28 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 5 training takes 0:00:46
[2024-12-07 16:34:30 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.551 
[2024-12-07 16:34:30 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 16:34:30 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:34:30 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4850, Recall: 0.4825, F1: 0.4793
[2024-12-07 16:34:31 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [6/70][0/49]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.2205 (1.2205)	loss 0.6937 (0.6937)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:34:42 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [6/70][10/49]	eta 0:00:41 lr 0.000000	 wd 0.0000	time 0.8340 (1.0714)	loss 0.7804 (0.7094)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 16:34:56 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [6/70][20/49]	eta 0:00:35 lr 0.000000	 wd 0.0000	time 3.8379 (1.2273)	loss 0.4333 (0.6647)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 16:35:08 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [6/70][30/49]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 1.2176 (1.2446)	loss 0.6937 (0.6852)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:35:17 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [6/70][40/49]	eta 0:00:10 lr 0.000000	 wd 0.0000	time 0.8692 (1.1607)	loss 1.1266 (0.6915)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 16:35:29 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 6 training takes 0:00:59
[2024-12-07 16:35:31 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.564 
[2024-12-07 16:35:31 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 16:35:31 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:35:31 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5053, Recall: 0.5063, F1: 0.4996
[2024-12-07 16:35:32 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [7/70][0/49]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 1.2292 (1.2292)	loss 0.6933 (0.6933)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:35:42 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [7/70][10/49]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 0.8348 (1.0379)	loss 0.7805 (0.7567)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 16:35:51 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [7/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8562 (0.9437)	loss 0.6067 (0.7266)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 16:36:01 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [7/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8986 (0.9609)	loss 0.7802 (0.7131)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 16:36:11 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [7/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.2151 (0.9683)	loss 0.6068 (0.7041)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 16:36:17 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 7 training takes 0:00:46
[2024-12-07 16:36:19 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.551 
[2024-12-07 16:36:19 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 16:36:19 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:36:19 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4850, Recall: 0.4825, F1: 0.4793
[2024-12-07 16:36:20 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [8/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2505 (1.2505)	loss 1.0405 (1.0405)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 16:36:32 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [8/70][10/49]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 0.8109 (1.1583)	loss 0.4338 (0.7093)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 16:36:43 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [8/70][20/49]	eta 0:00:32 lr 0.000000	 wd 0.0000	time 0.8518 (1.1245)	loss 0.8668 (0.6977)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:36:52 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [8/70][30/49]	eta 0:00:19 lr 0.000000	 wd 0.0000	time 1.1326 (1.0437)	loss 0.4333 (0.6991)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.570
[2024-12-07 16:37:02 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [8/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.8257 (1.0394)	loss 0.4335 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:37:10 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 8 training takes 0:00:50
[2024-12-07 16:37:12 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.474 
[2024-12-07 16:37:12 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 16:37:12 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:37:12 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4014, Recall: 0.3847, F1: 0.3900
[2024-12-07 16:37:13 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [9/70][0/49]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 1.2380 (1.2380)	loss 0.8667 (0.8667)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 16:37:22 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [9/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 1.2322 (0.9508)	loss 0.6067 (0.6383)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 16:37:32 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [9/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8821 (0.9340)	loss 0.6069 (0.6315)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 16:37:42 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [9/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8498 (0.9556)	loss 0.8667 (0.6683)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 16:37:50 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [9/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.9247 (0.9306)	loss 0.6066 (0.6892)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 16:37:58 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 9 training takes 0:00:46
[2024-12-07 16:38:00 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.577 
[2024-12-07 16:38:00 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 16:38:00 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:38:00 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5250, Recall: 0.5301, F1: 0.5193
[2024-12-07 16:38:02 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [10/70][0/49]	eta 0:01:04 lr 0.000000	 wd 0.0000	time 1.3121 (1.3121)	loss 0.8667 (0.8667)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 16:38:12 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [10/70][10/49]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 0.8380 (1.0269)	loss 0.9535 (0.6698)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.430
[2024-12-07 16:38:20 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [10/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.9088 (0.9398)	loss 0.9533 (0.6811)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 16:38:30 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [10/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8463 (0.9548)	loss 0.7800 (0.6795)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 16:38:40 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [10/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.9484 (0.9609)	loss 0.4339 (0.6829)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:38:46 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 10 training takes 0:00:46
[2024-12-07 16:38:48 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.526 
[2024-12-07 16:38:48 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 16:38:48 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:38:48 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4708, Recall: 0.4649, F1: 0.4611
[2024-12-07 16:38:50 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [11/70][0/49]	eta 0:01:09 lr 0.000000	 wd 0.0000	time 1.4119 (1.4119)	loss 0.6068 (0.6068)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 16:39:00 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [11/70][10/49]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 0.8032 (1.0202)	loss 0.6934 (0.7172)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:39:10 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [11/70][20/49]	eta 0:00:29 lr 0.000000	 wd 0.0000	time 0.8787 (1.0088)	loss 0.6069 (0.7100)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 16:39:22 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [11/70][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 1.2259 (1.0867)	loss 0.6935 (0.6907)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:39:31 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [11/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 1.0083 (1.0418)	loss 0.6072 (0.6893)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 16:39:40 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 11 training takes 0:00:51
[2024-12-07 16:39:41 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.474 
[2024-12-07 16:39:41 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 16:39:41 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:39:41 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4803, Recall: 0.4749, F1: 0.4481
[2024-12-07 16:39:43 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [12/70][0/49]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 1.2384 (1.2384)	loss 0.4334 (0.4334)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 16:39:53 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [12/70][10/49]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.2060 (1.0347)	loss 0.7800 (0.6146)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 16:40:03 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [12/70][20/49]	eta 0:00:29 lr 0.000000	 wd 0.0000	time 0.9085 (1.0283)	loss 0.8666 (0.6604)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 16:40:13 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [12/70][30/49]	eta 0:00:19 lr 0.000000	 wd 0.0000	time 0.8019 (1.0175)	loss 0.2600 (0.6487)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.383
[2024-12-07 16:40:23 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [12/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 1.2126 (1.0034)	loss 0.6939 (0.6554)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:40:30 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 12 training takes 0:00:48
[2024-12-07 16:40:32 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.603 
[2024-12-07 16:40:32 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 16:40:32 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:40:32 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5521, Recall: 0.5627, F1: 0.5485
[2024-12-07 16:40:33 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [13/70][0/49]	eta 0:01:02 lr 0.000000	 wd 0.0000	time 1.2753 (1.2753)	loss 0.6066 (0.6066)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:40:46 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [13/70][10/49]	eta 0:00:50 lr 0.000000	 wd 0.0000	time 0.8553 (1.2913)	loss 0.9536 (0.6857)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 16:40:56 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [13/70][20/49]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 1.1580 (1.1537)	loss 0.7801 (0.6770)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:41:05 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [13/70][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 1.2419 (1.0842)	loss 0.7801 (0.6823)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 16:41:19 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [13/70][40/49]	eta 0:00:10 lr 0.000000	 wd 0.0000	time 0.8983 (1.1629)	loss 0.8666 (0.6892)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:41:28 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 13 training takes 0:00:56
[2024-12-07 16:41:30 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.538 
[2024-12-07 16:41:30 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 16:41:30 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:41:30 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4491, Recall: 0.4436, F1: 0.4451
[2024-12-07 16:41:31 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [14/70][0/49]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.2163 (1.2163)	loss 0.5200 (0.5200)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 16:41:41 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [14/70][10/49]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.2268 (1.0418)	loss 0.5200 (0.5989)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:41:50 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [14/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8480 (0.9509)	loss 0.6936 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:42:00 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [14/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8280 (0.9658)	loss 0.6067 (0.6795)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 16:42:09 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [14/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.2543 (0.9574)	loss 0.9535 (0.6892)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 16:42:16 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 14 training takes 0:00:46
[2024-12-07 16:42:18 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.513 
[2024-12-07 16:42:18 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 16:42:18 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:42:18 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4640, Recall: 0.4561, F1: 0.4519
[2024-12-07 16:42:19 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [15/70][0/49]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 1.2441 (1.2441)	loss 0.6935 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:42:30 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [15/70][10/49]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 0.8369 (1.1084)	loss 0.7802 (0.6462)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 16:42:40 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [15/70][20/49]	eta 0:00:30 lr 0.000000	 wd 0.0000	time 1.2661 (1.0601)	loss 0.7802 (0.6852)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 16:42:49 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [15/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8820 (0.9948)	loss 0.7800 (0.7074)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 16:43:00 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [15/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.8813 (1.0083)	loss 1.0399 (0.7040)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:43:07 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 15 training takes 0:00:48
[2024-12-07 16:43:10 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.487 
[2024-12-07 16:43:10 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 16:43:10 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:43:10 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4372, Recall: 0.4236, F1: 0.4231
[2024-12-07 16:43:11 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [16/70][0/49]	eta 0:01:05 lr 0.000000	 wd 0.0000	time 1.3285 (1.3285)	loss 0.6934 (0.6934)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:43:19 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [16/70][10/49]	eta 0:00:35 lr 0.000000	 wd 0.0000	time 0.8654 (0.8994)	loss 0.6934 (0.6541)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:43:29 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [16/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8520 (0.9490)	loss 0.8668 (0.6687)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:43:39 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [16/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 1.2389 (0.9639)	loss 0.5204 (0.6991)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 16:43:48 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [16/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8504 (0.9382)	loss 0.8666 (0.7062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 16:43:57 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 16 training takes 0:00:47
[2024-12-07 16:43:59 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.526 
[2024-12-07 16:43:59 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 16:43:59 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:43:59 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5561, Recall: 0.5702, F1: 0.5121
[2024-12-07 16:44:00 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [17/70][0/49]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.2220 (1.2220)	loss 0.2599 (0.2599)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 16:44:10 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [17/70][10/49]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.0056 (1.0332)	loss 0.9533 (0.6461)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 16:44:19 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [17/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8304 (0.9418)	loss 0.5199 (0.6603)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 16:44:29 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [17/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8500 (0.9598)	loss 0.9533 (0.6794)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 16:44:38 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [17/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.2283 (0.9590)	loss 0.7801 (0.7018)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 16:44:46 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 17 training takes 0:00:46
[2024-12-07 16:44:48 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.564 
[2024-12-07 16:44:48 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 16:44:48 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:44:48 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5409, Recall: 0.5514, F1: 0.5264
[2024-12-07 16:44:50 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [18/70][0/49]	eta 0:01:13 lr 0.000000	 wd 0.0000	time 1.4936 (1.4936)	loss 0.5200 (0.5200)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:45:00 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [18/70][10/49]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 0.8565 (1.0389)	loss 0.9535 (0.6855)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 16:45:10 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [18/70][20/49]	eta 0:00:29 lr 0.000000	 wd 0.0000	time 0.9741 (1.0288)	loss 1.0400 (0.7429)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:45:18 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [18/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8460 (0.9706)	loss 0.6066 (0.7269)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 16:45:28 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [18/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8319 (0.9790)	loss 0.8667 (0.7167)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 16:45:36 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 18 training takes 0:00:47
[2024-12-07 16:45:38 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.654 
[2024-12-07 16:45:38 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 16:45:38 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:45:38 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5764, Recall: 0.5827, F1: 0.5784
[2024-12-07 16:45:40 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [19/70][0/49]	eta 0:01:04 lr 0.000000	 wd 0.0000	time 1.3184 (1.3184)	loss 0.6068 (0.6068)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:45:48 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [19/70][10/49]	eta 0:00:35 lr 0.000000	 wd 0.0000	time 0.8421 (0.9097)	loss 0.6067 (0.6855)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 16:45:58 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [19/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8495 (0.9512)	loss 0.7799 (0.6934)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 16:46:08 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [19/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 1.2079 (0.9681)	loss 0.6069 (0.6962)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 16:46:17 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [19/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8405 (0.9390)	loss 0.6069 (0.6976)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 16:46:25 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 19 training takes 0:00:46
[2024-12-07 16:46:27 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.526 
[2024-12-07 16:46:27 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 16:46:27 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:46:27 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4837, Recall: 0.4799, F1: 0.4713
[2024-12-07 16:46:28 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [20/70][0/49]	eta 0:01:03 lr 0.000000	 wd 0.0000	time 1.3004 (1.3004)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:46:38 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [20/70][10/49]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.1942 (1.0357)	loss 0.3467 (0.7170)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 16:46:47 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [20/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8426 (0.9496)	loss 0.7800 (0.6975)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 16:46:57 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [20/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8357 (0.9656)	loss 0.6934 (0.6878)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:47:06 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [20/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.2267 (0.9524)	loss 0.5202 (0.6934)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 16:47:14 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 20 training takes 0:00:46
[2024-12-07 16:47:15 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.577 
[2024-12-07 16:47:15 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 16:47:15 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:47:15 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5367, Recall: 0.5451, F1: 0.5285
[2024-12-07 16:47:17 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [21/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2503 (1.2503)	loss 0.5199 (0.5199)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:47:27 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [21/70][10/49]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 0.8364 (1.0272)	loss 0.6934 (0.6303)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:47:36 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [21/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 1.2485 (0.9775)	loss 0.7799 (0.6769)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 16:47:45 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [21/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8178 (0.9629)	loss 0.2600 (0.6850)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 16:47:58 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [21/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.8708 (1.0476)	loss 0.9532 (0.6722)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 16:48:06 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 21 training takes 0:00:50
[2024-12-07 16:48:09 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.705 
[2024-12-07 16:48:09 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 16:48:09 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:48:09 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.6442, Recall: 0.6629, F1: 0.6498
[2024-12-07 16:48:10 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [22/70][0/49]	eta 0:01:05 lr 0.000000	 wd 0.0000	time 1.3406 (1.3406)	loss 0.8666 (0.8666)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 16:48:18 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [22/70][10/49]	eta 0:00:34 lr 0.000000	 wd 0.0000	time 0.8416 (0.8949)	loss 0.2600 (0.6461)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.539
[2024-12-07 16:48:31 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [22/70][20/49]	eta 0:00:30 lr 0.000000	 wd 0.0000	time 1.2920 (1.0502)	loss 0.5201 (0.6439)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 16:48:44 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [22/70][30/49]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 1.1563 (1.1317)	loss 0.5201 (0.6766)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 16:48:53 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [22/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 1.2790 (1.0913)	loss 0.8667 (0.6786)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 16:49:02 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 22 training takes 0:00:53
[2024-12-07 16:49:04 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.551 
[2024-12-07 16:49:04 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 16:49:04 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:49:04 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5221, Recall: 0.5276, F1: 0.5086
[2024-12-07 16:49:05 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [23/70][0/49]	eta 0:01:02 lr 0.000000	 wd 0.0000	time 1.2698 (1.2698)	loss 1.0400 (1.0400)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 16:49:16 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [23/70][10/49]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 0.8689 (1.0435)	loss 1.2132 (0.7721)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.359
[2024-12-07 16:49:26 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [23/70][20/49]	eta 0:00:29 lr 0.000000	 wd 0.0000	time 1.3015 (1.0181)	loss 0.6932 (0.7263)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:49:34 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [23/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8348 (0.9594)	loss 0.6066 (0.6933)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 16:49:44 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [23/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8399 (0.9686)	loss 0.7799 (0.7060)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 16:49:51 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 23 training takes 0:00:46
[2024-12-07 16:49:53 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.654 
[2024-12-07 16:49:53 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 16:49:53 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:49:53 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5764, Recall: 0.5827, F1: 0.5784
[2024-12-07 16:49:55 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [24/70][0/49]	eta 0:01:25 lr 0.000000	 wd 0.0000	time 1.7439 (1.7439)	loss 0.7799 (0.7799)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 16:50:04 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [24/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.8529 (0.9673)	loss 0.8667 (0.7800)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 16:50:14 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [24/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 0.8163 (0.9793)	loss 0.4334 (0.7181)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:50:23 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [24/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 1.2365 (0.9592)	loss 0.8665 (0.6877)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 16:50:32 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [24/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8454 (0.9505)	loss 0.7802 (0.6954)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:50:41 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 24 training takes 0:00:47
[2024-12-07 16:50:43 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.500 
[2024-12-07 16:50:43 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 16:50:43 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:50:43 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4437, Recall: 0.4323, F1: 0.4319
[2024-12-07 16:50:44 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [25/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2555 (1.2555)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 16:50:53 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [25/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 1.2024 (0.9709)	loss 0.6066 (0.7879)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 16:51:03 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [25/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8239 (0.9546)	loss 0.5200 (0.7140)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 16:51:13 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [25/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8716 (0.9903)	loss 0.6933 (0.7073)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:51:24 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [25/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.2080 (0.9977)	loss 0.6069 (0.7018)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:51:31 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 25 training takes 0:00:48
[2024-12-07 16:51:33 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.538 
[2024-12-07 16:51:33 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 16:51:33 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:51:33 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4778, Recall: 0.4737, F1: 0.4702
[2024-12-07 16:51:34 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [26/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2469 (1.2469)	loss 0.5199 (0.5199)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 16:51:44 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [26/70][10/49]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 0.8137 (1.0304)	loss 0.3467 (0.6854)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 16:51:54 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [26/70][20/49]	eta 0:00:29 lr 0.000000	 wd 0.0000	time 1.1875 (1.0064)	loss 0.3467 (0.6933)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 16:52:03 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [26/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8379 (0.9591)	loss 0.8665 (0.7045)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 16:52:17 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [26/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.8961 (1.0660)	loss 0.7798 (0.6933)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 16:52:25 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 26 training takes 0:00:52
[2024-12-07 16:52:27 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.590 
[2024-12-07 16:52:27 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 16:52:27 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:52:27 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5327, Recall: 0.5388, F1: 0.5291
[2024-12-07 16:52:28 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [27/70][0/49]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 1.2341 (1.2341)	loss 0.6934 (0.6934)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:52:37 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [27/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 1.2137 (0.9513)	loss 0.4334 (0.5909)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 16:52:47 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [27/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8388 (0.9418)	loss 0.7800 (0.6438)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:52:57 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [27/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8349 (0.9632)	loss 0.6932 (0.7045)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:53:07 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [27/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.3199 (0.9739)	loss 0.6067 (0.6975)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 16:53:15 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 27 training takes 0:00:48
[2024-12-07 16:53:17 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.513 
[2024-12-07 16:53:17 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 16:53:17 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:53:17 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4640, Recall: 0.4561, F1: 0.4519
[2024-12-07 16:53:18 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [28/70][0/49]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 1.2346 (1.2346)	loss 0.6066 (0.6066)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 16:53:28 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [28/70][10/49]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 0.8326 (1.0375)	loss 0.6935 (0.7012)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:53:37 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [28/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 1.0854 (0.9550)	loss 0.6066 (0.6892)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 16:53:47 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [28/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8172 (0.9625)	loss 0.6067 (0.6905)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 16:53:57 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [28/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8972 (0.9663)	loss 0.8668 (0.6849)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 16:54:04 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 28 training takes 0:00:47
[2024-12-07 16:54:07 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.462 
[2024-12-07 16:54:07 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 16:54:07 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:54:07 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4372, Recall: 0.4211, F1: 0.4150
[2024-12-07 16:54:11 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [29/70][0/49]	eta 0:03:31 lr 0.000000	 wd 0.0000	time 4.3206 (4.3206)	loss 0.7801 (0.7801)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 16:54:22 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [29/70][10/49]	eta 0:00:53 lr 0.000000	 wd 0.0000	time 0.9267 (1.3714)	loss 0.7799 (0.6461)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 16:54:33 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [29/70][20/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 0.8414 (1.2554)	loss 0.6067 (0.6768)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 16:54:45 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [29/70][30/49]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 1.1255 (1.2346)	loss 0.6933 (0.6793)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:54:57 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [29/70][40/49]	eta 0:00:10 lr 0.000000	 wd 0.0000	time 1.8181 (1.2220)	loss 0.9532 (0.6849)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 16:55:10 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 29 training takes 0:01:03
[2024-12-07 16:55:12 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.590 
[2024-12-07 16:55:12 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 16:55:12 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:55:12 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5327, Recall: 0.5388, F1: 0.5291
[2024-12-07 16:55:14 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [30/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2529 (1.2529)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 16:55:23 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [30/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 1.2342 (0.9598)	loss 0.7799 (0.6539)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 16:55:32 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [30/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8474 (0.9401)	loss 0.7799 (0.6768)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 16:55:42 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [30/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8991 (0.9588)	loss 0.6068 (0.6654)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 16:55:51 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [30/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8656 (0.9337)	loss 0.4334 (0.6785)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 16:55:59 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 30 training takes 0:00:46
[2024-12-07 16:56:01 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.641 
[2024-12-07 16:56:01 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 16:56:01 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:56:01 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5308, Recall: 0.5288, F1: 0.5293
[2024-12-07 16:56:02 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [31/70][0/49]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 1.2345 (1.2345)	loss 0.6934 (0.6934)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:56:17 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [31/70][10/49]	eta 0:00:54 lr 0.000000	 wd 0.0000	time 0.8685 (1.4092)	loss 0.7801 (0.7091)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:56:27 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [31/70][20/49]	eta 0:00:35 lr 0.000000	 wd 0.0000	time 0.9061 (1.2146)	loss 0.8666 (0.6809)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:56:35 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [31/70][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.8584 (1.0958)	loss 0.8665 (0.6905)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 16:56:45 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [31/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.8426 (1.0694)	loss 0.5200 (0.6975)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 16:56:57 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 31 training takes 0:00:55
[2024-12-07 16:57:00 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.526 
[2024-12-07 16:57:00 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 16:57:00 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:57:00 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4259, Recall: 0.4198, F1: 0.4222
[2024-12-07 16:57:02 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [32/70][0/49]	eta 0:01:30 lr 0.000000	 wd 0.0000	time 1.8415 (1.8415)	loss 0.9533 (0.9533)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 16:57:13 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [32/70][10/49]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 1.3517 (1.1594)	loss 0.7801 (0.7170)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 16:57:22 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [32/70][20/49]	eta 0:00:30 lr 0.000000	 wd 0.0000	time 0.8450 (1.0546)	loss 0.6935 (0.6851)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:57:33 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [32/70][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.8255 (1.0726)	loss 0.6933 (0.6905)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:57:43 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [32/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.8397 (1.0498)	loss 0.6066 (0.6870)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 16:57:50 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 32 training takes 0:00:49
[2024-12-07 16:57:52 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.577 
[2024-12-07 16:57:52 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 16:57:52 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:57:52 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5000, Recall: 0.5000, F1: 0.4976
[2024-12-07 16:57:53 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [33/70][0/49]	eta 0:01:21 lr 0.000000	 wd 0.0000	time 1.6707 (1.6707)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 16:58:03 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [33/70][10/49]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 0.8722 (1.0420)	loss 1.1265 (0.7484)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 16:58:13 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [33/70][20/49]	eta 0:00:29 lr 0.000000	 wd 0.0000	time 0.8249 (1.0209)	loss 0.4334 (0.7057)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 16:58:22 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [33/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8372 (0.9636)	loss 0.6067 (0.6961)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 16:58:32 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [33/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8321 (0.9725)	loss 0.6934 (0.7039)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 16:58:39 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 33 training takes 0:00:47
[2024-12-07 16:58:43 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.487 
[2024-12-07 16:58:43 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 16:58:43 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:58:43 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3902, Recall: 0.3784, F1: 0.3834
[2024-12-07 16:58:44 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [34/70][0/49]	eta 0:01:04 lr 0.000000	 wd 0.0000	time 1.3229 (1.3229)	loss 1.0399 (1.0399)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 16:58:53 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [34/70][10/49]	eta 0:00:35 lr 0.000000	 wd 0.0000	time 0.8580 (0.9055)	loss 0.4332 (0.7563)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 16:59:02 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [34/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8877 (0.9472)	loss 0.9533 (0.7263)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 16:59:12 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [34/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 1.1791 (0.9596)	loss 0.6066 (0.7185)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 16:59:21 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [34/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8114 (0.9342)	loss 0.5199 (0.6933)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 16:59:29 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 34 training takes 0:00:46
[2024-12-07 16:59:31 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.500 
[2024-12-07 16:59:31 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 16:59:31 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 16:59:31 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3958, Recall: 0.3872, F1: 0.3910
[2024-12-07 16:59:34 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [35/70][0/49]	eta 0:02:34 lr 0.000000	 wd 0.0000	time 3.1459 (3.1459)	loss 0.7799 (0.7799)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 16:59:48 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [35/70][10/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 0.9573 (1.4903)	loss 0.8669 (0.6618)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 16:59:57 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [35/70][20/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 1.2083 (1.2514)	loss 0.4333 (0.6644)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 17:00:08 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [35/70][30/49]	eta 0:00:22 lr 0.000000	 wd 0.0000	time 1.9738 (1.1779)	loss 0.6066 (0.6765)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 17:00:18 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [35/70][40/49]	eta 0:00:10 lr 0.000000	 wd 0.0000	time 0.8483 (1.1393)	loss 0.6066 (0.6849)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 17:00:26 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 35 training takes 0:00:54
[2024-12-07 17:00:28 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.654 
[2024-12-07 17:00:28 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:00:28 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:00:28 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5100, Recall: 0.5075, F1: 0.5027
[2024-12-07 17:00:29 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [36/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2550 (1.2550)	loss 0.5200 (0.5200)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 17:00:38 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [36/70][10/49]	eta 0:00:35 lr 0.000000	 wd 0.0000	time 0.8509 (0.9018)	loss 0.6066 (0.7012)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 17:00:48 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [36/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8582 (0.9490)	loss 0.8666 (0.6809)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.578
[2024-12-07 17:00:58 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [36/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 1.2485 (0.9718)	loss 0.6934 (0.6653)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:01:07 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [36/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.9766 (0.9459)	loss 0.8667 (0.6954)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 17:01:17 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 36 training takes 0:00:48
[2024-12-07 17:01:19 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.641 
[2024-12-07 17:01:19 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 17:01:19 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:01:19 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5668, Recall: 0.5739, F1: 0.5684
[2024-12-07 17:01:21 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [37/70][0/49]	eta 0:01:25 lr 0.000000	 wd 0.0000	time 1.7372 (1.7372)	loss 0.4332 (0.4332)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 17:01:32 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [37/70][10/49]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 0.8495 (1.1152)	loss 0.6933 (0.7012)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:01:41 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [37/70][20/49]	eta 0:00:29 lr 0.000000	 wd 0.0000	time 1.2093 (1.0257)	loss 0.6066 (0.7015)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 17:01:50 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [37/70][30/49]	eta 0:00:19 lr 0.000000	 wd 0.0000	time 0.9517 (1.0008)	loss 0.8666 (0.7100)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.422
[2024-12-07 17:02:01 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [37/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.8536 (1.0128)	loss 0.8666 (0.7017)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 17:02:08 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 37 training takes 0:00:48
[2024-12-07 17:02:10 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.667 
[2024-12-07 17:02:10 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:02:10 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:02:10 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5764, Recall: 0.5764, F1: 0.5764
[2024-12-07 17:02:12 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [38/70][0/49]	eta 0:01:37 lr 0.000000	 wd 0.0000	time 1.9818 (1.9818)	loss 0.7800 (0.7800)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 17:02:21 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [38/70][10/49]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 0.9000 (1.0234)	loss 0.6933 (0.7011)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:02:32 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [38/70][20/49]	eta 0:00:30 lr 0.000000	 wd 0.0000	time 0.8733 (1.0476)	loss 0.6068 (0.6726)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 17:02:43 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [38/70][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 1.2225 (1.0701)	loss 0.7802 (0.6681)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 17:02:55 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [38/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 1.2273 (1.0982)	loss 0.6066 (0.6827)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 17:03:03 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 38 training takes 0:00:53
[2024-12-07 17:03:05 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.615 
[2024-12-07 17:03:05 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 17:03:05 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:03:05 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4783, Recall: 0.4812, F1: 0.4781
[2024-12-07 17:03:06 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [39/70][0/49]	eta 0:01:02 lr 0.000000	 wd 0.0000	time 1.2672 (1.2672)	loss 0.8667 (0.8667)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 17:03:16 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [39/70][10/49]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 0.8669 (1.0381)	loss 0.8665 (0.7012)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:03:25 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [39/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 1.2336 (0.9751)	loss 0.6068 (0.6892)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 17:03:35 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [39/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8382 (0.9614)	loss 0.6066 (0.7101)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 17:03:45 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [39/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8699 (0.9739)	loss 0.7799 (0.7144)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 17:03:52 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 39 training takes 0:00:46
[2024-12-07 17:03:54 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.551 
[2024-12-07 17:03:54 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 17:03:54 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:03:54 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4560, Recall: 0.4524, F1: 0.4535
[2024-12-07 17:03:57 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [40/70][0/49]	eta 0:02:40 lr 0.000000	 wd 0.0000	time 3.2793 (3.2793)	loss 0.8666 (0.8666)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 17:04:08 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [40/70][10/49]	eta 0:00:49 lr 0.000000	 wd 0.0000	time 0.8393 (1.2765)	loss 0.8665 (0.7247)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:04:18 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [40/70][20/49]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.8253 (1.1468)	loss 0.3466 (0.7097)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:04:28 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [40/70][30/49]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 1.1881 (1.1165)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:04:38 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [40/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 1.5266 (1.0788)	loss 0.5199 (0.7017)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 17:04:50 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 40 training takes 0:00:56
[2024-12-07 17:04:52 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.551 
[2024-12-07 17:04:52 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 17:04:52 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:04:52 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4560, Recall: 0.4524, F1: 0.4535
[2024-12-07 17:04:53 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [41/70][0/49]	eta 0:01:02 lr 0.000000	 wd 0.0000	time 1.2660 (1.2660)	loss 1.0402 (1.0402)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:05:04 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [41/70][10/49]	eta 0:00:42 lr 0.000000	 wd 0.0000	time 0.8591 (1.0875)	loss 0.7800 (0.6776)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 17:05:14 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [41/70][20/49]	eta 0:00:30 lr 0.000000	 wd 0.0000	time 1.1779 (1.0493)	loss 0.8666 (0.6768)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 17:05:23 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [41/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8593 (0.9859)	loss 0.7800 (0.6737)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 17:05:35 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [41/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.8669 (1.0358)	loss 0.8667 (0.6933)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 17:05:42 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 41 training takes 0:00:49
[2024-12-07 17:05:43 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.577 
[2024-12-07 17:05:43 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 17:05:43 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:05:43 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4534, Recall: 0.4549, F1: 0.4541
[2024-12-07 17:05:45 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [42/70][0/49]	eta 0:01:19 lr 0.000000	 wd 0.0000	time 1.6151 (1.6151)	loss 0.6067 (0.6067)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:05:55 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [42/70][10/49]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 0.8113 (1.0402)	loss 0.3466 (0.7720)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:06:05 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [42/70][20/49]	eta 0:00:29 lr 0.000000	 wd 0.0000	time 0.8488 (1.0192)	loss 0.4333 (0.7015)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 17:06:13 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [42/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8432 (0.9622)	loss 0.6935 (0.7101)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:06:23 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [42/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8200 (0.9723)	loss 0.4333 (0.7038)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 17:06:30 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 42 training takes 0:00:47
[2024-12-07 17:06:33 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.551 
[2024-12-07 17:06:33 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 17:06:33 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:06:33 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5454, Recall: 0.5576, F1: 0.5230
[2024-12-07 17:06:34 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [43/70][0/49]	eta 0:01:05 lr 0.000000	 wd 0.0000	time 1.3331 (1.3331)	loss 0.7800 (0.7800)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 17:06:44 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [43/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.9023 (0.9549)	loss 0.5200 (0.6854)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:06:54 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [43/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 0.8188 (0.9772)	loss 0.3466 (0.6644)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 17:07:04 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [43/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 1.2097 (0.9878)	loss 0.7798 (0.6821)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 17:07:12 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [43/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8331 (0.9550)	loss 0.6933 (0.6954)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:07:22 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 43 training takes 0:00:48
[2024-12-07 17:07:24 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.667 
[2024-12-07 17:07:24 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:07:24 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:07:24 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5231, Recall: 0.5163, F1: 0.5111
[2024-12-07 17:07:25 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [44/70][0/49]	eta 0:01:11 lr 0.000000	 wd 0.0000	time 1.4595 (1.4595)	loss 0.5200 (0.5200)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 17:07:39 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [44/70][10/49]	eta 0:00:52 lr 0.000000	 wd 0.0000	time 0.8520 (1.3538)	loss 0.7799 (0.6539)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 17:07:49 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [44/70][20/49]	eta 0:00:34 lr 0.000000	 wd 0.0000	time 1.2239 (1.1878)	loss 0.9533 (0.6974)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 17:07:58 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [44/70][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.9436 (1.0924)	loss 0.4334 (0.6793)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:08:08 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [44/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.8336 (1.0802)	loss 0.5200 (0.6954)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 17:08:15 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 44 training takes 0:00:51
[2024-12-07 17:08:18 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.551 
[2024-12-07 17:08:18 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 17:08:18 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:08:18 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3972, Recall: 0.4073, F1: 0.4017
[2024-12-07 17:08:20 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [45/70][0/49]	eta 0:01:37 lr 0.000000	 wd 0.0000	time 1.9875 (1.9875)	loss 0.6066 (0.6066)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:08:29 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [45/70][10/49]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 0.9658 (1.0307)	loss 0.6067 (0.6697)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 17:08:40 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [45/70][20/49]	eta 0:00:30 lr 0.000000	 wd 0.0000	time 0.8591 (1.0648)	loss 0.6933 (0.6933)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:08:50 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [45/70][30/49]	eta 0:00:19 lr 0.000000	 wd 0.0000	time 0.8896 (1.0498)	loss 0.8666 (0.6849)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 17:08:59 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [45/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.8376 (1.0055)	loss 0.6066 (0.6848)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 17:09:09 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 45 training takes 0:00:50
[2024-12-07 17:09:11 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.500 
[2024-12-07 17:09:11 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 17:09:11 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:09:11 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4941, Recall: 0.4925, F1: 0.4685
[2024-12-07 17:09:12 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [46/70][0/49]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 1.2249 (1.2249)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:09:24 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [46/70][10/49]	eta 0:00:47 lr 0.000000	 wd 0.0000	time 0.8424 (1.2112)	loss 0.8668 (0.6302)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:09:37 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [46/70][20/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 2.0643 (1.2514)	loss 0.8665 (0.7469)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 17:09:48 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [46/70][30/49]	eta 0:00:22 lr 0.000000	 wd 0.0000	time 1.2614 (1.2037)	loss 0.6933 (0.7240)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:10:00 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [46/70][40/49]	eta 0:00:10 lr 0.000000	 wd 0.0000	time 1.0135 (1.1882)	loss 0.6932 (0.7165)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:10:08 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 46 training takes 0:00:57
[2024-12-07 17:10:10 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.538 
[2024-12-07 17:10:10 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 17:10:10 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:10:10 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4907, Recall: 0.4887, F1: 0.4808
[2024-12-07 17:10:11 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [47/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2492 (1.2492)	loss 0.5200 (0.5200)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 17:10:21 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [47/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 1.2493 (0.9905)	loss 0.8665 (0.7248)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:10:30 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [47/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8478 (0.9441)	loss 0.5199 (0.7098)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 17:10:40 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [47/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8248 (0.9630)	loss 0.3466 (0.6989)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 17:10:49 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [47/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.2373 (0.9459)	loss 0.4333 (0.6890)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.453
[2024-12-07 17:10:57 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 47 training takes 0:00:46
[2024-12-07 17:10:59 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.654 
[2024-12-07 17:10:59 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:10:59 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:10:59 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5764, Recall: 0.5827, F1: 0.5784
[2024-12-07 17:11:00 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [48/70][0/49]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.2152 (1.2152)	loss 0.5199 (0.5199)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 17:11:10 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [48/70][10/49]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 0.8454 (1.0368)	loss 0.6933 (0.6618)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:11:20 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [48/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 1.2506 (0.9820)	loss 0.7799 (0.6809)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 17:11:29 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [48/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 1.0681 (0.9847)	loss 0.6066 (0.6877)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 17:11:42 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [48/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.8559 (1.0392)	loss 0.7801 (0.6975)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 17:11:48 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 48 training takes 0:00:49
[2024-12-07 17:11:51 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.654 
[2024-12-07 17:11:51 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:11:51 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:11:51 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5764, Recall: 0.5827, F1: 0.5784
[2024-12-07 17:11:53 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [49/70][0/49]	eta 0:01:18 lr 0.000000	 wd 0.0000	time 1.5965 (1.5965)	loss 0.5200 (0.5200)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 17:12:01 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [49/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 0.8465 (0.9262)	loss 0.7799 (0.6854)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.492
[2024-12-07 17:12:11 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [49/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8408 (0.9604)	loss 0.6935 (0.7263)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:12:21 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [49/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 1.2113 (0.9565)	loss 0.6066 (0.6989)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 17:12:30 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [49/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8659 (0.9426)	loss 0.6066 (0.7060)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:12:38 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 49 training takes 0:00:47
[2024-12-07 17:12:40 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.654 
[2024-12-07 17:12:40 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:12:40 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:12:40 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5417, Recall: 0.5376, F1: 0.5385
[2024-12-07 17:12:41 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [50/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2607 (1.2607)	loss 0.4334 (0.4334)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 17:12:51 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [50/70][10/49]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 1.2691 (1.0200)	loss 0.9532 (0.7011)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:13:00 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [50/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8784 (0.9607)	loss 0.7799 (0.6974)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 17:13:10 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [50/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8741 (0.9752)	loss 0.8666 (0.6960)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:13:19 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [50/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.2321 (0.9526)	loss 0.6932 (0.6975)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:13:27 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 50 training takes 0:00:47
[2024-12-07 17:13:29 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.692 
[2024-12-07 17:13:29 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:13:29 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:13:29 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.6090, Recall: 0.6090, F1: 0.6090
[2024-12-07 17:13:30 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [51/70][0/49]	eta 0:01:03 lr 0.000000	 wd 0.0000	time 1.2988 (1.2988)	loss 0.8665 (0.8665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:13:45 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [51/70][10/49]	eta 0:00:55 lr 0.000000	 wd 0.0000	time 2.0839 (1.4271)	loss 0.4333 (0.6460)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.570
[2024-12-07 17:13:59 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [51/70][20/49]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 0.8433 (1.4125)	loss 0.6066 (0.6561)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.523
[2024-12-07 17:14:08 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [51/70][30/49]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 1.5563 (1.2588)	loss 0.6935 (0.6793)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:14:18 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [51/70][40/49]	eta 0:00:10 lr 0.000000	 wd 0.0000	time 0.8395 (1.1824)	loss 0.6066 (0.6848)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 17:14:26 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 51 training takes 0:00:56
[2024-12-07 17:14:28 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.577 
[2024-12-07 17:14:28 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 17:14:28 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:14:28 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4534, Recall: 0.4549, F1: 0.4541
[2024-12-07 17:14:29 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [52/70][0/49]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 1.2277 (1.2277)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:14:38 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [52/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 1.2292 (0.9545)	loss 0.7800 (0.7011)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.477
[2024-12-07 17:14:48 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [52/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8313 (0.9413)	loss 0.6067 (0.7221)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 17:14:58 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [52/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8560 (0.9637)	loss 1.0399 (0.7324)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 17:15:06 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [52/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8588 (0.9357)	loss 0.6066 (0.7038)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.461
[2024-12-07 17:15:15 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 52 training takes 0:00:46
[2024-12-07 17:15:17 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.718 
[2024-12-07 17:15:17 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:15:17 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:15:17 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.6222, Recall: 0.5965, F1: 0.6028
[2024-12-07 17:15:18 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [53/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2609 (1.2609)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:15:28 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [53/70][10/49]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 0.8717 (1.0414)	loss 0.9532 (0.6854)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 17:15:37 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [53/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 1.0462 (0.9719)	loss 0.7799 (0.6933)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:15:48 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [53/70][30/49]	eta 0:00:19 lr 0.000000	 wd 0.0000	time 0.8518 (1.0078)	loss 0.7801 (0.7128)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:15:58 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [53/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.8240 (1.0057)	loss 0.5199 (0.6911)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 17:16:05 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 53 training takes 0:00:48
[2024-12-07 17:16:06 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.590 
[2024-12-07 17:16:06 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 17:16:06 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:16:06 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3846, Recall: 0.4185, F1: 0.3983
[2024-12-07 17:16:08 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [54/70][0/49]	eta 0:01:22 lr 0.000000	 wd 0.0000	time 1.6735 (1.6735)	loss 0.6932 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:16:18 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [54/70][10/49]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 0.8307 (1.0221)	loss 0.6932 (0.6854)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:16:28 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [54/70][20/49]	eta 0:00:29 lr 0.000000	 wd 0.0000	time 0.8388 (1.0094)	loss 0.5200 (0.7221)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:16:37 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [54/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 1.8430 (0.9874)	loss 0.3466 (0.6765)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.344
[2024-12-07 17:16:47 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [54/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8501 (0.9839)	loss 0.7798 (0.6763)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 17:16:55 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 54 training takes 0:00:48
[2024-12-07 17:16:57 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.538 
[2024-12-07 17:16:57 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.5%
[2024-12-07 17:16:57 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:16:57 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.4491, Recall: 0.4436, F1: 0.4451
[2024-12-07 17:16:58 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [55/70][0/49]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 1.2438 (1.2438)	loss 0.6066 (0.6066)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.516
[2024-12-07 17:17:07 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [55/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 1.2228 (0.9630)	loss 0.3466 (0.6933)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.531
[2024-12-07 17:17:17 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [55/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8366 (0.9417)	loss 0.6932 (0.6933)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:17:27 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [55/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8438 (0.9601)	loss 0.6932 (0.6821)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:17:35 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [55/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1538 (0.9400)	loss 0.5199 (0.6763)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.484
[2024-12-07 17:17:45 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 55 training takes 0:00:48
[2024-12-07 17:17:47 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.641 
[2024-12-07 17:17:47 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.6%
[2024-12-07 17:17:47 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:17:47 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.5159, Recall: 0.5138, F1: 0.5129
[2024-12-07 17:17:48 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [56/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2651 (1.2651)	loss 0.7800 (0.7800)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.508
[2024-12-07 17:17:58 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [56/70][10/49]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.1956 (1.0266)	loss 0.3466 (0.6539)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 17:18:07 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [56/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8180 (0.9438)	loss 0.3466 (0.6767)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.594
[2024-12-07 17:18:17 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [56/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8560 (0.9594)	loss 1.0399 (0.6793)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.469
[2024-12-07 17:18:26 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [56/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.2357 (0.9495)	loss 0.8666 (0.6912)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.547
[2024-12-07 17:18:34 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 56 training takes 0:00:46
[2024-12-07 17:18:36 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.692 
[2024-12-07 17:18:36 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:18:36 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:18:36 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.6004, Recall: 0.5940, F1: 0.5966
[2024-12-07 17:18:37 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [57/70][0/49]	eta 0:01:16 lr 0.000000	 wd 0.0000	time 1.5633 (1.5633)	loss 0.6933 (0.6933)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:20:15 swin_tiny_patch4_window7_224] (main.py 436): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 17:20:15 swin_tiny_patch4_window7_224] (main.py 437): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 17:21:08 swin_tiny_patch4_window7_224] (main.py 436): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 17:21:08 swin_tiny_patch4_window7_224] (main.py 437): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 17:27:27 swin_tiny_patch4_window7_224] (main.py 436): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 17:27:27 swin_tiny_patch4_window7_224] (main.py 437): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 17:28:41 swin_tiny_patch4_window7_224] (main.py 436): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 17:28:41 swin_tiny_patch4_window7_224] (main.py 437): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 17:28:41 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 17:28:41 swin_tiny_patch4_window7_224] (main.py 96): INFO <data.cached_image_folder.BreastMnistDataset object at 0x7e4e4fcee170>
[2024-12-07 17:28:41 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 17:28:41 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 17:28:41 swin_tiny_patch4_window7_224] (main.py 159): INFO Start training
[2024-12-07 17:30:38 swin_tiny_patch4_window7_224] (main.py 436): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 17:30:38 swin_tiny_patch4_window7_224] (main.py 437): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 17:30:38 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 17:30:38 swin_tiny_patch4_window7_224] (main.py 96): INFO <data.cached_image_folder.BreastMnistDataset object at 0x7d384de2f1c0>
[2024-12-07 17:30:38 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 17:30:38 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 17:30:38 swin_tiny_patch4_window7_224] (main.py 159): INFO Start training
[2024-12-07 17:31:31 swin_tiny_patch4_window7_224] (main.py 436): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 17:31:31 swin_tiny_patch4_window7_224] (main.py 437): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 17:31:31 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 17:31:32 swin_tiny_patch4_window7_224] (main.py 96): INFO <data.cached_image_folder.BreastMnistDataset object at 0x7e1c46baa140>
[2024-12-07 17:31:32 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 17:31:32 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 17:31:32 swin_tiny_patch4_window7_224] (main.py 159): INFO Start training
[2024-12-07 17:33:35 swin_tiny_patch4_window7_224] (main.py 436): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 17:33:35 swin_tiny_patch4_window7_224] (main.py 437): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 17:33:35 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 17:33:35 swin_tiny_patch4_window7_224] (main.py 96): INFO <data.cached_image_folder.BreastMnistDataset object at 0x7f33c30c71c0>
[2024-12-07 17:33:35 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 17:33:35 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 17:33:35 swin_tiny_patch4_window7_224] (main.py 159): INFO Start training
[2024-12-07 17:34:48 swin_tiny_patch4_window7_224] (main.py 436): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 17:34:48 swin_tiny_patch4_window7_224] (main.py 437): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 17:34:48 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 17:34:48 swin_tiny_patch4_window7_224] (main.py 96): INFO <data.cached_image_folder.BreastMnistDataset object at 0x7d89b74bf1c0>
[2024-12-07 17:34:48 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 17:34:48 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 17:34:48 swin_tiny_patch4_window7_224] (main.py 159): INFO Start training
[2024-12-07 17:36:15 swin_tiny_patch4_window7_224] (main.py 436): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 17:36:15 swin_tiny_patch4_window7_224] (main.py 437): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 17:36:15 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 17:36:15 swin_tiny_patch4_window7_224] (main.py 96): INFO <data.cached_image_folder.BreastMnistDataset object at 0x7dbb07a06140>
[2024-12-07 17:36:15 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 17:36:15 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 17:36:15 swin_tiny_patch4_window7_224] (main.py 159): INFO Start training
[2024-12-07 17:36:17 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][0/34]	eta 0:01:07 lr 0.000000	 wd 0.0000	time 1.9754 (1.9754)	loss -266.8178 (-266.8178)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-07 17:36:27 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8919 (1.1006)	loss -292.0244 (-276.6106)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.227
[2024-12-07 17:36:38 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.8967 (1.0868)	loss -291.9513 (-273.1357)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.266
[2024-12-07 17:36:48 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.2976 (1.0546)	loss -204.2507 (-265.0930)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 17:36:51 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 0 training takes 0:00:36
[2024-12-07 17:39:58 swin_tiny_patch4_window7_224] (main.py 436): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 17:39:58 swin_tiny_patch4_window7_224] (main.py 437): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 17:39:58 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 17:39:59 swin_tiny_patch4_window7_224] (main.py 96): INFO <data.cached_image_folder.BreastMnistDataset object at 0x7a44e730a1a0>
[2024-12-07 17:39:59 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 17:39:59 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 17:39:59 swin_tiny_patch4_window7_224] (main.py 159): INFO Start training
[2024-12-07 17:40:21 swin_tiny_patch4_window7_224] (main.py 436): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 17:40:21 swin_tiny_patch4_window7_224] (main.py 437): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 17:40:21 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 17:40:21 swin_tiny_patch4_window7_224] (main.py 96): INFO <data.cached_image_folder.BreastMnistDataset object at 0x7bfa0f6fe1d0>
[2024-12-07 17:40:21 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 17:40:21 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 17:40:21 swin_tiny_patch4_window7_224] (main.py 159): INFO Start training
[2024-12-07 17:40:55 swin_tiny_patch4_window7_224] (main.py 436): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 17:40:55 swin_tiny_patch4_window7_224] (main.py 437): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 17:40:55 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 17:40:55 swin_tiny_patch4_window7_224] (main.py 96): INFO <data.cached_image_folder.BreastMnistDataset object at 0x7ba7f5dc21d0>
[2024-12-07 17:40:55 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 17:40:55 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 17:40:55 swin_tiny_patch4_window7_224] (main.py 159): INFO Start training
[2024-12-07 17:40:57 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][0/34]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 1.1741 (1.1741)	loss -266.8178 (-266.8178)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-07 17:41:07 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 1.2878 (1.0762)	loss -292.0244 (-276.6106)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.227
[2024-12-07 17:41:16 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8883 (0.9932)	loss -291.9513 (-273.1357)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.266
[2024-12-07 17:41:27 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9206 (1.0294)	loss -204.2507 (-265.0930)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-07 17:41:30 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 0 training takes 0:00:34
[2024-12-07 17:41:32 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.308 
[2024-12-07 17:41:32 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 17:41:32 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.31%
[2024-12-07 17:41:32 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.6400, Recall: 0.5263, F1: 0.2687
[2024-12-07 17:41:34 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [1/70][0/34]	eta 0:01:04 lr 0.000000	 wd 0.0000	time 1.8967 (1.8967)	loss -274.2294 (-274.2294)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.281
[2024-12-07 17:41:44 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [1/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8749 (1.1247)	loss -227.5580 (-271.3437)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-07 17:41:56 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [1/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 1.2750 (1.1367)	loss -347.8488 (-261.3318)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.062
[2024-12-07 17:42:08 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [1/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.3055 (1.1624)	loss -279.2372 (-268.9248)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-07 17:42:11 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 1 training takes 0:00:38
[2024-12-07 17:42:13 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.282 
[2024-12-07 17:42:13 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.3%
[2024-12-07 17:42:13 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.31%
[2024-12-07 17:42:13 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.6364, Recall: 0.5088, F1: 0.2315
[2024-12-07 17:42:14 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [2/70][0/34]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 1.3249 (1.3249)	loss -254.2368 (-254.2368)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.359
[2024-12-07 17:42:25 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [2/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.9125 (1.0884)	loss -285.3260 (-280.1381)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-07 17:42:34 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [2/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 1.0254 (1.0088)	loss -336.5613 (-279.3759)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.125
[2024-12-07 17:44:57 swin_tiny_patch4_window7_224] (main.py 436): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 17:44:57 swin_tiny_patch4_window7_224] (main.py 437): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 17:44:57 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 17:44:57 swin_tiny_patch4_window7_224] (main.py 96): INFO <data.cached_image_folder.BreastMnistDataset object at 0x7f731002f8e0>
[2024-12-07 17:44:57 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 17:44:57 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 17:44:57 swin_tiny_patch4_window7_224] (main.py 159): INFO Start training
[2024-12-07 17:44:59 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][0/34]	eta 0:01:09 lr 0.000000	 wd 0.0000	time 2.0564 (2.0564)	loss -273.3534 (-273.3534)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 17:45:11 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][10/34]	eta 0:00:30 lr 0.000000	 wd 0.0000	time 1.0046 (1.2900)	loss -298.3708 (-282.0337)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 17:45:23 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][20/34]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.0356 (1.2383)	loss -300.5247 (-278.9001)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 17:45:34 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.4719 (1.1928)	loss -207.8442 (-271.2662)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 17:45:37 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 0 training takes 0:00:40
[2024-12-07 17:45:42 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.731 
[2024-12-07 17:45:42 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:45:42 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:45:42 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 17:45:44 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [1/70][0/34]	eta 0:01:17 lr 0.000000	 wd 0.0000	time 2.2689 (2.2689)	loss -281.5062 (-281.5062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 17:45:57 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [1/70][10/34]	eta 0:00:32 lr 0.000000	 wd 0.0000	time 1.5163 (1.3750)	loss -236.2766 (-280.3925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 17:46:10 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [1/70][20/34]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.9695 (1.3312)	loss -357.7151 (-270.1233)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-07 17:46:40 swin_tiny_patch4_window7_224] (main.py 436): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 17:46:40 swin_tiny_patch4_window7_224] (main.py 437): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 17:46:40 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 17:46:40 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 17:46:40 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 17:46:40 swin_tiny_patch4_window7_224] (main.py 159): INFO Start training
[2024-12-07 17:46:41 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][0/34]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 1.1230 (1.1230)	loss -273.3534 (-273.3534)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 17:46:52 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.8901 (1.0642)	loss -298.3708 (-282.0337)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 17:47:01 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 1.2660 (0.9997)	loss -300.5247 (-278.9001)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 17:47:11 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8936 (1.0071)	loss -207.8442 (-271.2662)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 17:47:14 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 0 training takes 0:00:33
[2024-12-07 17:47:16 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.731 
[2024-12-07 17:47:16 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:47:16 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:47:16 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 17:47:18 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [1/70][0/34]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.7536 (1.7536)	loss -281.5062 (-281.5062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 17:47:28 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [1/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 0.8960 (1.0357)	loss -236.2766 (-280.3925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 17:47:38 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [1/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8866 (1.0418)	loss -357.7151 (-270.1233)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-07 17:47:48 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [1/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.2986 (1.0179)	loss -289.9583 (-278.2883)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 17:47:51 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 1 training takes 0:00:35
[2024-12-07 17:47:53 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.731 
[2024-12-07 17:47:53 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:47:53 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:47:53 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 17:47:54 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [2/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2921 (1.2921)	loss -267.7273 (-267.7273)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 17:48:05 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [2/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 1.3058 (1.0783)	loss -293.0053 (-291.3281)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 17:48:14 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [2/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8956 (0.9975)	loss -356.4388 (-291.8768)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 17:48:25 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [2/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9017 (1.0190)	loss -304.7386 (-290.8866)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 17:48:27 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 2 training takes 0:00:34
[2024-12-07 17:48:29 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.731 
[2024-12-07 17:48:29 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:48:29 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:48:29 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 17:48:31 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [3/70][0/34]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 1.3362 (1.3362)	loss -336.4585 (-336.4585)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 17:48:41 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [3/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8848 (1.0896)	loss -287.8342 (-306.5669)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 17:48:58 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [3/70][20/34]	eta 0:00:19 lr 0.000000	 wd 0.0000	time 2.0336 (1.3656)	loss -349.2104 (-312.7304)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 17:49:12 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [3/70][30/34]	eta 0:00:05 lr 0.000000	 wd 0.0000	time 0.9429 (1.3905)	loss -271.8677 (-308.6061)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 17:49:15 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 3 training takes 0:00:45
[2024-12-07 17:49:17 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.731 
[2024-12-07 17:49:17 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:49:17 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:49:17 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 17:49:19 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [4/70][0/34]	eta 0:01:02 lr 0.000000	 wd 0.0000	time 1.8339 (1.8339)	loss -378.7469 (-378.7469)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 17:49:29 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [4/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.8882 (1.0707)	loss -337.2520 (-322.4963)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 17:49:39 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [4/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8945 (1.0590)	loss -321.0278 (-326.7348)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 17:49:49 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [4/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.3019 (1.0232)	loss -319.4481 (-331.5127)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 17:49:52 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 4 training takes 0:00:35
[2024-12-07 17:49:54 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.731 
[2024-12-07 17:49:54 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:49:54 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:49:54 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 17:49:56 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [5/70][0/34]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.7955 (1.7955)	loss -384.2366 (-384.2366)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 17:50:08 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [5/70][10/34]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 1.0028 (1.2048)	loss -361.0213 (-333.2059)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 17:50:17 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [5/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8782 (1.0609)	loss -365.7999 (-348.9593)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 17:50:29 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [5/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8626 (1.1161)	loss -378.1480 (-359.0623)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 17:50:32 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 5 training takes 0:00:37
[2024-12-07 17:50:34 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.731 
[2024-12-07 17:50:34 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:50:34 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:50:34 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 17:50:37 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [6/70][0/34]	eta 0:01:37 lr 0.000000	 wd 0.0000	time 2.8620 (2.8620)	loss -472.8571 (-472.8571)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-07 17:50:46 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [6/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.9105 (1.0959)	loss -387.0771 (-381.7968)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 17:50:56 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [6/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8801 (1.0692)	loss -435.6293 (-384.3046)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 17:51:07 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [6/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.1930 (1.0637)	loss -299.1339 (-379.3092)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 17:51:10 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 6 training takes 0:00:35
[2024-12-07 17:51:12 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.731 
[2024-12-07 17:51:12 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:51:12 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:51:12 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 17:51:13 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [7/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.2985 (1.2985)	loss -341.1183 (-341.1183)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 17:51:24 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [7/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8834 (1.1088)	loss -478.8052 (-400.4589)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 17:51:33 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [7/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 1.2915 (1.0249)	loss -314.5635 (-392.1180)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 17:51:45 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [7/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8964 (1.0606)	loss -400.4394 (-404.4583)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 17:51:47 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 7 training takes 0:00:35
[2024-12-07 17:51:50 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.731 
[2024-12-07 17:51:50 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:51:50 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:51:50 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 17:51:51 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [8/70][0/34]	eta 0:00:48 lr 0.000000	 wd 0.0000	time 1.4254 (1.4254)	loss -509.5515 (-509.5515)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 17:52:01 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [8/70][10/34]	eta 0:00:22 lr 0.000000	 wd 0.0000	time 0.8849 (0.9580)	loss -484.2863 (-416.5098)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 17:52:11 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [8/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8994 (1.0045)	loss -445.3886 (-422.0573)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 17:52:22 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [8/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8828 (1.0196)	loss -499.0620 (-438.3164)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 17:52:24 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 8 training takes 0:00:34
[2024-12-07 17:52:26 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.731 
[2024-12-07 17:52:26 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:52:26 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:52:26 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 17:52:27 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [9/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2833 (1.2833)	loss -510.3785 (-510.3785)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 17:52:41 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [9/70][10/34]	eta 0:00:32 lr 0.000000	 wd 0.0000	time 1.4713 (1.3521)	loss -394.0466 (-456.7621)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 17:52:52 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [9/70][20/34]	eta 0:00:16 lr 0.000000	 wd 0.0000	time 0.8850 (1.2115)	loss -434.5549 (-456.9736)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 17:53:00 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [9/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8769 (1.1065)	loss -366.7117 (-462.8512)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 17:53:04 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 9 training takes 0:00:38
[2024-12-07 17:53:06 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.731 
[2024-12-07 17:53:06 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:53:06 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:53:06 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 17:53:08 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [10/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3099 (1.3099)	loss -324.6683 (-324.6683)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 17:53:18 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [10/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 1.2661 (1.0276)	loss -556.6503 (-505.8113)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 17:53:27 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [10/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8868 (0.9956)	loss -467.9659 (-497.8165)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 17:53:44 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [10/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8938 (1.2249)	loss -554.3865 (-501.1661)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 17:53:51 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 10 training takes 0:00:44
[2024-12-07 17:53:53 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.731 
[2024-12-07 17:53:53 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:53:53 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:53:53 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 17:53:54 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [11/70][0/34]	eta 0:00:46 lr 0.000000	 wd 0.0000	time 1.3537 (1.3537)	loss -592.7676 (-592.7676)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 17:54:06 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [11/70][10/34]	eta 0:00:29 lr 0.000000	 wd 0.0000	time 1.2530 (1.2298)	loss -610.8892 (-531.5584)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 17:54:17 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [11/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 1.0950 (1.1372)	loss -482.8745 (-527.3323)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 17:54:27 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [11/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8801 (1.1014)	loss -458.3381 (-514.6387)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 17:54:30 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 11 training takes 0:00:36
[2024-12-07 17:54:31 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.731 
[2024-12-07 17:54:31 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:54:31 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:54:31 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 17:54:33 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [12/70][0/34]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.7984 (1.7984)	loss -496.9337 (-496.9337)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 17:54:48 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [12/70][10/34]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 1.3740 (1.5442)	loss -460.8807 (-500.6287)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 17:55:00 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [12/70][20/34]	eta 0:00:19 lr 0.000000	 wd 0.0000	time 0.8878 (1.3797)	loss -616.5151 (-531.7920)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 17:55:11 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [12/70][30/34]	eta 0:00:05 lr 0.000000	 wd 0.0000	time 0.8902 (1.2720)	loss -673.0825 (-547.6188)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 17:55:14 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 12 training takes 0:00:42
[2024-12-07 17:55:16 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.731 
[2024-12-07 17:55:16 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:55:16 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:55:16 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 17:55:20 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [13/70][0/34]	eta 0:02:26 lr 0.000000	 wd 0.0000	time 4.2996 (4.2996)	loss -472.3231 (-472.3231)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 17:55:31 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [13/70][10/34]	eta 0:00:32 lr 0.000000	 wd 0.0000	time 0.8968 (1.3634)	loss -693.3011 (-542.5451)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 17:55:42 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [13/70][20/34]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.9568 (1.2181)	loss -640.1853 (-551.1657)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 17:55:52 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [13/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.2818 (1.1629)	loss -610.5868 (-561.2132)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 17:55:55 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 13 training takes 0:00:38
[2024-12-07 17:55:57 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.731 
[2024-12-07 17:55:57 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:55:57 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:55:57 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 17:55:58 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [14/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3133 (1.3133)	loss -589.5861 (-589.5861)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 17:56:09 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [14/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.8938 (1.0803)	loss -653.5114 (-583.5626)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 17:56:18 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [14/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 1.2367 (1.0091)	loss -503.7437 (-571.1308)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 17:56:28 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [14/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8989 (1.0110)	loss -569.7780 (-583.6906)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 17:56:31 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 14 training takes 0:00:34
[2024-12-07 17:56:33 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.731 
[2024-12-07 17:56:33 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:56:33 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:56:33 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 17:56:35 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [15/70][0/34]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 1.7860 (1.7860)	loss -588.6301 (-588.6301)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 17:56:45 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [15/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.9029 (1.0578)	loss -474.9550 (-579.9992)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 17:56:55 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [15/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8885 (1.0542)	loss -634.6146 (-598.3900)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 17:57:05 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [15/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.2494 (1.0294)	loss -583.3863 (-611.4638)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 17:57:08 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 15 training takes 0:00:35
[2024-12-07 17:57:10 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.731 
[2024-12-07 17:57:10 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:57:10 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:57:10 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 17:57:11 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [16/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3153 (1.3153)	loss -696.7231 (-696.7231)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 17:57:22 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [16/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 1.2777 (1.0911)	loss -599.9292 (-644.2905)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 17:57:31 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [16/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8899 (1.0009)	loss -585.7471 (-631.1438)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 17:57:42 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [16/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9002 (1.0167)	loss -773.6776 (-630.4617)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 17:57:44 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 16 training takes 0:00:34
[2024-12-07 17:57:46 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.731 
[2024-12-07 17:57:46 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:57:46 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:57:46 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 17:57:48 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [17/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3008 (1.3008)	loss -610.4846 (-610.4846)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 17:57:59 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [17/70][10/34]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 1.2726 (1.1926)	loss -679.4055 (-637.8147)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 17:58:10 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [17/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.8915 (1.1354)	loss -710.8240 (-653.8013)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 17:58:20 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [17/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.2716 (1.0844)	loss -689.0738 (-664.1122)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 17:58:23 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 17 training takes 0:00:37
[2024-12-07 17:58:25 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.731 
[2024-12-07 17:58:25 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:58:25 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:58:25 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 17:58:26 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [18/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2782 (1.2782)	loss -636.3637 (-636.3637)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 17:58:37 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [18/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 1.2915 (1.0753)	loss -576.8672 (-665.2085)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 17:58:46 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [18/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8951 (0.9991)	loss -762.6776 (-700.7839)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 17:58:57 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [18/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8874 (1.0182)	loss -615.4745 (-675.9296)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 17:58:59 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 18 training takes 0:00:34
[2024-12-07 17:59:01 swin_tiny_patch4_window7_224] (main.py 359): INFO  * Accuracy validation@ 0.731 
[2024-12-07 17:59:01 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.7%
[2024-12-07 17:59:01 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 17:59:01 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 17:59:03 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [19/70][0/34]	eta 0:00:47 lr 0.000000	 wd 0.0000	time 1.4098 (1.4098)	loss -576.2172 (-576.2172)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 17:59:13 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [19/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.9173 (1.0826)	loss -650.2132 (-635.4259)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:00:05 swin_tiny_patch4_window7_224] (main.py 438): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 18:00:05 swin_tiny_patch4_window7_224] (main.py 439): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 18:00:05 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 18:00:05 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 18:00:05 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 18:00:05 swin_tiny_patch4_window7_224] (main.py 159): INFO Start training
[2024-12-07 18:00:07 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][0/34]	eta 0:01:08 lr 0.000000	 wd 0.0000	time 2.0000 (2.0000)	loss -273.3534 (-273.3534)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:00:19 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][10/34]	eta 0:00:30 lr 0.000000	 wd 0.0000	time 1.0280 (1.2847)	loss -298.3708 (-282.0337)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:00:36 swin_tiny_patch4_window7_224] (main.py 438): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 18:00:36 swin_tiny_patch4_window7_224] (main.py 439): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 18:00:36 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 18:00:36 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 18:00:36 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 18:00:36 swin_tiny_patch4_window7_224] (main.py 159): INFO Start training
[2024-12-07 18:00:37 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][0/34]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 1.1552 (1.1552)	loss -273.3534 (-273.3534)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:00:47 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.8869 (1.0702)	loss -298.3708 (-282.0337)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:00:58 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 1.1486 (1.0583)	loss -300.5247 (-278.9001)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:01:07 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [0/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8972 (1.0046)	loss -207.8442 (-271.2662)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 18:01:10 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 0 training takes 0:00:34
[2024-12-07 18:01:13 swin_tiny_patch4_window7_224] (main.py 361): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:01:13 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:01:13 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:01:13 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:01:14 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [1/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2769 (1.2769)	loss -281.5062 (-281.5062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:01:23 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [1/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 1.3039 (0.9916)	loss -236.2766 (-280.3925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:01:33 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [1/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8822 (0.9891)	loss -357.7151 (-270.1233)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-07 18:01:44 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [1/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8849 (1.0061)	loss -289.9583 (-278.2883)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:01:46 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 1 training takes 0:00:33
[2024-12-07 18:01:48 swin_tiny_patch4_window7_224] (main.py 361): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:01:48 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:01:48 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:01:48 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:01:50 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [2/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.2997 (1.2997)	loss -267.7273 (-267.7273)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:02:02 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [2/70][10/34]	eta 0:00:30 lr 0.000000	 wd 0.0000	time 0.9668 (1.2556)	loss -293.0053 (-291.3281)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:02:12 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [2/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 1.2917 (1.1066)	loss -356.4388 (-291.8768)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:02:22 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [2/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8867 (1.0736)	loss -304.7386 (-290.8866)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:02:24 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 2 training takes 0:00:36
[2024-12-07 18:02:26 swin_tiny_patch4_window7_224] (main.py 361): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:02:26 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:02:26 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:02:26 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:02:28 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [3/70][0/34]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 1.7873 (1.7873)	loss -336.4585 (-336.4585)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:02:38 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [3/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.8896 (1.0471)	loss -287.8342 (-306.5669)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:02:48 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [3/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8935 (1.0510)	loss -349.2104 (-312.7304)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:02:58 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [3/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.2658 (1.0259)	loss -271.8677 (-308.6061)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:03:02 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 3 training takes 0:00:35
[2024-12-07 18:03:04 swin_tiny_patch4_window7_224] (main.py 361): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:03:04 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:03:04 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:03:04 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:03:05 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [4/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2934 (1.2934)	loss -378.7469 (-378.7469)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:03:15 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [4/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 1.3008 (1.0721)	loss -337.2520 (-322.4963)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:03:24 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [4/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.9079 (0.9900)	loss -321.0278 (-326.7348)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:03:35 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [4/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8879 (1.0065)	loss -319.4481 (-331.5127)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:03:38 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 4 training takes 0:00:33
[2024-12-07 18:03:39 swin_tiny_patch4_window7_224] (main.py 361): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:03:39 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:03:39 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:03:39 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:03:41 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [5/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3191 (1.3191)	loss -384.2366 (-384.2366)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:03:51 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [5/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.9067 (1.0901)	loss -361.0213 (-333.2059)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:04:02 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [5/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.8955 (1.0722)	loss -365.7999 (-348.9593)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:04:11 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [5/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9040 (1.0153)	loss -378.1480 (-359.0623)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:04:15 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 5 training takes 0:00:35
[2024-12-07 18:04:17 swin_tiny_patch4_window7_224] (main.py 361): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:04:17 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:04:17 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:04:17 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:04:18 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [6/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2800 (1.2800)	loss -472.8571 (-472.8571)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-07 18:04:28 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [6/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 1.2660 (1.0202)	loss -387.0771 (-381.7968)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:04:38 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [6/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8896 (0.9875)	loss -435.6293 (-384.3046)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:04:48 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [6/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9077 (1.0082)	loss -299.1339 (-379.3092)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 18:04:51 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 6 training takes 0:00:34
[2024-12-07 18:04:53 swin_tiny_patch4_window7_224] (main.py 361): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:04:53 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:04:53 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:04:53 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:04:54 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [7/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3077 (1.3077)	loss -341.1183 (-341.1183)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:05:05 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [7/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8975 (1.0878)	loss -478.8052 (-400.4589)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:05:20 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [7/70][20/34]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 1.4371 (1.3068)	loss -314.5635 (-392.1180)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 18:05:35 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [7/70][30/34]	eta 0:00:05 lr 0.000000	 wd 0.0000	time 0.8932 (1.3640)	loss -400.4394 (-404.4583)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:05:38 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 7 training takes 0:00:45
[2024-12-07 18:05:39 swin_tiny_patch4_window7_224] (main.py 361): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:05:39 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:05:39 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:05:39 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:05:41 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [8/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2913 (1.2913)	loss -509.5515 (-509.5515)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:05:52 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [8/70][10/34]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 1.3048 (1.1738)	loss -484.2863 (-416.5098)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:06:03 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [8/70][20/34]	eta 0:00:16 lr 0.000000	 wd 0.0000	time 0.9025 (1.1438)	loss -445.3886 (-422.0573)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:06:13 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [8/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.2754 (1.0779)	loss -499.0620 (-438.3164)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:06:17 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 8 training takes 0:00:37
[2024-12-07 18:06:18 swin_tiny_patch4_window7_224] (main.py 361): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:06:18 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:06:18 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:06:18 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:06:20 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [9/70][0/34]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 1.3252 (1.3252)	loss -510.3785 (-510.3785)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:06:30 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [9/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 1.3169 (1.0403)	loss -394.0466 (-456.7621)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:06:39 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [9/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8738 (0.9792)	loss -434.5549 (-456.9736)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:06:51 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [9/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.3924 (1.0520)	loss -366.7117 (-462.8512)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 18:06:54 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 9 training takes 0:00:35
[2024-12-07 18:06:56 swin_tiny_patch4_window7_224] (main.py 361): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:06:56 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:06:56 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:06:56 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:06:57 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [10/70][0/34]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.7078 (1.7078)	loss -324.6683 (-324.6683)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 18:07:07 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [10/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.8848 (1.0632)	loss -556.6503 (-505.8113)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:07:18 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [10/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8704 (1.0573)	loss -467.9659 (-497.8165)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:07:27 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [10/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.2861 (1.0281)	loss -554.3865 (-501.1661)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:07:31 swin_tiny_patch4_window7_224] (main.py 271): INFO EPOCH 10 training takes 0:00:35
[2024-12-07 18:07:33 swin_tiny_patch4_window7_224] (main.py 361): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:07:33 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:07:33 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:07:33 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:07:34 swin_tiny_patch4_window7_224] (main.py 262): INFO Train: [11/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3148 (1.3148)	loss -592.7676 (-592.7676)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:11:44 swin_tiny_patch4_window7_224] (main.py 439): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 18:11:44 swin_tiny_patch4_window7_224] (main.py 440): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 18:11:44 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 18:11:44 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 18:11:44 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 18:11:44 swin_tiny_patch4_window7_224] (main.py 159): INFO Start training
[2024-12-07 18:11:46 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [0/70][0/34]	eta 0:00:54 lr 0.000000	 wd 0.0000	time 1.5958 (1.5958)	loss -273.3534 (-273.3534)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:11:55 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [0/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 0.9209 (0.9880)	loss -298.3708 (-282.0337)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:12:06 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [0/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.9027 (1.0272)	loss -300.5247 (-278.9001)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:12:16 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [0/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.1422 (1.0383)	loss -207.8442 (-271.2662)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 18:12:19 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 0 training takes 0:00:34
[2024-12-07 18:12:21 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:12:21 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:12:21 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:12:21 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:12:22 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [1/70][0/34]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 1.3387 (1.3387)	loss -281.5062 (-281.5062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:12:33 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [1/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8990 (1.1005)	loss -236.2766 (-280.3925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:12:43 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [1/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 1.3169 (1.0317)	loss -357.7151 (-270.1233)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-07 18:12:53 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [1/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9237 (1.0262)	loss -289.9583 (-278.2883)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:12:56 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 1 training takes 0:00:34
[2024-12-07 18:12:58 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:12:58 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:12:58 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:12:58 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:13:00 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [2/70][0/34]	eta 0:01:02 lr 0.000000	 wd 0.0000	time 1.8243 (1.8243)	loss -267.7273 (-267.7273)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:13:10 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [2/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.9267 (1.0434)	loss -293.0053 (-291.3281)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:13:20 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [2/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.9159 (1.0565)	loss -356.4388 (-291.8768)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:13:31 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [2/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.2827 (1.0518)	loss -304.7386 (-290.8866)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:13:34 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 2 training takes 0:00:35
[2024-12-07 18:13:36 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:13:36 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:13:36 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:13:36 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:13:37 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [3/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2859 (1.2859)	loss -336.4585 (-336.4585)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:13:49 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [3/70][10/34]	eta 0:00:29 lr 0.000000	 wd 0.0000	time 1.5725 (1.2398)	loss -287.8342 (-306.5669)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:13:59 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [3/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.8977 (1.1066)	loss -349.2104 (-312.7304)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:14:10 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [3/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9298 (1.0986)	loss -271.8677 (-308.6061)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:14:12 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 3 training takes 0:00:36
[2024-12-07 18:14:14 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:14:14 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:14:14 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:14:14 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:14:15 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [4/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3008 (1.3008)	loss -378.7469 (-378.7469)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:14:26 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [4/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.9211 (1.1070)	loss -337.2520 (-322.4963)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:14:37 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [4/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.9296 (1.0878)	loss -321.0278 (-326.7348)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:14:46 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [4/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9470 (1.0350)	loss -319.4481 (-331.5127)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:14:50 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 4 training takes 0:00:36
[2024-12-07 18:14:52 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:14:52 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:14:52 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:14:52 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:14:54 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [5/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3164 (1.3164)	loss -384.2366 (-384.2366)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:15:04 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [5/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 1.2972 (1.0442)	loss -361.0213 (-333.2059)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:15:14 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [5/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.9262 (1.0165)	loss -365.7999 (-348.9593)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:15:24 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [5/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8863 (1.0352)	loss -378.1480 (-359.0623)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:15:27 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 5 training takes 0:00:34
[2024-12-07 18:15:29 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:15:29 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:15:29 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:15:29 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:15:30 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [6/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3156 (1.3156)	loss -472.8571 (-472.8571)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-07 18:15:41 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [6/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.9222 (1.1050)	loss -387.0771 (-381.7968)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:15:52 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [6/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.9676 (1.1039)	loss -435.6293 (-384.3046)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:16:01 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [6/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9564 (1.0455)	loss -299.1339 (-379.3092)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 18:16:05 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 6 training takes 0:00:36
[2024-12-07 18:16:07 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:16:07 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:16:07 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:16:07 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:16:08 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [7/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3067 (1.3067)	loss -341.1183 (-341.1183)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:16:19 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [7/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 1.3013 (1.0379)	loss -478.8052 (-400.4589)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:16:28 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [7/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.9032 (1.0152)	loss -314.5635 (-392.1180)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 18:16:39 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [7/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9096 (1.0309)	loss -400.4394 (-404.4583)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:16:42 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 7 training takes 0:00:34
[2024-12-07 18:16:44 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:16:44 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:16:44 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:16:44 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:16:45 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [8/70][0/34]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 1.3402 (1.3402)	loss -509.5515 (-509.5515)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:16:56 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [8/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.9189 (1.1078)	loss -484.2863 (-416.5098)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:17:06 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [8/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 1.0426 (1.0793)	loss -445.3886 (-422.0573)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:17:16 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [8/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9203 (1.0274)	loss -499.0620 (-438.3164)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:17:19 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 8 training takes 0:00:35
[2024-12-07 18:17:21 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:17:21 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:17:21 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:17:21 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:17:23 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [9/70][0/34]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 1.3357 (1.3357)	loss -510.3785 (-510.3785)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:17:33 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [9/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 1.3129 (1.0526)	loss -394.0466 (-456.7621)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:17:44 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [9/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.9022 (1.0951)	loss -434.5549 (-456.9736)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:17:55 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [9/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9078 (1.0901)	loss -366.7117 (-462.8512)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 18:17:58 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 9 training takes 0:00:36
[2024-12-07 18:18:00 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:18:00 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:18:00 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:18:00 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:18:01 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [10/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.2951 (1.2951)	loss -324.6683 (-324.6683)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 18:18:12 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [10/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.9171 (1.0995)	loss -556.6503 (-505.8113)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:18:22 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [10/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 1.2215 (1.0841)	loss -467.9659 (-497.8165)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:18:32 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [10/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8865 (1.0299)	loss -554.3865 (-501.1661)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:18:35 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 10 training takes 0:00:35
[2024-12-07 18:18:37 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:18:37 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:18:37 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:18:37 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:18:39 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [11/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.2949 (1.2949)	loss -592.7676 (-592.7676)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:18:49 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [11/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 1.3316 (1.0325)	loss -610.8892 (-531.5584)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:18:59 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [11/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8997 (1.0200)	loss -482.8745 (-527.3323)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:19:09 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [11/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9465 (1.0370)	loss -458.3381 (-514.6387)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:19:12 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 11 training takes 0:00:34
[2024-12-07 18:19:14 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:19:14 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:19:14 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:19:14 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:19:15 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [12/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3139 (1.3139)	loss -496.9337 (-496.9337)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:19:26 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [12/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.9251 (1.1105)	loss -460.8807 (-500.6287)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:19:37 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [12/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 1.3093 (1.0910)	loss -616.5151 (-531.7920)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:19:46 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [12/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9041 (1.0353)	loss -673.0825 (-547.6188)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:19:50 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 12 training takes 0:00:35
[2024-12-07 18:19:52 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:19:52 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:19:52 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:19:52 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:19:53 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [13/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3186 (1.3186)	loss -472.3231 (-472.3231)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:20:04 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [13/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 1.3641 (1.0375)	loss -693.3011 (-542.5451)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:20:14 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [13/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.9197 (1.0209)	loss -640.1853 (-551.1657)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:20:24 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [13/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9486 (1.0413)	loss -610.5868 (-561.2132)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:20:27 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 13 training takes 0:00:35
[2024-12-07 18:20:29 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:20:29 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:20:29 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:20:29 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:20:30 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [14/70][0/34]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 1.3335 (1.3335)	loss -589.5861 (-589.5861)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:20:41 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [14/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.9044 (1.1133)	loss -653.5114 (-583.5626)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:20:52 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [14/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 1.2793 (1.0971)	loss -503.7437 (-571.1308)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:21:01 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [14/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9223 (1.0386)	loss -569.7780 (-583.6906)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:21:05 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 14 training takes 0:00:35
[2024-12-07 18:21:07 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:21:07 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:21:07 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:21:07 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:21:08 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [15/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2919 (1.2919)	loss -588.6301 (-588.6301)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:21:18 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [15/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 1.3226 (1.0374)	loss -474.9550 (-579.9992)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 18:21:28 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [15/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8983 (1.0164)	loss -634.6146 (-598.3900)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:21:39 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [15/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9201 (1.0360)	loss -583.3863 (-611.4638)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:21:42 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 15 training takes 0:00:34
[2024-12-07 18:21:44 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:21:44 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:21:44 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:21:44 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:21:45 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [16/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3228 (1.3228)	loss -696.7231 (-696.7231)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:21:57 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [16/70][10/34]	eta 0:00:29 lr 0.000000	 wd 0.0000	time 1.2450 (1.2158)	loss -599.9292 (-644.2905)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:22:08 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [16/70][20/34]	eta 0:00:16 lr 0.000000	 wd 0.0000	time 0.9150 (1.1610)	loss -585.7471 (-631.1438)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:22:18 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [16/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.2881 (1.0930)	loss -773.6776 (-630.4617)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:22:21 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 16 training takes 0:00:37
[2024-12-07 18:22:23 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:22:23 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:22:23 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:22:23 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:22:25 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [17/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3019 (1.3019)	loss -610.4846 (-610.4846)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:22:35 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [17/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 1.2957 (1.0530)	loss -679.4055 (-637.8147)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:22:45 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [17/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.9289 (1.0126)	loss -710.8240 (-653.8013)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:22:55 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [17/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9118 (1.0334)	loss -689.0738 (-664.1122)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:22:58 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 17 training takes 0:00:34
[2024-12-07 18:23:00 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:23:00 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:23:00 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:23:00 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:23:01 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [18/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3009 (1.3009)	loss -636.3637 (-636.3637)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:23:12 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [18/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8932 (1.0934)	loss -576.8672 (-665.2085)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:23:23 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [18/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 1.1295 (1.0872)	loss -762.6776 (-700.7839)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:23:32 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [18/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9223 (1.0357)	loss -615.4745 (-675.9296)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:23:36 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 18 training takes 0:00:35
[2024-12-07 18:23:38 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:23:38 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:23:38 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:23:38 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:23:39 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [19/70][0/34]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 1.3405 (1.3405)	loss -576.2172 (-576.2172)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:23:49 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [19/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 1.3006 (1.0541)	loss -650.2132 (-635.4259)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:24:00 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [19/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.9060 (1.0429)	loss -646.0895 (-672.6247)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:24:10 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [19/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9125 (1.0451)	loss -660.1988 (-681.9095)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:24:13 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 19 training takes 0:00:35
[2024-12-07 18:24:15 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:24:15 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:24:15 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:24:15 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:24:16 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [20/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3078 (1.3078)	loss -855.5208 (-855.5208)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:24:27 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [20/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.9806 (1.1055)	loss -656.4567 (-747.2589)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:24:38 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [20/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.9188 (1.0919)	loss -861.8800 (-723.5580)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:24:47 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [20/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9612 (1.0361)	loss -726.3320 (-707.2357)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:24:51 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 20 training takes 0:00:36
[2024-12-07 18:24:53 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:24:53 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:24:53 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:24:53 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:24:54 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [21/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3121 (1.3121)	loss -488.9527 (-488.9527)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 18:25:04 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [21/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 1.2927 (1.0577)	loss -807.9872 (-698.0561)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:25:14 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [21/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.9132 (1.0124)	loss -614.6497 (-682.9077)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:25:25 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [21/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9292 (1.0330)	loss -735.1633 (-722.9394)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:25:28 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 21 training takes 0:00:34
[2024-12-07 18:25:29 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:25:29 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:25:29 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:25:29 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:25:31 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [22/70][0/34]	eta 0:00:46 lr 0.000000	 wd 0.0000	time 1.3595 (1.3595)	loss -800.9890 (-800.9890)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:25:42 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [22/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8964 (1.1105)	loss -888.2883 (-765.2110)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:25:54 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [22/70][20/34]	eta 0:00:16 lr 0.000000	 wd 0.0000	time 1.3262 (1.1720)	loss -744.3777 (-733.1782)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:26:03 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [22/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9080 (1.0884)	loss -766.2706 (-737.0159)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:26:07 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 22 training takes 0:00:37
[2024-12-07 18:26:09 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:26:09 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:26:09 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:26:09 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:26:10 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [23/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2929 (1.2929)	loss -559.6683 (-559.6683)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 18:26:20 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [23/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 1.3134 (1.0047)	loss -569.7462 (-697.6759)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 18:26:30 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [23/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.9357 (1.0082)	loss -828.0718 (-720.6441)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:26:41 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [23/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9269 (1.0246)	loss -825.9526 (-748.3369)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:26:43 swin_tiny_patch4_window7_224] (main.py 272): INFO EPOCH 23 training takes 0:00:34
[2024-12-07 18:26:45 swin_tiny_patch4_window7_224] (main.py 362): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:26:45 swin_tiny_patch4_window7_224] (main.py 172): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:26:45 swin_tiny_patch4_window7_224] (main.py 174): INFO Max accuracy: 0.73%
[2024-12-07 18:26:45 swin_tiny_patch4_window7_224] (main.py 175): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:26:47 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [24/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2938 (1.2938)	loss -913.7678 (-913.7678)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:26:57 swin_tiny_patch4_window7_224] (main.py 263): INFO Train: [24/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.9160 (1.0972)	loss -715.1694 (-803.5784)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:32:18 swin_tiny_patch4_window7_224] (main.py 440): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 18:32:18 swin_tiny_patch4_window7_224] (main.py 441): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 18:32:18 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 18:32:18 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 18:32:18 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 18:32:18 swin_tiny_patch4_window7_224] (main.py 159): INFO Start training
[2024-12-07 18:34:25 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 18:34:25 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 18:34:25 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 18:34:25 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 18:34:25 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 18:34:25 swin_tiny_patch4_window7_224] (main.py 160): INFO Start training
[2024-12-07 18:40:03 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 18:40:03 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 18:40:03 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 18:40:03 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 18:40:03 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 18:40:03 swin_tiny_patch4_window7_224] (main.py 160): INFO Start training
[2024-12-07 18:40:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][0/34]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 1.1501 (1.1501)	loss 0.6010 (0.6010)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:40:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 1.2772 (1.0446)	loss 0.5693 (0.6022)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:40:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8866 (0.9931)	loss 0.5580 (0.6055)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:40:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9197 (1.0177)	loss 0.6858 (0.6129)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 18:40:37 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 0 training takes 0:00:34
[2024-12-07 18:40:39 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:40:39 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:40:39 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:40:39 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:40:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3098 (1.3098)	loss 0.5894 (0.5894)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:40:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.9023 (1.0872)	loss 0.6558 (0.5956)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:41:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.9841 (1.0750)	loss 0.4963 (0.6132)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-07 18:41:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.3254 (1.0949)	loss 0.5964 (0.6032)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:41:17 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 1 training takes 0:00:37
[2024-12-07 18:41:18 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:41:18 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:41:18 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:41:18 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:41:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][0/34]	eta 0:00:49 lr 0.000000	 wd 0.0000	time 1.4617 (1.4617)	loss 0.6287 (0.6287)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:41:33 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][10/34]	eta 0:00:31 lr 0.000000	 wd 0.0000	time 0.9512 (1.2968)	loss 0.6014 (0.5901)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:41:42 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 1.2912 (1.1365)	loss 0.4911 (0.5897)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:41:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9329 (1.1020)	loss 0.5728 (0.5939)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:41:55 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 2 training takes 0:00:36
[2024-12-07 18:41:57 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:41:57 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:41:57 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:41:57 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:41:59 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][0/34]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.8030 (1.8030)	loss 0.5453 (0.5453)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:42:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.9144 (1.0593)	loss 0.6210 (0.5847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:42:25 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 18:42:25 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 18:42:25 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 18:42:25 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 18:42:25 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 18:42:25 swin_tiny_patch4_window7_224] (main.py 160): INFO Start training
[2024-12-07 18:42:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][0/34]	eta 0:00:46 lr 0.000000	 wd 0.0000	time 1.3773 (1.3773)	loss 0.6010 (0.6010)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:42:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.8883 (1.0776)	loss 0.5693 (0.6022)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:42:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 1.0824 (1.0801)	loss 0.5580 (0.6055)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:43:02 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-07 18:43:02 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-07 18:43:02 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-07 18:43:02 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-07 18:43:02 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-07 18:43:02 swin_tiny_patch4_window7_224] (main.py 160): INFO Start training
[2024-12-07 18:43:03 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][0/34]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 1.1512 (1.1512)	loss 0.6010 (0.6010)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:43:15 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][10/34]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8934 (1.1317)	loss 0.5693 (0.6022)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:43:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 1.0893 (1.0264)	loss 0.5580 (0.6055)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:43:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9017 (1.0276)	loss 0.6858 (0.6129)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 18:43:37 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 0 training takes 0:00:34
[2024-12-07 18:43:39 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:43:39 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:43:39 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:43:39 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:43:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][0/34]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.7633 (1.7633)	loss 0.5894 (0.5894)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:43:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.9088 (1.0721)	loss 0.6558 (0.5956)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:44:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8869 (1.0620)	loss 0.4963 (0.6132)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-07 18:44:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.3125 (1.0340)	loss 0.5964 (0.6032)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:44:14 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 1 training takes 0:00:35
[2024-12-07 18:44:16 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:44:16 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:44:16 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:44:16 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:44:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2793 (1.2793)	loss 0.6287 (0.6287)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:44:28 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 1.3101 (1.0833)	loss 0.6014 (0.5901)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:44:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.9099 (1.0018)	loss 0.4911 (0.5897)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:44:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.3103 (1.0406)	loss 0.5728 (0.5939)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:44:52 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 2 training takes 0:00:36
[2024-12-07 18:44:54 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:44:54 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:44:54 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:44:54 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:44:57 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][0/34]	eta 0:01:34 lr 0.000000	 wd 0.0000	time 2.7695 (2.7695)	loss 0.5453 (0.5453)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:45:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][10/34]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 1.3204 (1.5607)	loss 0.6210 (0.5847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:45:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][20/34]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.9166 (1.2859)	loss 0.5220 (0.5796)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:45:32 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9059 (1.2149)	loss 0.6636 (0.5913)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:45:35 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 3 training takes 0:00:40
[2024-12-07 18:45:37 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:45:37 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:45:37 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:45:37 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:45:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3097 (1.3097)	loss 0.4789 (0.4789)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:45:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8948 (1.0929)	loss 0.5666 (0.5888)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:45:59 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 1.0038 (1.0718)	loss 0.6376 (0.5853)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:46:08 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8981 (1.0196)	loss 0.6208 (0.5826)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:46:12 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 4 training takes 0:00:35
[2024-12-07 18:46:14 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:46:14 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:46:14 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:46:14 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:46:15 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3046 (1.3046)	loss 0.5166 (0.5166)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:46:25 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 1.2938 (1.0255)	loss 0.5644 (0.6126)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:46:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8994 (1.0024)	loss 0.5703 (0.5909)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:46:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8758 (1.0203)	loss 0.5598 (0.5766)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:46:48 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 5 training takes 0:00:34
[2024-12-07 18:46:50 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:46:50 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:46:50 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:46:50 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:46:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2890 (1.2890)	loss 0.3960 (0.3960)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-07 18:47:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8913 (1.0900)	loss 0.5628 (0.5648)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:47:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 1.2715 (1.0658)	loss 0.5171 (0.5693)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:47:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8867 (1.0149)	loss 0.7122 (0.5852)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 18:47:25 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 6 training takes 0:00:34
[2024-12-07 18:47:27 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:47:27 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:47:27 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:47:27 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:47:29 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][0/34]	eta 0:00:47 lr 0.000000	 wd 0.0000	time 1.4039 (1.4039)	loss 0.6874 (0.6874)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:47:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 1.0215 (0.9724)	loss 0.4392 (0.5873)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:47:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.9082 (1.0021)	loss 0.7223 (0.6043)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 18:47:59 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8974 (1.0352)	loss 0.6241 (0.5895)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:48:02 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 7 training takes 0:00:34
[2024-12-07 18:48:04 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:48:04 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:48:04 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:48:04 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:48:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2713 (1.2713)	loss 0.4533 (0.4533)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:48:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.9096 (1.0956)	loss 0.5177 (0.6001)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:48:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 1.2976 (1.0396)	loss 0.5729 (0.5979)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:48:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.2922 (1.0668)	loss 0.5049 (0.5794)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:48:41 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 8 training takes 0:00:36
[2024-12-07 18:48:43 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:48:43 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:48:43 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:48:43 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:48:45 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][0/34]	eta 0:00:48 lr 0.000000	 wd 0.0000	time 1.4291 (1.4291)	loss 0.5013 (0.5013)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:48:54 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 0.9724 (0.9673)	loss 0.6760 (0.5822)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:49:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8749 (1.0023)	loss 0.6116 (0.5883)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:49:15 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9082 (1.0181)	loss 0.7381 (0.5832)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 18:49:17 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 9 training takes 0:00:34
[2024-12-07 18:49:19 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:49:19 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:49:19 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:49:19 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:49:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][0/34]	eta 0:00:46 lr 0.000000	 wd 0.0000	time 1.3579 (1.3579)	loss 0.8184 (0.8184)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 18:49:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.9036 (1.0873)	loss 0.4916 (0.5508)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:49:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 1.3200 (1.0395)	loss 0.6326 (0.5711)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:49:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8939 (1.0211)	loss 0.5009 (0.5728)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:49:54 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 10 training takes 0:00:34
[2024-12-07 18:49:56 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:49:56 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:49:56 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:49:56 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:49:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][0/34]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.8035 (1.8035)	loss 0.4402 (0.4402)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:50:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 0.8991 (1.0298)	loss 0.4533 (0.5576)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:50:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8900 (1.0449)	loss 0.6006 (0.5641)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:50:28 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.3024 (1.0377)	loss 0.6727 (0.5857)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:50:31 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 11 training takes 0:00:35
[2024-12-07 18:50:33 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:50:33 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:50:33 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:50:33 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:50:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3119 (1.3119)	loss 0.6302 (0.6302)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:50:45 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 1.1463 (1.0907)	loss 0.6778 (0.6282)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:50:54 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8862 (0.9943)	loss 0.5110 (0.5926)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:51:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8882 (1.0113)	loss 0.4457 (0.5793)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:51:07 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 12 training takes 0:00:34
[2024-12-07 18:51:09 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:51:09 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:51:09 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:51:09 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:51:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][0/34]	eta 0:00:51 lr 0.000000	 wd 0.0000	time 1.5082 (1.5082)	loss 0.6762 (0.6762)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:51:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8928 (1.0909)	loss 0.4400 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:51:32 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.8859 (1.0753)	loss 0.4976 (0.5978)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:51:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.2239 (1.0296)	loss 0.5401 (0.5892)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:51:45 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 13 training takes 0:00:35
[2024-12-07 18:51:47 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:51:47 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:51:47 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:51:47 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:51:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.2952 (1.2952)	loss 0.5712 (0.5712)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:51:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 1.2630 (1.0336)	loss 0.5087 (0.5872)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:52:08 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8933 (0.9964)	loss 0.6844 (0.6044)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:52:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9207 (1.0202)	loss 0.6279 (0.5926)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:52:22 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 14 training takes 0:00:35
[2024-12-07 18:52:24 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:52:24 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:52:24 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:52:24 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:52:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][0/34]	eta 0:00:54 lr 0.000000	 wd 0.0000	time 1.6030 (1.6030)	loss 0.6209 (0.6209)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:52:36 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.8871 (1.0832)	loss 0.7594 (0.6096)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 18:52:47 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.8777 (1.0733)	loss 0.5637 (0.5921)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:52:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.2626 (1.0306)	loss 0.6191 (0.5785)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:53:00 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 15 training takes 0:00:35
[2024-12-07 18:53:02 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:53:02 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:53:02 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:53:02 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:53:03 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3220 (1.3220)	loss 0.4942 (0.4942)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:53:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 1.3064 (1.0518)	loss 0.6331 (0.5636)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:53:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.9364 (1.0094)	loss 0.6306 (0.5823)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:53:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9245 (1.0243)	loss 0.4304 (0.5869)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:53:36 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 16 training takes 0:00:34
[2024-12-07 18:53:38 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:53:38 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:53:38 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:53:38 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:53:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.2991 (1.2991)	loss 0.6311 (0.6311)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:53:50 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.9062 (1.0893)	loss 0.5567 (0.5989)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:54:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 1.1265 (1.0647)	loss 0.4857 (0.5778)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:54:10 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8893 (1.0117)	loss 0.5682 (0.5707)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:54:13 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 17 training takes 0:00:35
[2024-12-07 18:54:15 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:54:15 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:54:15 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:54:15 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:54:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3226 (1.3226)	loss 0.6414 (0.6414)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:54:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 1.3011 (1.0358)	loss 0.6799 (0.5877)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:54:36 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.9070 (1.0037)	loss 0.4992 (0.5510)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:54:47 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8975 (1.0203)	loss 0.6117 (0.5772)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:54:50 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 18 training takes 0:00:34
[2024-12-07 18:54:51 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:54:51 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:54:51 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:54:51 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:54:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2897 (1.2897)	loss 0.6619 (0.6619)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:55:03 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8977 (1.0885)	loss 0.6090 (0.6194)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:55:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 1.2967 (1.0766)	loss 0.6169 (0.5878)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:55:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8992 (1.0192)	loss 0.6256 (0.5809)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:55:27 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 19 training takes 0:00:35
[2024-12-07 18:55:29 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:55:29 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:55:29 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:55:29 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:55:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2906 (1.2906)	loss 0.4327 (0.4327)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:55:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 1.2845 (0.9860)	loss 0.6040 (0.5285)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:55:50 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.9104 (1.0011)	loss 0.4454 (0.5552)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:56:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8908 (1.0194)	loss 0.5701 (0.5768)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:56:03 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 20 training takes 0:00:34
[2024-12-07 18:56:05 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:56:05 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:56:05 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:56:05 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:56:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][0/34]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.8164 (1.8164)	loss 0.8028 (0.8028)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 18:56:19 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][10/34]	eta 0:00:29 lr 0.000000	 wd 0.0000	time 0.8854 (1.2261)	loss 0.4887 (0.5967)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:56:29 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 1.3058 (1.1259)	loss 0.7069 (0.6142)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:56:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9035 (1.0698)	loss 0.5564 (0.5771)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:56:41 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 21 training takes 0:00:36
[2024-12-07 18:56:44 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:56:44 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:56:44 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:56:44 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:56:45 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][0/34]	eta 0:00:47 lr 0.000000	 wd 0.0000	time 1.4014 (1.4014)	loss 0.5134 (0.5134)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:56:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 0.9638 (0.9687)	loss 0.4383 (0.5395)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:57:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8707 (1.0053)	loss 0.5537 (0.5720)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:57:15 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8714 (1.0190)	loss 0.5673 (0.5712)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:57:18 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 22 training takes 0:00:34
[2024-12-07 18:57:20 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:57:20 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:57:20 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:57:20 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:57:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2898 (1.2898)	loss 0.7431 (0.7431)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 18:57:32 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8963 (1.0874)	loss 0.7504 (0.6207)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 18:57:42 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 1.3084 (1.0271)	loss 0.5125 (0.6019)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:57:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8812 (1.0195)	loss 0.5048 (0.5773)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 18:57:54 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 23 training takes 0:00:34
[2024-12-07 18:57:57 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:57:57 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:57:57 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:57:57 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:57:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][0/34]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.8036 (1.8036)	loss 0.4250 (0.4250)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:58:08 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 0.8790 (1.0277)	loss 0.6087 (0.5289)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:58:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8892 (1.0252)	loss 0.5523 (0.5655)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:58:28 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.2742 (1.0249)	loss 0.7266 (0.5706)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 18:58:31 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 24 training takes 0:00:34
[2024-12-07 18:58:33 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:58:33 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:58:33 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:58:33 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:58:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2791 (1.2791)	loss 0.5644 (0.5644)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:58:45 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.9105 (1.0983)	loss 0.3756 (0.5634)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-07 18:58:54 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.9033 (1.0034)	loss 0.7085 (0.5827)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:59:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8983 (1.0209)	loss 0.5745 (0.5786)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:59:08 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 25 training takes 0:00:34
[2024-12-07 18:59:09 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:59:09 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:59:09 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:59:09 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:59:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][0/34]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.7060 (1.7060)	loss 0.5560 (0.5560)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 18:59:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.8917 (1.0727)	loss 0.6218 (0.5847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 18:59:32 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8835 (1.0647)	loss 0.6842 (0.5984)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 18:59:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.3097 (1.0295)	loss 0.4310 (0.5837)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 18:59:45 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 26 training takes 0:00:35
[2024-12-07 18:59:47 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 18:59:47 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 18:59:47 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 18:59:47 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 18:59:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3192 (1.3192)	loss 0.4454 (0.4454)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 19:00:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][10/34]	eta 0:00:31 lr 0.000000	 wd 0.0000	time 0.9851 (1.3141)	loss 0.4838 (0.5239)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 19:00:10 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.8833 (1.1230)	loss 0.5619 (0.5433)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 19:00:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8897 (1.1043)	loss 0.5058 (0.5646)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 19:00:24 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 27 training takes 0:00:37
[2024-12-07 19:00:26 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:00:26 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:00:26 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:00:26 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:00:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][0/34]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 1.7815 (1.7815)	loss 0.6010 (0.6010)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 19:00:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8853 (1.0886)	loss 0.5502 (0.5932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 19:00:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.9014 (1.0730)	loss 0.5663 (0.5782)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 19:00:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.3067 (1.0318)	loss 0.5057 (0.5737)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 19:01:01 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 28 training takes 0:00:35
[2024-12-07 19:01:03 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:01:03 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:01:03 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:01:03 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:01:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][0/34]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 1.3253 (1.3253)	loss 0.4377 (0.4377)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 19:01:15 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 1.2937 (1.0531)	loss 0.6069 (0.5390)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 19:01:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8726 (0.9976)	loss 0.6853 (0.5688)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 19:01:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8920 (1.0153)	loss 0.3625 (0.5754)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-07 19:01:38 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 29 training takes 0:00:34
[2024-12-07 19:01:39 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:01:39 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:01:39 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:01:39 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:01:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.2995 (1.2995)	loss 0.4396 (0.4396)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 19:01:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8817 (1.0851)	loss 0.7483 (0.5665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 19:02:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 1.2024 (1.0649)	loss 0.6442 (0.5698)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 19:02:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8644 (1.0074)	loss 0.5025 (0.5838)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 19:02:14 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 30 training takes 0:00:34
[2024-12-07 19:02:17 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:02:17 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:02:17 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:02:17 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:02:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2766 (1.2766)	loss 0.6609 (0.6609)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 19:02:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 1.0726 (0.9588)	loss 0.4313 (0.5680)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 19:02:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8958 (0.9851)	loss 0.5494 (0.5527)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 19:02:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8955 (1.0075)	loss 0.7762 (0.5770)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 19:02:51 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 31 training takes 0:00:33
[2024-12-07 19:02:52 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:02:52 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:02:52 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:02:52 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:02:54 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.2950 (1.2950)	loss 0.5101 (0.5101)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 19:03:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.8889 (1.0832)	loss 0.4505 (0.5892)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 19:03:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 1.2854 (1.0346)	loss 0.4229 (0.5724)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 19:03:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8842 (1.0160)	loss 0.6699 (0.5776)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 19:03:27 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 32 training takes 0:00:34
[2024-12-07 19:03:29 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:03:29 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:03:29 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:03:29 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:03:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][0/34]	eta 0:01:03 lr 0.000000	 wd 0.0000	time 1.8582 (1.8582)	loss 0.6160 (0.6160)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 19:03:42 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][10/34]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 0.8866 (1.1691)	loss 0.4947 (0.5854)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 19:03:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.8913 (1.1157)	loss 0.3774 (0.5673)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-07 19:04:03 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.1736 (1.0946)	loss 0.8267 (0.5809)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 19:04:06 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 33 training takes 0:00:36
[2024-12-07 19:04:08 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:04:08 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:04:08 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:04:08 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:04:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][0/34]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 1.3258 (1.3258)	loss 0.4324 (0.4324)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 19:04:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.9159 (1.0948)	loss 0.7321 (0.5791)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 19:04:29 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 1.2539 (1.0198)	loss 0.6432 (0.5742)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 19:04:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9056 (1.0198)	loss 0.5036 (0.5730)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 19:04:42 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 34 training takes 0:00:34
[2024-12-07 19:04:44 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:04:44 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:04:44 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:04:44 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:04:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][0/34]	eta 0:01:02 lr 0.000000	 wd 0.0000	time 1.8245 (1.8245)	loss 0.6232 (0.6232)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 19:04:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.8904 (1.0540)	loss 0.6802 (0.5847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 19:05:06 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.9111 (1.0467)	loss 0.6937 (0.5760)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 19:05:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.2755 (1.0339)	loss 0.6232 (0.5723)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 19:05:19 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 35 training takes 0:00:35
[2024-12-07 19:05:21 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:05:21 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:05:21 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:05:21 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:05:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [36/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2848 (1.2848)	loss 0.5474 (0.5474)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 19:05:33 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [36/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 1.1231 (1.0835)	loss 0.6240 (0.6374)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 19:05:42 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [36/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.9104 (0.9988)	loss 0.3738 (0.5724)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-07 19:05:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [36/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9177 (1.0183)	loss 0.4867 (0.5661)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 19:05:55 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 36 training takes 0:00:34
[2024-12-07 19:05:57 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:05:57 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:05:57 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:05:57 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:05:59 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [37/70][0/34]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.6826 (1.6826)	loss 0.6729 (0.6729)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 19:06:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [37/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8899 (1.0886)	loss 0.6053 (0.5782)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 19:06:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [37/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.8968 (1.0751)	loss 0.6917 (0.5792)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 19:06:29 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [37/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.2957 (1.0347)	loss 0.5639 (0.5711)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 19:06:33 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 37 training takes 0:00:35
[2024-12-07 19:06:35 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:06:35 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:06:35 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:06:35 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:06:36 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [38/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2699 (1.2699)	loss 0.6048 (0.6048)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 19:06:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [38/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 1.3242 (1.0512)	loss 0.4951 (0.5677)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 19:06:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [38/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8892 (1.0014)	loss 0.6417 (0.5853)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 19:07:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [38/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8735 (1.0197)	loss 0.5120 (0.5755)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 19:07:09 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 38 training takes 0:00:34
[2024-12-07 19:07:11 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:07:11 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:07:11 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:07:11 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:07:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [39/70][0/34]	eta 0:00:46 lr 0.000000	 wd 0.0000	time 1.3666 (1.3666)	loss 0.6251 (0.6251)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 19:07:25 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [39/70][10/34]	eta 0:00:30 lr 0.000000	 wd 0.0000	time 0.8984 (1.2585)	loss 0.6388 (0.5436)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 19:07:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [39/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 1.2814 (1.1331)	loss 0.5727 (0.5628)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 19:07:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [39/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8937 (1.0766)	loss 0.4557 (0.5777)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 19:07:47 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 39 training takes 0:00:36
[2024-12-07 19:07:50 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:07:50 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:07:50 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:07:50 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:07:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [40/70][0/34]	eta 0:00:48 lr 0.000000	 wd 0.0000	time 1.4210 (1.4210)	loss 0.4629 (0.4629)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 19:08:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [40/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 0.9342 (0.9622)	loss 0.5358 (0.5700)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 19:08:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [40/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8950 (1.0015)	loss 0.3674 (0.5575)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-07 19:08:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [40/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9386 (1.0197)	loss 0.5938 (0.5704)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 19:08:24 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 40 training takes 0:00:34
[2024-12-07 19:08:26 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:08:26 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:08:26 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:08:26 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:08:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [41/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.2963 (1.2963)	loss 0.5664 (0.5664)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 19:08:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [41/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.8953 (1.0744)	loss 0.6342 (0.5763)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 19:08:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [41/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 1.3239 (1.0294)	loss 0.5445 (0.5673)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 19:08:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [41/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8971 (1.0171)	loss 0.5389 (0.5692)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 19:09:00 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 41 training takes 0:00:34
[2024-12-07 19:09:03 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:09:03 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:09:03 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:09:03 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:09:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [42/70][0/34]	eta 0:01:02 lr 0.000000	 wd 0.0000	time 1.8269 (1.8269)	loss 0.5062 (0.5062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 19:09:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [42/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 0.8823 (1.0306)	loss 0.6974 (0.5993)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 19:09:25 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [42/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8868 (1.0401)	loss 0.6787 (0.5757)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 19:09:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [42/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.3296 (1.0340)	loss 0.5457 (0.5760)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 19:09:38 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 42 training takes 0:00:35
[2024-12-07 19:09:40 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:09:40 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:09:40 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:09:40 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:09:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [43/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2820 (1.2820)	loss 0.4641 (0.4641)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 19:09:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [43/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 1.0699 (1.0800)	loss 0.6958 (0.5465)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 19:10:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [43/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.9031 (0.9971)	loss 0.6831 (0.5629)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 19:10:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [43/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9106 (1.0141)	loss 0.5362 (0.5674)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 19:10:14 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 43 training takes 0:00:34
[2024-12-07 19:10:16 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:10:16 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:10:16 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:10:16 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:10:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [44/70][0/34]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.6930 (1.6930)	loss 0.6234 (0.6234)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 19:10:28 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [44/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8910 (1.0886)	loss 0.6202 (0.5586)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 19:10:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [44/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.9106 (1.0737)	loss 0.4321 (0.5654)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 19:10:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [44/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.2901 (1.0351)	loss 0.5409 (0.5610)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 19:10:52 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 44 training takes 0:00:35
[2024-12-07 19:10:54 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:10:54 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:10:54 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:10:54 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:10:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [45/70][0/34]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.8019 (1.8019)	loss 0.7267 (0.7267)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 19:11:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [45/70][10/34]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.9567 (1.1449)	loss 0.5606 (0.5419)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 19:11:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [45/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8790 (1.0278)	loss 0.7247 (0.5715)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 19:11:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [45/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8902 (1.0349)	loss 0.7306 (0.5692)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-07 19:11:29 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 45 training takes 0:00:34
[2024-12-07 19:11:31 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:11:31 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:11:31 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:11:31 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:11:33 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [46/70][0/34]	eta 0:00:55 lr 0.000000	 wd 0.0000	time 1.6304 (1.6304)	loss 0.5702 (0.5702)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 19:11:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [46/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8910 (1.0866)	loss 0.6626 (0.5718)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 19:11:54 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [46/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.8971 (1.0785)	loss 0.6921 (0.5740)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 19:12:03 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [46/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.2828 (1.0373)	loss 0.4399 (0.5620)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 19:12:07 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 46 training takes 0:00:36
[2024-12-07 19:12:09 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:12:09 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:12:09 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:12:09 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:12:10 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [47/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3121 (1.3121)	loss 0.5536 (0.5536)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 19:12:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [47/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 1.3199 (1.0529)	loss 0.3077 (0.5353)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 1.000
[2024-12-07 19:12:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [47/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8876 (0.9997)	loss 0.6004 (0.5742)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 19:12:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [47/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9318 (1.0166)	loss 0.6472 (0.5775)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 19:12:43 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 47 training takes 0:00:34
[2024-12-07 19:12:45 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:12:45 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:12:45 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:12:45 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:12:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [48/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3098 (1.3098)	loss 0.6066 (0.6066)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 19:12:57 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [48/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.9084 (1.0947)	loss 0.5516 (0.6210)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 19:13:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [48/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.9851 (1.0741)	loss 0.4517 (0.5859)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 19:13:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [48/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8986 (1.0175)	loss 0.4153 (0.5778)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 19:13:20 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 48 training takes 0:00:35
[2024-12-07 19:13:22 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:13:22 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:13:22 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:13:22 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:13:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [49/70][0/34]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 1.3473 (1.3473)	loss 0.5475 (0.5475)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 19:13:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [49/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 1.2603 (1.0276)	loss 0.5805 (0.6000)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 19:13:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [49/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8857 (0.9983)	loss 0.5438 (0.5780)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-07 19:13:54 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [49/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9311 (1.0199)	loss 0.3577 (0.5785)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-07 19:13:57 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 49 training takes 0:00:34
[2024-12-07 19:13:58 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:13:58 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:13:58 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:13:58 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:14:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [50/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2862 (1.2862)	loss 0.6065 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 19:14:10 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [50/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8909 (1.0861)	loss 0.3808 (0.5411)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-07 19:14:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [50/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 1.3083 (1.0680)	loss 0.4918 (0.5600)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 19:14:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [50/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.0707 (1.0210)	loss 0.7943 (0.5806)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 19:14:35 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 50 training takes 0:00:36
[2024-12-07 19:14:37 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:14:37 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:14:37 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:14:37 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:14:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [51/70][0/34]	eta 0:00:48 lr 0.000000	 wd 0.0000	time 1.4218 (1.4218)	loss 0.7727 (0.7727)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-07 19:14:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [51/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 0.9970 (0.9683)	loss 0.6112 (0.5828)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-07 19:14:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [51/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8922 (1.0074)	loss 0.6523 (0.5785)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-07 19:15:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [51/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8972 (1.0247)	loss 0.4977 (0.5756)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-07 19:15:12 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 51 training takes 0:00:34
[2024-12-07 19:15:14 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-07 19:15:14 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-07 19:15:14 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-07 19:15:14 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-07 19:15:15 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [52/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3137 (1.3137)	loss 0.4144 (0.4144)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-07 19:15:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [52/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.9159 (1.0959)	loss 0.6092 (0.5847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:23:29 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-09 18:23:29 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-09 18:25:47 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-09 18:25:47 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-09 18:34:16 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-09 18:34:16 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-09 18:34:16 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-09 18:34:16 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-09 18:34:16 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-09 18:34:16 swin_tiny_patch4_window7_224] (main.py 160): INFO Start training
[2024-12-09 18:34:19 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][0/34]	eta 0:01:35 lr 0.000000	 wd 0.0000	time 2.8015 (2.8015)	loss 0.6010 (0.6010)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:34:28 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8199 (1.0911)	loss 0.5693 (0.6022)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:34:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8070 (1.0334)	loss 0.5580 (0.6055)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:34:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.9210 (0.9671)	loss 0.6858 (0.6129)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 18:34:50 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 0 training takes 0:00:33
[2024-12-09 18:34:52 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:34:52 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:34:52 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:34:52 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:34:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][0/34]	eta 0:00:51 lr 0.000000	 wd 0.0000	time 1.5017 (1.5017)	loss 0.5894 (0.5894)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:35:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][10/34]	eta 0:00:22 lr 0.000000	 wd 0.0000	time 1.1746 (0.9544)	loss 0.6558 (0.5956)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 18:35:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8285 (0.9380)	loss 0.4963 (0.6132)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-09 18:35:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 1.0400 (0.9565)	loss 0.5964 (0.6032)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:35:24 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 1 training takes 0:00:32
[2024-12-09 18:35:26 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:35:26 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:35:26 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:35:26 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:35:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][0/34]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.1843 (1.1843)	loss 0.6287 (0.6287)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:35:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][10/34]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.9382 (1.0610)	loss 0.6014 (0.5901)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:35:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 1.4539 (0.9765)	loss 0.4911 (0.5897)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 18:35:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8183 (0.9829)	loss 0.5728 (0.5939)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:35:59 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 2 training takes 0:00:32
[2024-12-09 18:36:00 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:36:00 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:36:00 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:36:00 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:36:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][0/34]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 1.1590 (1.1590)	loss 0.5453 (0.5453)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:36:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8088 (1.1218)	loss 0.6210 (0.5847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:36:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 1.1901 (1.0339)	loss 0.5220 (0.5796)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:36:36 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 2.4426 (1.1684)	loss 0.6636 (0.5913)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 18:36:43 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 3 training takes 0:00:42
[2024-12-09 18:36:46 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:36:46 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:36:46 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:36:46 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:36:47 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2834 (1.2834)	loss 0.4789 (0.4789)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 18:36:57 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 0.8031 (1.0190)	loss 0.5666 (0.5888)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:37:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8514 (0.9218)	loss 0.6376 (0.5853)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:37:15 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8096 (0.9406)	loss 0.6208 (0.5826)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:37:18 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 4 training takes 0:00:31
[2024-12-09 18:37:19 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:37:19 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:37:19 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:37:19 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:37:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][0/34]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.1985 (1.1985)	loss 0.5166 (0.5166)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:37:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 0.8106 (1.0151)	loss 0.5644 (0.6126)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:37:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 1.1882 (0.9744)	loss 0.5703 (0.5909)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:37:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8168 (0.9427)	loss 0.5598 (0.5766)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:37:52 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 5 training takes 0:00:32
[2024-12-09 18:37:54 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:37:54 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:37:54 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:37:54 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:37:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][0/34]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.6787 (1.6787)	loss 0.3960 (0.3960)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-09 18:38:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][10/34]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.8050 (0.9058)	loss 0.5628 (0.5648)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:38:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8109 (0.9501)	loss 0.5171 (0.5693)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:38:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 1.1760 (0.9210)	loss 0.7122 (0.5852)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 18:38:27 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 6 training takes 0:00:32
[2024-12-09 18:38:28 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:38:28 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:38:28 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:38:28 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:38:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][0/34]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.1913 (1.1913)	loss 0.6874 (0.6874)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 18:38:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][10/34]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 1.2015 (0.9158)	loss 0.4392 (0.5873)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 18:38:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8343 (0.9280)	loss 0.7223 (0.6043)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 18:38:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 1.0868 (0.9453)	loss 0.6241 (0.5895)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:39:00 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 7 training takes 0:00:31
[2024-12-09 18:39:02 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:39:02 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:39:02 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:39:02 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:39:03 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][0/34]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.2023 (1.2023)	loss 0.4533 (0.4533)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 18:39:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 1.0888 (1.0307)	loss 0.5177 (0.6001)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:39:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8110 (0.9325)	loss 0.5729 (0.5979)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:39:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8068 (0.9433)	loss 0.5049 (0.5794)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:39:34 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 8 training takes 0:00:31
[2024-12-09 18:39:35 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:39:35 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:39:35 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:39:35 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:39:36 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][0/34]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.1808 (1.1808)	loss 0.5013 (0.5013)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:39:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 0.8169 (1.0047)	loss 0.6760 (0.5822)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 18:39:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 1.1647 (0.9472)	loss 0.6116 (0.5883)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:40:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.7931 (0.9363)	loss 0.7381 (0.5832)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 18:40:07 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 9 training takes 0:00:31
[2024-12-09 18:40:09 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:40:09 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:40:09 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:40:09 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:40:10 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][0/34]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.6818 (1.6818)	loss 0.8184 (0.8184)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 18:40:19 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 0.8105 (0.9906)	loss 0.4916 (0.5508)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:40:29 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.9481 (0.9854)	loss 0.6326 (0.5711)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:40:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8074 (0.9307)	loss 0.5009 (0.5728)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:40:41 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 10 training takes 0:00:32
[2024-12-09 18:40:43 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:40:43 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:40:43 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:40:43 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:40:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3190 (1.3190)	loss 0.4402 (0.4402)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 18:40:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][10/34]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.8090 (0.8717)	loss 0.4533 (0.5576)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 18:41:03 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8118 (0.9236)	loss 0.6006 (0.5641)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:41:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 1.1559 (0.9184)	loss 0.6727 (0.5857)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 18:41:15 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 11 training takes 0:00:31
[2024-12-09 18:41:17 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:41:17 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:41:17 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:41:17 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:41:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][0/34]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 1.1660 (1.1660)	loss 0.6302 (0.6302)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:41:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][10/34]	eta 0:00:22 lr 0.000000	 wd 0.0000	time 1.1774 (0.9278)	loss 0.6778 (0.6282)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 18:41:36 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8185 (0.9194)	loss 0.5110 (0.5926)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:41:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8474 (0.9410)	loss 0.4457 (0.5793)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 18:41:48 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 12 training takes 0:00:31
[2024-12-09 18:41:50 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:41:50 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:41:50 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:41:50 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:41:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][0/34]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.1851 (1.1851)	loss 0.6762 (0.6762)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 18:42:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 0.9246 (1.0071)	loss 0.4400 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 18:42:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8634 (0.9170)	loss 0.4976 (0.5978)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:42:19 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8157 (0.9307)	loss 0.5401 (0.5892)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:42:21 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 13 training takes 0:00:31
[2024-12-09 18:42:23 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:42:23 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:42:23 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:42:23 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:42:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][0/34]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.2001 (1.2001)	loss 0.5712 (0.5712)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:42:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 0.8259 (1.0017)	loss 0.5087 (0.5872)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:42:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 1.1810 (0.9696)	loss 0.6844 (0.6044)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 18:42:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8356 (0.9390)	loss 0.6279 (0.5926)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:42:55 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 14 training takes 0:00:31
[2024-12-09 18:42:57 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:42:57 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:42:57 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:42:57 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:42:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][0/34]	eta 0:00:56 lr 0.000000	 wd 0.0000	time 1.6552 (1.6552)	loss 0.6209 (0.6209)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:43:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 0.8009 (0.9659)	loss 0.7594 (0.6096)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 18:43:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8059 (0.9775)	loss 0.5637 (0.5921)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:43:25 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8050 (0.9274)	loss 0.6191 (0.5785)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:43:29 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 15 training takes 0:00:32
[2024-12-09 18:43:31 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:43:31 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:43:31 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:43:31 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:43:32 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][0/34]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 1.1741 (1.1741)	loss 0.4942 (0.4942)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:43:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][10/34]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 1.0733 (0.8899)	loss 0.6331 (0.5636)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:43:50 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8108 (0.9225)	loss 0.6306 (0.5823)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:44:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 1.1730 (0.9351)	loss 0.4304 (0.5869)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 18:44:03 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 16 training takes 0:00:31
[2024-12-09 18:44:04 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:44:04 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:44:04 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:44:04 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:44:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][0/34]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.1996 (1.1996)	loss 0.6311 (0.6311)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:44:15 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 1.1887 (1.0008)	loss 0.5567 (0.5989)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:44:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8301 (0.9258)	loss 0.4857 (0.5778)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:44:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8638 (0.9482)	loss 0.5682 (0.5707)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:44:36 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 17 training takes 0:00:31
[2024-12-09 18:44:38 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:44:38 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:44:38 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:44:38 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:44:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][0/34]	eta 0:00:42 lr 0.000000	 wd 0.0000	time 1.2362 (1.2362)	loss 0.6414 (0.6414)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:44:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 0.8171 (1.0198)	loss 0.6799 (0.5877)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 18:44:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 1.1564 (0.9435)	loss 0.4992 (0.5510)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:45:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8262 (0.9430)	loss 0.6117 (0.5772)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:45:10 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 18 training takes 0:00:31
[2024-12-09 18:45:11 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:45:11 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:45:11 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:45:11 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:45:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][0/34]	eta 0:00:52 lr 0.000000	 wd 0.0000	time 1.5441 (1.5441)	loss 0.6619 (0.6619)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 18:45:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 0.8086 (1.0123)	loss 0.6090 (0.6194)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:45:32 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 1.1897 (0.9924)	loss 0.6169 (0.5878)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:45:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8074 (0.9385)	loss 0.6256 (0.5809)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:45:43 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 19 training takes 0:00:31
[2024-12-09 18:45:46 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:45:46 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:45:46 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:45:46 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:45:47 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][0/34]	eta 0:00:54 lr 0.000000	 wd 0.0000	time 1.5931 (1.5931)	loss 0.4327 (0.4327)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 18:45:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][10/34]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.8125 (0.8984)	loss 0.6040 (0.5285)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:46:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8164 (0.9398)	loss 0.4454 (0.5552)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 18:46:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 1.1951 (0.9227)	loss 0.5701 (0.5768)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:46:18 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 20 training takes 0:00:32
[2024-12-09 18:46:19 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:46:19 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:46:19 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:46:19 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:46:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][0/34]	eta 0:00:41 lr 0.000000	 wd 0.0000	time 1.2191 (1.2191)	loss 0.8028 (0.8028)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 18:46:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][10/34]	eta 0:00:22 lr 0.000000	 wd 0.0000	time 1.1900 (0.9325)	loss 0.4887 (0.5967)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:46:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8128 (0.9298)	loss 0.7069 (0.6142)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 18:46:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 1.0176 (0.9470)	loss 0.5564 (0.5771)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:46:51 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 21 training takes 0:00:31
[2024-12-09 18:46:53 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:46:53 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:46:53 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:46:53 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:46:54 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][0/34]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.2016 (1.2016)	loss 0.5134 (0.5134)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:47:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 0.8523 (0.9967)	loss 0.4383 (0.5395)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 18:47:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8168 (0.9092)	loss 0.5537 (0.5720)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:47:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8135 (0.9283)	loss 0.5673 (0.5712)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:47:24 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 22 training takes 0:00:31
[2024-12-09 18:47:26 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:47:26 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:47:26 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:47:26 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:47:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][0/34]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 1.1600 (1.1600)	loss 0.7431 (0.7431)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 18:47:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 0.8177 (1.0048)	loss 0.7504 (0.6207)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 18:47:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 1.1546 (0.9523)	loss 0.5125 (0.6019)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:47:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8321 (0.9330)	loss 0.5048 (0.5773)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:47:57 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 23 training takes 0:00:31
[2024-12-09 18:47:59 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:47:59 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:47:59 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:47:59 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:48:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][0/34]	eta 0:00:55 lr 0.000000	 wd 0.0000	time 1.6450 (1.6450)	loss 0.4250 (0.4250)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 18:48:10 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 0.8070 (0.9805)	loss 0.6087 (0.5289)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:48:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8294 (0.9843)	loss 0.5523 (0.5655)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:48:28 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8121 (0.9292)	loss 0.7266 (0.5706)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 18:48:31 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 24 training takes 0:00:32
[2024-12-09 18:48:34 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:48:34 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:48:34 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:48:34 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:48:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][0/34]	eta 0:00:42 lr 0.000000	 wd 0.0000	time 1.2617 (1.2617)	loss 0.5644 (0.5644)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:48:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][10/34]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.8210 (0.8813)	loss 0.3756 (0.5634)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-09 18:48:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8136 (0.9281)	loss 0.7085 (0.5827)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 18:49:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 1.1873 (0.9254)	loss 0.5745 (0.5786)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:49:05 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 25 training takes 0:00:31
[2024-12-09 18:49:07 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:49:07 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:49:07 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:49:07 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:49:08 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][0/34]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.1826 (1.1826)	loss 0.5560 (0.5560)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:49:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 1.1883 (0.9631)	loss 0.6218 (0.5847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:49:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8146 (0.9210)	loss 0.6842 (0.5984)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 18:49:36 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8061 (0.9391)	loss 0.4310 (0.5837)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 18:49:39 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 26 training takes 0:00:31
[2024-12-09 18:49:40 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:49:40 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:49:40 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:49:40 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:49:42 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][0/34]	eta 0:00:42 lr 0.000000	 wd 0.0000	time 1.2503 (1.2503)	loss 0.4454 (0.4454)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 18:49:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 0.8443 (1.0156)	loss 0.4838 (0.5239)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:50:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8134 (0.9200)	loss 0.5619 (0.5433)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:50:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8258 (0.9393)	loss 0.5058 (0.5646)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:50:12 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 27 training takes 0:00:31
[2024-12-09 18:50:14 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:50:14 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:50:14 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:50:14 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:50:15 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][0/34]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.1835 (1.1835)	loss 0.6010 (0.6010)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:50:25 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 0.8094 (1.0084)	loss 0.5502 (0.5932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:50:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 1.1861 (0.9587)	loss 0.5663 (0.5782)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:50:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8386 (0.9352)	loss 0.5057 (0.5737)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:50:45 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 28 training takes 0:00:31
[2024-12-09 18:50:47 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:50:47 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:50:47 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:50:47 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:50:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][0/34]	eta 0:00:56 lr 0.000000	 wd 0.0000	time 1.6677 (1.6677)	loss 0.4377 (0.4377)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 18:50:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 0.8109 (0.9693)	loss 0.6069 (0.5390)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:51:08 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.7903 (0.9726)	loss 0.6853 (0.5688)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 18:51:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8193 (0.9221)	loss 0.3625 (0.5754)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-09 18:51:19 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 29 training takes 0:00:31
[2024-12-09 18:51:21 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:51:21 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:51:21 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:51:21 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:51:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][0/34]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 1.1732 (1.1732)	loss 0.4396 (0.4396)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 18:51:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][10/34]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.7979 (0.8542)	loss 0.7483 (0.5665)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 18:51:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8095 (0.9116)	loss 0.6442 (0.5698)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 18:51:50 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 1.1831 (0.9140)	loss 0.5025 (0.5838)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:51:53 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 30 training takes 0:00:31
[2024-12-09 18:51:54 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:51:54 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:51:54 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:51:54 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:51:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][0/34]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.1805 (1.1805)	loss 0.6609 (0.6609)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 18:52:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 1.1778 (0.9630)	loss 0.4313 (0.5680)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 18:52:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8194 (0.9216)	loss 0.5494 (0.5527)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:52:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8066 (0.9406)	loss 0.7762 (0.5770)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 18:52:26 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 31 training takes 0:00:31
[2024-12-09 18:52:28 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:52:28 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:52:28 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:52:28 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:52:29 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][0/34]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.1986 (1.1986)	loss 0.5101 (0.5101)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:52:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 0.8211 (1.0114)	loss 0.4505 (0.5892)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 18:52:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 1.1134 (0.9705)	loss 0.4229 (0.5724)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 18:52:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8063 (0.9651)	loss 0.6699 (0.5776)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 18:53:00 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 32 training takes 0:00:32
[2024-12-09 18:53:02 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:53:02 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:53:02 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:53:02 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:53:03 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][0/34]	eta 0:00:51 lr 0.000000	 wd 0.0000	time 1.5200 (1.5200)	loss 0.6160 (0.6160)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:53:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 0.8167 (1.0157)	loss 0.4947 (0.5854)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:53:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 1.0773 (0.9912)	loss 0.3774 (0.5673)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-09 18:53:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8120 (0.9348)	loss 0.8267 (0.5809)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 18:53:34 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 33 training takes 0:00:31
[2024-12-09 18:53:36 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:53:36 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:53:36 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:53:36 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:53:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][0/34]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 1.3240 (1.3240)	loss 0.4324 (0.4324)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 18:53:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][10/34]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.8288 (0.8780)	loss 0.7321 (0.5791)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 18:53:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8084 (0.9289)	loss 0.6432 (0.5742)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 18:54:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 1.1654 (0.9173)	loss 0.5036 (0.5730)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:54:08 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 34 training takes 0:00:31
[2024-12-09 18:54:09 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:54:09 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:54:09 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:54:09 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:54:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][0/34]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.1899 (1.1899)	loss 0.6232 (0.6232)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:54:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][10/34]	eta 0:00:22 lr 0.000000	 wd 0.0000	time 1.2094 (0.9357)	loss 0.6802 (0.5847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 18:54:29 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8043 (0.9103)	loss 0.6937 (0.5760)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 18:54:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8362 (0.9351)	loss 0.6232 (0.5723)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:54:41 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 35 training takes 0:00:31
[2024-12-09 18:54:43 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:54:43 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:54:43 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:54:43 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:54:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [36/70][0/34]	eta 0:00:42 lr 0.000000	 wd 0.0000	time 1.2594 (1.2594)	loss 0.5474 (0.5474)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:54:54 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [36/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 0.8219 (1.0224)	loss 0.6240 (0.6374)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:55:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [36/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8741 (0.9311)	loss 0.3738 (0.5724)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-09 18:55:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [36/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8303 (0.9454)	loss 0.4867 (0.5661)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:55:15 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 36 training takes 0:00:31
[2024-12-09 18:55:16 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:55:16 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:55:16 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:55:16 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:55:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [37/70][0/34]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3067 (1.3067)	loss 0.6729 (0.6729)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 18:55:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [37/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 0.8221 (1.0031)	loss 0.6053 (0.5782)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:55:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [37/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 1.1998 (0.9835)	loss 0.6917 (0.5792)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 18:55:45 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [37/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8248 (0.9345)	loss 0.5639 (0.5711)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:55:48 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 37 training takes 0:00:31
[2024-12-09 18:55:50 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:55:50 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:55:50 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:55:50 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:55:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [38/70][0/34]	eta 0:00:49 lr 0.000000	 wd 0.0000	time 1.4434 (1.4434)	loss 0.6048 (0.6048)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 18:56:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [38/70][10/34]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.8133 (0.8866)	loss 0.4951 (0.5677)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:58:01 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-09 18:58:01 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-09 18:58:01 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-09 18:58:01 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-09 18:58:01 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-09 18:58:01 swin_tiny_patch4_window7_224] (main.py 160): INFO Start training
[2024-12-09 18:58:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][0/34]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 1.3412 (1.3412)	loss 0.6010 (0.6010)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:58:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][10/34]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.8361 (0.8701)	loss 0.5693 (0.6022)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:58:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8087 (0.9214)	loss 0.5580 (0.6055)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 18:58:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 1.1600 (0.9246)	loss 0.6858 (0.6129)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 18:58:32 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 0 training takes 0:00:31
[2024-12-09 18:58:34 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 18:58:34 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 18:58:34 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 18:58:34 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 18:58:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][0/34]	eta 0:00:41 lr 0.000000	 wd 0.0000	time 1.2117 (1.2117)	loss 0.5894 (0.5894)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 18:58:50 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][10/34]	eta 0:00:34 lr 0.000000	 wd 0.0000	time 2.0500 (1.4167)	loss 0.6558 (0.5956)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:07:12 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-09 19:07:12 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-09 19:07:12 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-09 19:07:12 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-09 19:07:12 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-09 19:07:12 swin_tiny_patch4_window7_224] (main.py 160): INFO Start training
[2024-12-09 19:07:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][0/34]	eta 0:00:52 lr 0.000000	 wd 0.0000	time 1.5354 (1.5354)	loss 0.6010 (0.6010)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 19:07:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 0.8101 (0.9726)	loss 0.5693 (0.6022)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 19:07:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][20/34]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.8224 (1.0382)	loss 0.5580 (0.6055)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 19:07:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 1.2299 (0.9923)	loss 0.6858 (0.6129)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:07:46 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 0 training takes 0:00:33
[2024-12-09 19:07:48 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 19:07:48 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 19:07:48 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:07:48 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 19:07:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][0/34]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.1996 (1.1996)	loss 0.5894 (0.5894)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 19:08:12 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-09 19:08:12 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-09 19:08:12 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-09 19:08:13 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-09 19:08:13 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-09 19:08:13 swin_tiny_patch4_window7_224] (main.py 160): INFO Start training
[2024-12-09 19:08:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][0/34]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.1795 (1.1795)	loss 0.6010 (0.6010)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 19:08:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][10/34]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.8193 (0.8720)	loss 0.5693 (0.6022)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 19:08:32 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8124 (0.9128)	loss 0.5580 (0.6055)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 19:08:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 1.1778 (0.9289)	loss 0.6858 (0.6129)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:08:44 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 0 training takes 0:00:31
[2024-12-09 19:08:46 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 19:08:46 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 19:08:46 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:08:46 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 19:08:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][0/34]	eta 0:01:14 lr 0.000000	 wd 0.0000	time 2.1963 (2.1963)	loss 0.5894 (0.5894)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 19:09:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][10/34]	eta 0:00:31 lr 0.000000	 wd 0.0000	time 0.8240 (1.3088)	loss 0.6558 (0.5956)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:09:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 1.2377 (1.1215)	loss 0.4963 (0.6132)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-09 19:09:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.8253 (1.0914)	loss 0.5964 (0.6032)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 19:09:22 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 1 training takes 0:00:36
[2024-12-09 19:09:25 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 19:09:25 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 19:09:25 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:09:25 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 19:09:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2915 (1.2915)	loss 0.6287 (0.6287)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:09:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][10/34]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.8121 (0.8747)	loss 0.6014 (0.5901)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 19:09:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8215 (0.9054)	loss 0.4911 (0.5897)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 19:09:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 1.1820 (0.9184)	loss 0.5728 (0.5939)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 19:09:56 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 2 training takes 0:00:31
[2024-12-09 19:09:57 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 19:09:57 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 19:09:57 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:09:57 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 19:09:59 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][0/34]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 1.1600 (1.1600)	loss 0.5453 (0.5453)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 19:10:08 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 1.0108 (0.9812)	loss 0.6210 (0.5847)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:10:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8215 (0.9013)	loss 0.5220 (0.5796)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 19:10:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8176 (0.9170)	loss 0.6636 (0.5913)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:10:28 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 3 training takes 0:00:30
[2024-12-09 19:10:30 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 19:10:30 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 19:10:30 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:10:30 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 19:10:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][0/34]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.1939 (1.1939)	loss 0.4789 (0.4789)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 19:10:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 0.8279 (0.9865)	loss 0.5666 (0.5888)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 19:10:50 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 1.1879 (0.9562)	loss 0.6376 (0.5853)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:10:59 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8087 (0.9212)	loss 0.6208 (0.5826)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:11:01 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 4 training takes 0:00:31
[2024-12-09 19:11:04 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 19:11:04 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 19:11:04 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:11:04 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 19:11:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][0/34]	eta 0:00:46 lr 0.000000	 wd 0.0000	time 1.3810 (1.3810)	loss 0.5166 (0.5166)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 19:11:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][10/34]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.8132 (0.8807)	loss 0.5644 (0.6126)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 19:11:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8245 (0.9222)	loss 0.5703 (0.5909)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 19:11:32 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 1.1755 (0.9207)	loss 0.5598 (0.5766)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 19:11:35 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 5 training takes 0:00:31
[2024-12-09 19:11:37 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 19:11:37 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 19:11:37 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:11:37 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 19:11:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][0/34]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.1795 (1.1795)	loss 0.3960 (0.3960)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.938
[2024-12-09 19:11:47 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 1.0455 (0.9657)	loss 0.5628 (0.5648)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 19:11:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8218 (0.8992)	loss 0.5171 (0.5693)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 19:12:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8200 (0.9116)	loss 0.7122 (0.5852)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:12:08 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 6 training takes 0:00:30
[2024-12-09 19:12:09 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 19:12:09 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 19:12:09 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:12:09 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 19:12:10 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][0/34]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.1786 (1.1786)	loss 0.6874 (0.6874)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:12:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 0.8103 (0.9900)	loss 0.4392 (0.5873)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 19:12:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 1.3851 (0.9808)	loss 0.7223 (0.6043)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:12:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8125 (0.9286)	loss 0.6241 (0.5895)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:12:41 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 7 training takes 0:00:31
[2024-12-09 19:12:43 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 19:12:43 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 19:12:43 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:12:43 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 19:12:45 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][0/34]	eta 0:00:42 lr 0.000000	 wd 0.0000	time 1.2613 (1.2613)	loss 0.4533 (0.4533)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 19:12:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][10/34]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.8234 (0.8701)	loss 0.5177 (0.6001)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 19:13:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8289 (0.9083)	loss 0.5729 (0.5979)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 19:13:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 1.1962 (0.9196)	loss 0.5049 (0.5794)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 19:13:14 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 8 training takes 0:00:31
[2024-12-09 19:13:16 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 19:13:16 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 19:13:16 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:13:16 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 19:13:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][0/34]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.1990 (1.1990)	loss 0.5013 (0.5013)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 19:13:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 0.8159 (0.9782)	loss 0.6760 (0.5822)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:13:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8109 (0.9048)	loss 0.6116 (0.5883)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:13:45 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8278 (0.9229)	loss 0.7381 (0.5832)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:13:47 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 9 training takes 0:00:31
[2024-12-09 19:13:49 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 19:13:49 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 19:13:49 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:13:49 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 19:13:50 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][0/34]	eta 0:00:41 lr 0.000000	 wd 0.0000	time 1.2133 (1.2133)	loss 0.8184 (0.8184)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:14:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 0.8096 (0.9857)	loss 0.4916 (0.5508)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 19:14:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 1.1415 (0.9689)	loss 0.6326 (0.5711)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:14:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8329 (0.9281)	loss 0.5009 (0.5728)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 19:14:21 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 10 training takes 0:00:31
[2024-12-09 19:14:23 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 19:14:23 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 19:14:23 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:14:23 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 19:14:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][0/34]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.2658 (1.2658)	loss 0.4402 (0.4402)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 19:14:33 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][10/34]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.8182 (0.8740)	loss 0.4533 (0.5576)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 19:14:42 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8172 (0.9133)	loss 0.6006 (0.5641)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:14:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 1.2207 (0.9298)	loss 0.6727 (0.5857)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:14:55 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 11 training takes 0:00:31
[2024-12-09 19:14:56 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 19:14:56 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 19:14:56 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:14:56 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 19:14:57 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][0/34]	eta 0:00:41 lr 0.000000	 wd 0.0000	time 1.2088 (1.2088)	loss 0.6302 (0.6302)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:15:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 0.8991 (0.9829)	loss 0.6778 (0.6282)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:15:15 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 0.8350 (0.9100)	loss 0.5110 (0.5926)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 19:15:25 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8304 (0.9277)	loss 0.4457 (0.5793)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 19:15:28 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 12 training takes 0:00:31
[2024-12-09 19:15:29 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 19:15:29 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 19:15:29 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:15:29 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 19:15:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][0/34]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.1770 (1.1770)	loss 0.6762 (0.6762)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:15:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 1.1824 (1.0295)	loss 0.4400 (0.6065)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 19:15:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.8397 (1.0880)	loss 0.4976 (0.5978)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 19:16:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 1.1747 (1.0148)	loss 0.5401 (0.5892)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 19:16:04 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 13 training takes 0:00:34
[2024-12-09 19:16:06 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 19:16:06 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 19:16:06 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:16:06 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 19:16:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][0/34]	eta 0:00:41 lr 0.000000	 wd 0.0000	time 1.2103 (1.2103)	loss 0.5712 (0.5712)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 19:16:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][10/34]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 1.1811 (1.0911)	loss 0.5087 (0.5872)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 19:16:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][20/34]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 1.3804 (1.1278)	loss 0.6844 (0.6044)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:16:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][30/34]	eta 0:00:04 lr 0.000000	 wd 0.0000	time 0.9123 (1.1434)	loss 0.6279 (0.5926)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:16:46 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 14 training takes 0:00:40
[2024-12-09 19:16:50 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 19:16:50 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 19:16:50 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:16:50 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 19:16:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][0/34]	eta 0:01:09 lr 0.000000	 wd 0.0000	time 2.0432 (2.0432)	loss 0.6209 (0.6209)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:17:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][10/34]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 1.2026 (0.9834)	loss 0.7594 (0.6096)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:17:10 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][20/34]	eta 0:00:13 lr 0.000000	 wd 0.0000	time 0.8051 (0.9498)	loss 0.5637 (0.5921)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 19:17:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.8455 (0.9937)	loss 0.6191 (0.5785)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:17:23 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 15 training takes 0:00:33
[2024-12-09 19:17:25 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 19:17:25 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 19:17:25 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:17:25 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 19:17:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][0/34]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 1.2053 (1.2053)	loss 0.4942 (0.4942)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 19:17:36 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][10/34]	eta 0:00:24 lr 0.000000	 wd 0.0000	time 0.8173 (1.0080)	loss 0.6331 (0.5636)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:21:39 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-09 19:21:39 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-09 19:21:39 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-09 19:21:39 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-09 19:21:39 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-09 19:21:39 swin_tiny_patch4_window7_224] (main.py 160): INFO Start training
[2024-12-09 19:21:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][0/34]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 1.0791 (1.0791)	loss 0.6010 (0.6010)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 19:21:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][10/34]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.8157 (0.8452)	loss 0.5693 (0.6022)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 19:21:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][20/34]	eta 0:00:12 lr 0.000000	 wd 0.0000	time 1.1993 (0.9170)	loss 0.5580 (0.6055)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 19:22:08 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][30/34]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.9834 (0.9458)	loss 0.6858 (0.6129)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:22:10 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 0 training takes 0:00:31
[2024-12-09 19:23:34 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-09 19:23:34 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-09 19:24:03 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-09 19:24:03 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-09 19:24:03 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-09 19:24:03 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-09 19:24:03 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-09 19:24:03 swin_tiny_patch4_window7_224] (main.py 160): INFO Start training
[2024-12-09 19:24:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][0/49]	eta 0:00:50 lr 0.000000	 wd 0.0000	time 1.0396 (1.0396)	loss 0.7090 (0.7090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:24:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.8211 (0.9533)	loss 0.7770 (0.6988)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 19:24:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][20/49]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.9264 (0.8930)	loss 0.6988 (0.6987)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:24:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8205 (0.9090)	loss 0.7683 (0.7009)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 19:24:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.0639 (0.9211)	loss 0.7286 (0.7061)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:24:48 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 0 training takes 0:00:44
[2024-12-09 19:24:49 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 19:24:49 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 19:24:49 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:24:49 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 19:24:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2508 (1.2508)	loss 0.7122 (0.7122)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:25:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8082 (0.9918)	loss 0.6734 (0.6926)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:25:10 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 0.8428 (0.9916)	loss 0.7112 (0.6938)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:25:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.7994 (0.9355)	loss 0.6833 (0.6991)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:25:28 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8155 (0.9411)	loss 0.6977 (0.6993)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:25:35 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 1 training takes 0:00:45
[2024-12-09 19:25:37 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 19:25:37 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 19:25:37 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:25:37 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 19:25:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][0/49]	eta 0:01:02 lr 0.000000	 wd 0.0000	time 1.2719 (1.2719)	loss 0.6554 (0.6554)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:25:47 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][10/49]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.8169 (0.8650)	loss 0.6877 (0.6949)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:25:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8388 (0.9091)	loss 0.6921 (0.6953)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:26:06 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.2083 (0.9145)	loss 0.6927 (0.6955)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:26:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8113 (0.8957)	loss 0.6636 (0.6957)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:26:22 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 2 training takes 0:00:44
[2024-12-09 19:26:24 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 19:26:24 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 19:26:24 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:26:24 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 19:26:25 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1683 (1.1683)	loss 0.7025 (0.7025)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:26:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][10/49]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 1.2153 (1.0075)	loss 0.6904 (0.6944)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:26:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 1.1311 (0.9341)	loss 0.6966 (0.6953)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:26:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8135 (0.9454)	loss 0.7396 (0.6981)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.125
[2024-12-09 19:27:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1749 (0.9384)	loss 0.6853 (0.6959)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:27:09 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 3 training takes 0:00:45
[2024-12-09 19:27:11 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.718 
[2024-12-09 19:27:11 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.718%
[2024-12-09 19:27:11 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:27:11 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5333, Recall: 0.5063, F1: 0.4583
[2024-12-09 19:27:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1713 (1.1713)	loss 0.6924 (0.6924)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:27:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8082 (0.9748)	loss 0.6896 (0.6994)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:27:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 1.1885 (0.9468)	loss 0.6897 (0.6958)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:27:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8252 (0.9181)	loss 0.7159 (0.6963)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:27:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8293 (0.9292)	loss 0.6945 (0.6949)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:27:55 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 4 training takes 0:00:44
[2024-12-09 19:27:57 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.705 
[2024-12-09 19:27:57 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.705%
[2024-12-09 19:27:57 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:27:57 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4899, Recall: 0.4975, F1: 0.4522
[2024-12-09 19:27:59 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][0/49]	eta 0:01:20 lr 0.000000	 wd 0.0000	time 1.6510 (1.6510)	loss 0.7054 (0.7054)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:28:08 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 0.8234 (0.9451)	loss 0.7358 (0.7016)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 19:28:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8103 (0.9471)	loss 0.7155 (0.6993)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 19:28:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.0461 (0.9153)	loss 0.6914 (0.6991)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:28:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8139 (0.9884)	loss 0.6840 (0.6976)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:28:48 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 5 training takes 0:00:50
[2024-12-09 19:28:49 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.705 
[2024-12-09 19:28:49 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.705%
[2024-12-09 19:28:49 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:28:49 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5750, Recall: 0.5426, F1: 0.5370
[2024-12-09 19:28:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][0/49]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.2191 (1.2191)	loss 0.6933 (0.6933)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:29:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8033 (0.9968)	loss 0.7181 (0.6934)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 19:29:08 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8344 (0.9106)	loss 0.6943 (0.6924)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:29:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8011 (0.9248)	loss 0.6896 (0.6911)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:29:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1846 (0.9292)	loss 0.7153 (0.6927)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:29:34 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 6 training takes 0:00:44
[2024-12-09 19:29:36 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.615 
[2024-12-09 19:29:36 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.615%
[2024-12-09 19:29:36 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:29:36 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4960, Recall: 0.4962, F1: 0.4957
[2024-12-09 19:29:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][0/49]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.2084 (1.2084)	loss 0.6803 (0.6803)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:29:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8170 (0.9883)	loss 0.7130 (0.6987)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:29:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 1.1671 (0.9592)	loss 0.7032 (0.7003)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:30:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8151 (0.9203)	loss 0.6876 (0.6962)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:30:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8427 (0.9266)	loss 0.6756 (0.6939)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:30:20 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 7 training takes 0:00:44
[2024-12-09 19:30:22 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.603 
[2024-12-09 19:30:22 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.603%
[2024-12-09 19:30:22 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:30:22 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5024, Recall: 0.5025, F1: 0.5024
[2024-12-09 19:30:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][0/49]	eta 0:01:22 lr 0.000000	 wd 0.0000	time 1.6803 (1.6803)	loss 0.6832 (0.6832)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:30:33 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.8044 (0.9536)	loss 0.6931 (0.6890)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:30:42 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8127 (0.9461)	loss 0.7030 (0.6946)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 19:30:50 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.0456 (0.9094)	loss 0.6865 (0.6941)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:31:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8093 (0.9139)	loss 0.6912 (0.6953)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:31:07 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 8 training takes 0:00:45
[2024-12-09 19:31:09 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.551 
[2024-12-09 19:31:09 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.551%
[2024-12-09 19:31:09 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:31:09 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5221, Recall: 0.5276, F1: 0.5086
[2024-12-09 19:31:10 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1749 (1.1749)	loss 0.7038 (0.7038)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:31:19 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][10/49]	eta 0:00:35 lr 0.000000	 wd 0.0000	time 1.1801 (0.8985)	loss 0.6894 (0.6965)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:31:28 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8025 (0.9011)	loss 0.6892 (0.6924)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:31:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8092 (0.9164)	loss 0.6899 (0.6923)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:31:45 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.7960 (0.8910)	loss 0.6884 (0.6913)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:31:53 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 9 training takes 0:00:44
[2024-12-09 19:31:55 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.397 
[2024-12-09 19:31:55 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.397%
[2024-12-09 19:31:55 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:31:55 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5770, Recall: 0.5576, F1: 0.3925
[2024-12-09 19:31:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][0/49]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 1.2349 (1.2349)	loss 0.6924 (0.6924)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:32:06 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8168 (0.9862)	loss 0.6971 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:32:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8153 (0.9057)	loss 0.6898 (0.6940)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:32:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8249 (0.9208)	loss 0.6975 (0.6952)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:32:33 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1888 (0.9235)	loss 0.7010 (0.6942)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:32:40 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 10 training takes 0:00:44
[2024-12-09 19:32:41 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.679 
[2024-12-09 19:32:41 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.679%
[2024-12-09 19:32:41 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:32:41 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4444, Recall: 0.4799, F1: 0.4401
[2024-12-09 19:32:42 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1767 (1.1767)	loss 0.6981 (0.6981)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:32:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8091 (0.9884)	loss 0.7001 (0.6951)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:33:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 1.1582 (0.9591)	loss 0.7138 (0.6944)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.188
[2024-12-09 19:33:10 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8106 (0.9248)	loss 0.6811 (0.6960)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 19:33:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8064 (0.9317)	loss 0.6864 (0.6959)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:33:26 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 11 training takes 0:00:44
[2024-12-09 19:33:28 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.705 
[2024-12-09 19:33:28 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.705%
[2024-12-09 19:33:28 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:33:28 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5347, Recall: 0.5125, F1: 0.4849
[2024-12-09 19:33:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][0/49]	eta 0:01:21 lr 0.000000	 wd 0.0000	time 1.6678 (1.6678)	loss 0.6951 (0.6951)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:33:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 0.8308 (0.9443)	loss 0.7018 (0.6986)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:33:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8184 (0.9454)	loss 0.6817 (0.6966)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:33:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.0669 (0.9119)	loss 0.6886 (0.6959)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:34:06 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8110 (0.9170)	loss 0.7084 (0.6959)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:34:13 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 12 training takes 0:00:45
[2024-12-09 19:34:15 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.615 
[2024-12-09 19:34:15 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.615%
[2024-12-09 19:34:15 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:34:15 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4571, Recall: 0.4662, F1: 0.4583
[2024-12-09 19:34:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1932 (1.1932)	loss 0.7132 (0.7132)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 19:34:25 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][10/49]	eta 0:00:34 lr 0.000000	 wd 0.0000	time 1.1637 (0.8887)	loss 0.6961 (0.7047)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:34:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.7951 (0.9023)	loss 0.6982 (0.6992)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:34:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8555 (0.9241)	loss 0.6858 (0.6980)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:34:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8097 (0.8973)	loss 0.7095 (0.6976)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:35:00 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 13 training takes 0:00:44
[2024-12-09 19:35:01 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.628 
[2024-12-09 19:35:01 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.628%
[2024-12-09 19:35:01 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:35:01 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5463, Recall: 0.5501, F1: 0.5471
[2024-12-09 19:35:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1958 (1.1958)	loss 0.6793 (0.6793)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:35:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.9552 (0.9859)	loss 0.6856 (0.6903)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:35:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8122 (0.9038)	loss 0.6926 (0.6896)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:35:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8175 (0.9225)	loss 0.6897 (0.6915)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:35:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1778 (0.9163)	loss 0.7198 (0.6921)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 19:35:46 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 14 training takes 0:00:44
[2024-12-09 19:35:48 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.654 
[2024-12-09 19:35:48 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.654%
[2024-12-09 19:35:48 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:35:48 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5272, Recall: 0.5226, F1: 0.5217
[2024-12-09 19:35:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1717 (1.1717)	loss 0.6795 (0.6795)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:35:59 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][10/49]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 0.8205 (1.0127)	loss 0.6717 (0.6900)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:36:08 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 1.2412 (0.9770)	loss 0.6784 (0.6939)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:36:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8352 (0.9467)	loss 0.6935 (0.6940)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:36:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8575 (0.9569)	loss 0.7025 (0.6942)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:36:34 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 15 training takes 0:00:46
[2024-12-09 19:36:36 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.333 
[2024-12-09 19:36:36 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.333%
[2024-12-09 19:36:36 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:36:36 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4769, Recall: 0.4837, F1: 0.3262
[2024-12-09 19:36:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][0/49]	eta 0:01:25 lr 0.000000	 wd 0.0000	time 1.7443 (1.7443)	loss 0.7084 (0.7084)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 19:36:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8304 (0.9789)	loss 0.7019 (0.7003)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:36:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 0.8200 (0.9681)	loss 0.6950 (0.6955)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:37:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1813 (0.9403)	loss 0.7044 (0.6961)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:37:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8308 (0.9291)	loss 0.6901 (0.6948)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:37:22 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 16 training takes 0:00:46
[2024-12-09 19:37:23 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.564 
[2024-12-09 19:37:23 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.564%
[2024-12-09 19:37:23 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:37:23 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4785, Recall: 0.4762, F1: 0.4759
[2024-12-09 19:37:25 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][0/49]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.2155 (1.2155)	loss 0.6883 (0.6883)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:37:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][10/49]	eta 0:00:35 lr 0.000000	 wd 0.0000	time 1.2031 (0.9216)	loss 0.6924 (0.6949)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:37:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8696 (0.9279)	loss 0.6804 (0.6907)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:37:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8657 (0.9525)	loss 0.6838 (0.6894)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:38:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1503 (0.9394)	loss 0.7008 (0.6913)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:38:10 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 17 training takes 0:00:46
[2024-12-09 19:38:12 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.526 
[2024-12-09 19:38:12 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.526%
[2024-12-09 19:38:12 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:38:12 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4075, Recall: 0.4048, F1: 0.4061
[2024-12-09 19:38:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2503 (1.2503)	loss 0.6769 (0.6769)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:38:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][10/49]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 0.8475 (1.0458)	loss 0.6997 (0.6911)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:38:33 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 1.2321 (0.9832)	loss 0.6899 (0.6918)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:38:42 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8764 (0.9781)	loss 0.6900 (0.6930)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:38:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8193 (0.9844)	loss 0.6920 (0.6930)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:38:59 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 18 training takes 0:00:47
[2024-12-09 19:39:01 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.449 
[2024-12-09 19:39:01 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.449%
[2024-12-09 19:39:01 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:39:01 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5021, Recall: 0.5025, F1: 0.4413
[2024-12-09 19:39:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][0/49]	eta 0:01:23 lr 0.000000	 wd 0.0000	time 1.7043 (1.7043)	loss 0.7009 (0.7009)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:39:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8118 (0.9799)	loss 0.7107 (0.6931)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 19:39:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 0.8117 (0.9682)	loss 0.6704 (0.6895)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:39:29 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8131 (0.9206)	loss 0.6978 (0.6910)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:39:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8243 (0.9316)	loss 0.6981 (0.6914)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:39:46 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 19 training takes 0:00:45
[2024-12-09 19:39:48 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.462 
[2024-12-09 19:39:48 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.462%
[2024-12-09 19:39:48 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:39:48 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4733, Recall: 0.4662, F1: 0.4379
[2024-12-09 19:39:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.2028 (1.2028)	loss 0.6929 (0.6929)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:39:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][10/49]	eta 0:00:34 lr 0.000000	 wd 0.0000	time 1.0469 (0.8920)	loss 0.7265 (0.6968)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:40:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8361 (0.9147)	loss 0.7067 (0.6986)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:40:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8372 (0.9333)	loss 0.6804 (0.6958)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:40:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8362 (0.9101)	loss 0.6948 (0.6944)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:40:34 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 20 training takes 0:00:45
[2024-12-09 19:40:35 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.526 
[2024-12-09 19:40:35 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.526%
[2024-12-09 19:40:35 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:40:35 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4423, Recall: 0.4348, F1: 0.4367
[2024-12-09 19:40:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][0/49]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.2243 (1.2243)	loss 0.6812 (0.6812)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:40:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8264 (0.9973)	loss 0.6748 (0.6922)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:40:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8310 (0.9178)	loss 0.6704 (0.6895)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 19:41:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8245 (0.9341)	loss 0.6825 (0.6895)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:41:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.2500 (0.9432)	loss 0.6994 (0.6916)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:41:21 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 21 training takes 0:00:45
[2024-12-09 19:41:23 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.564 
[2024-12-09 19:41:23 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.564%
[2024-12-09 19:41:23 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:41:23 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4924, Recall: 0.4912, F1: 0.4884
[2024-12-09 19:41:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1978 (1.1978)	loss 0.6860 (0.6860)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:41:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][10/49]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 0.8204 (1.0061)	loss 0.7043 (0.6905)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 19:41:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 1.1902 (0.9800)	loss 0.6993 (0.6944)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:41:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8622 (0.9391)	loss 0.6907 (0.6933)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:42:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8629 (0.9450)	loss 0.6818 (0.6937)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:42:08 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 22 training takes 0:00:45
[2024-12-09 19:42:10 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.538 
[2024-12-09 19:42:10 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.538%
[2024-12-09 19:42:10 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:42:10 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5030, Recall: 0.5038, F1: 0.4902
[2024-12-09 19:42:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][0/49]	eta 0:01:18 lr 0.000000	 wd 0.0000	time 1.5992 (1.5992)	loss 0.6951 (0.6951)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 19:42:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][10/49]	eta 0:00:35 lr 0.000000	 wd 0.0000	time 0.8212 (0.9127)	loss 0.6942 (0.6964)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:42:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8273 (0.9422)	loss 0.6695 (0.6933)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:42:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1892 (0.9433)	loss 0.7080 (0.6940)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:42:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8154 (0.9224)	loss 0.6806 (0.6926)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:42:56 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 23 training takes 0:00:45
[2024-12-09 19:42:58 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.538 
[2024-12-09 19:42:58 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.538%
[2024-12-09 19:42:58 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:42:58 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4907, Recall: 0.4887, F1: 0.4808
[2024-12-09 19:42:59 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2604 (1.2604)	loss 0.7053 (0.7053)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:43:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 1.1759 (0.9697)	loss 0.6757 (0.6948)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:43:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8352 (0.9151)	loss 0.7184 (0.6950)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 19:43:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8182 (0.9316)	loss 0.6998 (0.6943)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:43:36 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1925 (0.9186)	loss 0.6899 (0.6948)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:43:43 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 24 training takes 0:00:45
[2024-12-09 19:43:45 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.526 
[2024-12-09 19:43:45 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.526%
[2024-12-09 19:43:45 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:43:45 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4960, Recall: 0.4950, F1: 0.4805
[2024-12-09 19:43:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][0/49]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.2085 (1.2085)	loss 0.7171 (0.7171)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:43:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8151 (0.9992)	loss 0.6948 (0.6955)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:44:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 1.1890 (0.9327)	loss 0.6883 (0.6956)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:44:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8029 (0.9244)	loss 0.6820 (0.6925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:44:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.7997 (0.9299)	loss 0.6753 (0.6926)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:44:30 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 25 training takes 0:00:44
[2024-12-09 19:44:31 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.564 
[2024-12-09 19:44:31 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.564%
[2024-12-09 19:44:31 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:44:31 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5053, Recall: 0.5063, F1: 0.4996
[2024-12-09 19:44:33 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][0/49]	eta 0:01:12 lr 0.000000	 wd 0.0000	time 1.4811 (1.4811)	loss 0.7010 (0.7010)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:44:42 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8178 (0.9817)	loss 0.7057 (0.6896)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:44:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 0.8064 (0.9672)	loss 0.6888 (0.6897)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:45:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8501 (0.9188)	loss 0.6765 (0.6902)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:45:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8355 (0.9258)	loss 0.7130 (0.6908)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 19:45:16 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 26 training takes 0:00:45
[2024-12-09 19:45:19 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.500 
[2024-12-09 19:45:19 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.500%
[2024-12-09 19:45:19 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:45:19 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4699, Recall: 0.4624, F1: 0.4524
[2024-12-09 19:45:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][0/49]	eta 0:01:02 lr 0.000000	 wd 0.0000	time 1.2673 (1.2673)	loss 0.6767 (0.6767)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:45:28 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][10/49]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.8201 (0.8691)	loss 0.7036 (0.6921)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:45:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8163 (0.9115)	loss 0.7138 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 19:45:47 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.2066 (0.9219)	loss 0.6742 (0.6931)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 19:45:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8312 (0.9004)	loss 0.6913 (0.6934)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:46:04 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 27 training takes 0:00:44
[2024-12-09 19:46:05 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.564 
[2024-12-09 19:46:05 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.564%
[2024-12-09 19:46:05 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:46:05 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5409, Recall: 0.5514, F1: 0.5264
[2024-12-09 19:46:06 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1925 (1.1925)	loss 0.6908 (0.6908)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:46:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 1.1922 (0.9911)	loss 0.7094 (0.6937)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 19:46:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8088 (0.9133)	loss 0.7032 (0.6965)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 19:46:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8242 (0.9271)	loss 0.6834 (0.6944)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:46:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.2052 (0.9148)	loss 0.6825 (0.6945)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:46:50 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 28 training takes 0:00:44
[2024-12-09 19:46:52 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.538 
[2024-12-09 19:46:52 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.538%
[2024-12-09 19:46:52 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:46:52 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4641, Recall: 0.4586, F1: 0.4583
[2024-12-09 19:46:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][0/49]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 1.2262 (1.2262)	loss 0.6882 (0.6882)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:47:03 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][10/49]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 0.8317 (1.0094)	loss 0.7092 (0.6903)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:47:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 1.1629 (0.9539)	loss 0.6683 (0.6940)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 19:47:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8200 (0.9292)	loss 0.7010 (0.6929)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:47:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8395 (0.9342)	loss 0.6992 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:47:37 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 29 training takes 0:00:44
[2024-12-09 19:47:38 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.500 
[2024-12-09 19:47:38 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.500%
[2024-12-09 19:47:38 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:47:38 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4699, Recall: 0.4624, F1: 0.4524
[2024-12-09 19:47:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][0/49]	eta 0:01:22 lr 0.000000	 wd 0.0000	time 1.6920 (1.6920)	loss 0.7130 (0.7130)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 19:47:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.8097 (0.9616)	loss 0.6882 (0.6881)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:47:59 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8495 (0.9647)	loss 0.6915 (0.6922)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:48:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1572 (0.9314)	loss 0.6843 (0.6897)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:48:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8180 (0.9329)	loss 0.6839 (0.6916)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:48:25 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 30 training takes 0:00:46
[2024-12-09 19:48:26 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.449 
[2024-12-09 19:48:26 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.449%
[2024-12-09 19:48:26 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:48:26 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4428, Recall: 0.4273, F1: 0.4139
[2024-12-09 19:48:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1897 (1.1897)	loss 0.6754 (0.6754)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:48:36 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 1.2356 (0.9259)	loss 0.6926 (0.6892)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:48:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8404 (0.9184)	loss 0.7027 (0.6888)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:48:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8159 (0.9304)	loss 0.6922 (0.6889)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:49:03 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8119 (0.9038)	loss 0.6893 (0.6907)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:49:11 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 31 training takes 0:00:44
[2024-12-09 19:49:13 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.538 
[2024-12-09 19:49:13 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.538%
[2024-12-09 19:49:13 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:49:13 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5150, Recall: 0.5188, F1: 0.4986
[2024-12-09 19:49:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1880 (1.1880)	loss 0.6908 (0.6908)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:49:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8066 (0.9849)	loss 0.7187 (0.6946)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.125
[2024-12-09 19:49:32 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8133 (0.9059)	loss 0.6938 (0.6929)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:49:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8026 (0.9180)	loss 0.7051 (0.6942)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:49:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1848 (0.9270)	loss 0.6986 (0.6923)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:49:57 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 32 training takes 0:00:44
[2024-12-09 19:49:59 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.513 
[2024-12-09 19:49:59 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.513%
[2024-12-09 19:49:59 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:49:59 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4768, Recall: 0.4712, F1: 0.4619
[2024-12-09 19:50:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1772 (1.1772)	loss 0.6740 (0.6740)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:50:10 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8307 (0.9920)	loss 0.6995 (0.6920)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:50:19 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 1.1697 (0.9741)	loss 0.6966 (0.6947)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:50:28 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8172 (0.9233)	loss 0.6889 (0.6923)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:50:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8119 (0.9325)	loss 0.6842 (0.6916)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:50:44 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 33 training takes 0:00:44
[2024-12-09 19:50:46 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.538 
[2024-12-09 19:50:46 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.538%
[2024-12-09 19:50:46 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:50:46 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4491, Recall: 0.4436, F1: 0.4451
[2024-12-09 19:50:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][0/49]	eta 0:01:22 lr 0.000000	 wd 0.0000	time 1.6858 (1.6858)	loss 0.6893 (0.6893)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:50:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][10/49]	eta 0:00:35 lr 0.000000	 wd 0.0000	time 0.8085 (0.9174)	loss 0.7030 (0.6928)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:51:06 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8263 (0.9379)	loss 0.6908 (0.6953)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:51:15 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.2173 (0.9237)	loss 0.6987 (0.6947)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:51:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8277 (0.9151)	loss 0.6940 (0.6927)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 19:51:32 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 34 training takes 0:00:45
[2024-12-09 19:51:33 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.526 
[2024-12-09 19:51:33 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.526%
[2024-12-09 19:51:33 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:51:33 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5079, Recall: 0.5100, F1: 0.4886
[2024-12-09 19:51:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][0/49]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.2150 (1.2150)	loss 0.7024 (0.7024)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 19:51:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 1.1983 (0.9499)	loss 0.7001 (0.6909)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:51:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8419 (0.9259)	loss 0.6884 (0.6883)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:52:03 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8214 (0.9412)	loss 0.6789 (0.6891)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:52:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1209 (0.9207)	loss 0.6824 (0.6906)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:52:19 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 35 training takes 0:00:45
[2024-12-09 19:52:20 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.577 
[2024-12-09 19:52:20 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.577%
[2024-12-09 19:52:20 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:52:20 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5000, Recall: 0.5000, F1: 0.4976
[2024-12-09 19:52:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [36/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.2030 (1.2030)	loss 0.7191 (0.7191)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:52:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [36/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8181 (0.9947)	loss 0.6955 (0.6914)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:52:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [36/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 1.1108 (0.9262)	loss 0.6887 (0.6907)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:52:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [36/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8168 (0.9256)	loss 0.6702 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:52:59 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [36/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8015 (0.9306)	loss 0.6958 (0.6936)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:53:05 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 36 training takes 0:00:44
[2024-12-09 19:53:07 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.449 
[2024-12-09 19:53:07 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.449%
[2024-12-09 19:53:07 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:53:07 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4663, Recall: 0.4574, F1: 0.4275
[2024-12-09 19:53:08 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [37/70][0/49]	eta 0:01:07 lr 0.000000	 wd 0.0000	time 1.3867 (1.3867)	loss 0.6958 (0.6958)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:53:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [37/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8210 (0.9882)	loss 0.6833 (0.6901)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:53:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [37/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 0.8116 (0.9720)	loss 0.6937 (0.6899)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:53:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [37/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8021 (0.9218)	loss 0.6696 (0.6890)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:53:45 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [37/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8150 (0.9277)	loss 0.7059 (0.6900)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 19:53:52 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 37 training takes 0:00:45
[2024-12-09 19:53:54 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.487 
[2024-12-09 19:53:54 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.487%
[2024-12-09 19:53:54 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:53:54 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4229, Recall: 0.4085, F1: 0.4113
[2024-12-09 19:53:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [38/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2590 (1.2590)	loss 0.6817 (0.6817)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:54:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [38/70][10/49]	eta 0:00:34 lr 0.000000	 wd 0.0000	time 0.8133 (0.8766)	loss 0.7166 (0.6963)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:54:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [38/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8146 (0.9077)	loss 0.6942 (0.6939)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:54:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [38/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1852 (0.9167)	loss 0.6847 (0.6939)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:54:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [38/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8157 (0.8939)	loss 0.7160 (0.6942)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:54:39 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 38 training takes 0:00:44
[2024-12-09 19:54:40 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.564 
[2024-12-09 19:54:40 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.564%
[2024-12-09 19:54:40 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:54:40 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5175, Recall: 0.5213, F1: 0.5096
[2024-12-09 19:54:42 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [39/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1823 (1.1823)	loss 0.6807 (0.6807)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:54:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [39/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 1.1952 (0.9569)	loss 0.6711 (0.6887)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:54:59 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [39/70][20/49]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.8005 (0.8957)	loss 0.6789 (0.6877)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:55:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [39/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8103 (0.9137)	loss 0.7104 (0.6902)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 19:55:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [39/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1780 (0.9006)	loss 0.6779 (0.6907)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:55:25 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 39 training takes 0:00:44
[2024-12-09 19:55:26 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.551 
[2024-12-09 19:55:26 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.551%
[2024-12-09 19:55:26 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:55:26 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5102, Recall: 0.5125, F1: 0.4999
[2024-12-09 19:55:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [40/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1703 (1.1703)	loss 0.6733 (0.6733)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:55:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [40/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8077 (0.9803)	loss 0.6994 (0.6971)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 19:55:45 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [40/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 1.0905 (0.9114)	loss 0.6811 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 19:55:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [40/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8243 (0.9130)	loss 0.7217 (0.6954)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 19:56:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [40/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8042 (0.9220)	loss 0.6926 (0.6957)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:56:11 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 40 training takes 0:00:44
[2024-12-09 19:56:12 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.500 
[2024-12-09 19:56:12 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.500%
[2024-12-09 19:56:12 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:56:12 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4941, Recall: 0.4925, F1: 0.4685
[2024-12-09 19:56:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [41/70][0/49]	eta 0:01:08 lr 0.000000	 wd 0.0000	time 1.4033 (1.4033)	loss 0.7135 (0.7135)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 19:56:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [41/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8220 (0.9765)	loss 0.7100 (0.6942)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:56:32 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [41/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8054 (0.9548)	loss 0.6905 (0.6915)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 19:56:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [41/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8167 (0.9092)	loss 0.7109 (0.6902)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:56:50 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [41/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8049 (0.9160)	loss 0.7051 (0.6909)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:56:57 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 41 training takes 0:00:44
[2024-12-09 19:56:59 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.538 
[2024-12-09 19:56:59 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.538%
[2024-12-09 19:56:59 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:56:59 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4907, Recall: 0.4887, F1: 0.4808
[2024-12-09 19:57:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [42/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2460 (1.2460)	loss 0.6920 (0.6920)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:57:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [42/70][10/49]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.8056 (0.8607)	loss 0.6863 (0.6852)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:57:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [42/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8137 (0.9010)	loss 0.6903 (0.6879)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:57:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [42/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1533 (0.9079)	loss 0.7280 (0.6906)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 19:57:36 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [42/70][40/49]	eta 0:00:07 lr 0.000000	 wd 0.0000	time 0.8049 (0.8874)	loss 0.6984 (0.6902)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:57:43 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 42 training takes 0:00:44
[2024-12-09 19:57:45 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.538 
[2024-12-09 19:57:45 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.538%
[2024-12-09 19:57:45 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:57:45 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5030, Recall: 0.5038, F1: 0.4902
[2024-12-09 19:57:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [43/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1811 (1.1811)	loss 0.7031 (0.7031)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:57:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [43/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 1.1634 (0.9453)	loss 0.7048 (0.6914)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 19:58:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [43/70][20/49]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.8452 (0.8921)	loss 0.6836 (0.6930)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 19:58:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [43/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.7967 (0.9080)	loss 0.6939 (0.6909)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:58:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [43/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1413 (0.8919)	loss 0.6937 (0.6909)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:58:29 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 43 training takes 0:00:44
[2024-12-09 19:58:31 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.577 
[2024-12-09 19:58:31 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.577%
[2024-12-09 19:58:31 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:58:31 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5481, Recall: 0.5602, F1: 0.5366
[2024-12-09 19:58:32 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [44/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1899 (1.1899)	loss 0.6818 (0.6818)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:58:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [44/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.7976 (0.9782)	loss 0.6755 (0.6946)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:58:50 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [44/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 1.1296 (0.9131)	loss 0.6788 (0.6944)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:58:59 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [44/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.7996 (0.9153)	loss 0.6925 (0.6919)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 19:59:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [44/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8159 (0.9212)	loss 0.7013 (0.6915)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 19:59:15 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 44 training takes 0:00:44
[2024-12-09 19:59:17 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.513 
[2024-12-09 19:59:17 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.513%
[2024-12-09 19:59:17 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 19:59:17 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5010, Recall: 0.5013, F1: 0.4785
[2024-12-09 19:59:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [45/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2476 (1.2476)	loss 0.6786 (0.6786)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:59:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [45/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.8179 (0.9699)	loss 0.6733 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:59:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [45/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.9557 (0.9565)	loss 0.7039 (0.6936)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 19:59:45 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [45/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8120 (0.9083)	loss 0.6847 (0.6926)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 19:59:54 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [45/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8217 (0.9158)	loss 0.7076 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 20:00:01 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 45 training takes 0:00:44
[2024-12-09 20:00:03 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.487 
[2024-12-09 20:00:03 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.487%
[2024-12-09 20:00:03 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:00:03 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4990, Recall: 0.4987, F1: 0.4647
[2024-12-09 20:00:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [46/70][0/49]	eta 0:01:09 lr 0.000000	 wd 0.0000	time 1.4273 (1.4273)	loss 0.6991 (0.6991)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:00:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [46/70][10/49]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.8034 (0.8712)	loss 0.6951 (0.6875)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:00:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [46/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8156 (0.9012)	loss 0.6904 (0.6903)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:00:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [46/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1632 (0.9018)	loss 0.6942 (0.6905)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:00:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [46/70][40/49]	eta 0:00:07 lr 0.000000	 wd 0.0000	time 0.8078 (0.8883)	loss 0.6809 (0.6905)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:00:47 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 46 training takes 0:00:44
[2024-12-09 20:00:49 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.538 
[2024-12-09 20:00:49 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.538%
[2024-12-09 20:00:49 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:00:49 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4778, Recall: 0.4737, F1: 0.4702
[2024-12-09 20:00:50 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [47/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1816 (1.1816)	loss 0.7233 (0.7233)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:00:59 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [47/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 1.1627 (0.9246)	loss 0.6907 (0.6942)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:01:08 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [47/70][20/49]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.7991 (0.8872)	loss 0.7307 (0.6928)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.125
[2024-12-09 20:01:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [47/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.7947 (0.9040)	loss 0.6817 (0.6896)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:01:25 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [47/70][40/49]	eta 0:00:07 lr 0.000000	 wd 0.0000	time 0.9809 (0.8842)	loss 0.6844 (0.6915)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:01:33 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 47 training takes 0:00:43
[2024-12-09 20:01:34 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.564 
[2024-12-09 20:01:34 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.564%
[2024-12-09 20:01:34 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:01:34 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5409, Recall: 0.5514, F1: 0.5264
[2024-12-09 20:01:36 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [48/70][0/49]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.2047 (1.2047)	loss 0.6907 (0.6907)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:01:45 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [48/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8150 (0.9791)	loss 0.6928 (0.6931)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:01:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [48/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8549 (0.9017)	loss 0.7168 (0.6924)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 20:02:03 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [48/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8243 (0.9147)	loss 0.7043 (0.6908)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:02:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [48/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.9815 (0.9223)	loss 0.6810 (0.6908)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:02:19 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 48 training takes 0:00:44
[2024-12-09 20:02:20 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.538 
[2024-12-09 20:02:20 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.538%
[2024-12-09 20:02:20 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:02:20 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5030, Recall: 0.5038, F1: 0.4902
[2024-12-09 20:02:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [49/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1962 (1.1962)	loss 0.6869 (0.6869)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:02:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [49/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.8291 (0.9619)	loss 0.6750 (0.6905)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 20:02:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [49/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8781 (0.9554)	loss 0.7012 (0.6913)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:02:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [49/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8146 (0.9105)	loss 0.6868 (0.6937)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:02:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [49/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8124 (0.9189)	loss 0.7039 (0.6931)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:03:05 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 49 training takes 0:00:44
[2024-12-09 20:03:07 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.487 
[2024-12-09 20:03:07 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.487%
[2024-12-09 20:03:07 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:03:07 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4872, Recall: 0.4837, F1: 0.4583
[2024-12-09 20:03:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [50/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2571 (1.2571)	loss 0.6841 (0.6841)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:03:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [50/70][10/49]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.8099 (0.8677)	loss 0.6749 (0.6901)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 20:03:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [50/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8144 (0.9026)	loss 0.6975 (0.6889)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:03:36 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [50/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1932 (0.9131)	loss 0.7032 (0.6899)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 20:03:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [50/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8200 (0.8914)	loss 0.6999 (0.6915)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:03:52 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 50 training takes 0:00:44
[2024-12-09 20:03:53 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.487 
[2024-12-09 20:03:53 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.487%
[2024-12-09 20:03:53 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:03:53 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4372, Recall: 0.4236, F1: 0.4231
[2024-12-09 20:03:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [51/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1802 (1.1802)	loss 0.6713 (0.6713)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 20:04:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [51/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 1.2254 (0.9665)	loss 0.6928 (0.6940)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:04:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [51/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8017 (0.9095)	loss 0.7009 (0.6929)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:04:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [51/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8134 (0.9201)	loss 0.6969 (0.6911)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:04:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [51/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.2044 (0.9092)	loss 0.7060 (0.6901)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:04:38 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 51 training takes 0:00:44
[2024-12-09 20:04:40 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.564 
[2024-12-09 20:04:40 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.564%
[2024-12-09 20:04:40 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:04:40 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5293, Recall: 0.5363, F1: 0.5185
[2024-12-09 20:04:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [52/70][0/49]	eta 0:01:50 lr 0.000000	 wd 0.0000	time 2.2548 (2.2548)	loss 0.6940 (0.6940)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:05:23 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-09 20:05:23 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-09 20:05:23 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-09 20:05:23 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-09 20:05:23 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-09 20:05:23 swin_tiny_patch4_window7_224] (main.py 160): INFO Start training
[2024-12-09 20:05:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][0/49]	eta 0:02:02 lr 0.000000	 wd 0.0000	time 2.4991 (2.4991)	loss 0.7090 (0.7090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:05:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][10/49]	eta 0:00:48 lr 0.000000	 wd 0.0000	time 1.3549 (1.2378)	loss 0.7770 (0.6988)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 20:05:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][20/49]	eta 0:00:35 lr 0.000000	 wd 0.0000	time 0.9193 (1.2260)	loss 0.6988 (0.6987)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:06:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][30/49]	eta 0:00:23 lr 0.000000	 wd 0.0000	time 1.3531 (1.2359)	loss 0.7683 (0.7009)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 20:06:12 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-09 20:06:12 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-09 20:06:12 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-09 20:06:12 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-09 20:06:12 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-09 20:06:12 swin_tiny_patch4_window7_224] (main.py 160): INFO Start training
[2024-12-09 20:06:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][0/49]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.2058 (1.2058)	loss 0.7090 (0.7090)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:06:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][10/49]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.8120 (0.8584)	loss 0.7770 (0.6988)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 20:06:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8299 (0.9018)	loss 0.6988 (0.6987)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:14:17 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-09 20:14:17 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-09 20:14:17 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-09 20:14:17 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-09 20:14:17 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-09 20:14:17 swin_tiny_patch4_window7_224] (main.py 160): INFO Start training
[2024-12-09 20:14:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][0/49]	eta 0:00:50 lr 0.000000	 wd 0.0000	time 1.0397 (1.0397)	loss 0.7075 (0.7075)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:14:28 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.8087 (0.9533)	loss 0.7767 (0.6983)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 20:14:45 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-09 20:14:45 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-09 20:14:45 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-09 20:14:46 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-09 20:14:46 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-09 20:14:46 swin_tiny_patch4_window7_224] (main.py 160): INFO Start training
[2024-12-09 20:14:47 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][0/49]	eta 0:00:50 lr 0.000000	 wd 0.0000	time 1.0246 (1.0246)	loss 0.7075 (0.7075)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:14:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.8207 (0.9536)	loss 0.7767 (0.6983)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 20:15:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 1.1835 (0.9218)	loss 0.6991 (0.6990)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:15:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8266 (0.9079)	loss 0.7662 (0.7007)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 20:15:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8415 (0.9170)	loss 0.7297 (0.7058)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:15:30 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 0 training takes 0:00:44
[2024-12-09 20:15:31 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 20:15:31 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 20:15:31 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:15:31 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 20:15:33 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][0/49]	eta 0:01:22 lr 0.000000	 wd 0.0000	time 1.6894 (1.6894)	loss 0.7125 (0.7125)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:15:42 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][10/49]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 0.7840 (1.0008)	loss 0.6728 (0.6933)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:15:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 0.8029 (0.9733)	loss 0.7131 (0.6939)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:16:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.7966 (0.9180)	loss 0.6853 (0.6989)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:16:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8188 (0.9247)	loss 0.7026 (0.6992)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:16:16 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 1 training takes 0:00:45
[2024-12-09 20:16:19 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 20:16:19 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 20:16:19 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:16:19 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 20:16:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][0/49]	eta 0:00:56 lr 0.000000	 wd 0.0000	time 1.1540 (1.1540)	loss 0.6577 (0.6577)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:16:28 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][10/49]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.8127 (0.8553)	loss 0.6926 (0.6954)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:16:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][20/49]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.8113 (0.8957)	loss 0.6891 (0.6954)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:16:47 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1305 (0.9141)	loss 0.6953 (0.6955)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:16:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][40/49]	eta 0:00:07 lr 0.000000	 wd 0.0000	time 0.7984 (0.8879)	loss 0.6622 (0.6958)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 20:17:03 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 2 training takes 0:00:44
[2024-12-09 20:17:05 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 20:17:05 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 20:17:05 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:17:05 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 20:17:06 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][0/49]	eta 0:00:56 lr 0.000000	 wd 0.0000	time 1.1623 (1.1623)	loss 0.7008 (0.7008)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:17:15 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 1.1585 (0.9693)	loss 0.6923 (0.6928)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:17:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][20/49]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.8072 (0.8947)	loss 0.6939 (0.6939)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:17:33 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.7995 (0.9224)	loss 0.7395 (0.6969)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.125
[2024-12-09 20:17:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.8091 (1.0125)	loss 0.6868 (0.6950)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:17:53 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 3 training takes 0:00:48
[2024-12-09 20:17:54 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.718 
[2024-12-09 20:17:54 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.718%
[2024-12-09 20:17:54 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:17:54 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5333, Recall: 0.5063, F1: 0.4583
[2024-12-09 20:17:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][0/49]	eta 0:01:15 lr 0.000000	 wd 0.0000	time 1.5450 (1.5450)	loss 0.6950 (0.6950)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:18:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.8138 (0.9618)	loss 0.6904 (0.6992)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:18:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8118 (0.9552)	loss 0.6911 (0.6957)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:18:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8003 (0.9058)	loss 0.7212 (0.6961)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:18:32 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8055 (0.9151)	loss 0.6936 (0.6948)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:18:39 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 4 training takes 0:00:44
[2024-12-09 20:18:41 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.705 
[2024-12-09 20:18:41 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.705%
[2024-12-09 20:18:41 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:18:41 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4899, Recall: 0.4975, F1: 0.4522
[2024-12-09 20:18:42 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2483 (1.2483)	loss 0.7051 (0.7051)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:18:50 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][10/49]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.8048 (0.8594)	loss 0.7374 (0.7020)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 20:19:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8142 (0.9010)	loss 0.7142 (0.6991)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 20:19:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1752 (0.9045)	loss 0.6899 (0.6990)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 20:19:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.7939 (0.8979)	loss 0.6839 (0.6975)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:19:26 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 5 training takes 0:00:44
[2024-12-09 20:19:27 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.705 
[2024-12-09 20:19:27 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.705%
[2024-12-09 20:19:27 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:19:27 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5750, Recall: 0.5426, F1: 0.5370
[2024-12-09 20:19:28 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][0/49]	eta 0:00:56 lr 0.000000	 wd 0.0000	time 1.1531 (1.1531)	loss 0.6957 (0.6957)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:19:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 1.1393 (0.9352)	loss 0.7183 (0.6944)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 20:19:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 1.7959 (0.9846)	loss 0.6945 (0.6929)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:19:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8043 (0.9964)	loss 0.6900 (0.6916)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:20:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1476 (0.9791)	loss 0.7180 (0.6929)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:20:14 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 6 training takes 0:00:47
[2024-12-09 20:20:16 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.615 
[2024-12-09 20:20:16 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.615%
[2024-12-09 20:20:16 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:20:16 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4960, Recall: 0.4962, F1: 0.4957
[2024-12-09 20:20:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][0/49]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.2211 (1.2211)	loss 0.6807 (0.6807)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 20:20:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][10/49]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 0.8185 (1.0047)	loss 0.7070 (0.6972)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:20:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 1.1024 (0.9828)	loss 0.7006 (0.6997)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:20:45 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8156 (0.9287)	loss 0.6913 (0.6955)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:20:54 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.7993 (0.9334)	loss 0.6765 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:21:01 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 7 training takes 0:00:44
[2024-12-09 20:21:03 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.603 
[2024-12-09 20:21:03 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.603%
[2024-12-09 20:21:03 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:21:03 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5024, Recall: 0.5025, F1: 0.5024
[2024-12-09 20:21:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][0/49]	eta 0:01:06 lr 0.000000	 wd 0.0000	time 1.3513 (1.3513)	loss 0.6842 (0.6842)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:21:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][10/49]	eta 0:00:34 lr 0.000000	 wd 0.0000	time 0.8057 (0.8843)	loss 0.6946 (0.6896)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:21:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8108 (0.9185)	loss 0.6994 (0.6945)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:21:32 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1689 (0.9221)	loss 0.6856 (0.6946)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:21:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8194 (0.9028)	loss 0.6940 (0.6957)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:21:48 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 8 training takes 0:00:44
[2024-12-09 20:21:50 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.538 
[2024-12-09 20:21:50 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.538%
[2024-12-09 20:21:50 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:21:50 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5150, Recall: 0.5188, F1: 0.4986
[2024-12-09 20:21:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1676 (1.1676)	loss 0.7050 (0.7050)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 20:22:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 1.1850 (0.9344)	loss 0.6884 (0.6969)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:22:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8228 (0.9002)	loss 0.6888 (0.6927)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:22:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.8567 (1.0568)	loss 0.6904 (0.6922)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:22:32 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.8020 (1.0319)	loss 0.6869 (0.6915)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:22:39 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 9 training takes 0:00:48
[2024-12-09 20:22:40 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.423 
[2024-12-09 20:22:40 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.423%
[2024-12-09 20:22:40 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:22:40 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5907, Recall: 0.5752, F1: 0.4207
[2024-12-09 20:22:42 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2517 (1.2517)	loss 0.6929 (0.6929)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:22:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8057 (0.9824)	loss 0.6947 (0.6943)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:23:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 1.0670 (0.9697)	loss 0.6906 (0.6949)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:23:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8419 (0.9194)	loss 0.7011 (0.6962)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:23:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8071 (0.9286)	loss 0.7000 (0.6950)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:23:25 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 10 training takes 0:00:44
[2024-12-09 20:23:27 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.692 
[2024-12-09 20:23:27 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.692%
[2024-12-09 20:23:27 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:23:27 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5091, Recall: 0.5038, F1: 0.4777
[2024-12-09 20:23:29 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][0/49]	eta 0:01:12 lr 0.000000	 wd 0.0000	time 1.4853 (1.4853)	loss 0.6989 (0.6989)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:23:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][10/49]	eta 0:00:34 lr 0.000000	 wd 0.0000	time 0.8118 (0.8826)	loss 0.7010 (0.6956)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:23:47 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8021 (0.9143)	loss 0.7133 (0.6943)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.188
[2024-12-09 20:23:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 2.0107 (0.9311)	loss 0.6823 (0.6963)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 20:24:06 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8080 (0.9428)	loss 0.6871 (0.6962)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:24:14 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 11 training takes 0:00:46
[2024-12-09 20:24:16 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.692 
[2024-12-09 20:24:16 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.692%
[2024-12-09 20:24:16 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:24:16 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5091, Recall: 0.5038, F1: 0.4777
[2024-12-09 20:24:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1650 (1.1650)	loss 0.6950 (0.6950)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:24:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 1.2021 (0.9588)	loss 0.7023 (0.6986)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:24:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8039 (0.8991)	loss 0.6785 (0.6966)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:24:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8123 (0.9186)	loss 0.6889 (0.6959)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:24:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1830 (0.9040)	loss 0.7099 (0.6961)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:25:00 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 12 training takes 0:00:44
[2024-12-09 20:25:02 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.577 
[2024-12-09 20:25:02 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.577%
[2024-12-09 20:25:02 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:25:02 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4093, Recall: 0.4248, F1: 0.4154
[2024-12-09 20:25:03 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.2036 (1.2036)	loss 0.7181 (0.7181)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 20:25:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8501 (0.9916)	loss 0.6950 (0.7044)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:25:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 1.1374 (0.9255)	loss 0.6993 (0.6996)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:25:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8080 (0.9266)	loss 0.6837 (0.6977)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:25:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8010 (0.9328)	loss 0.7122 (0.6975)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:25:47 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 13 training takes 0:00:44
[2024-12-09 20:25:48 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.590 
[2024-12-09 20:25:48 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.590%
[2024-12-09 20:25:48 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:25:48 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4941, Recall: 0.4937, F1: 0.4935
[2024-12-09 20:25:50 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][0/49]	eta 0:01:03 lr 0.000000	 wd 0.0000	time 1.2910 (1.2910)	loss 0.6794 (0.6794)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 20:25:59 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8007 (0.9856)	loss 0.6850 (0.6904)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:26:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 0.8842 (0.9721)	loss 0.6916 (0.6895)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:26:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8218 (0.9241)	loss 0.6900 (0.6914)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:26:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8201 (0.9316)	loss 0.7205 (0.6921)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 20:26:33 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 14 training takes 0:00:45
[2024-12-09 20:26:36 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.679 
[2024-12-09 20:26:36 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.679%
[2024-12-09 20:26:36 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:26:36 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5379, Recall: 0.5251, F1: 0.5196
[2024-12-09 20:26:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][0/49]	eta 0:01:02 lr 0.000000	 wd 0.0000	time 1.2688 (1.2688)	loss 0.6798 (0.6798)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:26:45 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][10/49]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.8081 (0.8666)	loss 0.6703 (0.6896)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:26:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8192 (0.9042)	loss 0.6781 (0.6936)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:27:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1877 (0.9065)	loss 0.6939 (0.6939)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:27:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.7981 (0.8909)	loss 0.7026 (0.6940)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:27:20 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 15 training takes 0:00:44
[2024-12-09 20:27:22 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.308 
[2024-12-09 20:27:22 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.308%
[2024-12-09 20:27:22 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:27:22 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4450, Recall: 0.4662, F1: 0.2961
[2024-12-09 20:27:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1887 (1.1887)	loss 0.7092 (0.7092)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:27:32 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 1.1770 (0.9342)	loss 0.7009 (0.7004)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:27:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.7922 (0.9026)	loss 0.6940 (0.6955)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:27:50 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8387 (0.9206)	loss 0.7049 (0.6964)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:27:59 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.9853 (0.9017)	loss 0.6921 (0.6949)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:28:07 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 16 training takes 0:00:44
[2024-12-09 20:28:08 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.603 
[2024-12-09 20:28:08 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.603%
[2024-12-09 20:28:08 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:28:08 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4694, Recall: 0.4724, F1: 0.4701
[2024-12-09 20:28:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1783 (1.1783)	loss 0.6880 (0.6880)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:28:19 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8201 (0.9883)	loss 0.6913 (0.6955)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:28:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8534 (0.9083)	loss 0.6789 (0.6908)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:28:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8320 (0.9213)	loss 0.6862 (0.6896)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:28:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.2186 (0.9310)	loss 0.6987 (0.6915)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:28:53 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 17 training takes 0:00:44
[2024-12-09 20:28:55 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.564 
[2024-12-09 20:28:55 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.564%
[2024-12-09 20:28:55 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:28:55 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4031, Recall: 0.4160, F1: 0.4086
[2024-12-09 20:28:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][0/49]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.2100 (1.2100)	loss 0.6789 (0.6789)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:29:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8125 (0.9863)	loss 0.7032 (0.6914)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:29:15 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 1.1545 (0.9779)	loss 0.6885 (0.6922)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:29:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8152 (0.9285)	loss 0.6929 (0.6933)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 20:29:33 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8186 (0.9356)	loss 0.6925 (0.6933)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:29:40 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 18 training takes 0:00:45
[2024-12-09 20:29:42 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.462 
[2024-12-09 20:29:42 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.462%
[2024-12-09 20:29:42 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:29:42 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5359, Recall: 0.5414, F1: 0.4583
[2024-12-09 20:29:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][0/49]	eta 0:01:12 lr 0.000000	 wd 0.0000	time 1.4852 (1.4852)	loss 0.7036 (0.7036)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:29:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][10/49]	eta 0:00:34 lr 0.000000	 wd 0.0000	time 0.7996 (0.8854)	loss 0.7125 (0.6928)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 20:30:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8276 (0.9175)	loss 0.6698 (0.6893)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:30:10 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1805 (0.9123)	loss 0.6975 (0.6906)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:30:19 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8066 (0.9017)	loss 0.6964 (0.6909)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:30:27 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 19 training takes 0:00:44
[2024-12-09 20:30:29 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.474 
[2024-12-09 20:30:29 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.474%
[2024-12-09 20:30:29 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:30:29 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4803, Recall: 0.4749, F1: 0.4481
[2024-12-09 20:30:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1944 (1.1944)	loss 0.6955 (0.6955)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:30:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][10/49]	eta 0:00:35 lr 0.000000	 wd 0.0000	time 1.1843 (0.9206)	loss 0.7228 (0.6959)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:30:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8162 (0.9081)	loss 0.7102 (0.6987)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:30:57 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8088 (0.9243)	loss 0.6829 (0.6959)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:31:06 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8081 (0.9012)	loss 0.6954 (0.6945)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:31:14 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 20 training takes 0:00:45
[2024-12-09 20:31:15 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.551 
[2024-12-09 20:31:15 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.551%
[2024-12-09 20:31:15 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:31:15 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4391, Recall: 0.4373, F1: 0.4382
[2024-12-09 20:31:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][0/49]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.2087 (1.2087)	loss 0.6794 (0.6794)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:31:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8037 (0.9955)	loss 0.6743 (0.6927)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:31:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8018 (0.9132)	loss 0.6688 (0.6897)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 20:31:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8214 (0.9318)	loss 0.6843 (0.6895)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:31:54 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.0734 (0.9364)	loss 0.7007 (0.6915)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:32:00 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 21 training takes 0:00:45
[2024-12-09 20:32:02 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.603 
[2024-12-09 20:32:02 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.603%
[2024-12-09 20:32:02 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:32:02 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4871, Recall: 0.4875, F1: 0.4872
[2024-12-09 20:32:03 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1993 (1.1993)	loss 0.6849 (0.6849)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:32:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][10/49]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 0.8858 (1.0096)	loss 0.7038 (0.6908)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 20:32:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 1.0850 (0.9875)	loss 0.7003 (0.6946)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:32:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8238 (0.9346)	loss 0.6896 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:32:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8173 (0.9396)	loss 0.6808 (0.6934)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:32:47 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 22 training takes 0:00:45
[2024-12-09 20:32:50 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.551 
[2024-12-09 20:32:50 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.551%
[2024-12-09 20:32:50 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:32:50 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4979, Recall: 0.4975, F1: 0.4902
[2024-12-09 20:32:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][0/49]	eta 0:01:06 lr 0.000000	 wd 0.0000	time 1.3627 (1.3627)	loss 0.6954 (0.6954)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 20:32:59 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][10/49]	eta 0:00:34 lr 0.000000	 wd 0.0000	time 0.8048 (0.8775)	loss 0.6916 (0.6966)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:33:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8309 (0.9202)	loss 0.6712 (0.6934)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 20:33:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1597 (0.9214)	loss 0.7080 (0.6941)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 20:33:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8122 (0.9034)	loss 0.6801 (0.6927)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:33:35 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 23 training takes 0:00:44
[2024-12-09 20:33:36 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.538 
[2024-12-09 20:33:36 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.538%
[2024-12-09 20:33:36 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:33:36 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4778, Recall: 0.4737, F1: 0.4702
[2024-12-09 20:33:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1669 (1.1669)	loss 0.7027 (0.7027)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:33:47 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 1.1782 (0.9480)	loss 0.6771 (0.6949)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:33:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8412 (0.9048)	loss 0.7171 (0.6954)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 20:34:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8241 (0.9211)	loss 0.6981 (0.6946)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:34:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1372 (0.9049)	loss 0.6887 (0.6950)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:34:21 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 24 training takes 0:00:44
[2024-12-09 20:34:23 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.513 
[2024-12-09 20:34:23 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.513%
[2024-12-09 20:34:23 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:34:23 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4768, Recall: 0.4712, F1: 0.4619
[2024-12-09 20:34:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1973 (1.1973)	loss 0.7150 (0.7150)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:34:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8345 (0.9967)	loss 0.6920 (0.6955)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:34:42 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 1.0996 (0.9287)	loss 0.6962 (0.6963)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:34:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8225 (0.9331)	loss 0.6802 (0.6928)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:35:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8083 (0.9389)	loss 0.6764 (0.6927)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:35:08 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 25 training takes 0:00:45
[2024-12-09 20:35:10 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.577 
[2024-12-09 20:35:10 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.577%
[2024-12-09 20:35:10 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:35:10 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5129, Recall: 0.5150, F1: 0.5091
[2024-12-09 20:35:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][0/49]	eta 0:01:05 lr 0.000000	 wd 0.0000	time 1.3397 (1.3397)	loss 0.7013 (0.7013)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:35:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8079 (0.9886)	loss 0.7072 (0.6903)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:35:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 0.8909 (0.9720)	loss 0.6884 (0.6907)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 20:35:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8246 (0.9217)	loss 0.6754 (0.6908)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 20:35:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8229 (0.9285)	loss 0.7117 (0.6911)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 20:35:54 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 26 training takes 0:00:44
[2024-12-09 20:35:57 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.513 
[2024-12-09 20:35:57 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.513%
[2024-12-09 20:35:57 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:35:57 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4768, Recall: 0.4712, F1: 0.4619
[2024-12-09 20:35:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][0/49]	eta 0:01:03 lr 0.000000	 wd 0.0000	time 1.2943 (1.2943)	loss 0.6730 (0.6730)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 20:36:06 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][10/49]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.8292 (0.8698)	loss 0.7043 (0.6915)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:36:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8144 (0.9123)	loss 0.7149 (0.6940)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 20:36:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.2212 (0.9263)	loss 0.6779 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 20:36:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8384 (0.9033)	loss 0.6927 (0.6936)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:36:42 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 27 training takes 0:00:45
[2024-12-09 20:36:43 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.577 
[2024-12-09 20:36:43 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.577%
[2024-12-09 20:36:43 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:36:43 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5367, Recall: 0.5451, F1: 0.5285
[2024-12-09 20:36:45 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2647 (1.2647)	loss 0.6900 (0.6900)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:36:54 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 1.1790 (0.9925)	loss 0.7143 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:37:03 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8238 (0.9114)	loss 0.7059 (0.6972)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:37:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8125 (0.9273)	loss 0.6834 (0.6949)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:37:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1759 (0.9166)	loss 0.6845 (0.6953)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:37:28 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 28 training takes 0:00:44
[2024-12-09 20:37:30 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.564 
[2024-12-09 20:37:30 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.564%
[2024-12-09 20:37:30 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:37:30 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4785, Recall: 0.4762, F1: 0.4759
[2024-12-09 20:37:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][0/49]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.2106 (1.2106)	loss 0.6872 (0.6872)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:37:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8337 (0.9769)	loss 0.7066 (0.6902)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:37:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 1.1989 (0.9272)	loss 0.6700 (0.6942)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 20:37:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.7971 (0.9177)	loss 0.6996 (0.6934)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 20:38:08 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8061 (0.9255)	loss 0.7028 (0.6934)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:38:14 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 29 training takes 0:00:44
[2024-12-09 20:38:16 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.500 
[2024-12-09 20:38:16 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.500%
[2024-12-09 20:38:16 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:38:16 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4699, Recall: 0.4624, F1: 0.4524
[2024-12-09 20:38:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][0/49]	eta 0:01:14 lr 0.000000	 wd 0.0000	time 1.5184 (1.5184)	loss 0.7140 (0.7140)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 20:38:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.8236 (0.9741)	loss 0.6822 (0.6863)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:38:36 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 0.8143 (0.9664)	loss 0.6909 (0.6910)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:38:45 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8418 (0.9179)	loss 0.6900 (0.6894)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:38:54 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8052 (0.9260)	loss 0.6800 (0.6917)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 20:39:01 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 30 training takes 0:00:45
[2024-12-09 20:39:03 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.449 
[2024-12-09 20:39:03 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.449%
[2024-12-09 20:39:03 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:39:03 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4546, Recall: 0.4424, F1: 0.4212
[2024-12-09 20:39:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][0/49]	eta 0:01:02 lr 0.000000	 wd 0.0000	time 1.2738 (1.2738)	loss 0.6772 (0.6772)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:39:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][10/49]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.8257 (0.8670)	loss 0.6914 (0.6895)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:39:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8063 (0.9033)	loss 0.7015 (0.6879)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:39:32 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1589 (0.9106)	loss 0.6930 (0.6889)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:39:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8139 (0.8917)	loss 0.6918 (0.6911)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:39:48 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 31 training takes 0:00:44
[2024-12-09 20:39:50 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.551 
[2024-12-09 20:39:50 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.551%
[2024-12-09 20:39:50 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:39:50 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5337, Recall: 0.5426, F1: 0.5162
[2024-12-09 20:39:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1731 (1.1731)	loss 0.6923 (0.6923)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:40:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 1.1896 (0.9430)	loss 0.7260 (0.6952)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.125
[2024-12-09 20:40:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8215 (0.9016)	loss 0.6882 (0.6930)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:40:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8134 (0.9212)	loss 0.6967 (0.6939)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:40:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1134 (0.9035)	loss 0.6993 (0.6922)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:40:34 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 32 training takes 0:00:44
[2024-12-09 20:40:36 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.526 
[2024-12-09 20:40:36 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.526%
[2024-12-09 20:40:36 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:40:36 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4837, Recall: 0.4799, F1: 0.4713
[2024-12-09 20:40:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1763 (1.1763)	loss 0.6736 (0.6736)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 20:40:47 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8577 (0.9876)	loss 0.6979 (0.6906)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:40:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 1.1992 (0.9239)	loss 0.6985 (0.6945)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:41:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.7954 (0.9205)	loss 0.6910 (0.6927)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:41:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8144 (0.9287)	loss 0.6818 (0.6923)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:41:21 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 33 training takes 0:00:44
[2024-12-09 20:41:22 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.538 
[2024-12-09 20:41:22 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.538%
[2024-12-09 20:41:22 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:41:22 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4491, Recall: 0.4436, F1: 0.4451
[2024-12-09 20:41:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][0/49]	eta 0:01:07 lr 0.000000	 wd 0.0000	time 1.3767 (1.3767)	loss 0.6928 (0.6928)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:41:33 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.8159 (0.9724)	loss 0.7041 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:41:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8116 (0.9623)	loss 0.6911 (0.6956)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:41:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8227 (0.9181)	loss 0.6968 (0.6947)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:42:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8038 (0.9231)	loss 0.6920 (0.6928)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:42:07 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 34 training takes 0:00:44
[2024-12-09 20:42:10 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.526 
[2024-12-09 20:42:10 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.526%
[2024-12-09 20:42:10 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:42:10 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5079, Recall: 0.5100, F1: 0.4886
[2024-12-09 20:42:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][0/49]	eta 0:01:02 lr 0.000000	 wd 0.0000	time 1.2707 (1.2707)	loss 0.6998 (0.6998)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:42:19 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][10/49]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.7985 (0.8666)	loss 0.6994 (0.6913)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:42:29 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.7964 (0.9048)	loss 0.6834 (0.6890)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 20:42:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1623 (0.9115)	loss 0.6841 (0.6898)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:42:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8374 (0.8920)	loss 0.6774 (0.6906)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:42:54 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 35 training takes 0:00:44
[2024-12-09 20:42:56 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.577 
[2024-12-09 20:42:56 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.577%
[2024-12-09 20:42:56 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:42:56 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5000, Recall: 0.5000, F1: 0.4976
[2024-12-09 20:42:57 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [36/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1980 (1.1980)	loss 0.7089 (0.7089)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:43:06 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [36/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 1.1924 (0.9608)	loss 0.6956 (0.6916)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:43:15 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [36/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8165 (0.9038)	loss 0.6905 (0.6914)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:43:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [36/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8131 (0.9216)	loss 0.6697 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:43:33 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [36/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1227 (0.9022)	loss 0.6908 (0.6933)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:43:40 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 36 training takes 0:00:44
[2024-12-09 20:43:42 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.462 
[2024-12-09 20:43:42 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.462%
[2024-12-09 20:43:42 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:43:42 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4733, Recall: 0.4662, F1: 0.4379
[2024-12-09 20:43:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [37/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1764 (1.1764)	loss 0.7015 (0.7015)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:43:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [37/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.8087 (0.9692)	loss 0.6883 (0.6915)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:44:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [37/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 1.0739 (0.9081)	loss 0.6923 (0.6907)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:44:10 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [37/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8434 (0.9137)	loss 0.6791 (0.6903)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:44:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [37/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8168 (0.9240)	loss 0.7062 (0.6903)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:44:27 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 37 training takes 0:00:44
[2024-12-09 20:44:28 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.487 
[2024-12-09 20:44:28 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.487%
[2024-12-09 20:44:28 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:44:28 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4229, Recall: 0.4085, F1: 0.4113
[2024-12-09 20:44:29 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [38/70][0/49]	eta 0:01:03 lr 0.000000	 wd 0.0000	time 1.3050 (1.3050)	loss 0.6861 (0.6861)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:44:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [38/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.8094 (0.9720)	loss 0.7137 (0.6962)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:44:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [38/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8785 (0.9628)	loss 0.6853 (0.6947)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:44:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [38/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8559 (0.9603)	loss 0.6825 (0.6941)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:45:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [38/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8125 (0.9575)	loss 0.7094 (0.6943)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:45:15 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 38 training takes 0:00:46
[2024-12-09 20:45:17 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.577 
[2024-12-09 20:45:17 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.577%
[2024-12-09 20:45:17 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:45:17 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5250, Recall: 0.5301, F1: 0.5193
[2024-12-09 20:45:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [39/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1875 (1.1875)	loss 0.6790 (0.6790)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 20:45:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [39/70][10/49]	eta 0:00:34 lr 0.000000	 wd 0.0000	time 1.0775 (0.8788)	loss 0.6703 (0.6883)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 20:45:36 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [39/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8247 (0.8994)	loss 0.6845 (0.6880)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:45:45 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [39/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8288 (0.9136)	loss 0.7042 (0.6896)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:45:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [39/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8105 (0.8911)	loss 0.6878 (0.6914)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:46:01 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 39 training takes 0:00:44
[2024-12-09 20:46:03 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.538 
[2024-12-09 20:46:03 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.538%
[2024-12-09 20:46:03 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:46:03 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4907, Recall: 0.4887, F1: 0.4808
[2024-12-09 20:46:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [40/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1720 (1.1720)	loss 0.6885 (0.6885)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:46:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [40/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.8183 (0.9698)	loss 0.7030 (0.7005)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:46:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [40/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8286 (0.8978)	loss 0.6776 (0.6951)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:46:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [40/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8139 (0.9137)	loss 0.7222 (0.6964)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 20:46:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [40/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1754 (0.9135)	loss 0.6891 (0.6962)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:46:47 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 40 training takes 0:00:44
[2024-12-09 20:46:49 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.500 
[2024-12-09 20:46:49 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.500%
[2024-12-09 20:46:49 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:46:49 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4941, Recall: 0.4925, F1: 0.4685
[2024-12-09 20:46:50 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [41/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1994 (1.1994)	loss 0.7047 (0.7047)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:47:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [41/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8240 (0.9870)	loss 0.7088 (0.6936)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:47:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [41/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 1.2286 (0.9610)	loss 0.6994 (0.6917)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:47:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [41/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8560 (0.9289)	loss 0.7065 (0.6913)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:47:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [41/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8111 (0.9310)	loss 0.7064 (0.6916)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:47:34 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 41 training takes 0:00:44
[2024-12-09 20:47:36 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.538 
[2024-12-09 20:47:36 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.538%
[2024-12-09 20:47:36 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:47:36 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4907, Recall: 0.4887, F1: 0.4808
[2024-12-09 20:47:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [42/70][0/49]	eta 0:01:19 lr 0.000000	 wd 0.0000	time 1.6307 (1.6307)	loss 0.6930 (0.6930)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:47:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [42/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 0.8089 (0.9242)	loss 0.6953 (0.6873)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:47:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [42/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8130 (0.9383)	loss 0.6937 (0.6892)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:48:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [42/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1837 (0.9162)	loss 0.7243 (0.6914)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 20:48:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [42/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8191 (0.9129)	loss 0.6973 (0.6906)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:48:21 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 42 training takes 0:00:45
[2024-12-09 20:48:23 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.538 
[2024-12-09 20:48:23 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.538%
[2024-12-09 20:48:23 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:48:23 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5030, Recall: 0.5038, F1: 0.4902
[2024-12-09 20:48:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [43/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1996 (1.1996)	loss 0.7057 (0.7057)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:48:33 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [43/70][10/49]	eta 0:00:35 lr 0.000000	 wd 0.0000	time 1.2264 (0.9063)	loss 0.7064 (0.6928)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 20:48:42 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [43/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8147 (0.9082)	loss 0.6899 (0.6944)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:48:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [43/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8082 (0.9268)	loss 0.6941 (0.6918)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:49:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [43/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8142 (0.8996)	loss 0.6937 (0.6916)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:49:08 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 43 training takes 0:00:44
[2024-12-09 20:49:09 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.564 
[2024-12-09 20:49:09 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.564%
[2024-12-09 20:49:09 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:49:09 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5293, Recall: 0.5363, F1: 0.5185
[2024-12-09 20:49:10 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [44/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1849 (1.1849)	loss 0.6811 (0.6811)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:49:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [44/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8141 (0.9853)	loss 0.6726 (0.6930)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 20:49:28 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [44/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8174 (0.9068)	loss 0.6849 (0.6938)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:49:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [44/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8114 (0.9213)	loss 0.6955 (0.6927)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 20:49:47 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [44/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1852 (0.9221)	loss 0.7024 (0.6922)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 20:49:54 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 44 training takes 0:00:44
[2024-12-09 20:49:56 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.513 
[2024-12-09 20:49:56 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.513%
[2024-12-09 20:49:56 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:49:56 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5010, Recall: 0.5013, F1: 0.4785
[2024-12-09 20:49:57 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [45/70][0/49]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.2078 (1.2078)	loss 0.6818 (0.6818)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:50:06 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [45/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8194 (0.9860)	loss 0.6724 (0.6929)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 20:50:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [45/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 1.1945 (0.9613)	loss 0.7062 (0.6946)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:50:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [45/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8244 (0.9255)	loss 0.6938 (0.6933)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:50:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [45/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8214 (0.9316)	loss 0.7026 (0.6937)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:50:40 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 45 training takes 0:00:44
[2024-12-09 20:50:42 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.487 
[2024-12-09 20:50:42 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.487%
[2024-12-09 20:50:42 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:50:42 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4990, Recall: 0.4987, F1: 0.4647
[2024-12-09 20:50:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [46/70][0/49]	eta 0:01:21 lr 0.000000	 wd 0.0000	time 1.6668 (1.6668)	loss 0.7053 (0.7053)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:50:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [46/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 0.8024 (0.9409)	loss 0.6873 (0.6887)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:51:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [46/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8105 (0.9432)	loss 0.6803 (0.6905)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:51:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [46/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1138 (0.9105)	loss 0.6911 (0.6905)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:51:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [46/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8180 (0.9116)	loss 0.6762 (0.6908)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:51:27 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 46 training takes 0:00:44
[2024-12-09 20:51:29 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.538 
[2024-12-09 20:51:29 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.538%
[2024-12-09 20:51:29 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:51:29 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4778, Recall: 0.4737, F1: 0.4702
[2024-12-09 20:51:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [47/70][0/49]	eta 0:00:56 lr 0.000000	 wd 0.0000	time 1.1627 (1.1627)	loss 0.7251 (0.7251)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 20:51:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [47/70][10/49]	eta 0:00:34 lr 0.000000	 wd 0.0000	time 1.1979 (0.8952)	loss 0.6858 (0.6957)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:51:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [47/70][20/49]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.8180 (0.8916)	loss 0.7163 (0.6936)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.188
[2024-12-09 20:51:57 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [47/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8123 (0.9075)	loss 0.6808 (0.6903)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:52:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [47/70][40/49]	eta 0:00:07 lr 0.000000	 wd 0.0000	time 0.8045 (0.8832)	loss 0.6862 (0.6918)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:52:13 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 47 training takes 0:00:44
[2024-12-09 20:52:15 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.551 
[2024-12-09 20:52:15 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.551%
[2024-12-09 20:52:15 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:52:15 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5221, Recall: 0.5276, F1: 0.5086
[2024-12-09 20:52:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [48/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1663 (1.1663)	loss 0.6958 (0.6958)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:52:25 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [48/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.7976 (0.9763)	loss 0.6946 (0.6937)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:52:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [48/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8128 (0.8993)	loss 0.7216 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 20:52:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [48/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8019 (0.9140)	loss 0.7091 (0.6924)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:52:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [48/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.2059 (0.9174)	loss 0.6862 (0.6919)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:52:59 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 48 training takes 0:00:44
[2024-12-09 20:53:01 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.564 
[2024-12-09 20:53:01 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.564%
[2024-12-09 20:53:01 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:53:01 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5175, Recall: 0.5213, F1: 0.5096
[2024-12-09 20:53:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [49/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.2012 (1.2012)	loss 0.6853 (0.6853)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:53:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [49/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8044 (0.9846)	loss 0.6774 (0.6911)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:53:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [49/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 1.1900 (0.9601)	loss 0.6950 (0.6909)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:53:29 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [49/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8137 (0.9218)	loss 0.6812 (0.6939)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:53:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [49/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8139 (0.9269)	loss 0.6968 (0.6934)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:53:45 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 49 training takes 0:00:44
[2024-12-09 20:53:47 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.500 
[2024-12-09 20:53:47 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.500%
[2024-12-09 20:53:47 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:53:47 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4941, Recall: 0.4925, F1: 0.4685
[2024-12-09 20:53:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [50/70][0/49]	eta 0:01:23 lr 0.000000	 wd 0.0000	time 1.6983 (1.6983)	loss 0.6857 (0.6857)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:53:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [50/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 0.8080 (0.9315)	loss 0.6796 (0.6921)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 20:54:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [50/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.7997 (0.9380)	loss 0.6903 (0.6893)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:54:15 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [50/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.0887 (0.9053)	loss 0.6972 (0.6905)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:54:25 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [50/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8294 (0.9123)	loss 0.7020 (0.6923)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:54:32 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 50 training takes 0:00:45
[2024-12-09 20:54:34 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.487 
[2024-12-09 20:54:34 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.487%
[2024-12-09 20:54:34 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:54:34 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4372, Recall: 0.4236, F1: 0.4231
[2024-12-09 20:54:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [51/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1883 (1.1883)	loss 0.6621 (0.6621)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.875
[2024-12-09 20:54:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [51/70][10/49]	eta 0:00:34 lr 0.000000	 wd 0.0000	time 1.1625 (0.8938)	loss 0.6945 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:54:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [51/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8068 (0.9027)	loss 0.6998 (0.6923)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:55:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [51/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8136 (0.9161)	loss 0.6909 (0.6911)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:55:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [51/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8198 (0.8905)	loss 0.7006 (0.6902)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:55:18 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 51 training takes 0:00:44
[2024-12-09 20:55:20 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.564 
[2024-12-09 20:55:20 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.564%
[2024-12-09 20:55:20 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:55:20 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5293, Recall: 0.5363, F1: 0.5185
[2024-12-09 20:55:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [52/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1756 (1.1756)	loss 0.6942 (0.6942)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:55:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [52/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.8129 (0.9732)	loss 0.7020 (0.6951)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 20:55:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [52/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8203 (0.8982)	loss 0.7041 (0.6928)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:55:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [52/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8214 (0.9132)	loss 0.7193 (0.6923)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 20:55:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [52/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1714 (0.9178)	loss 0.7084 (0.6926)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 20:56:05 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 52 training takes 0:00:44
[2024-12-09 20:56:06 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.526 
[2024-12-09 20:56:06 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.526%
[2024-12-09 20:56:06 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:56:06 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4837, Recall: 0.4799, F1: 0.4713
[2024-12-09 20:56:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [53/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1657 (1.1657)	loss 0.7185 (0.7185)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 20:56:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [53/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8248 (0.9769)	loss 0.7059 (0.6960)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:56:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [53/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 1.2031 (0.9582)	loss 0.7082 (0.6919)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:56:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [53/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8079 (0.9201)	loss 0.7009 (0.6937)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:56:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [53/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8218 (0.9281)	loss 0.6926 (0.6928)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:56:51 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 53 training takes 0:00:44
[2024-12-09 20:56:53 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.564 
[2024-12-09 20:56:53 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.564%
[2024-12-09 20:56:53 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:56:53 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5293, Recall: 0.5363, F1: 0.5185
[2024-12-09 20:56:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [54/70][0/49]	eta 0:01:22 lr 0.000000	 wd 0.0000	time 1.6893 (1.6893)	loss 0.6803 (0.6803)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:57:03 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [54/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 0.8280 (0.9304)	loss 0.7021 (0.6930)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:57:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [54/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8244 (0.9388)	loss 0.6849 (0.6911)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 20:57:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [54/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1891 (0.9114)	loss 0.7011 (0.6916)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:57:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [54/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8111 (0.9103)	loss 0.7039 (0.6911)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 20:57:38 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 54 training takes 0:00:44
[2024-12-09 20:57:40 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.564 
[2024-12-09 20:57:40 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.564%
[2024-12-09 20:57:40 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 20:57:40 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4924, Recall: 0.4912, F1: 0.4884
[2024-12-09 20:57:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [55/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1751 (1.1751)	loss 0.6818 (0.6818)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 20:57:50 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [55/70][10/49]	eta 0:00:34 lr 0.000000	 wd 0.0000	time 1.1894 (0.8952)	loss 0.7064 (0.6930)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 20:57:59 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [55/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8185 (0.9050)	loss 0.6833 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:07:16 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-09 21:07:16 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-09 21:07:16 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-09 21:07:17 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-09 21:07:17 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-09 21:07:17 swin_tiny_patch4_window7_224] (main.py 160): INFO Start training
[2024-12-09 21:07:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][0/49]	eta 0:00:52 lr 0.000000	 wd 0.0000	time 1.0786 (1.0786)	loss 0.7375 (0.7375)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:07:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.8027 (0.9680)	loss 0.6507 (0.7199)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:07:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 1.1878 (0.9560)	loss 0.7157 (0.7170)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:07:45 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8066 (0.9077)	loss 0.6968 (0.7161)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:07:54 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8068 (0.9167)	loss 0.7580 (0.7104)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:08:01 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 0 training takes 0:00:44
[2024-12-09 21:08:03 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 21:08:03 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 21:08:03 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 21:08:03 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 21:08:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][0/49]	eta 0:01:21 lr 0.000000	 wd 0.0000	time 1.6633 (1.6633)	loss 0.7298 (0.7298)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:08:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 0.7945 (0.9250)	loss 0.7077 (0.6996)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:08:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8431 (0.9390)	loss 0.7349 (0.6964)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:08:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.2020 (0.9150)	loss 0.7151 (0.6958)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:08:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8441 (0.9112)	loss 0.6727 (0.6985)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:08:48 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 1 training takes 0:00:45
[2024-12-09 21:08:50 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 21:08:50 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 21:08:50 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 21:08:50 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 21:08:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][0/49]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.2207 (1.2207)	loss 0.7214 (0.7214)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:09:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][10/49]	eta 0:00:35 lr 0.000000	 wd 0.0000	time 1.2136 (0.9161)	loss 0.6961 (0.6991)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:09:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8120 (0.9111)	loss 0.7340 (0.7050)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:09:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8300 (0.9233)	loss 0.6923 (0.7005)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:09:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.2596 (0.9141)	loss 0.7032 (0.6995)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:09:36 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 2 training takes 0:00:46
[2024-12-09 21:09:38 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 21:09:38 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 21:09:38 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 21:09:38 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 21:09:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][0/49]	eta 0:00:56 lr 0.000000	 wd 0.0000	time 1.1555 (1.1555)	loss 0.7042 (0.7042)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:09:50 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][10/49]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 0.8236 (1.1430)	loss 0.6624 (0.6979)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:10:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][20/49]	eta 0:00:30 lr 0.000000	 wd 0.0000	time 1.1974 (1.0423)	loss 0.6955 (0.6945)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:10:08 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.7934 (0.9776)	loss 0.7198 (0.6976)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 21:10:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.7991 (0.9715)	loss 0.6922 (0.6969)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:10:24 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 3 training takes 0:00:46
[2024-12-09 21:10:26 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 21:10:26 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 21:10:26 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 21:10:26 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 21:10:28 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][0/49]	eta 0:01:20 lr 0.000000	 wd 0.0000	time 1.6408 (1.6408)	loss 0.6866 (0.6866)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:10:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 0.8086 (0.9447)	loss 0.6831 (0.6889)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:10:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8206 (0.9446)	loss 0.6702 (0.6946)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:10:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1934 (0.9150)	loss 0.6640 (0.6955)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:12:03 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-05
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-06
  WEIGHT_DECAY: 1.0e-05

[2024-12-09 21:12:03 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-09 21:12:03 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-09 21:12:03 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-09 21:12:03 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-09 21:12:03 swin_tiny_patch4_window7_224] (main.py 160): INFO Start training
[2024-12-09 21:12:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][0/49]	eta 0:00:50 lr 0.000003	 wd 0.0000	time 1.0271 (1.0271)	loss 0.7375 (0.7375)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:12:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][10/49]	eta 0:00:43 lr 0.000003	 wd 0.0000	time 0.8122 (1.1246)	loss 0.6909 (0.7152)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:12:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][20/49]	eta 0:00:28 lr 0.000003	 wd 0.0000	time 0.8542 (0.9806)	loss 0.7019 (0.7071)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:12:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][30/49]	eta 0:00:18 lr 0.000003	 wd 0.0000	time 0.8234 (0.9751)	loss 0.6779 (0.7032)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:12:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][40/49]	eta 0:00:08 lr 0.000003	 wd 0.0000	time 1.1950 (0.9698)	loss 0.6974 (0.7019)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:12:50 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 0 training takes 0:00:46
[2024-12-09 21:12:51 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.577 
[2024-12-09 21:12:51 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.577%
[2024-12-09 21:12:51 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.58%
[2024-12-09 21:12:51 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4861, Recall: 0.4850, F1: 0.4847
[2024-12-09 21:12:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][0/49]	eta 0:00:57 lr 0.000003	 wd 0.0000	time 1.1820 (1.1820)	loss 0.7081 (0.7081)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 21:13:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][10/49]	eta 0:00:38 lr 0.000003	 wd 0.0000	time 0.8092 (0.9923)	loss 0.7091 (0.6943)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:13:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][20/49]	eta 0:00:28 lr 0.000003	 wd 0.0000	time 1.2285 (0.9708)	loss 0.7195 (0.6941)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:13:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][30/49]	eta 0:00:17 lr 0.000003	 wd 0.0000	time 1.2779 (0.9467)	loss 0.6943 (0.6923)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:13:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][40/49]	eta 0:00:08 lr 0.000003	 wd 0.0000	time 0.8228 (0.9521)	loss 0.7015 (0.6948)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:13:37 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 1 training takes 0:00:45
[2024-12-09 21:13:39 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.423 
[2024-12-09 21:13:39 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.423%
[2024-12-09 21:13:39 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.58%
[2024-12-09 21:13:39 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5292, Recall: 0.5301, F1: 0.4230
[2024-12-09 21:13:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][0/49]	eta 0:01:22 lr 0.000003	 wd 0.0000	time 1.6822 (1.6822)	loss 0.7062 (0.7062)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:13:50 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][10/49]	eta 0:00:36 lr 0.000003	 wd 0.0000	time 0.8774 (0.9289)	loss 0.6787 (0.6954)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:13:59 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][20/49]	eta 0:00:27 lr 0.000003	 wd 0.0000	time 0.8030 (0.9464)	loss 0.6886 (0.6937)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:14:08 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][30/49]	eta 0:00:17 lr 0.000003	 wd 0.0000	time 1.1871 (0.9268)	loss 0.6845 (0.6931)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:14:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][40/49]	eta 0:00:08 lr 0.000003	 wd 0.0000	time 0.8053 (0.9184)	loss 0.6851 (0.6944)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:14:25 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 2 training takes 0:00:45
[2024-12-09 21:14:27 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.590 
[2024-12-09 21:14:27 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.590%
[2024-12-09 21:14:27 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.59%
[2024-12-09 21:14:27 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4159, Recall: 0.4336, F1: 0.4222
[2024-12-09 21:14:28 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][0/49]	eta 0:00:58 lr 0.000003	 wd 0.0000	time 1.1970 (1.1970)	loss 0.7011 (0.7011)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:14:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][10/49]	eta 0:00:35 lr 0.000003	 wd 0.0000	time 1.1780 (0.9115)	loss 0.6859 (0.6990)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:14:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][20/49]	eta 0:00:26 lr 0.000003	 wd 0.0000	time 0.8430 (0.9058)	loss 0.7216 (0.6956)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:14:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][30/49]	eta 0:00:17 lr 0.000003	 wd 0.0000	time 0.8061 (0.9162)	loss 0.7189 (0.6980)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:15:03 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][40/49]	eta 0:00:08 lr 0.000003	 wd 0.0000	time 0.8046 (0.8894)	loss 0.6860 (0.6966)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:15:11 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 3 training takes 0:00:44
[2024-12-09 21:15:13 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.385 
[2024-12-09 21:15:13 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.385%
[2024-12-09 21:15:13 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.59%
[2024-12-09 21:15:13 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4626, Recall: 0.4586, F1: 0.3830
[2024-12-09 21:15:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][0/49]	eta 0:00:58 lr 0.000003	 wd 0.0000	time 1.1870 (1.1870)	loss 0.6874 (0.6874)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:15:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][10/49]	eta 0:00:38 lr 0.000003	 wd 0.0000	time 0.8102 (0.9794)	loss 0.6919 (0.6921)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:15:32 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][20/49]	eta 0:00:26 lr 0.000003	 wd 0.0000	time 0.8127 (0.9021)	loss 0.6740 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:15:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][30/49]	eta 0:00:17 lr 0.000003	 wd 0.0000	time 0.8117 (0.9152)	loss 0.6696 (0.6931)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 21:15:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][40/49]	eta 0:00:08 lr 0.000003	 wd 0.0000	time 1.1699 (0.9249)	loss 0.6862 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:15:57 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 4 training takes 0:00:44
[2024-12-09 21:15:59 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.564 
[2024-12-09 21:15:59 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.564%
[2024-12-09 21:15:59 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.59%
[2024-12-09 21:15:59 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4924, Recall: 0.4912, F1: 0.4884
[2024-12-09 21:16:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][0/49]	eta 0:00:57 lr 0.000003	 wd 0.0000	time 1.1751 (1.1751)	loss 0.6962 (0.6962)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:16:10 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][10/49]	eta 0:00:38 lr 0.000003	 wd 0.0000	time 0.8139 (0.9816)	loss 0.6962 (0.6921)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:16:19 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][20/49]	eta 0:00:27 lr 0.000003	 wd 0.0000	time 1.1649 (0.9637)	loss 0.6847 (0.6901)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:16:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][30/49]	eta 0:00:17 lr 0.000003	 wd 0.0000	time 0.8301 (0.9185)	loss 0.7158 (0.6903)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:16:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][40/49]	eta 0:00:08 lr 0.000003	 wd 0.0000	time 0.8112 (0.9259)	loss 0.7025 (0.6911)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:16:43 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 5 training takes 0:00:44
[2024-12-09 21:16:46 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.385 
[2024-12-09 21:16:46 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.385%
[2024-12-09 21:16:46 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.59%
[2024-12-09 21:16:46 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4887, Recall: 0.4887, F1: 0.3846
[2024-12-09 21:16:47 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][0/49]	eta 0:01:21 lr 0.000003	 wd 0.0000	time 1.6630 (1.6630)	loss 0.6934 (0.6934)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:16:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][10/49]	eta 0:00:37 lr 0.000003	 wd 0.0000	time 0.8072 (0.9633)	loss 0.6892 (0.6852)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:17:06 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][20/49]	eta 0:00:27 lr 0.000003	 wd 0.0000	time 0.8119 (0.9537)	loss 0.6998 (0.6887)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:17:15 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][30/49]	eta 0:00:17 lr 0.000003	 wd 0.0000	time 1.1783 (0.9336)	loss 0.6906 (0.6920)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:17:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][40/49]	eta 0:00:08 lr 0.000003	 wd 0.0000	time 0.7973 (0.9161)	loss 0.6764 (0.6913)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:17:31 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 6 training takes 0:00:45
[2024-12-09 21:17:33 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.551 
[2024-12-09 21:17:33 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.551%
[2024-12-09 21:17:33 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.59%
[2024-12-09 21:17:33 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5102, Recall: 0.5125, F1: 0.4999
[2024-12-09 21:17:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][0/49]	eta 0:00:57 lr 0.000003	 wd 0.0000	time 1.1737 (1.1737)	loss 0.6970 (0.6970)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:17:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][10/49]	eta 0:00:35 lr 0.000003	 wd 0.0000	time 1.1504 (0.9037)	loss 0.6936 (0.6836)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:17:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][20/49]	eta 0:00:25 lr 0.000003	 wd 0.0000	time 0.8167 (0.8938)	loss 0.6638 (0.6876)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:18:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][30/49]	eta 0:00:17 lr 0.000003	 wd 0.0000	time 0.8079 (0.9096)	loss 0.6590 (0.6879)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:18:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][40/49]	eta 0:00:07 lr 0.000003	 wd 0.0000	time 0.8250 (0.8844)	loss 0.6938 (0.6913)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:18:17 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 7 training takes 0:00:44
[2024-12-09 21:18:18 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.654 
[2024-12-09 21:18:18 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.654%
[2024-12-09 21:18:18 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.65%
[2024-12-09 21:18:18 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4196, Recall: 0.4624, F1: 0.4282
[2024-12-09 21:18:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][0/49]	eta 0:00:57 lr 0.000003	 wd 0.0000	time 1.1749 (1.1749)	loss 0.6942 (0.6942)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:18:29 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][10/49]	eta 0:00:37 lr 0.000003	 wd 0.0000	time 0.8146 (0.9740)	loss 0.6880 (0.6902)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:18:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][20/49]	eta 0:00:25 lr 0.000003	 wd 0.0000	time 0.7982 (0.8934)	loss 0.7112 (0.6873)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:18:47 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][30/49]	eta 0:00:17 lr 0.000003	 wd 0.0000	time 0.8073 (0.9082)	loss 0.6894 (0.6855)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:18:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][40/49]	eta 0:00:08 lr 0.000003	 wd 0.0000	time 1.1981 (0.9081)	loss 0.7362 (0.6890)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:19:03 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 8 training takes 0:00:44
[2024-12-09 21:19:04 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.462 
[2024-12-09 21:19:04 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.462%
[2024-12-09 21:19:04 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.65%
[2024-12-09 21:19:04 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4850, Recall: 0.4812, F1: 0.4436
[2024-12-09 21:19:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][0/49]	eta 0:00:57 lr 0.000003	 wd 0.0000	time 1.1824 (1.1824)	loss 0.6970 (0.6970)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:19:15 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][10/49]	eta 0:00:38 lr 0.000003	 wd 0.0000	time 0.8153 (0.9763)	loss 0.6981 (0.7043)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:19:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][20/49]	eta 0:00:27 lr 0.000003	 wd 0.0000	time 1.1655 (0.9348)	loss 0.7732 (0.6968)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.125
[2024-12-09 21:19:32 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][30/49]	eta 0:00:17 lr 0.000003	 wd 0.0000	time 0.8035 (0.9115)	loss 0.7150 (0.6936)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:19:42 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][40/49]	eta 0:00:08 lr 0.000003	 wd 0.0000	time 0.8036 (0.9180)	loss 0.7088 (0.6949)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:19:48 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 9 training takes 0:00:44
[2024-12-09 21:19:50 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.526 
[2024-12-09 21:19:50 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.526%
[2024-12-09 21:19:50 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.65%
[2024-12-09 21:19:50 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4960, Recall: 0.4950, F1: 0.4805
[2024-12-09 21:19:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][0/49]	eta 0:01:19 lr 0.000003	 wd 0.0000	time 1.6293 (1.6293)	loss 0.7216 (0.7216)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:20:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][10/49]	eta 0:00:37 lr 0.000003	 wd 0.0000	time 0.8145 (0.9716)	loss 0.6856 (0.6892)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:20:10 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][20/49]	eta 0:00:27 lr 0.000003	 wd 0.0000	time 0.8131 (0.9592)	loss 0.6830 (0.6905)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:20:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][30/49]	eta 0:00:17 lr 0.000003	 wd 0.0000	time 0.7984 (0.9106)	loss 0.6808 (0.6922)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:20:28 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][40/49]	eta 0:00:08 lr 0.000003	 wd 0.0000	time 0.8110 (0.9202)	loss 0.6848 (0.6893)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:20:35 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 10 training takes 0:00:44
[2024-12-09 21:20:37 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.487 
[2024-12-09 21:20:37 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.487%
[2024-12-09 21:20:37 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.65%
[2024-12-09 21:20:37 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4872, Recall: 0.4837, F1: 0.4583
[2024-12-09 21:20:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][0/49]	eta 0:00:58 lr 0.000003	 wd 0.0000	time 1.1888 (1.1888)	loss 0.7202 (0.7202)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:20:47 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][10/49]	eta 0:00:33 lr 0.000003	 wd 0.0000	time 0.8186 (0.8624)	loss 0.6740 (0.6743)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:20:57 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][20/49]	eta 0:00:27 lr 0.000003	 wd 0.0000	time 0.8152 (0.9478)	loss 0.7038 (0.6836)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:21:06 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][30/49]	eta 0:00:18 lr 0.000003	 wd 0.0000	time 0.8089 (0.9481)	loss 0.7258 (0.6862)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:21:15 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-09 21:21:15 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-09 21:21:15 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-09 21:21:16 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3200594
[2024-12-09 21:21:16 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-09 21:21:16 swin_tiny_patch4_window7_224] (main.py 160): INFO Start training
[2024-12-09 21:21:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][0/49]	eta 0:01:14 lr 0.000000	 wd 0.0000	time 1.5305 (1.5305)	loss 0.7375 (0.7375)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:21:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.8822 (0.9697)	loss 0.6507 (0.7199)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:21:36 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.7852 (0.9542)	loss 0.7157 (0.7170)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:21:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8181 (0.9063)	loss 0.6968 (0.7161)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:21:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8025 (0.9153)	loss 0.7580 (0.7104)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:22:00 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 0 training takes 0:00:44
[2024-12-09 21:22:02 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 21:22:02 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 21:22:02 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 21:22:02 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 21:22:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][0/49]	eta 0:01:01 lr 0.000000	 wd 0.0000	time 1.2539 (1.2539)	loss 0.7298 (0.7298)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:22:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][10/49]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.7920 (0.8539)	loss 0.7077 (0.6996)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:22:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][20/49]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.8221 (0.8919)	loss 0.7349 (0.6964)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:22:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1753 (0.9029)	loss 0.7151 (0.6958)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:22:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][40/49]	eta 0:00:07 lr 0.000000	 wd 0.0000	time 0.8164 (0.8843)	loss 0.6727 (0.6985)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:22:46 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 1 training takes 0:00:44
[2024-12-09 21:22:48 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 21:22:48 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 21:22:48 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 21:22:48 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 21:22:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1916 (1.1916)	loss 0.7214 (0.7214)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:22:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 1.1487 (0.9493)	loss 0.6961 (0.6991)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:23:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8135 (0.9023)	loss 0.7340 (0.7050)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:23:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8360 (0.9200)	loss 0.6923 (0.7005)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:23:25 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.2161 (0.9043)	loss 0.7032 (0.6995)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:23:33 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 2 training takes 0:00:44
[2024-12-09 21:23:34 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 21:23:34 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 21:23:34 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 21:23:34 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 21:23:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1750 (1.1750)	loss 0.7042 (0.7042)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:23:45 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.8079 (0.9740)	loss 0.6624 (0.6979)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:23:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 1.0685 (0.9064)	loss 0.6955 (0.6945)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:24:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8091 (0.9104)	loss 0.7198 (0.6976)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 21:24:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8444 (0.9181)	loss 0.6922 (0.6969)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:24:18 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 3 training takes 0:00:44
[2024-12-09 21:24:20 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 21:24:20 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 21:24:20 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 21:24:20 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 21:24:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][0/49]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.2080 (1.2080)	loss 0.6866 (0.6866)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:24:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8172 (0.9853)	loss 0.6831 (0.6889)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:24:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 1.0261 (0.9655)	loss 0.6702 (0.6946)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:24:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8099 (0.9155)	loss 0.6640 (0.6955)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:24:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8335 (0.9236)	loss 0.6955 (0.6958)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:25:04 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 4 training takes 0:00:44
[2024-12-09 21:25:07 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.718 
[2024-12-09 21:25:07 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.718%
[2024-12-09 21:25:07 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 21:25:07 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3636, Recall: 0.4912, F1: 0.4179
[2024-12-09 21:25:08 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][0/49]	eta 0:01:08 lr 0.000000	 wd 0.0000	time 1.3959 (1.3959)	loss 0.7045 (0.7045)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:25:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][10/49]	eta 0:00:34 lr 0.000000	 wd 0.0000	time 0.8305 (0.8818)	loss 0.7265 (0.6988)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.188
[2024-12-09 21:25:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8168 (0.9150)	loss 0.7049 (0.6969)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:25:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1766 (0.9177)	loss 0.7164 (0.6974)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.188
[2024-12-09 21:25:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8018 (0.8981)	loss 0.6754 (0.6969)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:25:52 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 5 training takes 0:00:44
[2024-12-09 21:25:53 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.744 
[2024-12-09 21:25:53 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.744%
[2024-12-09 21:25:53 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:25:53 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.7067, Recall: 0.5388, F1: 0.5076
[2024-12-09 21:25:54 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][0/49]	eta 0:00:56 lr 0.000000	 wd 0.0000	time 1.1586 (1.1586)	loss 0.7121 (0.7121)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:26:03 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 1.1604 (0.9408)	loss 0.6952 (0.6938)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:26:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][20/49]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.8040 (0.8957)	loss 0.7154 (0.6925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 21:26:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8103 (0.9106)	loss 0.6877 (0.6946)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:26:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1401 (0.8953)	loss 0.7127 (0.6956)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:26:37 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 6 training takes 0:00:44
[2024-12-09 21:26:39 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.718 
[2024-12-09 21:26:39 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.718%
[2024-12-09 21:26:39 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:26:39 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5699, Recall: 0.5213, F1: 0.4923
[2024-12-09 21:26:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1996 (1.1996)	loss 0.6907 (0.6907)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:26:50 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8014 (0.9788)	loss 0.6967 (0.6951)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:26:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.9969 (0.9046)	loss 0.6719 (0.6949)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:27:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.7929 (0.9093)	loss 0.6932 (0.6950)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:27:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8966 (0.9151)	loss 0.6792 (0.6949)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:27:23 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 7 training takes 0:00:43
[2024-12-09 21:27:25 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.705 
[2024-12-09 21:27:25 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.705%
[2024-12-09 21:27:25 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:27:25 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4899, Recall: 0.4975, F1: 0.4522
[2024-12-09 21:27:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1638 (1.1638)	loss 0.6791 (0.6791)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:27:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.7961 (0.9717)	loss 0.6852 (0.6921)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:27:45 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 1.1608 (0.9498)	loss 0.7000 (0.6891)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:27:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.7945 (0.9042)	loss 0.6869 (0.6900)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:28:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8137 (0.9128)	loss 0.6900 (0.6901)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:28:08 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 8 training takes 0:00:43
[2024-12-09 21:28:10 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.526 
[2024-12-09 21:28:10 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.526%
[2024-12-09 21:28:10 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:28:10 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5437, Recall: 0.5551, F1: 0.5074
[2024-12-09 21:28:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][0/49]	eta 0:01:18 lr 0.000000	 wd 0.0000	time 1.6112 (1.6112)	loss 0.6965 (0.6965)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:28:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 0.8090 (0.9236)	loss 0.7084 (0.6914)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:28:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8052 (0.9351)	loss 0.7043 (0.6941)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:28:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.9702 (0.9002)	loss 0.7204 (0.6936)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:28:47 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8004 (0.9045)	loss 0.6825 (0.6943)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:28:55 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 9 training takes 0:00:44
[2024-12-09 21:28:57 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.615 
[2024-12-09 21:28:57 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.615%
[2024-12-09 21:28:57 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:28:57 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4783, Recall: 0.4812, F1: 0.4781
[2024-12-09 21:28:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1929 (1.1929)	loss 0.6950 (0.6950)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:29:06 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][10/49]	eta 0:00:34 lr 0.000000	 wd 0.0000	time 1.1185 (0.8857)	loss 0.6792 (0.6905)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:29:15 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8051 (0.9009)	loss 0.7013 (0.6909)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:29:25 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.7982 (0.9153)	loss 0.6972 (0.6927)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:29:33 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.7996 (0.8896)	loss 0.6962 (0.6930)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:29:41 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 10 training takes 0:00:44
[2024-12-09 21:29:42 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 21:29:42 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 21:29:42 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:29:42 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.6184, Recall: 0.5150, F1: 0.4645
[2024-12-09 21:29:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1677 (1.1677)	loss 0.6949 (0.6949)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:29:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8839 (0.9864)	loss 0.7074 (0.6908)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:30:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8686 (0.9071)	loss 0.7015 (0.6939)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:30:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.7992 (0.9187)	loss 0.7056 (0.6947)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:30:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1836 (0.9167)	loss 0.7144 (0.6955)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:30:27 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 11 training takes 0:00:44
[2024-12-09 21:30:29 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 21:30:29 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 21:30:29 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:30:29 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 21:30:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][0/49]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.2132 (1.2132)	loss 0.6896 (0.6896)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:30:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8062 (0.9802)	loss 0.6759 (0.6924)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:30:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 1.1686 (0.9386)	loss 0.6638 (0.6938)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 21:30:57 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8037 (0.9170)	loss 0.7189 (0.6929)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 21:31:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8150 (0.9250)	loss 0.7053 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:31:13 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 12 training takes 0:00:44
[2024-12-09 21:31:15 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.705 
[2024-12-09 21:31:15 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.705%
[2024-12-09 21:31:15 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:31:15 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3618, Recall: 0.4825, F1: 0.4135
[2024-12-09 21:31:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][0/49]	eta 0:01:16 lr 0.000000	 wd 0.0000	time 1.5646 (1.5646)	loss 0.6890 (0.6890)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:31:25 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.8094 (0.9590)	loss 0.6895 (0.6913)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:31:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8021 (0.9537)	loss 0.6817 (0.6911)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:31:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8117 (0.9046)	loss 0.7009 (0.6917)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:31:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8107 (0.9145)	loss 0.7078 (0.6919)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:31:59 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 13 training takes 0:00:44
[2024-12-09 21:32:01 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 21:32:01 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 21:32:01 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:32:01 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.6184, Recall: 0.5150, F1: 0.4645
[2024-12-09 21:32:03 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][0/49]	eta 0:01:03 lr 0.000000	 wd 0.0000	time 1.2978 (1.2978)	loss 0.6945 (0.6945)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:32:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][10/49]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.7836 (0.8625)	loss 0.7013 (0.6958)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:32:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8009 (0.9040)	loss 0.6937 (0.6954)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:32:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1487 (0.9089)	loss 0.6786 (0.6967)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:32:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [14/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8057 (0.8940)	loss 0.6910 (0.6957)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:32:46 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 14 training takes 0:00:44
[2024-12-09 21:32:48 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.615 
[2024-12-09 21:32:48 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.615%
[2024-12-09 21:32:48 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:32:48 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4571, Recall: 0.4662, F1: 0.4583
[2024-12-09 21:32:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][0/49]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.2081 (1.2081)	loss 0.7036 (0.7036)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:32:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 1.1458 (0.9316)	loss 0.6745 (0.6963)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:33:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8103 (0.9070)	loss 0.6847 (0.6958)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:33:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8323 (0.9202)	loss 0.6960 (0.6938)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:33:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [15/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8141 (0.8927)	loss 0.6767 (0.6947)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:33:32 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 15 training takes 0:00:44
[2024-12-09 21:33:34 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.551 
[2024-12-09 21:33:34 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.551%
[2024-12-09 21:33:34 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:33:34 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4850, Recall: 0.4825, F1: 0.4793
[2024-12-09 21:33:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1670 (1.1670)	loss 0.6713 (0.6713)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 21:33:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.8103 (0.9723)	loss 0.7127 (0.6966)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:33:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][20/49]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.8072 (0.8939)	loss 0.6873 (0.6942)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:34:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8192 (0.9135)	loss 0.6810 (0.6946)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:34:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [16/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1738 (0.9222)	loss 0.6948 (0.6937)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:34:18 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 16 training takes 0:00:44
[2024-12-09 21:34:20 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.577 
[2024-12-09 21:34:20 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.577%
[2024-12-09 21:34:20 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:34:20 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4708, Recall: 0.4699, F1: 0.4703
[2024-12-09 21:34:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1898 (1.1898)	loss 0.7029 (0.7029)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:34:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8257 (0.9800)	loss 0.6908 (0.6912)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:34:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 1.1757 (0.9548)	loss 0.6983 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:34:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8214 (0.9116)	loss 0.6829 (0.6931)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:34:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [17/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8082 (0.9198)	loss 0.6966 (0.6926)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:35:04 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 17 training takes 0:00:44
[2024-12-09 21:35:06 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.603 
[2024-12-09 21:35:06 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.603%
[2024-12-09 21:35:06 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:35:06 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3902, Recall: 0.4273, F1: 0.4043
[2024-12-09 21:35:08 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][0/49]	eta 0:01:21 lr 0.000000	 wd 0.0000	time 1.6559 (1.6559)	loss 0.6774 (0.6774)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:35:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 0.8221 (0.9353)	loss 0.6904 (0.6890)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:35:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8061 (0.9429)	loss 0.6816 (0.6884)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:35:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.0306 (0.9073)	loss 0.7082 (0.6889)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:35:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [18/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.7976 (0.9094)	loss 0.7019 (0.6906)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:35:51 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 18 training takes 0:00:44
[2024-12-09 21:35:53 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.603 
[2024-12-09 21:35:53 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.603%
[2024-12-09 21:35:53 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:35:53 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5162, Recall: 0.5175, F1: 0.5159
[2024-12-09 21:35:54 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][0/49]	eta 0:00:56 lr 0.000000	 wd 0.0000	time 1.1429 (1.1429)	loss 0.6987 (0.6987)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:36:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][10/49]	eta 0:00:34 lr 0.000000	 wd 0.0000	time 1.1092 (0.8798)	loss 0.6984 (0.6977)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:36:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8178 (0.9004)	loss 0.7082 (0.6940)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:36:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8897 (0.9168)	loss 0.6856 (0.6947)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:36:29 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [19/70][40/49]	eta 0:00:07 lr 0.000000	 wd 0.0000	time 0.7829 (0.8885)	loss 0.7053 (0.6950)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:36:37 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 19 training takes 0:00:44
[2024-12-09 21:36:39 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.667 
[2024-12-09 21:36:39 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.667%
[2024-12-09 21:36:39 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:36:39 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5020, Recall: 0.5013, F1: 0.4889
[2024-12-09 21:36:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1998 (1.1998)	loss 0.6882 (0.6882)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:36:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 1.1194 (0.9786)	loss 0.7304 (0.6925)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:36:57 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][20/49]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.8047 (0.8943)	loss 0.6808 (0.6939)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:37:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.7997 (0.9108)	loss 0.6773 (0.6916)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:37:15 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [20/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1391 (0.8985)	loss 0.6884 (0.6906)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:37:23 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 20 training takes 0:00:44
[2024-12-09 21:37:24 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.603 
[2024-12-09 21:37:24 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.603%
[2024-12-09 21:37:24 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:37:24 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3456, Recall: 0.4123, F1: 0.3760
[2024-12-09 21:37:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1711 (1.1711)	loss 0.7194 (0.7194)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.188
[2024-12-09 21:37:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8004 (0.9772)	loss 0.7005 (0.7045)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:37:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.9987 (0.9054)	loss 0.6796 (0.6948)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:37:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8179 (0.9107)	loss 0.6893 (0.6917)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:38:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [21/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.0029 (0.9184)	loss 0.6870 (0.6912)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:38:09 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 21 training takes 0:00:44
[2024-12-09 21:38:10 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.705 
[2024-12-09 21:38:10 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.705%
[2024-12-09 21:38:10 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:38:10 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4899, Recall: 0.4975, F1: 0.4522
[2024-12-09 21:38:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1670 (1.1670)	loss 0.6889 (0.6889)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:38:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8159 (0.9787)	loss 0.6643 (0.6952)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:38:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 1.1908 (0.9635)	loss 0.7057 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:38:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.7943 (0.9139)	loss 0.6849 (0.6927)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:38:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [22/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8071 (0.9207)	loss 0.6921 (0.6921)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:38:54 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 22 training takes 0:00:44
[2024-12-09 21:38:57 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.615 
[2024-12-09 21:38:57 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.615%
[2024-12-09 21:38:57 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:38:57 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4308, Recall: 0.4511, F1: 0.4359
[2024-12-09 21:38:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][0/49]	eta 0:01:20 lr 0.000000	 wd 0.0000	time 1.6368 (1.6368)	loss 0.6881 (0.6881)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:39:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 0.8087 (0.9244)	loss 0.7095 (0.6917)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:39:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8146 (0.9365)	loss 0.6874 (0.6941)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:39:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.0263 (0.9014)	loss 0.7062 (0.6927)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:39:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [23/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.7947 (0.9052)	loss 0.6892 (0.6940)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:39:41 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 23 training takes 0:00:44
[2024-12-09 21:39:43 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.500 
[2024-12-09 21:39:43 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.500%
[2024-12-09 21:39:43 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:39:43 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4699, Recall: 0.4624, F1: 0.4524
[2024-12-09 21:39:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1659 (1.1659)	loss 0.7000 (0.7000)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:39:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][10/49]	eta 0:00:34 lr 0.000000	 wd 0.0000	time 1.1332 (0.8759)	loss 0.6800 (0.6872)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:40:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][20/49]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.7870 (0.8879)	loss 0.6661 (0.6867)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:40:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8428 (0.9068)	loss 0.6973 (0.6890)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:40:19 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [24/70][40/49]	eta 0:00:07 lr 0.000000	 wd 0.0000	time 0.7849 (0.8816)	loss 0.7001 (0.6889)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:40:27 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 24 training takes 0:00:44
[2024-12-09 21:40:28 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.590 
[2024-12-09 21:40:28 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.590%
[2024-12-09 21:40:28 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:40:28 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4941, Recall: 0.4937, F1: 0.4935
[2024-12-09 21:40:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.2036 (1.2036)	loss 0.6987 (0.6987)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:40:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 1.0331 (0.9906)	loss 0.6908 (0.6995)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:40:47 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8358 (0.9041)	loss 0.6899 (0.6955)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:40:57 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8133 (0.9187)	loss 0.7035 (0.6958)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:41:06 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [25/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1439 (0.9071)	loss 0.6727 (0.6960)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:41:13 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 25 training takes 0:00:44
[2024-12-09 21:41:14 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.590 
[2024-12-09 21:41:14 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.590%
[2024-12-09 21:41:14 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:41:14 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4787, Recall: 0.4787, F1: 0.4787
[2024-12-09 21:41:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1760 (1.1760)	loss 0.6851 (0.6851)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:41:25 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][10/49]	eta 0:00:37 lr 0.000000	 wd 0.0000	time 0.8066 (0.9736)	loss 0.7065 (0.6946)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:41:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 1.1613 (0.9149)	loss 0.6972 (0.6945)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:41:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8137 (0.9108)	loss 0.6998 (0.6939)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:41:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [26/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8032 (0.9198)	loss 0.6815 (0.6913)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:41:59 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 26 training takes 0:00:44
[2024-12-09 21:42:00 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.551 
[2024-12-09 21:42:00 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.551%
[2024-12-09 21:42:00 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:42:00 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4712, Recall: 0.4674, F1: 0.4671
[2024-12-09 21:42:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][0/49]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 1.2329 (1.2329)	loss 0.7026 (0.7026)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:42:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.7948 (0.9780)	loss 0.6933 (0.6931)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:42:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 1.1041 (0.9590)	loss 0.6983 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:42:28 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8057 (0.9093)	loss 0.6929 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:42:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [27/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8072 (0.9183)	loss 0.6803 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:42:44 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 27 training takes 0:00:44
[2024-12-09 21:42:46 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.641 
[2024-12-09 21:42:46 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.641%
[2024-12-09 21:42:46 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:42:46 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5439, Recall: 0.5439, F1: 0.5439
[2024-12-09 21:42:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][0/49]	eta 0:01:23 lr 0.000000	 wd 0.0000	time 1.6984 (1.6984)	loss 0.6803 (0.6803)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:42:57 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][10/49]	eta 0:00:35 lr 0.000000	 wd 0.0000	time 0.7961 (0.9207)	loss 0.7031 (0.6897)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:43:06 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8003 (0.9348)	loss 0.6913 (0.6889)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:43:14 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.0717 (0.9036)	loss 0.6820 (0.6905)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:43:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [28/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8108 (0.9088)	loss 0.6966 (0.6923)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:43:31 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 28 training takes 0:00:44
[2024-12-09 21:43:33 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.603 
[2024-12-09 21:43:33 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.603%
[2024-12-09 21:43:33 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:43:33 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4694, Recall: 0.4724, F1: 0.4701
[2024-12-09 21:43:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1681 (1.1681)	loss 0.6684 (0.6684)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:43:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][10/49]	eta 0:00:34 lr 0.000000	 wd 0.0000	time 1.1240 (0.8809)	loss 0.6832 (0.6920)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:43:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8212 (0.8979)	loss 0.6819 (0.6939)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:44:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8390 (0.9140)	loss 0.7064 (0.6938)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:44:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [29/70][40/49]	eta 0:00:07 lr 0.000000	 wd 0.0000	time 0.8261 (0.8882)	loss 0.6916 (0.6939)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:44:17 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 29 training takes 0:00:44
[2024-12-09 21:44:19 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.564 
[2024-12-09 21:44:19 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.564%
[2024-12-09 21:44:19 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:44:19 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4924, Recall: 0.4912, F1: 0.4884
[2024-12-09 21:44:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1808 (1.1808)	loss 0.6928 (0.6928)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:44:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 1.0403 (0.9829)	loss 0.7056 (0.6937)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:44:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8147 (0.9068)	loss 0.6804 (0.6924)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 21:44:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8238 (0.9241)	loss 0.7261 (0.6937)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:44:57 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [30/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.1821 (0.9202)	loss 0.7032 (0.6936)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:45:04 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 30 training takes 0:00:44
[2024-12-09 21:45:05 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.590 
[2024-12-09 21:45:05 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.590%
[2024-12-09 21:45:05 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:45:05 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4941, Recall: 0.4937, F1: 0.4935
[2024-12-09 21:45:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][0/49]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 1.1946 (1.1946)	loss 0.6945 (0.6945)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:45:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8136 (0.9899)	loss 0.7120 (0.6914)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 21:45:25 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 1.1679 (0.9399)	loss 0.6797 (0.6905)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:45:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8571 (0.9255)	loss 0.7307 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:45:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [31/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8350 (0.9337)	loss 0.6795 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:45:50 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 31 training takes 0:00:44
[2024-12-09 21:45:52 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.551 
[2024-12-09 21:45:52 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.551%
[2024-12-09 21:45:52 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:45:52 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4198, Recall: 0.4223, F1: 0.4210
[2024-12-09 21:45:54 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][0/49]	eta 0:01:22 lr 0.000000	 wd 0.0000	time 1.6867 (1.6867)	loss 0.6948 (0.6948)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:46:03 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8283 (0.9791)	loss 0.7064 (0.6962)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:46:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][20/49]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 0.8262 (0.9657)	loss 0.6984 (0.6945)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:46:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8029 (0.9157)	loss 0.6671 (0.6923)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:46:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [32/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8167 (0.9252)	loss 0.6796 (0.6932)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:46:37 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 32 training takes 0:00:45
[2024-12-09 21:46:39 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.474 
[2024-12-09 21:46:39 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.474%
[2024-12-09 21:46:39 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:46:39 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3846, Recall: 0.3697, F1: 0.3758
[2024-12-09 21:46:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][0/49]	eta 0:01:02 lr 0.000000	 wd 0.0000	time 1.2788 (1.2788)	loss 0.6931 (0.6931)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:46:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][10/49]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.8004 (0.8614)	loss 0.6880 (0.6923)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:46:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.8077 (0.9044)	loss 0.6861 (0.6902)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:47:08 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 1.1658 (0.9126)	loss 0.7011 (0.6904)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:47:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [33/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8222 (0.8937)	loss 0.6947 (0.6937)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:47:24 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 33 training takes 0:00:44
[2024-12-09 21:47:25 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.603 
[2024-12-09 21:47:25 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.603%
[2024-12-09 21:47:25 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:47:25 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4694, Recall: 0.4724, F1: 0.4701
[2024-12-09 21:47:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][0/49]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 1.2155 (1.2155)	loss 0.6997 (0.6997)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:47:36 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][10/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 1.1493 (0.9360)	loss 0.7206 (0.6994)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:47:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][20/49]	eta 0:00:25 lr 0.000000	 wd 0.0000	time 0.8217 (0.8943)	loss 0.6702 (0.6930)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 21:47:54 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8103 (0.9140)	loss 0.6940 (0.6913)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:48:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [34/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 1.0425 (0.8959)	loss 0.6850 (0.6916)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:48:10 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 34 training takes 0:00:44
[2024-12-09 21:48:11 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.513 
[2024-12-09 21:48:11 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.513%
[2024-12-09 21:48:11 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:48:11 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4640, Recall: 0.4561, F1: 0.4519
[2024-12-09 21:48:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][0/49]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 1.1757 (1.1757)	loss 0.6913 (0.6913)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:48:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.8092 (0.9849)	loss 0.7075 (0.6865)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:48:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][20/49]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 1.0023 (0.9119)	loss 0.6923 (0.6916)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:48:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][30/49]	eta 0:00:17 lr 0.000000	 wd 0.0000	time 0.8008 (0.9197)	loss 0.7041 (0.6924)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:48:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [35/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.9018 (0.9255)	loss 0.7061 (0.6944)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:48:56 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 35 training takes 0:00:44
[2024-12-09 21:48:58 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.538 
[2024-12-09 21:48:58 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.538%
[2024-12-09 21:48:58 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.74%
[2024-12-09 21:48:58 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4135, Recall: 0.4135, F1: 0.4135
[2024-12-09 21:48:59 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [36/70][0/49]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 1.2408 (1.2408)	loss 0.7261 (0.7261)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:49:20 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-09 21:49:20 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-09 21:49:20 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-09 21:49:20 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3208706
[2024-12-09 21:49:20 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-09 21:49:20 swin_tiny_patch4_window7_224] (main.py 160): INFO Start training
[2024-12-09 21:49:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][0/49]	eta 0:00:53 lr 0.000000	 wd 0.0000	time 1.0884 (1.0884)	loss 0.7199 (0.7199)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:49:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][10/49]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 0.8435 (1.0147)	loss 0.7147 (0.6861)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:49:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8653 (0.9441)	loss 0.6430 (0.7004)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:49:50 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 0.8489 (0.9613)	loss 0.6434 (0.7032)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:50:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8800 (0.9689)	loss 0.7514 (0.7053)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:50:07 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 0 training takes 0:00:46
[2024-12-09 21:50:09 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 21:50:09 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 21:50:09 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 21:50:09 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 21:50:10 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][0/49]	eta 0:01:17 lr 0.000000	 wd 0.0000	time 1.5757 (1.5757)	loss 0.6883 (0.6883)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:50:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][10/49]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 0.8765 (1.0319)	loss 0.7012 (0.7127)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:50:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][20/49]	eta 0:00:29 lr 0.000000	 wd 0.0000	time 0.8666 (1.0185)	loss 0.6680 (0.7081)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:50:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][30/49]	eta 0:00:18 lr 0.000000	 wd 0.0000	time 1.1732 (0.9795)	loss 0.7274 (0.6990)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:50:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][40/49]	eta 0:00:08 lr 0.000000	 wd 0.0000	time 0.8537 (0.9745)	loss 0.6680 (0.6979)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:50:57 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 1 training takes 0:00:48
[2024-12-09 21:50:59 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 21:50:59 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 21:50:59 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 21:50:59 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 21:51:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][0/49]	eta 0:01:02 lr 0.000000	 wd 0.0000	time 1.2677 (1.2677)	loss 0.7093 (0.7093)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:51:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][10/49]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 1.2126 (0.9868)	loss 0.7378 (0.6995)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 21:51:19 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][20/49]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.8534 (0.9465)	loss 0.7091 (0.6939)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:51:41 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 70
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 10
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-09 21:51:41 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-09 21:51:41 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-09 21:51:41 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3224930
[2024-12-09 21:51:41 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-09 21:51:41 swin_tiny_patch4_window7_224] (main.py 160): INFO Start training
[2024-12-09 21:51:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][0/49]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 1.2424 (1.2424)	loss 0.6913 (0.6913)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:51:54 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][10/49]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 0.9623 (1.1372)	loss 0.7327 (0.7008)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:52:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][20/49]	eta 0:00:31 lr 0.000000	 wd 0.0000	time 1.4063 (1.1013)	loss 0.7085 (0.6997)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:52:15 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.9855 (1.0775)	loss 0.7272 (0.6987)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:52:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.9933 (1.0867)	loss 0.6624 (0.6972)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:52:35 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 0 training takes 0:00:53
[2024-12-09 21:52:37 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 21:52:37 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 21:52:37 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 21:52:37 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 21:52:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][0/49]	eta 0:01:07 lr 0.000000	 wd 0.0000	time 1.3834 (1.3834)	loss 0.7153 (0.7153)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:52:50 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][10/49]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 1.0410 (1.1710)	loss 0.7037 (0.7112)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:53:00 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][20/49]	eta 0:00:31 lr 0.000000	 wd 0.0000	time 1.2218 (1.0896)	loss 0.7300 (0.6968)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:53:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][30/49]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.9606 (1.1058)	loss 0.7186 (0.6988)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:53:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.9693 (1.1066)	loss 0.7127 (0.6967)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:53:31 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 1 training takes 0:00:54
[2024-12-09 21:53:34 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 21:53:34 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 21:53:34 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 21:53:34 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 21:53:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][0/49]	eta 0:01:07 lr 0.000000	 wd 0.0000	time 1.3752 (1.3752)	loss 0.7011 (0.7011)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 21:53:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][10/49]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 1.3255 (1.1545)	loss 0.6858 (0.6871)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:53:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][20/49]	eta 0:00:31 lr 0.000000	 wd 0.0000	time 1.0002 (1.0753)	loss 0.7016 (0.6843)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:54:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 1.0249 (1.0914)	loss 0.7057 (0.6911)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:54:19 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 1.0012 (1.0988)	loss 0.6900 (0.6919)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:54:27 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 2 training takes 0:00:53
[2024-12-09 21:54:30 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 21:54:30 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 21:54:30 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 21:54:30 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 21:54:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][0/49]	eta 0:01:09 lr 0.000000	 wd 0.0000	time 1.4162 (1.4162)	loss 0.6937 (0.6937)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:54:42 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][10/49]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3839 (1.1302)	loss 0.6875 (0.6950)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:54:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][20/49]	eta 0:00:31 lr 0.000000	 wd 0.0000	time 0.9664 (1.0766)	loss 0.6921 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 21:55:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.9674 (1.0874)	loss 0.6867 (0.6919)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:55:15 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/70][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.9633 (1.0916)	loss 0.7346 (0.6931)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.125
[2024-12-09 21:55:23 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 3 training takes 0:00:52
[2024-12-09 21:55:26 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 21:55:26 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 21:55:26 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 21:55:26 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 21:55:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][0/49]	eta 0:01:13 lr 0.000000	 wd 0.0000	time 1.4989 (1.4989)	loss 0.6910 (0.6910)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:55:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/70][10/49]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 1.3950 (1.1117)	loss 0.7183 (0.7009)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:57:00 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-05
  CLIP_GRAD: 5.0
  EPOCHS: 20
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-09 21:57:00 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-09 21:57:00 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-09 21:57:00 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3224930
[2024-12-09 21:57:00 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-09 21:57:00 swin_tiny_patch4_window7_224] (main.py 160): INFO Start training
[2024-12-09 21:57:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/20][0/49]	eta 0:01:27 lr 0.000000	 wd 0.0000	time 1.7936 (1.7936)	loss 0.6913 (0.6913)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:57:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/20][10/49]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 0.9685 (1.1362)	loss 0.7327 (0.7008)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:57:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/20][20/49]	eta 0:00:32 lr 0.000000	 wd 0.0000	time 1.0015 (1.1222)	loss 0.7085 (0.6997)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:57:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/20][30/49]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.9693 (1.1160)	loss 0.7272 (0.6987)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 21:57:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 1.3986 (1.1003)	loss 0.6624 (0.6972)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 21:57:54 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 0 training takes 0:00:53
[2024-12-09 21:57:56 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 21:57:56 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 21:57:56 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 21:57:56 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 21:57:57 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/20][0/49]	eta 0:01:06 lr 0.000000	 wd 0.0000	time 1.3648 (1.3648)	loss 0.7153 (0.7153)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:58:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/20][10/49]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 0.9840 (1.1434)	loss 0.7037 (0.7112)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:58:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/20][20/49]	eta 0:00:32 lr 0.000000	 wd 0.0000	time 0.9564 (1.1221)	loss 0.7300 (0.6968)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:58:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/20][30/49]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 1.2702 (1.1195)	loss 0.7186 (0.6988)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 21:58:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 1.0391 (1.0870)	loss 0.7127 (0.6967)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 21:58:50 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 1 training takes 0:00:53
[2024-12-09 21:58:52 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 21:58:52 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 21:58:52 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 21:58:52 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 21:58:53 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/20][0/49]	eta 0:01:09 lr 0.000000	 wd 0.0000	time 1.4174 (1.4174)	loss 0.7011 (0.7011)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 21:59:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/20][10/49]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 0.9752 (1.1490)	loss 0.6858 (0.6871)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:59:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/20][20/49]	eta 0:00:32 lr 0.000000	 wd 0.0000	time 0.9874 (1.1319)	loss 0.7016 (0.6843)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:59:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/20][30/49]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 1.4225 (1.1133)	loss 0.7057 (0.6911)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 21:59:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.9796 (1.0896)	loss 0.6900 (0.6919)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 21:59:46 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 2 training takes 0:00:53
[2024-12-09 21:59:48 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 21:59:48 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 21:59:48 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 21:59:48 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 21:59:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/20][0/49]	eta 0:01:07 lr 0.000000	 wd 0.0000	time 1.3841 (1.3841)	loss 0.6937 (0.6937)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 22:00:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/20][10/49]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.0057 (1.1520)	loss 0.6875 (0.6950)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:00:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/20][20/49]	eta 0:00:32 lr 0.000000	 wd 0.0000	time 1.0367 (1.1296)	loss 0.6921 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 22:00:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/20][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 1.1679 (1.0847)	loss 0.6867 (0.6919)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:00:32 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.9577 (1.0832)	loss 0.7346 (0.6931)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.125
[2024-12-09 22:00:41 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 3 training takes 0:00:53
[2024-12-09 22:00:44 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 22:00:44 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 22:00:44 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 22:00:44 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 22:00:45 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/20][0/49]	eta 0:01:08 lr 0.000000	 wd 0.0000	time 1.3900 (1.3900)	loss 0.6910 (0.6910)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:00:57 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/20][10/49]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 0.9611 (1.1781)	loss 0.7183 (0.7009)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 22:01:10 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/20][20/49]	eta 0:00:36 lr 0.000000	 wd 0.0000	time 0.9792 (1.2621)	loss 0.6772 (0.6963)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:01:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/20][30/49]	eta 0:00:22 lr 0.000000	 wd 0.0000	time 1.3834 (1.1816)	loss 0.7115 (0.6943)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 22:01:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/20][40/49]	eta 0:00:10 lr 0.000000	 wd 0.0000	time 0.9736 (1.1526)	loss 0.6833 (0.6930)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 22:01:40 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 4 training takes 0:00:56
[2024-12-09 22:01:42 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.679 
[2024-12-09 22:01:42 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.679%
[2024-12-09 22:01:42 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 22:01:42 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4444, Recall: 0.4799, F1: 0.4401
[2024-12-09 22:01:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/20][0/49]	eta 0:01:07 lr 0.000000	 wd 0.0000	time 1.3845 (1.3845)	loss 0.7022 (0.7022)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 22:01:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/20][10/49]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 0.9761 (1.1354)	loss 0.6838 (0.6905)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 22:02:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/20][20/49]	eta 0:00:32 lr 0.000000	 wd 0.0000	time 1.3935 (1.1140)	loss 0.6960 (0.6914)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:02:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/20][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.9761 (1.0796)	loss 0.6796 (0.6909)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:02:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.9724 (1.0866)	loss 0.6940 (0.6913)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:02:36 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 5 training takes 0:00:53
[2024-12-09 22:02:38 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.679 
[2024-12-09 22:02:38 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.679%
[2024-12-09 22:02:38 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 22:02:38 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4444, Recall: 0.4799, F1: 0.4401
[2024-12-09 22:02:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/20][0/49]	eta 0:01:10 lr 0.000000	 wd 0.0000	time 1.4451 (1.4451)	loss 0.7044 (0.7044)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:02:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/20][10/49]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 0.9680 (1.1483)	loss 0.7010 (0.6882)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:03:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/20][20/49]	eta 0:00:31 lr 0.000000	 wd 0.0000	time 1.4097 (1.0902)	loss 0.6829 (0.6911)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 22:03:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/20][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.9785 (1.0790)	loss 0.6963 (0.6924)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:03:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.9610 (1.0847)	loss 0.6549 (0.6921)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.812
[2024-12-09 22:03:31 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 6 training takes 0:00:53
[2024-12-09 22:03:34 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.628 
[2024-12-09 22:03:34 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.628%
[2024-12-09 22:03:34 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 22:03:34 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4665, Recall: 0.4749, F1: 0.4659
[2024-12-09 22:03:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/20][0/49]	eta 0:01:08 lr 0.000000	 wd 0.0000	time 1.4010 (1.4010)	loss 0.6801 (0.6801)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 22:03:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/20][10/49]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.2777 (1.1370)	loss 0.6927 (0.6867)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:03:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/20][20/49]	eta 0:00:30 lr 0.000000	 wd 0.0000	time 0.9763 (1.0574)	loss 0.6927 (0.6929)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:04:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/20][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.9682 (1.0684)	loss 0.6882 (0.6906)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:04:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.9722 (1.0767)	loss 0.6872 (0.6904)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:04:26 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 7 training takes 0:00:52
[2024-12-09 22:04:29 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.564 
[2024-12-09 22:04:29 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.564%
[2024-12-09 22:04:29 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 22:04:29 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4031, Recall: 0.4160, F1: 0.4086
[2024-12-09 22:04:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/20][0/49]	eta 0:01:08 lr 0.000000	 wd 0.0000	time 1.4005 (1.4005)	loss 0.7138 (0.7138)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 22:04:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/20][10/49]	eta 0:00:42 lr 0.000000	 wd 0.0000	time 1.3756 (1.0828)	loss 0.6851 (0.6998)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:04:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/20][20/49]	eta 0:00:30 lr 0.000000	 wd 0.0000	time 0.9661 (1.0615)	loss 0.6942 (0.6971)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:05:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/20][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.9629 (1.0724)	loss 0.6778 (0.6944)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 22:05:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 1.0077 (1.0802)	loss 0.7012 (0.6958)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:05:21 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 8 training takes 0:00:52
[2024-12-09 22:05:24 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.590 
[2024-12-09 22:05:24 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.590%
[2024-12-09 22:05:24 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 22:05:24 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4787, Recall: 0.4787, F1: 0.4787
[2024-12-09 22:05:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/20][0/49]	eta 0:01:34 lr 0.000000	 wd 0.0000	time 1.9234 (1.9234)	loss 0.6962 (0.6962)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:05:36 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/20][10/49]	eta 0:00:41 lr 0.000000	 wd 0.0000	time 0.9626 (1.0759)	loss 0.7000 (0.6873)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:05:47 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/20][20/49]	eta 0:00:31 lr 0.000000	 wd 0.0000	time 0.9781 (1.0884)	loss 0.7081 (0.6890)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:05:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/20][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.9804 (1.0945)	loss 0.6821 (0.6906)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:06:08 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 1.3414 (1.0911)	loss 0.6988 (0.6922)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 22:06:17 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 9 training takes 0:00:53
[2024-12-09 22:06:19 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.538 
[2024-12-09 22:06:19 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.538%
[2024-12-09 22:06:19 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 22:06:19 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4135, Recall: 0.4135, F1: 0.4135
[2024-12-09 22:06:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/20][0/49]	eta 0:01:33 lr 0.000000	 wd 0.0000	time 1.9051 (1.9051)	loss 0.6958 (0.6958)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:07:03 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 0.0003125
  CLIP_GRAD: 5.0
  EPOCHS: 20
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 4
  WARMUP_LR: 3.125e-06
  WEIGHT_DECAY: 0.0001

[2024-12-09 22:07:03 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-09 22:07:03 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-09 22:07:03 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3224930
[2024-12-09 22:07:03 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-09 22:07:03 swin_tiny_patch4_window7_224] (main.py 160): INFO Start training
[2024-12-09 22:07:05 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/20][0/49]	eta 0:01:01 lr 0.000003	 wd 0.0001	time 1.2505 (1.2505)	loss 0.6913 (0.6913)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:07:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/20][10/49]	eta 0:00:44 lr 0.000003	 wd 0.0001	time 0.9832 (1.1406)	loss 0.7151 (0.6953)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:07:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/20][20/49]	eta 0:00:31 lr 0.000003	 wd 0.0001	time 1.4169 (1.0899)	loss 0.6991 (0.6975)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:07:37 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/20][30/49]	eta 0:00:20 lr 0.000003	 wd 0.0001	time 1.0183 (1.0790)	loss 0.7108 (0.6953)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:07:48 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/20][40/49]	eta 0:00:09 lr 0.000003	 wd 0.0001	time 0.9859 (1.0847)	loss 0.6907 (0.6951)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 22:07:57 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 0 training takes 0:00:53
[2024-12-09 22:07:59 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.500 
[2024-12-09 22:07:59 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.500%
[2024-12-09 22:07:59 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.50%
[2024-12-09 22:07:59 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4699, Recall: 0.4624, F1: 0.4524
[2024-12-09 22:08:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/20][0/49]	eta 0:01:08 lr 0.000003	 wd 0.0001	time 1.3979 (1.3979)	loss 0.7094 (0.7094)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 22:08:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/20][10/49]	eta 0:00:44 lr 0.000003	 wd 0.0001	time 1.3209 (1.1494)	loss 0.7029 (0.6951)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:08:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/20][20/49]	eta 0:00:30 lr 0.000003	 wd 0.0001	time 0.9782 (1.0680)	loss 0.6905 (0.6994)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:08:33 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/20][30/49]	eta 0:00:20 lr 0.000003	 wd 0.0001	time 0.9768 (1.0800)	loss 0.7091 (0.6975)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 22:08:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/20][40/49]	eta 0:00:09 lr 0.000003	 wd 0.0001	time 0.9761 (1.0880)	loss 0.7013 (0.6959)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 22:08:52 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 1 training takes 0:00:52
[2024-12-09 22:08:55 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.654 
[2024-12-09 22:08:55 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.654%
[2024-12-09 22:08:55 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.65%
[2024-12-09 22:08:55 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3542, Recall: 0.4474, F1: 0.3953
[2024-12-09 22:08:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/20][0/49]	eta 0:01:08 lr 0.000003	 wd 0.0001	time 1.4043 (1.4043)	loss 0.6805 (0.6805)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 22:09:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/20][10/49]	eta 0:00:42 lr 0.000003	 wd 0.0001	time 1.3752 (1.0791)	loss 0.6697 (0.6844)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 22:09:17 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/20][20/49]	eta 0:00:30 lr 0.000003	 wd 0.0001	time 0.9762 (1.0673)	loss 0.6902 (0.6828)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:09:29 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/20][30/49]	eta 0:00:20 lr 0.000003	 wd 0.0001	time 0.9803 (1.0797)	loss 0.7084 (0.6913)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:09:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/20][40/49]	eta 0:00:09 lr 0.000003	 wd 0.0001	time 1.0171 (1.0858)	loss 0.7035 (0.6917)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 22:09:47 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 2 training takes 0:00:52
[2024-12-09 22:09:50 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.551 
[2024-12-09 22:09:50 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.551%
[2024-12-09 22:09:50 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.65%
[2024-12-09 22:09:50 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.5337, Recall: 0.5426, F1: 0.5162
[2024-12-09 22:09:52 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/20][0/49]	eta 0:01:34 lr 0.000003	 wd 0.0001	time 1.9246 (1.9246)	loss 0.6927 (0.6927)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:10:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/20][10/49]	eta 0:00:42 lr 0.000003	 wd 0.0001	time 0.9869 (1.0959)	loss 0.6801 (0.6982)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:10:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/20][20/49]	eta 0:00:31 lr 0.000003	 wd 0.0001	time 0.9705 (1.1032)	loss 0.6858 (0.6933)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 22:10:24 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/20][30/49]	eta 0:00:21 lr 0.000003	 wd 0.0001	time 0.9679 (1.1065)	loss 0.6929 (0.6931)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:10:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/20][40/49]	eta 0:00:09 lr 0.000003	 wd 0.0001	time 1.3669 (1.1002)	loss 0.7464 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.125
[2024-12-09 22:10:43 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 3 training takes 0:00:53
[2024-12-09 22:10:45 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.538 
[2024-12-09 22:10:45 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.538%
[2024-12-09 22:10:45 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.65%
[2024-12-09 22:10:45 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4641, Recall: 0.4586, F1: 0.4583
[2024-12-09 22:10:47 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/20][0/49]	eta 0:01:24 lr 0.000003	 wd 0.0001	time 1.7236 (1.7236)	loss 0.6939 (0.6939)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:10:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/20][10/49]	eta 0:00:44 lr 0.000003	 wd 0.0001	time 0.9727 (1.1435)	loss 0.7152 (0.6978)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:11:10 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/20][20/49]	eta 0:00:34 lr 0.000003	 wd 0.0001	time 0.9708 (1.1841)	loss 0.6822 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 22:11:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/20][30/49]	eta 0:00:22 lr 0.000003	 wd 0.0001	time 1.0018 (1.1613)	loss 0.7161 (0.6914)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 22:11:32 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/20][40/49]	eta 0:00:10 lr 0.000003	 wd 0.0001	time 1.3957 (1.1338)	loss 0.6689 (0.6919)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 22:11:41 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 4 training takes 0:00:55
[2024-12-09 22:11:43 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.526 
[2024-12-09 22:11:43 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.526%
[2024-12-09 22:11:43 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.65%
[2024-12-09 22:11:43 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3862, Recall: 0.3897, F1: 0.3879
[2024-12-09 22:11:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/20][0/49]	eta 0:01:12 lr 0.000003	 wd 0.0001	time 1.4787 (1.4787)	loss 0.7194 (0.7194)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:11:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/20][10/49]	eta 0:00:44 lr 0.000003	 wd 0.0001	time 0.9721 (1.1450)	loss 0.6968 (0.6914)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:12:42 swin_tiny_patch4_window7_224] (main.py 441): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 20
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-09 22:12:42 swin_tiny_patch4_window7_224] (main.py 442): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-09 22:12:42 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-09 22:12:42 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 3224930
[2024-12-09 22:12:42 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 0.23366688
[2024-12-09 22:12:42 swin_tiny_patch4_window7_224] (main.py 160): INFO Start training
[2024-12-09 22:12:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/20][0/49]	eta 0:01:02 lr 0.000000	 wd 0.0000	time 1.2825 (1.2825)	loss 0.6908 (0.6908)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:12:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/20][10/49]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 0.9912 (1.1562)	loss 0.7307 (0.7012)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:13:06 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/20][20/49]	eta 0:00:32 lr 0.000000	 wd 0.0000	time 1.4213 (1.1307)	loss 0.7076 (0.7000)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:13:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/20][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 1.0049 (1.0920)	loss 0.7255 (0.6990)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:13:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [0/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.9649 (1.0935)	loss 0.6608 (0.6976)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 22:13:36 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 0 training takes 0:00:53
[2024-12-09 22:13:38 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 22:13:38 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 22:13:38 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 22:13:38 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 22:13:39 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/20][0/49]	eta 0:01:08 lr 0.000000	 wd 0.0000	time 1.4041 (1.4041)	loss 0.7151 (0.7151)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:13:50 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/20][10/49]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 0.9632 (1.1409)	loss 0.7029 (0.7109)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:14:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/20][20/49]	eta 0:00:31 lr 0.000000	 wd 0.0000	time 1.3896 (1.0871)	loss 0.7268 (0.6962)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 22:14:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/20][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.9658 (1.0765)	loss 0.7176 (0.6983)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 22:14:22 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [1/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.9754 (1.0808)	loss 0.7124 (0.6964)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 22:14:31 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 1 training takes 0:00:53
[2024-12-09 22:14:33 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 22:14:33 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 22:14:33 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 22:14:33 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 22:14:35 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/20][0/49]	eta 0:01:09 lr 0.000000	 wd 0.0000	time 1.4093 (1.4093)	loss 0.6950 (0.6950)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:14:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/20][10/49]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3905 (1.1433)	loss 0.6835 (0.6869)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:14:56 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/20][20/49]	eta 0:00:30 lr 0.000000	 wd 0.0000	time 0.9594 (1.0642)	loss 0.6989 (0.6839)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:15:07 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/20][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.9724 (1.0772)	loss 0.7052 (0.6907)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:15:18 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [2/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.9766 (1.0826)	loss 0.6891 (0.6914)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:15:26 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 2 training takes 0:00:52
[2024-12-09 22:15:29 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.718 
[2024-12-09 22:15:29 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.718%
[2024-12-09 22:15:29 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 22:15:29 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3636, Recall: 0.4912, F1: 0.4179
[2024-12-09 22:15:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/20][0/49]	eta 0:01:10 lr 0.000000	 wd 0.0000	time 1.4483 (1.4483)	loss 0.6946 (0.6946)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:15:41 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/20][10/49]	eta 0:00:42 lr 0.000000	 wd 0.0000	time 1.4125 (1.0858)	loss 0.6889 (0.6942)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:15:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/20][20/49]	eta 0:00:31 lr 0.000000	 wd 0.0000	time 0.9903 (1.0692)	loss 0.6902 (0.6924)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 22:16:02 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/20][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.9663 (1.0771)	loss 0.6858 (0.6907)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:16:13 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [3/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 1.0047 (1.0810)	loss 0.7328 (0.6924)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.188
[2024-12-09 22:16:21 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 3 training takes 0:00:52
[2024-12-09 22:16:24 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.731 
[2024-12-09 22:16:24 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.731%
[2024-12-09 22:16:24 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 22:16:24 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3654, Recall: 0.5000, F1: 0.4222
[2024-12-09 22:16:26 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/20][0/49]	eta 0:01:36 lr 0.000000	 wd 0.0000	time 1.9662 (1.9662)	loss 0.6879 (0.6879)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:16:36 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/20][10/49]	eta 0:00:43 lr 0.000000	 wd 0.0000	time 0.9676 (1.1129)	loss 0.7172 (0.6998)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 22:16:47 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/20][20/49]	eta 0:00:32 lr 0.000000	 wd 0.0000	time 0.9763 (1.1162)	loss 0.6769 (0.6953)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 22:16:58 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/20][30/49]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.9960 (1.1162)	loss 0.7133 (0.6937)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 22:17:09 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [4/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 1.3798 (1.1097)	loss 0.6813 (0.6926)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 22:17:17 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 4 training takes 0:00:53
[2024-12-09 22:17:19 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.641 
[2024-12-09 22:17:19 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.641%
[2024-12-09 22:17:19 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 22:17:19 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4106, Recall: 0.4536, F1: 0.4222
[2024-12-09 22:17:21 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/20][0/49]	eta 0:01:28 lr 0.000000	 wd 0.0000	time 1.7989 (1.7989)	loss 0.6960 (0.6960)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:17:32 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/20][10/49]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 0.9646 (1.1431)	loss 0.6832 (0.6897)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 22:17:43 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/20][20/49]	eta 0:00:32 lr 0.000000	 wd 0.0000	time 1.0055 (1.1297)	loss 0.6989 (0.6908)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:17:54 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/20][30/49]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.9896 (1.1236)	loss 0.6793 (0.6905)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 22:18:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [5/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 1.2893 (1.0933)	loss 0.6954 (0.6909)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:18:13 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 5 training takes 0:00:53
[2024-12-09 22:18:15 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.628 
[2024-12-09 22:18:15 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.628%
[2024-12-09 22:18:15 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 22:18:15 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4665, Recall: 0.4749, F1: 0.4659
[2024-12-09 22:18:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/20][0/49]	eta 0:01:08 lr 0.000000	 wd 0.0000	time 1.3903 (1.3903)	loss 0.7047 (0.7047)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:18:28 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/20][10/49]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 0.9620 (1.1385)	loss 0.6966 (0.6870)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:18:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/20][20/49]	eta 0:00:32 lr 0.000000	 wd 0.0000	time 0.9658 (1.1198)	loss 0.6803 (0.6899)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:18:49 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/20][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 1.3690 (1.1050)	loss 0.6964 (0.6913)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:18:59 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [6/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.9619 (1.0809)	loss 0.6558 (0.6913)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.750
[2024-12-09 22:19:08 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 6 training takes 0:00:53
[2024-12-09 22:19:11 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.551 
[2024-12-09 22:19:11 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.551%
[2024-12-09 22:19:11 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 22:19:11 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.3972, Recall: 0.4073, F1: 0.4017
[2024-12-09 22:19:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/20][0/49]	eta 0:01:09 lr 0.000000	 wd 0.0000	time 1.4241 (1.4241)	loss 0.6768 (0.6768)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 22:19:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/20][10/49]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 0.9551 (1.1472)	loss 0.6937 (0.6864)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:19:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/20][20/49]	eta 0:00:32 lr 0.000000	 wd 0.0000	time 1.1034 (1.1277)	loss 0.6933 (0.6926)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:19:44 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/20][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 1.1397 (1.0826)	loss 0.6906 (0.6907)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:19:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [7/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.9733 (1.0839)	loss 0.6834 (0.6903)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 22:20:04 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 7 training takes 0:00:53
[2024-12-09 22:20:06 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.577 
[2024-12-09 22:20:06 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.577%
[2024-12-09 22:20:06 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 22:20:06 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4333, Recall: 0.4398, F1: 0.4359
[2024-12-09 22:20:08 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/20][0/49]	eta 0:01:11 lr 0.000000	 wd 0.0000	time 1.4606 (1.4606)	loss 0.7102 (0.7102)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 22:20:19 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/20][10/49]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 0.9696 (1.1578)	loss 0.6831 (0.6987)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 22:20:30 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/20][20/49]	eta 0:00:32 lr 0.000000	 wd 0.0000	time 1.3662 (1.1108)	loss 0.6935 (0.6957)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:20:40 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/20][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.9851 (1.0839)	loss 0.6756 (0.6935)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 22:20:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [8/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.9785 (1.0906)	loss 0.7019 (0.6948)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:21:01 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 8 training takes 0:00:54
[2024-12-09 22:21:03 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.590 
[2024-12-09 22:21:03 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.590%
[2024-12-09 22:21:03 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 22:21:03 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4941, Recall: 0.4937, F1: 0.4935
[2024-12-09 22:21:04 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/20][0/49]	eta 0:01:09 lr 0.000000	 wd 0.0000	time 1.4083 (1.4083)	loss 0.6942 (0.6942)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:21:15 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/20][10/49]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 0.9960 (1.1509)	loss 0.6987 (0.6859)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 22:21:25 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/20][20/49]	eta 0:00:31 lr 0.000000	 wd 0.0000	time 1.2758 (1.0820)	loss 0.7058 (0.6880)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:21:36 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/20][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.9656 (1.0778)	loss 0.6819 (0.6898)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:21:47 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [9/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.9618 (1.0824)	loss 0.6960 (0.6913)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 22:21:56 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 9 training takes 0:00:53
[2024-12-09 22:21:58 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.564 
[2024-12-09 22:21:58 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.564%
[2024-12-09 22:21:58 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 22:21:58 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4924, Recall: 0.4912, F1: 0.4884
[2024-12-09 22:21:59 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/20][0/49]	eta 0:01:07 lr 0.000000	 wd 0.0000	time 1.3756 (1.3756)	loss 0.6972 (0.6972)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:22:11 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/20][10/49]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 1.3929 (1.1409)	loss 0.7138 (0.6946)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.250
[2024-12-09 22:22:20 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/20][20/49]	eta 0:00:30 lr 0.000000	 wd 0.0000	time 0.9746 (1.0627)	loss 0.6823 (0.6918)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:22:31 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/20][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 1.0068 (1.0697)	loss 0.6993 (0.6943)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:22:42 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [10/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.9943 (1.0778)	loss 0.7022 (0.6941)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:22:51 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 10 training takes 0:00:52
[2024-12-09 22:22:54 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.487 
[2024-12-09 22:22:54 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.487%
[2024-12-09 22:22:54 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 22:22:54 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4631, Recall: 0.4536, F1: 0.4429
[2024-12-09 22:22:55 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/20][0/49]	eta 0:01:10 lr 0.000000	 wd 0.0000	time 1.4466 (1.4466)	loss 0.6907 (0.6907)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:23:06 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/20][10/49]	eta 0:00:42 lr 0.000000	 wd 0.0000	time 1.3930 (1.0979)	loss 0.6987 (0.6921)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:23:16 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/20][20/49]	eta 0:00:31 lr 0.000000	 wd 0.0000	time 0.9804 (1.0786)	loss 0.6986 (0.6969)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.438
[2024-12-09 22:23:27 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/20][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.9700 (1.0836)	loss 0.6751 (0.6942)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 22:23:38 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [11/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.9685 (1.0898)	loss 0.7067 (0.6947)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.312
[2024-12-09 22:23:46 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 11 training takes 0:00:52
[2024-12-09 22:23:49 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.564 
[2024-12-09 22:23:49 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.564%
[2024-12-09 22:23:49 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 22:23:49 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4632, Recall: 0.4612, F1: 0.4619
[2024-12-09 22:23:51 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/20][0/49]	eta 0:01:35 lr 0.000000	 wd 0.0000	time 1.9543 (1.9543)	loss 0.7133 (0.7133)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 22:24:01 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/20][10/49]	eta 0:00:42 lr 0.000000	 wd 0.0000	time 0.9862 (1.0861)	loss 0.6995 (0.6908)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:24:12 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/20][20/49]	eta 0:00:31 lr 0.000000	 wd 0.0000	time 0.9696 (1.0988)	loss 0.6945 (0.6889)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:24:23 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/20][30/49]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.9754 (1.1004)	loss 0.7034 (0.6902)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 22:24:34 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [12/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 1.3880 (1.0985)	loss 0.6875 (0.6904)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:24:42 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 12 training takes 0:00:53
[2024-12-09 22:24:44 swin_tiny_patch4_window7_224] (main.py 364): INFO  * Accuracy validation@ 0.526 
[2024-12-09 22:24:44 swin_tiny_patch4_window7_224] (main.py 173): INFO Accuracy of the network on the 78 test images: 0.526%
[2024-12-09 22:24:44 swin_tiny_patch4_window7_224] (main.py 175): INFO Max accuracy: 0.73%
[2024-12-09 22:24:44 swin_tiny_patch4_window7_224] (main.py 176): INFO Precision: 0.4708, Recall: 0.4649, F1: 0.4611
[2024-12-09 22:24:46 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/20][0/49]	eta 0:01:30 lr 0.000000	 wd 0.0000	time 1.8384 (1.8384)	loss 0.6848 (0.6848)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.500
[2024-12-09 22:24:57 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/20][10/49]	eta 0:00:44 lr 0.000000	 wd 0.0000	time 0.9632 (1.1462)	loss 0.7054 (0.6927)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.375
[2024-12-09 22:25:08 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/20][20/49]	eta 0:00:32 lr 0.000000	 wd 0.0000	time 0.9534 (1.1246)	loss 0.7115 (0.6989)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.625
[2024-12-09 22:25:19 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/20][30/49]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.9585 (1.1174)	loss 0.6885 (0.6981)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.562
[2024-12-09 22:25:29 swin_tiny_patch4_window7_224] (main.py 265): INFO Train: [13/20][40/49]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 1.3297 (1.0912)	loss 0.6819 (0.6945)	grad_norm 0.000000 (0.0000)	loss_scale 0.0000 (0.0000)	accuracy training 0.688
[2024-12-09 22:25:38 swin_tiny_patch4_window7_224] (main.py 274): INFO EPOCH 13 training takes 0:00:53
[2024-12-10 20:22:49 swin_tiny_patch4_window7_224] (main.py 436): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.1
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 6
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: false
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 20
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 3.125e-07
  WEIGHT_DECAY: 1.0e-05

[2024-12-10 20:22:49 swin_tiny_patch4_window7_224] (main.py 437): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data", "zip": false, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-10 20:22:49 swin_tiny_patch4_window7_224] (main.py 95): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-10 20:22:49 swin_tiny_patch4_window7_224] (main.py 100): INFO number of params: 3224930
[2024-12-10 20:22:49 swin_tiny_patch4_window7_224] (main.py 103): INFO number of GFLOPs: 0.23366688
[2024-12-10 20:22:49 swin_tiny_patch4_window7_224] (main.py 164): INFO Start training
