[2024-12-02 11:38:26 swin_tiny_patch4_window7_224] (main.py 372): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 11:38:26 swin_tiny_patch4_window7_224] (main.py 373): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 11:38:26 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 11:38:26 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=1000, bias=True)
)
[2024-12-02 11:38:26 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1385002
[2024-12-02 11:38:26 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 11:38:26 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 11:38:26 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 11:38:26 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 1000
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 11:44:06 swin_tiny_patch4_window7_224] (main.py 372): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 11:44:06 swin_tiny_patch4_window7_224] (main.py 373): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 11:44:06 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 11:44:06 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 11:44:06 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 11:44:06 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 11:44:06 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 11:44:06 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 11:44:06 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 11:49:00 swin_tiny_patch4_window7_224] (main.py 372): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 11:49:00 swin_tiny_patch4_window7_224] (main.py 373): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 11:49:00 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 11:49:00 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 11:49:00 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 11:49:00 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 11:49:00 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 11:49:00 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 11:49:00 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 11:51:36 swin_tiny_patch4_window7_224] (main.py 373): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 11:51:36 swin_tiny_patch4_window7_224] (main.py 374): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 11:51:36 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 11:51:36 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 11:51:36 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 11:51:36 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 11:51:36 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 11:51:36 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 11:51:36 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 11:53:44 swin_tiny_patch4_window7_224] (main.py 373): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 11:53:44 swin_tiny_patch4_window7_224] (main.py 374): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 11:53:44 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 11:53:44 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 11:53:44 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 11:53:44 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 11:53:44 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 11:53:44 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 11:53:44 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 11:57:19 swin_tiny_patch4_window7_224] (main.py 374): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 11:57:19 swin_tiny_patch4_window7_224] (main.py 375): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 11:57:19 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 11:57:19 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 11:57:19 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 11:57:19 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 11:57:19 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 11:57:19 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 11:57:19 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 11:57:48 swin_tiny_patch4_window7_224] (main.py 374): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 11:57:48 swin_tiny_patch4_window7_224] (main.py 375): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 11:57:48 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 11:57:48 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 11:57:48 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 11:57:48 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 11:57:48 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 11:57:48 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 11:57:48 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 11:59:17 swin_tiny_patch4_window7_224] (main.py 376): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 11:59:17 swin_tiny_patch4_window7_224] (main.py 377): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 11:59:17 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 11:59:17 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 11:59:17 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 11:59:17 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 11:59:17 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 11:59:17 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 11:59:17 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:01:21 swin_tiny_patch4_window7_224] (main.py 377): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:01:21 swin_tiny_patch4_window7_224] (main.py 378): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:01:21 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:01:21 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:01:21 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:01:21 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:01:21 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:01:21 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:01:21 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:04:04 swin_tiny_patch4_window7_224] (main.py 377): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:04:04 swin_tiny_patch4_window7_224] (main.py 378): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:04:04 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:04:04 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:04:04 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:04:04 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:04:04 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:04:04 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:04:04 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:04:35 swin_tiny_patch4_window7_224] (main.py 377): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:04:35 swin_tiny_patch4_window7_224] (main.py 378): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:04:35 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:04:35 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:04:35 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:04:35 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:04:35 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:04:35 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:04:35 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:05:19 swin_tiny_patch4_window7_224] (main.py 377): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:05:19 swin_tiny_patch4_window7_224] (main.py 378): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:05:19 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:05:19 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:05:19 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:05:19 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:05:19 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:05:19 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:05:19 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:07:08 swin_tiny_patch4_window7_224] (main.py 377): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:07:08 swin_tiny_patch4_window7_224] (main.py 378): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:07:08 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:07:08 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:07:08 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:07:08 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:07:08 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:07:08 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:07:08 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:07:31 swin_tiny_patch4_window7_224] (main.py 377): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:07:31 swin_tiny_patch4_window7_224] (main.py 378): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:07:31 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:07:31 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:07:31 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:07:31 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:07:31 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:07:31 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:07:31 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:07:45 swin_tiny_patch4_window7_224] (main.py 377): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:07:45 swin_tiny_patch4_window7_224] (main.py 378): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:07:45 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:07:45 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:07:45 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:07:45 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:07:45 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:07:45 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:07:45 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:08:29 swin_tiny_patch4_window7_224] (main.py 379): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:08:29 swin_tiny_patch4_window7_224] (main.py 380): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:08:29 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:08:29 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:08:29 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:08:29 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:08:29 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:08:29 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:08:29 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:09:08 swin_tiny_patch4_window7_224] (main.py 379): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:09:08 swin_tiny_patch4_window7_224] (main.py 380): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:09:08 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:09:08 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:09:08 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:09:08 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:09:08 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:09:08 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:09:08 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:09:40 swin_tiny_patch4_window7_224] (main.py 379): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:09:40 swin_tiny_patch4_window7_224] (main.py 380): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:09:40 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:09:40 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:09:40 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:09:40 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:09:40 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:09:40 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:09:40 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:12:54 swin_tiny_patch4_window7_224] (main.py 380): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:12:54 swin_tiny_patch4_window7_224] (main.py 381): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:12:54 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:12:54 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:12:54 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:12:54 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:12:54 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:12:54 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:12:54 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:15:22 swin_tiny_patch4_window7_224] (main.py 380): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:15:22 swin_tiny_patch4_window7_224] (main.py 381): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:15:22 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:15:22 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:15:22 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:15:22 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:15:22 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:15:22 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:15:22 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:17:38 swin_tiny_patch4_window7_224] (main.py 380): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:17:38 swin_tiny_patch4_window7_224] (main.py 381): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:17:38 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:17:38 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:17:38 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:17:38 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:17:38 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:17:38 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:17:38 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:17:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3154 (0.3154)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:17:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.2178 (0.1998)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:17:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2686 (0.2007)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:17:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2460 (0.2180)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:17:46 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:07
[2024-12-02 12:18:50 swin_tiny_patch4_window7_224] (main.py 380): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:18:50 swin_tiny_patch4_window7_224] (main.py 381): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:18:50 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:18:50 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:18:50 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:18:50 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:18:50 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:18:50 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:18:50 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:18:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][0/34]	eta 0:00:09 lr 0.000000	 wd 0.0500	time 0.2705 (0.2705)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:18:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1765 (0.1869)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:18:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1732 (0.1817)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:18:55 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1673 (0.1796)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:18:56 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 12:20:05 swin_tiny_patch4_window7_224] (main.py 380): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:20:05 swin_tiny_patch4_window7_224] (main.py 381): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:20:05 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:20:05 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:20:05 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:20:05 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:20:05 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:20:05 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:20:05 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:20:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][0/34]	eta 0:00:08 lr 0.000000	 wd 0.0500	time 0.2639 (0.2639)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:20:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1684 (0.1933)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:20:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2717 (0.1973)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:20:11 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2473 (0.2120)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:20:12 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:07
[2024-12-02 12:21:19 swin_tiny_patch4_window7_224] (main.py 380): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:21:19 swin_tiny_patch4_window7_224] (main.py 381): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:21:19 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:21:19 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:21:19 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:21:19 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:21:19 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:21:19 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:21:19 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:21:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][0/34]	eta 0:00:09 lr 0.000000	 wd 0.0500	time 0.2679 (0.2679)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:21:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.2087 (0.1937)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:21:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2255 (0.2128)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:21:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1880 (0.2124)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:21:27 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:07
[2024-12-02 12:23:55 swin_tiny_patch4_window7_224] (main.py 382): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:23:55 swin_tiny_patch4_window7_224] (main.py 383): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:23:55 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:23:55 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:23:55 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:23:55 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:23:55 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:23:55 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:23:55 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:23:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3180 (0.3180)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:23:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1862 (0.2198)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:24:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2386 (0.2099)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:24:02 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2363 (0.2207)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:24:03 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:07
[2024-12-02 12:42:13 swin_tiny_patch4_window7_224] (main.py 382): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:42:13 swin_tiny_patch4_window7_224] (main.py 383): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:42:13 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:42:13 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:42:13 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:42:13 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:42:13 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:42:13 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:42:13 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:42:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3091 (0.3091)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:42:15 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1808 (0.1932)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:42:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1695 (0.1861)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:42:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1601 (0.1805)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:42:19 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 12:42:39 swin_tiny_patch4_window7_224] (main.py 382): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:42:39 swin_tiny_patch4_window7_224] (main.py 383): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:42:39 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:42:39 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:42:39 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:42:39 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:42:39 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:42:39 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:42:39 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:42:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3017 (0.3017)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:42:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1680 (0.1957)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:42:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1879 (0.1861)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:42:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1796 (0.1822)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:42:45 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 12:45:00 swin_tiny_patch4_window7_224] (main.py 382): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:45:00 swin_tiny_patch4_window7_224] (main.py 383): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:45:00 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:45:00 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:45:00 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:45:00 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:45:00 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:45:00 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:45:00 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:45:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][0/34]	eta 0:00:15 lr 0.000000	 wd 0.0500	time 0.4575 (0.4575)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1717 (0.2234)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1634 (0.1990)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1882 (0.1927)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:07 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 12:45:28 swin_tiny_patch4_window7_224] (main.py 382): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:45:28 swin_tiny_patch4_window7_224] (main.py 383): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:45:28 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:45:28 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:45:28 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:45:28 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:45:28 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:45:28 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:45:28 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:45:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3026 (0.3026)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1721 (0.2030)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1620 (0.1872)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1674 (0.1866)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:34 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 12:45:35 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:45:35 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:45:35 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:45:35 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:45:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/300][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3455 (0.3455)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2387 (0.2397)	loss 1.2106 (1.1857)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2119 (0.2417)	loss 1.3177 (1.1705)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:42 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2025 (0.2226)	loss 1.0078 (1.1956)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:43 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 1 training takes 0:00:07
[2024-12-02 12:45:44 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:45:44 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:45:44 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:45:44 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:45:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/300][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3129 (0.3129)	loss 0.9030 (0.9030)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1865 (0.2097)	loss 1.3133 (1.1674)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1770 (0.1971)	loss 1.1163 (1.1561)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1798 (0.1885)	loss 1.3294 (1.1946)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:50 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 2 training takes 0:00:06
[2024-12-02 12:45:51 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:45:51 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:45:51 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:45:51 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:45:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/300][0/34]	eta 0:00:16 lr 0.000000	 wd 0.0500	time 0.4776 (0.4776)	loss 1.2180 (1.2180)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/300][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.1760 (0.2638)	loss 0.8115 (1.1970)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1709 (0.2199)	loss 1.2076 (1.2151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1808 (0.2068)	loss 1.2020 (1.1984)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:45:58 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 3 training takes 0:00:06
[2024-12-02 12:45:59 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:45:59 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:45:59 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:45:59 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:45:59 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/300][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3216 (0.3216)	loss 1.4127 (1.4127)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1844 (0.2060)	loss 1.1205 (1.1524)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1713 (0.1905)	loss 1.4133 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2636 (0.2010)	loss 1.0023 (1.1951)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:06 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 4 training takes 0:00:06
[2024-12-02 12:46:07 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:46:07 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:46:07 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:46:07 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:46:08 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/300][0/34]	eta 0:00:14 lr 0.000000	 wd 0.0500	time 0.4398 (0.4398)	loss 1.0050 (1.0050)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1875 (0.2127)	loss 1.3082 (1.1669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:12 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1748 (0.1926)	loss 1.4345 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1691 (0.1851)	loss 1.1244 (1.1977)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:14 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 5 training takes 0:00:06
[2024-12-02 12:46:15 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:46:15 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:46:15 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:46:15 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:46:15 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/300][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3208 (0.3208)	loss 1.2188 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1810 (0.2091)	loss 0.8230 (1.1925)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2686 (0.2208)	loss 1.2182 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1652 (0.2252)	loss 1.2178 (1.1813)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:22 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 6 training takes 0:00:07
[2024-12-02 12:46:23 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:46:23 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:46:23 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:46:23 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:46:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/300][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3549 (0.3549)	loss 1.0111 (1.0111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:25 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1678 (0.2019)	loss 1.0072 (1.1654)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:27 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2069 (0.1913)	loss 0.9054 (1.1399)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:29 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1727 (0.1859)	loss 1.2147 (1.1798)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:29 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 7 training takes 0:00:06
[2024-12-02 12:46:30 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:46:30 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:46:30 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:46:30 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:46:31 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/300][0/34]	eta 0:00:13 lr 0.000000	 wd 0.0500	time 0.3826 (0.3826)	loss 1.1182 (1.1182)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:33 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/300][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.2633 (0.2697)	loss 1.0214 (1.2186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1633 (0.2489)	loss 1.2093 (1.2085)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1705 (0.2229)	loss 1.0152 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:38 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 8 training takes 0:00:07
[2024-12-02 12:46:39 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:46:39 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:46:39 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:46:39 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:46:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/300][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3269 (0.3269)	loss 1.0264 (1.0264)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1760 (0.1993)	loss 1.3252 (1.1444)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1775 (0.1920)	loss 1.5173 (1.1804)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1684 (0.1854)	loss 1.5330 (1.1794)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:45 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 9 training takes 0:00:06
[2024-12-02 12:46:47 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:46:47 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:46:47 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:46:47 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:46:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/300][0/34]	eta 0:00:16 lr 0.000000	 wd 0.0500	time 0.4846 (0.4846)	loss 1.3284 (1.3284)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/300][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.1696 (0.2661)	loss 1.1036 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1638 (0.2241)	loss 1.2124 (1.1887)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1805 (0.2083)	loss 1.1163 (1.1807)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:54 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 10 training takes 0:00:07
[2024-12-02 12:46:55 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:46:55 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:46:55 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:46:55 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:46:55 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/300][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3584 (0.3584)	loss 1.4163 (1.4163)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:57 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1778 (0.1934)	loss 0.8097 (1.2118)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:46:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1706 (0.1825)	loss 1.3154 (1.2331)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2678 (0.2007)	loss 0.7169 (1.1948)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:02 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 11 training takes 0:00:07
[2024-12-02 12:47:03 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:47:03 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:47:03 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:47:03 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:47:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/300][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3681 (0.3681)	loss 1.1152 (1.1152)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1887 (0.2067)	loss 1.3062 (1.2064)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1864 (0.1935)	loss 1.0982 (1.2008)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1659 (0.1881)	loss 1.4206 (1.1763)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:09 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 12 training takes 0:00:06
[2024-12-02 12:47:10 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:47:10 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:47:10 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:47:10 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:47:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/300][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3330 (0.3330)	loss 1.2212 (1.2212)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:12 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1899 (0.2080)	loss 1.2048 (1.1112)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:15 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2862 (0.2268)	loss 1.3212 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1906 (0.2270)	loss 1.3129 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:18 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 13 training takes 0:00:07
[2024-12-02 12:47:19 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:47:19 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:47:19 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:47:19 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:47:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/300][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3552 (0.3552)	loss 1.3150 (1.3150)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:21 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1690 (0.2056)	loss 0.9079 (1.0414)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1661 (0.1875)	loss 1.5214 (1.1916)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1736 (0.1860)	loss 1.2292 (1.1842)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:25 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 14 training takes 0:00:06
[2024-12-02 12:47:26 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:47:26 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:47:26 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:47:26 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:47:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/300][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3530 (0.3530)	loss 0.8971 (0.8971)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:29 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/300][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.2440 (0.2696)	loss 1.4212 (1.1306)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:31 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1711 (0.2396)	loss 1.3204 (1.1848)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:33 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1634 (0.2170)	loss 1.3373 (1.1890)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:33 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 15 training takes 0:00:07
[2024-12-02 12:47:34 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:47:34 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:47:34 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:47:34 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:47:35 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/300][0/34]	eta 0:00:13 lr 0.000000	 wd 0.0500	time 0.3867 (0.3867)	loss 1.0005 (1.0005)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1785 (0.2016)	loss 1.2136 (1.1193)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1748 (0.1928)	loss 0.8986 (1.1694)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2197 (0.1884)	loss 1.3288 (1.1791)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:41 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 16 training takes 0:00:06
[2024-12-02 12:47:42 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:47:42 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:47:42 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:47:42 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:47:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/300][0/34]	eta 0:00:16 lr 0.000000	 wd 0.0500	time 0.4970 (0.4970)	loss 1.4139 (1.4139)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1757 (0.2327)	loss 1.3061 (1.2603)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2002 (0.2085)	loss 1.2102 (1.1890)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1857 (0.1995)	loss 1.0017 (1.1820)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:49 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 17 training takes 0:00:06
[2024-12-02 12:47:50 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:47:50 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:47:50 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:47:50 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:47:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/300][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3379 (0.3379)	loss 1.3049 (1.3049)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1685 (0.2020)	loss 1.1154 (1.1879)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2365 (0.1982)	loss 1.4091 (1.1868)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:57 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2319 (0.2161)	loss 1.0122 (1.1849)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:47:57 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 18 training takes 0:00:07
[2024-12-02 12:47:58 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:47:58 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:47:58 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:47:58 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:47:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/300][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3316 (0.3316)	loss 1.0286 (1.0286)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1746 (0.1940)	loss 1.1265 (1.2362)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:02 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1845 (0.1892)	loss 0.9085 (1.1835)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:04 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1798 (0.1864)	loss 1.2118 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:04 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 19 training takes 0:00:06
[2024-12-02 12:48:05 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:48:05 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:48:05 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:48:05 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:48:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/300][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3521 (0.3521)	loss 1.3092 (1.3092)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:08 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2387 (0.2173)	loss 1.3186 (1.2343)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2540 (0.2314)	loss 0.9077 (1.2009)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:12 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1921 (0.2163)	loss 1.1030 (1.2027)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:13 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 20 training takes 0:00:07
[2024-12-02 12:48:14 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:48:14 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:48:14 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:48:14 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:48:14 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/300][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3681 (0.3681)	loss 1.0226 (1.0226)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1653 (0.2021)	loss 1.2127 (1.1962)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1773 (0.1975)	loss 1.6450 (1.1826)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1601 (0.1905)	loss 1.4221 (1.1872)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:20 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 21 training takes 0:00:06
[2024-12-02 12:48:21 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:48:21 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:48:21 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:48:21 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:48:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/300][0/34]	eta 0:00:17 lr 0.000000	 wd 0.0500	time 0.5173 (0.5173)	loss 1.4136 (1.4136)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/300][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.1859 (0.2666)	loss 1.1175 (1.1990)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1642 (0.2230)	loss 1.4164 (1.2163)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1810 (0.2061)	loss 1.3064 (1.1859)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:28 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 22 training takes 0:00:06
[2024-12-02 12:48:29 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:48:29 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:48:29 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:48:29 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:48:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/300][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3571 (0.3571)	loss 1.1186 (1.1186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1744 (0.2072)	loss 0.8045 (1.1530)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:33 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1803 (0.1892)	loss 1.4216 (1.1972)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2296 (0.2039)	loss 1.1113 (1.1729)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:36 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 23 training takes 0:00:07
[2024-12-02 12:48:38 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:48:38 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:48:38 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:48:38 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:48:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/300][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3379 (0.3379)	loss 1.2105 (1.2105)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1875 (0.1981)	loss 1.1162 (1.1744)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:42 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1951 (0.1926)	loss 1.2089 (1.1896)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1648 (0.1876)	loss 1.3081 (1.2048)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:44 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 24 training takes 0:00:06
[2024-12-02 12:48:45 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:48:45 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:48:45 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:48:45 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:48:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/300][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3740 (0.3740)	loss 1.2229 (1.2229)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1872 (0.2151)	loss 1.5144 (1.2567)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2475 (0.2294)	loss 1.1144 (1.1926)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1905 (0.2219)	loss 1.3066 (1.1866)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:52 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 25 training takes 0:00:07
[2024-12-02 12:48:53 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:48:53 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:48:53 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:48:53 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:48:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/300][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3412 (0.3412)	loss 1.3199 (1.3199)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1590 (0.1921)	loss 1.0294 (1.1535)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:57 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1861 (0.1890)	loss 1.2143 (1.1770)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:48:59 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1702 (0.1855)	loss 1.0025 (1.1751)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:00 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 26 training takes 0:00:06
[2024-12-02 12:49:01 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:49:01 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:49:01 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:49:01 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:49:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/300][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3697 (0.3697)	loss 1.4119 (1.4119)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:04 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/300][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.2708 (0.2711)	loss 1.5333 (1.1610)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1881 (0.2379)	loss 1.4040 (1.1913)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1702 (0.2192)	loss 1.4108 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:08 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 27 training takes 0:00:07
[2024-12-02 12:49:09 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:49:09 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:49:09 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:49:09 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:49:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/300][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3448 (0.3448)	loss 1.3144 (1.3144)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:11 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1744 (0.2005)	loss 1.2006 (1.1132)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1611 (0.1866)	loss 1.4167 (1.1531)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:15 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2476 (0.1920)	loss 1.1021 (1.1701)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:16 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 28 training takes 0:00:06
[2024-12-02 12:49:17 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:49:17 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:49:17 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:49:17 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:49:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/300][0/34]	eta 0:00:16 lr 0.000000	 wd 0.0500	time 0.4965 (0.4965)	loss 1.3227 (1.3227)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1971 (0.2274)	loss 1.0086 (1.2451)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:21 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1687 (0.1997)	loss 1.0040 (1.2303)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1656 (0.1927)	loss 1.2243 (1.2024)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:23 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 29 training takes 0:00:06
[2024-12-02 12:49:25 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:49:25 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:49:25 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:49:25 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:49:25 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/300][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3316 (0.3316)	loss 1.1026 (1.1026)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:27 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1858 (0.2067)	loss 1.1117 (1.1223)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:29 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2450 (0.2186)	loss 1.1088 (1.1668)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1983 (0.2260)	loss 1.4201 (1.1742)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:32 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 30 training takes 0:00:07
[2024-12-02 12:49:33 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:49:33 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:49:33 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:49:33 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:49:33 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/300][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3186 (0.3186)	loss 1.3124 (1.3124)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:35 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/300][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1933 (0.2050)	loss 1.3106 (1.2149)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/300][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1647 (0.1872)	loss 1.2093 (1.1914)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1830 (0.1855)	loss 0.7156 (1.1797)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:39 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 31 training takes 0:00:06
[2024-12-02 12:49:40 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:49:40 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:49:40 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:49:40 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:49:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/300][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3122 (0.3122)	loss 1.0058 (1.0058)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2407 (0.2498)	loss 1.0125 (1.2167)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1893 (0.2482)	loss 1.0123 (1.1377)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1982 (0.2271)	loss 1.4166 (1.1854)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:48 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 32 training takes 0:00:07
[2024-12-02 12:49:49 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:49:49 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:49:49 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:49:49 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:49:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [33/300][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3593 (0.3593)	loss 1.1313 (1.1313)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:49:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [33/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1883 (0.2095)	loss 0.6049 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:50:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [36/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1911 (0.1904)	loss 1.0131 (1.1773)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:50:20 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 36 training takes 0:00:06
[2024-12-02 12:50:21 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:50:21 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:50:21 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:50:21 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:50:21 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/300][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3289 (0.3289)	loss 1.3151 (1.3151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:50:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/300][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2409 (0.2201)	loss 1.1040 (1.2517)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:50:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/300][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2192 (0.2264)	loss 0.7092 (1.2056)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:50:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/300][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1744 (0.2180)	loss 1.1129 (1.1746)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:50:28 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 37 training takes 0:00:07
[2024-12-02 12:55:43 swin_tiny_patch4_window7_224] (main.py 382): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:55:43 swin_tiny_patch4_window7_224] (main.py 383): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:55:43 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:55:43 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:55:43 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:55:43 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:55:43 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:55:43 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:55:43 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:55:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3092 (0.3092)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:55:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1838 (0.1922)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:55:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1690 (0.1804)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:55:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1626 (0.1760)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:55:49 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 12:55:50 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:55:50 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:55:50 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:55:50 swin_tiny_patch4_window7_224] (main.py 160): INFO config : AMP_ENABLE: False
AMP_OPT_LEVEL: 
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: None
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE: ['']
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: no
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: True
  ZIP_MODE: True
ENABLE_AMP: False
EVAL_MODE: False
FUSED_LAYERNORM: False
FUSED_WINDOW_PROCESS: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: 
  RESUME: 
  SIMMIM:
    NORM_TARGET:
      ENABLE: False
      PATCH_SIZE: 47
  SWIN:
    APE: False
    DEPTHS: [2, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    QKV_BIAS: True
    QK_SCALE: None
    WINDOW_SIZE: 7
  SWINV2:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: False
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS: [3, 6, 12, 24]
    PATCH_NORM: True
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: False
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: False
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS: [2, 2, 6, 2]
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: False
    MLP_FC2_BIAS: True
    MLP_RATIO: 4.0
    MOE_BLOCKS: [[-1], [-1], [-1], [-1]]
    MOE_DROP: 0.0
    NORMALIZE_GATE: False
    NUM_HEADS: [3, 6, 12, 24]
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: True
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES: [0, 0, 0, 0]
    QKV_BIAS: True
    QK_SCALE: None
    TOP_VALUE: 1
    USE_BPR: True
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
  SEQUENTIAL: False
  SHUFFLE: False
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: True
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: True
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: False
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05, ignoring auto resume
[2024-12-02 12:55:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][0/34]	eta 0:00:14 lr 0.000000	 wd 0.0500	time 0.4290 (0.4290)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:56:48 swin_tiny_patch4_window7_224] (main.py 382): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 12:56:48 swin_tiny_patch4_window7_224] (main.py 383): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 12:56:48 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 12:56:48 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 12:56:48 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 12:56:48 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 12:56:48 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 12:56:48 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 12:56:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3402 (0.3402)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:56:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2671 (0.2097)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:56:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2432 (0.2224)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:56:55 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1664 (0.2191)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:56:56 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:07
[2024-12-02 12:56:57 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:56:57 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:56:57 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:56:57 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3233 (0.3233)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:56:59 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1869 (0.2017)	loss 1.2106 (1.1857)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1645 (0.1853)	loss 1.3177 (1.1705)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:02 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1616 (0.1788)	loss 1.0078 (1.1956)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:03 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 1 training takes 0:00:06
[2024-12-02 12:57:04 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:57:04 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:57:04 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:57:04 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3614 (0.3614)	loss 0.9030 (0.9030)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.2489 (0.2734)	loss 1.3133 (1.1674)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1713 (0.2369)	loss 1.1163 (1.1561)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1915 (0.2159)	loss 1.3294 (1.1946)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:11 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 2 training takes 0:00:07
[2024-12-02 12:57:12 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:57:12 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:57:12 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:57:12 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3247 (0.3247)	loss 1.2180 (1.2180)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:14 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1835 (0.2027)	loss 0.8115 (1.1970)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1724 (0.1930)	loss 1.2076 (1.2151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1777 (0.1901)	loss 1.2020 (1.1984)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:18 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 3 training takes 0:00:06
[2024-12-02 12:57:20 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:57:20 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:57:20 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:57:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][0/34]	eta 0:00:16 lr 0.000000	 wd 0.0500	time 0.4940 (0.4940)	loss 1.4127 (1.4127)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1575 (0.2419)	loss 1.1205 (1.1524)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1868 (0.2076)	loss 1.4133 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1721 (0.1941)	loss 1.0023 (1.1951)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:26 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 4 training takes 0:00:06
[2024-12-02 12:57:27 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:57:27 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:57:27 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:57:27 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3145 (0.3145)	loss 1.0050 (1.0050)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:29 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1632 (0.1976)	loss 1.3082 (1.1669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:31 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1787 (0.1865)	loss 1.4345 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:33 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2486 (0.2015)	loss 1.1244 (1.1977)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:34 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 5 training takes 0:00:06
[2024-12-02 12:57:35 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:57:35 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:57:35 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:57:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3546 (0.3546)	loss 1.2188 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1720 (0.1960)	loss 0.8230 (1.1925)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1713 (0.1808)	loss 1.2182 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1704 (0.1788)	loss 1.2178 (1.1813)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:41 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 6 training takes 0:00:06
[2024-12-02 12:57:42 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:57:42 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:57:42 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:57:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3436 (0.3436)	loss 1.0111 (1.0111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1728 (0.1938)	loss 1.0072 (1.1654)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2595 (0.1996)	loss 0.9054 (1.1399)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2187 (0.2144)	loss 1.2147 (1.1798)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:50 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 7 training takes 0:00:07
[2024-12-02 12:57:50 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:57:50 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:57:50 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:57:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3604 (0.3604)	loss 1.1182 (1.1182)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1920 (0.2116)	loss 1.0214 (1.2186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:55 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1770 (0.1984)	loss 1.2093 (1.2085)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1779 (0.1925)	loss 1.0152 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:57:57 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 8 training takes 0:00:06
[2024-12-02 12:57:58 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:57:58 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:57:58 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:57:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3339 (0.3339)	loss 1.0264 (1.0264)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2502 (0.2489)	loss 1.3252 (1.1444)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2158 (0.2469)	loss 1.5173 (1.1804)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1826 (0.2245)	loss 1.5330 (1.1794)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:05 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 9 training takes 0:00:07
[2024-12-02 12:58:06 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:58:06 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:58:06 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:58:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3242 (0.3242)	loss 1.3284 (1.3284)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1778 (0.1973)	loss 1.1036 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1568 (0.1827)	loss 1.2124 (1.1887)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:12 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1765 (0.1786)	loss 1.1163 (1.1807)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:12 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 10 training takes 0:00:06
[2024-12-02 12:58:14 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:58:14 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:58:14 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:58:14 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][0/34]	eta 0:00:15 lr 0.000000	 wd 0.0500	time 0.4682 (0.4682)	loss 1.4163 (1.4163)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.2189 (0.2739)	loss 0.8097 (1.2118)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1819 (0.2317)	loss 1.3154 (1.2331)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1900 (0.2141)	loss 0.7169 (1.1948)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:21 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 11 training takes 0:00:07
[2024-12-02 12:58:22 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:58:22 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:58:22 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:58:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3428 (0.3428)	loss 1.1152 (1.1152)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1815 (0.2025)	loss 1.3062 (1.2064)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1708 (0.1870)	loss 1.0982 (1.2008)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2488 (0.1919)	loss 1.4206 (1.1763)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:29 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 12 training takes 0:00:06
[2024-12-02 12:58:30 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:58:30 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:58:30 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:58:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][0/34]	eta 0:00:15 lr 0.000000	 wd 0.0500	time 0.4652 (0.4652)	loss 1.2212 (1.2212)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1941 (0.2099)	loss 1.2048 (1.1112)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1897 (0.1945)	loss 1.3212 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1628 (0.1862)	loss 1.3129 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:36 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 13 training takes 0:00:06
[2024-12-02 12:58:37 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:58:37 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:58:37 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:58:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3278 (0.3278)	loss 1.3150 (1.3150)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1770 (0.1998)	loss 0.9079 (1.0414)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2521 (0.2047)	loss 1.5214 (1.1916)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2076 (0.2157)	loss 1.2292 (1.1842)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:44 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 14 training takes 0:00:07
[2024-12-02 12:58:45 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:58:45 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:58:45 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:58:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3294 (0.3294)	loss 0.8971 (0.8971)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1831 (0.2068)	loss 1.4212 (1.1306)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1953 (0.1935)	loss 1.3204 (1.1848)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1826 (0.1875)	loss 1.3373 (1.1890)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:52 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 15 training takes 0:00:06
[2024-12-02 12:58:53 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:58:53 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:58:53 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:58:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3689 (0.3689)	loss 1.0005 (1.0005)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:55 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2606 (0.2442)	loss 1.2136 (1.1193)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:58:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2396 (0.2457)	loss 0.8986 (1.1694)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1623 (0.2233)	loss 1.3288 (1.1791)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:00 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 16 training takes 0:00:07
[2024-12-02 12:59:01 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:59:01 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:59:01 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:59:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3503 (0.3503)	loss 1.4139 (1.4139)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1865 (0.2029)	loss 1.3061 (1.2603)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1678 (0.1889)	loss 1.2102 (1.1890)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1752 (0.1851)	loss 1.0017 (1.1820)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:07 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 17 training takes 0:00:06
[2024-12-02 12:59:08 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:59:08 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:59:08 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:59:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][0/34]	eta 0:00:16 lr 0.000000	 wd 0.0500	time 0.4823 (0.4823)	loss 1.3049 (1.3049)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:11 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.2393 (0.2759)	loss 1.1154 (1.1879)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1617 (0.2292)	loss 1.4091 (1.1868)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:15 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1645 (0.2100)	loss 1.0122 (1.1849)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:15 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 18 training takes 0:00:07
[2024-12-02 12:59:16 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:59:16 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:59:16 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:59:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3608 (0.3608)	loss 1.0286 (1.0286)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1643 (0.2109)	loss 1.1265 (1.2362)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:21 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1724 (0.1969)	loss 0.9085 (1.1835)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2402 (0.1990)	loss 1.2118 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:23 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 19 training takes 0:00:06
[2024-12-02 12:59:25 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:59:25 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:59:25 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:59:25 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][0/34]	eta 0:00:17 lr 0.000000	 wd 0.0500	time 0.5050 (0.5050)	loss 1.3092 (1.3092)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:27 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1707 (0.2193)	loss 1.3186 (1.2343)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:29 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1791 (0.2014)	loss 0.9077 (1.2009)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:31 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1793 (0.1931)	loss 1.1030 (1.2027)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:31 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 20 training takes 0:00:06
[2024-12-02 12:59:32 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:59:32 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:59:32 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:59:33 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][0/34]	eta 0:00:13 lr 0.000000	 wd 0.0500	time 0.3844 (0.3844)	loss 1.0226 (1.0226)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1632 (0.1961)	loss 1.2127 (1.1962)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2471 (0.1989)	loss 1.6450 (1.1826)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2608 (0.2135)	loss 1.4221 (1.1872)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:40 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 21 training takes 0:00:07
[2024-12-02 12:59:41 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:59:41 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:59:41 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:59:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3214 (0.3214)	loss 1.4136 (1.4136)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1616 (0.1926)	loss 1.1175 (1.1990)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1714 (0.1799)	loss 1.4164 (1.2163)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1746 (0.1760)	loss 1.3064 (1.1859)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:47 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 22 training takes 0:00:05
[2024-12-02 12:59:47 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:59:47 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:59:47 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:59:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3140 (0.3140)	loss 1.1186 (1.1186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2576 (0.2277)	loss 0.8045 (1.1530)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2456 (0.2358)	loss 1.4216 (1.1972)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1895 (0.2231)	loss 1.1113 (1.1729)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:55 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 23 training takes 0:00:07
[2024-12-02 12:59:56 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 12:59:56 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 12:59:56 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 12:59:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3130 (0.3130)	loss 1.2105 (1.2105)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 12:59:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1950 (0.2009)	loss 1.1162 (1.1744)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2355 (0.2086)	loss 1.2089 (1.1896)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2333 (0.2134)	loss 1.3081 (1.2048)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:03 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 24 training takes 0:00:07
[2024-12-02 13:00:05 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:00:05 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:00:05 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:00:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][0/34]	eta 0:00:16 lr 0.000000	 wd 0.0500	time 0.4725 (0.4725)	loss 1.2229 (1.2229)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.1703 (0.2693)	loss 1.5144 (1.2567)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1853 (0.2222)	loss 1.1144 (1.1926)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:11 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1776 (0.2089)	loss 1.3066 (1.1866)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:12 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 25 training takes 0:00:07
[2024-12-02 13:00:12 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:00:12 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:00:12 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:00:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3452 (0.3452)	loss 1.3199 (1.3199)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:15 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1739 (0.2102)	loss 1.0294 (1.1535)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1851 (0.1933)	loss 1.2143 (1.1770)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2425 (0.2030)	loss 1.0025 (1.1751)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:20 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 26 training takes 0:00:07
[2024-12-02 13:00:21 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:00:21 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:00:21 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:00:21 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][0/34]	eta 0:00:15 lr 0.000000	 wd 0.0500	time 0.4468 (0.4468)	loss 1.4119 (1.4119)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1671 (0.2090)	loss 1.5333 (1.1610)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:25 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1590 (0.1882)	loss 1.4040 (1.1913)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1608 (0.1819)	loss 1.4108 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:27 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 27 training takes 0:00:06
[2024-12-02 13:00:28 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:00:28 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:00:28 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:00:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3220 (0.3220)	loss 1.3144 (1.3144)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1823 (0.1910)	loss 1.2006 (1.1132)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2400 (0.1963)	loss 1.4167 (1.1531)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2360 (0.2099)	loss 1.1021 (1.1701)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:35 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 28 training takes 0:00:07
[2024-12-02 13:00:36 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:00:36 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:00:36 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:00:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3642 (0.3642)	loss 1.3227 (1.3227)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1675 (0.2057)	loss 1.0086 (1.2451)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1827 (0.2051)	loss 1.0040 (1.2303)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:42 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1834 (0.2009)	loss 1.2243 (1.2024)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:43 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 29 training takes 0:00:06
[2024-12-02 13:00:44 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:00:44 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:00:44 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:00:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3651 (0.3651)	loss 1.1026 (1.1026)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][10/34]	eta 0:00:08 lr 0.000000	 wd 0.0500	time 0.2559 (0.3428)	loss 1.1117 (1.1223)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][20/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1816 (0.3120)	loss 1.1088 (1.1668)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][30/34]	eta 0:00:01 lr 0.000000	 wd 0.0500	time 0.1657 (0.2674)	loss 1.4201 (1.1742)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:00:53 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 30 training takes 0:00:08
[2024-12-02 13:00:54 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:00:54 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:00:54 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:00:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3600 (0.3600)	loss 1.3124 (1.3124)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:16 swin_tiny_patch4_window7_224] (main.py 382): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 1.5625e-05
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.5625e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.5625e-08
  WEIGHT_DECAY: 0.05

[2024-12-02 13:01:16 swin_tiny_patch4_window7_224] (main.py 383): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 13:01:16 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:01:16 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 13:01:16 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 13:01:16 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 13:01:16 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:01:16 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:01:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][0/34]	eta 0:00:08 lr 0.000000	 wd 0.0500	time 0.2579 (0.2579)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1574 (0.1791)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1579 (0.1767)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1651 (0.1769)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:22 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:05
[2024-12-02 13:01:23 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:01:23 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:01:23 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:01:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3088 (0.3088)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2477 (0.2391)	loss 1.2106 (1.1857)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1643 (0.2335)	loss 1.3177 (1.1705)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1722 (0.2116)	loss 1.0078 (1.1956)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:30 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 1 training takes 0:00:07
[2024-12-02 13:01:31 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:01:31 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:01:31 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:01:31 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3103 (0.3103)	loss 0.9030 (0.9030)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:33 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1635 (0.1990)	loss 1.3133 (1.1674)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:35 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1597 (0.1873)	loss 1.1163 (1.1561)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1643 (0.1789)	loss 1.3294 (1.1946)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:37 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 2 training takes 0:00:06
[2024-12-02 13:01:38 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:01:38 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:01:38 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:01:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][0/34]	eta 0:00:16 lr 0.000000	 wd 0.0500	time 0.4938 (0.4938)	loss 1.2180 (1.2180)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.2360 (0.2790)	loss 0.8115 (1.1970)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1642 (0.2273)	loss 1.2076 (1.2151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1612 (0.2059)	loss 1.2020 (1.1984)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:45 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 3 training takes 0:00:06
[2024-12-02 13:01:46 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:01:46 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:01:46 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:01:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3595 (0.3595)	loss 1.4127 (1.4127)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1669 (0.1906)	loss 1.1205 (1.1524)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1600 (0.1772)	loss 1.4133 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2474 (0.1788)	loss 1.0023 (1.1951)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:52 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 4 training takes 0:00:06
[2024-12-02 13:01:54 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:01:54 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:01:54 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:01:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][0/34]	eta 0:00:14 lr 0.000000	 wd 0.0500	time 0.4377 (0.4377)	loss 1.0050 (1.0050)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1594 (0.2097)	loss 1.3082 (1.1669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1945 (0.1920)	loss 1.4345 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:01:59 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1629 (0.1875)	loss 1.1244 (1.1977)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:00 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 5 training takes 0:00:06
[2024-12-02 13:02:01 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:02:01 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:02:01 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:02:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3098 (0.3098)	loss 1.2188 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1867 (0.1943)	loss 0.8230 (1.1925)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1566 (0.1836)	loss 1.2182 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2405 (0.2008)	loss 1.2178 (1.1813)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:08 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 6 training takes 0:00:06
[2024-12-02 13:02:09 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:02:09 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:02:09 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:02:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3168 (0.3168)	loss 1.0111 (1.0111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:11 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1810 (0.1961)	loss 1.0072 (1.1654)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1738 (0.1829)	loss 0.9054 (1.1399)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:14 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1693 (0.1814)	loss 1.2147 (1.1798)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:15 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 7 training takes 0:00:06
[2024-12-02 13:02:16 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:02:16 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:02:16 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:02:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3416 (0.3416)	loss 1.1182 (1.1182)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1727 (0.1941)	loss 1.0214 (1.2186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2345 (0.2147)	loss 1.2093 (1.2085)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1617 (0.2135)	loss 1.0152 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:23 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 8 training takes 0:00:07
[2024-12-02 13:02:24 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:02:24 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:02:24 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:02:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3422 (0.3422)	loss 1.0264 (1.0264)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1580 (0.1880)	loss 1.3252 (1.1444)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1799 (0.1806)	loss 1.5173 (1.1804)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1695 (0.1786)	loss 1.5330 (1.1794)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:30 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 9 training takes 0:00:06
[2024-12-02 13:02:31 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:02:31 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:02:31 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:02:31 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3106 (0.3106)	loss 1.3284 (1.3284)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2535 (0.2464)	loss 1.1036 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1626 (0.2375)	loss 1.2124 (1.1887)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1631 (0.2144)	loss 1.1163 (1.1807)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:38 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 10 training takes 0:00:07
[2024-12-02 13:02:39 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:02:39 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:02:39 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:02:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3495 (0.3495)	loss 1.4163 (1.4163)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:42 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1609 (0.2012)	loss 0.8097 (1.2118)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1831 (0.1913)	loss 1.3154 (1.2331)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1656 (0.1826)	loss 0.7169 (1.1948)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:46 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 11 training takes 0:00:06
[2024-12-02 13:02:47 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:02:47 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:02:47 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:02:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][0/34]	eta 0:00:18 lr 0.000000	 wd 0.0500	time 0.5361 (0.5361)	loss 1.1152 (1.1152)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.1590 (0.2588)	loss 1.3062 (1.2064)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1657 (0.2158)	loss 1.0982 (1.2008)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1763 (0.2008)	loss 1.4206 (1.1763)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:54 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 12 training takes 0:00:06
[2024-12-02 13:02:55 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:02:55 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:02:55 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:02:55 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.2998 (0.2998)	loss 1.2212 (1.2212)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:57 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1710 (0.1847)	loss 1.2048 (1.1112)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:02:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1746 (0.1834)	loss 1.3212 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2366 (0.1888)	loss 1.3129 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:01 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 13 training takes 0:00:06
[2024-12-02 13:03:02 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:03:02 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:03:02 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:03:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3617 (0.3617)	loss 1.3150 (1.3150)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1725 (0.2020)	loss 0.9079 (1.0414)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1762 (0.1891)	loss 1.5214 (1.1916)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:08 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1648 (0.1868)	loss 1.2292 (1.1842)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:09 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 14 training takes 0:00:06
[2024-12-02 13:03:10 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:03:10 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:03:10 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:03:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3041 (0.3041)	loss 0.8971 (0.8971)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:12 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1767 (0.1887)	loss 1.4212 (1.1306)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:14 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2766 (0.1965)	loss 1.3204 (1.1848)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2503 (0.2092)	loss 1.3373 (1.1890)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:17 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 15 training takes 0:00:07
[2024-12-02 13:03:18 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:03:18 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:03:18 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:03:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3064 (0.3064)	loss 1.0005 (1.0005)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1736 (0.2055)	loss 1.2136 (1.1193)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1728 (0.1951)	loss 0.8986 (1.1694)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1646 (0.1889)	loss 1.3288 (1.1791)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:24 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 16 training takes 0:00:06
[2024-12-02 13:03:25 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:03:25 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:03:25 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:03:25 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3477 (0.3477)	loss 1.4139 (1.4139)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2747 (0.2300)	loss 1.3061 (1.2603)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1661 (0.2358)	loss 1.2102 (1.1890)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1901 (0.2169)	loss 1.0017 (1.1820)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:32 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 17 training takes 0:00:07
[2024-12-02 13:03:33 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:03:33 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:03:33 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:03:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3026 (0.3026)	loss 1.3049 (1.3049)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:35 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1662 (0.1855)	loss 1.1154 (1.1879)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1846 (0.1811)	loss 1.4091 (1.1868)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1845 (0.1794)	loss 1.0122 (1.1849)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:39 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 18 training takes 0:00:06
[2024-12-02 13:03:41 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:03:41 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:03:41 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:03:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][0/34]	eta 0:00:16 lr 0.000000	 wd 0.0500	time 0.4812 (0.4812)	loss 1.0286 (1.0286)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.1682 (0.2579)	loss 1.1265 (1.2362)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1610 (0.2130)	loss 0.9085 (1.1835)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1661 (0.1997)	loss 1.2118 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:47 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 19 training takes 0:00:06
[2024-12-02 13:03:48 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:03:48 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:03:48 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:03:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3040 (0.3040)	loss 1.3092 (1.3092)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1547 (0.1833)	loss 1.3186 (1.2343)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1605 (0.1745)	loss 0.9077 (1.2009)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2315 (0.1736)	loss 1.1030 (1.2027)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:54 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 20 training takes 0:00:06
[2024-12-02 13:03:56 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:03:56 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:03:56 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:03:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][0/34]	eta 0:00:14 lr 0.000000	 wd 0.0500	time 0.4247 (0.4247)	loss 1.0226 (1.0226)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:03:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1613 (0.2052)	loss 1.2127 (1.1962)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1654 (0.1894)	loss 1.6450 (1.1826)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1746 (0.1818)	loss 1.4221 (1.1872)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:02 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 21 training takes 0:00:06
[2024-12-02 13:04:03 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:04:03 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:04:03 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:04:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3003 (0.3003)	loss 1.4136 (1.4136)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1691 (0.2002)	loss 1.1175 (1.1990)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2190 (0.1905)	loss 1.4164 (1.2163)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2067 (0.2032)	loss 1.3064 (1.1859)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:10 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 22 training takes 0:00:07
[2024-12-02 13:04:11 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:04:11 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:04:11 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:04:11 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3426 (0.3426)	loss 1.1186 (1.1186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1636 (0.1879)	loss 0.8045 (1.1530)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:14 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1572 (0.1758)	loss 1.4216 (1.1972)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1585 (0.1709)	loss 1.1113 (1.1729)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:17 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 23 training takes 0:00:05
[2024-12-02 13:04:17 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:04:17 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:04:17 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:04:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3288 (0.3288)	loss 1.2105 (1.2105)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1740 (0.1899)	loss 1.1162 (1.1744)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2392 (0.2043)	loss 1.2089 (1.1896)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1625 (0.2082)	loss 1.3081 (1.2048)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:24 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 24 training takes 0:00:06
[2024-12-02 13:04:25 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:04:25 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:04:25 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:04:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3161 (0.3161)	loss 1.2229 (1.2229)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:27 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1627 (0.1932)	loss 1.5144 (1.2567)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:29 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1900 (0.1877)	loss 1.1144 (1.1926)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:31 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1594 (0.1798)	loss 1.3066 (1.1866)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:31 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 25 training takes 0:00:06
[2024-12-02 13:04:32 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:04:32 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:04:32 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:04:33 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3529 (0.3529)	loss 1.3199 (1.3199)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:35 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2359 (0.2314)	loss 1.0294 (1.1535)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1611 (0.2255)	loss 1.2143 (1.1770)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1815 (0.2110)	loss 1.0025 (1.1751)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:40 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 26 training takes 0:00:07
[2024-12-02 13:04:41 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:04:41 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:04:41 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:04:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3578 (0.3578)	loss 1.4119 (1.4119)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1672 (0.1975)	loss 1.5333 (1.1610)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1720 (0.1824)	loss 1.4040 (1.1913)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1682 (0.1812)	loss 1.4108 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:47 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 27 training takes 0:00:06
[2024-12-02 13:04:48 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:04:48 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:04:48 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:04:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][0/34]	eta 0:00:15 lr 0.000000	 wd 0.0500	time 0.4512 (0.4512)	loss 1.3144 (1.3144)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.1775 (0.2635)	loss 1.2006 (1.1132)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1632 (0.2200)	loss 1.4167 (1.1531)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1709 (0.2016)	loss 1.1021 (1.1701)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:55 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 28 training takes 0:00:06
[2024-12-02 13:04:56 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:04:56 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:04:56 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:04:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3424 (0.3424)	loss 1.3227 (1.3227)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:04:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1590 (0.1872)	loss 1.0086 (1.2451)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1652 (0.1811)	loss 1.0040 (1.2303)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:02 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2341 (0.1864)	loss 1.2243 (1.2024)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:02 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 29 training takes 0:00:06
[2024-12-02 13:05:04 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:05:04 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:05:04 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:05:04 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][0/34]	eta 0:00:15 lr 0.000000	 wd 0.0500	time 0.4616 (0.4616)	loss 1.1026 (1.1026)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1901 (0.2010)	loss 1.1117 (1.1223)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1633 (0.1846)	loss 1.1088 (1.1668)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1687 (0.1805)	loss 1.4201 (1.1742)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:10 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 30 training takes 0:00:06
[2024-12-02 13:05:11 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:05:11 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:05:11 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:05:11 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3500 (0.3500)	loss 1.3124 (1.3124)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1826 (0.2034)	loss 1.3106 (1.2149)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:15 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2409 (0.1970)	loss 1.2093 (1.1914)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2403 (0.2116)	loss 0.7156 (1.1797)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:18 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 31 training takes 0:00:07
[2024-12-02 13:05:19 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:05:19 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:05:19 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:05:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3202 (0.3202)	loss 1.0058 (1.0058)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:21 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1696 (0.1943)	loss 1.0125 (1.2167)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1595 (0.1803)	loss 1.0123 (1.1377)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1726 (0.1779)	loss 1.4166 (1.1854)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:25 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 32 training takes 0:00:06
[2024-12-02 13:05:26 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:05:26 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:05:26 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:05:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [33/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3059 (0.3059)	loss 1.1313 (1.1313)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [33/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.2505 (0.2037)	loss 0.6049 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [33/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.2515 (0.2225)	loss 1.3294 (1.1954)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [33/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1605 (0.2101)	loss 1.0163 (1.1927)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:33 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 33 training takes 0:00:07
[2024-12-02 13:05:34 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:05:34 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:05:34 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:05:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [34/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3523 (0.3523)	loss 1.1084 (1.1084)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [34/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1883 (0.2021)	loss 1.3212 (1.1620)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [34/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1645 (0.1845)	loss 1.3186 (1.1931)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [34/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1725 (0.1808)	loss 0.9284 (1.1845)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:40 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 34 training takes 0:00:06
[2024-12-02 13:05:41 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:05:41 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:05:41 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:05:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [35/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3148 (0.3148)	loss 1.1111 (1.1111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [35/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.2363 (0.2431)	loss 0.8124 (1.1889)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [35/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1628 (0.2299)	loss 0.9057 (1.1603)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [35/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1613 (0.2088)	loss 1.6174 (1.1775)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:48 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 35 training takes 0:00:06
[2024-12-02 13:05:49 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:05:49 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:05:49 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:05:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [36/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3648 (0.3648)	loss 1.4135 (1.4135)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [36/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1651 (0.2027)	loss 1.3019 (1.1401)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [36/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1838 (0.1849)	loss 1.1178 (1.1869)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [36/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1752 (0.1841)	loss 1.0131 (1.1773)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:55 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 36 training takes 0:00:06
[2024-12-02 13:05:56 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:05:56 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:05:56 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:05:57 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/50][0/34]	eta 0:00:14 lr 0.000000	 wd 0.0500	time 0.4166 (0.4166)	loss 1.3151 (1.3151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:05:59 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1638 (0.2309)	loss 1.1040 (1.2517)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1895 (0.2058)	loss 0.7092 (1.2056)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:02 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1663 (0.1965)	loss 1.1129 (1.1746)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:03 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 37 training takes 0:00:06
[2024-12-02 13:06:04 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:06:04 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:06:04 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:06:04 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [38/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3521 (0.3521)	loss 0.9028 (0.9028)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [38/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1808 (0.1983)	loss 1.2352 (1.1704)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:08 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [38/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1869 (0.1914)	loss 1.4207 (1.1830)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [38/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2322 (0.2067)	loss 1.0141 (1.1747)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:11 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 38 training takes 0:00:07
[2024-12-02 13:06:12 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:06:12 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:06:12 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:06:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [39/50][0/34]	eta 0:00:12 lr 0.000000	 wd 0.0500	time 0.3666 (0.3666)	loss 0.9233 (0.9233)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:14 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [39/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1671 (0.2074)	loss 1.3170 (1.2329)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [39/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1642 (0.1887)	loss 1.3231 (1.2046)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [39/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1604 (0.1841)	loss 0.9093 (1.2043)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:18 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 39 training takes 0:00:06
[2024-12-02 13:06:19 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:06:19 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:06:19 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:06:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [40/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3114 (0.3114)	loss 1.1246 (1.1246)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [40/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1638 (0.1946)	loss 1.2323 (1.1760)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [40/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2423 (0.2137)	loss 1.1203 (1.2085)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [40/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1634 (0.2135)	loss 1.0112 (1.2018)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:27 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 40 training takes 0:00:07
[2024-12-02 13:06:28 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:06:28 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:06:28 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:06:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [41/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3126 (0.3126)	loss 1.0274 (1.0274)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [41/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1712 (0.1962)	loss 1.1096 (1.2295)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:31 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [41/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1736 (0.1874)	loss 1.1239 (1.2008)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:33 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [41/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1630 (0.1800)	loss 1.2138 (1.2016)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:34 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 41 training takes 0:00:06
[2024-12-02 13:06:35 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:06:35 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:06:35 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:06:35 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [42/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3381 (0.3381)	loss 0.9176 (0.9176)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [42/50][10/34]	eta 0:00:06 lr 0.000000	 wd 0.0500	time 0.2586 (0.2513)	loss 1.3111 (1.1131)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [42/50][20/34]	eta 0:00:03 lr 0.000000	 wd 0.0500	time 0.1639 (0.2309)	loss 1.1106 (1.1564)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [42/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1777 (0.2134)	loss 1.0226 (1.1715)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:42 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 42 training takes 0:00:07
[2024-12-02 13:06:43 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:06:43 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:06:43 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:06:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [43/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3333 (0.3333)	loss 1.3139 (1.3139)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [43/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1660 (0.2037)	loss 0.7032 (1.1111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [43/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1671 (0.1881)	loss 1.0167 (1.1435)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [43/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1766 (0.1853)	loss 1.3263 (1.1784)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:49 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 43 training takes 0:00:06
[2024-12-02 13:06:50 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:06:50 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:06:50 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:06:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [44/50][0/34]	eta 0:00:15 lr 0.000000	 wd 0.0500	time 0.4540 (0.4540)	loss 1.2082 (1.2082)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [44/50][10/34]	eta 0:00:05 lr 0.000000	 wd 0.0500	time 0.1704 (0.2465)	loss 1.1141 (1.1958)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:55 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [44/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1647 (0.2133)	loss 1.0141 (1.2047)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:57 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [44/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1693 (0.2013)	loss 1.4171 (1.2017)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:06:57 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 44 training takes 0:00:06
[2024-12-02 13:06:58 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:06:58 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:06:58 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:06:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [45/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3104 (0.3104)	loss 1.0091 (1.0091)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [45/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1644 (0.1895)	loss 1.0239 (1.1648)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:02 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [45/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1725 (0.1783)	loss 1.0019 (1.1559)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:04 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [45/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2397 (0.1921)	loss 1.2294 (1.1755)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:05 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 45 training takes 0:00:06
[2024-12-02 13:07:06 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:07:06 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:07:06 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:07:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [46/50][0/34]	eta 0:00:11 lr 0.000000	 wd 0.0500	time 0.3386 (0.3386)	loss 1.0175 (1.0175)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:08 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [46/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1602 (0.1924)	loss 1.2075 (1.2443)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [46/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1784 (0.1836)	loss 1.4277 (1.2311)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:12 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [46/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1703 (0.1782)	loss 1.1107 (1.1996)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:12 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 46 training takes 0:00:06
[2024-12-02 13:07:13 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:07:13 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:07:13 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:07:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [47/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3066 (0.3066)	loss 1.3101 (1.3101)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:15 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [47/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1657 (0.1919)	loss 1.1094 (1.1374)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [47/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2454 (0.1991)	loss 1.1018 (1.1581)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [47/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.2072 (0.2078)	loss 1.3091 (1.1700)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:20 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 47 training takes 0:00:06
[2024-12-02 13:07:21 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:07:21 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:07:21 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:07:21 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [48/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3064 (0.3064)	loss 1.1175 (1.1175)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [48/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.1562 (0.1849)	loss 0.9134 (1.1412)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:25 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [48/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.1832 (0.1779)	loss 1.2073 (1.2090)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [48/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1599 (0.1756)	loss 1.2137 (1.1842)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:27 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 48 training takes 0:00:05
[2024-12-02 13:07:28 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:07:28 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:07:28 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:07:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [49/50][0/34]	eta 0:00:10 lr 0.000000	 wd 0.0500	time 0.3014 (0.3014)	loss 1.1293 (1.1293)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [49/50][10/34]	eta 0:00:04 lr 0.000000	 wd 0.0500	time 0.2077 (0.1859)	loss 1.1128 (1.2068)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [49/50][20/34]	eta 0:00:02 lr 0.000000	 wd 0.0500	time 0.2239 (0.2077)	loss 1.0198 (1.1625)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [49/50][30/34]	eta 0:00:00 lr 0.000000	 wd 0.0500	time 0.1593 (0.2009)	loss 1.2172 (1.1699)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:07:35 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 49 training takes 0:00:06
[2024-12-02 13:07:35 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:07:35 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:07:35 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:07:36 swin_tiny_patch4_window7_224] (main.py 175): INFO Training time 0:06:19
[2024-12-02 13:14:11 swin_tiny_patch4_window7_224] (main.py 382): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 3.125e-06
  WEIGHT_DECAY: 0.05

[2024-12-02 13:14:11 swin_tiny_patch4_window7_224] (main.py 383): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 13:14:11 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:14:11 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 13:14:11 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 13:14:11 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 13:14:11 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:14:11 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:14:12 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][0/34]	eta 0:00:09 lr 0.000003	 wd 0.0500	time 0.2794 (0.2794)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1583 (0.1794)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:15 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1692 (0.1700)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2440 (0.1757)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:17 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 13:14:19 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:14:19 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:14:19 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:14:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][0/34]	eta 0:00:17 lr 0.000003	 wd 0.0500	time 0.5050 (0.5050)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:21 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1792 (0.2257)	loss 1.2106 (1.1857)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1714 (0.2015)	loss 1.3177 (1.1705)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:25 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1703 (0.1928)	loss 1.0078 (1.1956)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:25 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 1 training takes 0:00:06
[2024-12-02 13:14:26 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:14:26 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:14:26 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:14:27 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3452 (0.3452)	loss 0.9030 (0.9030)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1729 (0.2001)	loss 1.3133 (1.1674)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2139 (0.1849)	loss 1.1163 (1.1561)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2363 (0.2010)	loss 1.3294 (1.1946)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:33 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 2 training takes 0:00:06
[2024-12-02 13:14:34 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:14:34 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:14:34 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:14:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3061 (0.3061)	loss 1.2180 (1.2180)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1725 (0.1848)	loss 0.8115 (1.1970)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1628 (0.1789)	loss 1.2076 (1.2151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1727 (0.1749)	loss 1.2020 (1.1984)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:40 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 3 training takes 0:00:05
[2024-12-02 13:14:41 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:14:41 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:14:41 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:14:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3335 (0.3335)	loss 1.4127 (1.4127)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1699 (0.1952)	loss 1.1205 (1.1524)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2457 (0.2038)	loss 1.4133 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1773 (0.2093)	loss 1.0023 (1.1951)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:48 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 4 training takes 0:00:07
[2024-12-02 13:14:49 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:14:49 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:14:49 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:14:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3062 (0.3062)	loss 1.0050 (1.0050)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1605 (0.1928)	loss 1.3082 (1.1669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1599 (0.1789)	loss 1.4345 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1729 (0.1748)	loss 1.1244 (1.1977)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:55 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 5 training takes 0:00:06
[2024-12-02 13:14:56 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:14:56 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:14:56 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:14:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3397 (0.3397)	loss 1.2188 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:14:59 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.2340 (0.2398)	loss 0.8230 (1.1925)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2328 (0.2385)	loss 1.2182 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1607 (0.2199)	loss 1.2178 (1.1813)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:03 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 6 training takes 0:00:07
[2024-12-02 13:15:04 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:15:04 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:15:04 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:15:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3451 (0.3451)	loss 1.0111 (1.0111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1612 (0.1871)	loss 1.0072 (1.1654)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:08 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1805 (0.1842)	loss 0.9054 (1.1399)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1643 (0.1787)	loss 1.2147 (1.1798)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:10 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 7 training takes 0:00:06
[2024-12-02 13:15:11 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:15:11 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:15:11 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:15:12 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][0/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4225 (0.4225)	loss 1.1182 (1.1182)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:14 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2263 (0.2680)	loss 1.0214 (1.2186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1582 (0.2209)	loss 1.2093 (1.2085)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1864 (0.2027)	loss 1.0152 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:18 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 8 training takes 0:00:06
[2024-12-02 13:15:19 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:15:19 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:15:19 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:15:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3071 (0.3071)	loss 1.0264 (1.0264)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:21 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1626 (0.1901)	loss 1.3252 (1.1444)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1620 (0.1759)	loss 1.5173 (1.1804)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1875 (0.1728)	loss 1.5330 (1.1794)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:25 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 9 training takes 0:00:06
[2024-12-02 13:15:27 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:15:27 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:15:27 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:15:27 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][0/34]	eta 0:00:17 lr 0.000003	 wd 0.0500	time 0.5040 (0.5040)	loss 1.3284 (1.3284)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:29 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1581 (0.2222)	loss 1.1036 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:31 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1566 (0.1971)	loss 1.2124 (1.1887)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1712 (0.1881)	loss 1.1163 (1.1807)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:33 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 10 training takes 0:00:06
[2024-12-02 13:15:34 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:15:34 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:15:34 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:15:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3440 (0.3440)	loss 1.4163 (1.4163)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1718 (0.1956)	loss 0.8097 (1.2118)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1771 (0.1817)	loss 1.3154 (1.2331)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2620 (0.1991)	loss 0.7169 (1.1948)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:41 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 11 training takes 0:00:06
[2024-12-02 13:15:42 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:15:42 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:15:42 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:15:42 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][0/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4294 (0.4294)	loss 1.1152 (1.1152)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1723 (0.1993)	loss 1.3062 (1.2064)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1837 (0.1843)	loss 1.0982 (1.2008)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1609 (0.1786)	loss 1.4206 (1.1763)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:48 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 12 training takes 0:00:06
[2024-12-02 13:15:49 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:15:49 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:15:49 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:15:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3680 (0.3680)	loss 1.2212 (1.2212)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1578 (0.1885)	loss 1.2048 (1.1112)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2403 (0.2069)	loss 1.3212 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [13/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1698 (0.2118)	loss 1.3129 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:56 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 13 training takes 0:00:07
[2024-12-02 13:15:57 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:15:57 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:15:57 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:15:57 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3484 (0.3484)	loss 1.3150 (1.3150)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:15:59 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1611 (0.2003)	loss 0.9079 (1.0414)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1658 (0.1832)	loss 1.5214 (1.1916)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [14/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1594 (0.1802)	loss 1.2292 (1.1842)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:03 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 14 training takes 0:00:06
[2024-12-02 13:16:04 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:16:04 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:16:04 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:16:04 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3717 (0.3717)	loss 0.8971 (0.8971)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.2322 (0.2467)	loss 1.4212 (1.1306)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1739 (0.2371)	loss 1.3204 (1.1848)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:11 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [15/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1753 (0.2168)	loss 1.3373 (1.1890)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:11 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 15 training takes 0:00:07
[2024-12-02 13:16:12 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:16:12 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:16:12 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:16:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3337 (0.3337)	loss 1.0005 (1.0005)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:14 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1663 (0.1976)	loss 1.2136 (1.1193)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1678 (0.1854)	loss 0.8986 (1.1694)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [16/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1788 (0.1806)	loss 1.3288 (1.1791)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:18 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 16 training takes 0:00:06
[2024-12-02 13:16:20 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:16:20 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:16:20 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:16:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.4050 (0.4050)	loss 1.4139 (1.4139)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.1694 (0.2513)	loss 1.3061 (1.2603)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1746 (0.2158)	loss 1.2102 (1.1890)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [17/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1581 (0.2027)	loss 1.0017 (1.1820)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:27 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 17 training takes 0:00:06
[2024-12-02 13:16:28 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:16:28 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:16:28 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:16:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3484 (0.3484)	loss 1.3049 (1.3049)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1540 (0.1895)	loss 1.1154 (1.1879)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:31 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1698 (0.1786)	loss 1.4091 (1.1868)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:33 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [18/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2317 (0.1898)	loss 1.0122 (1.1849)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:34 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 18 training takes 0:00:06
[2024-12-02 13:16:35 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:16:35 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:16:35 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:16:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3040 (0.3040)	loss 1.0286 (1.0286)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1708 (0.1881)	loss 1.1265 (1.2362)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1820 (0.1763)	loss 0.9085 (1.1835)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [19/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1700 (0.1744)	loss 1.2118 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:41 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 19 training takes 0:00:05
[2024-12-02 13:16:42 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:16:42 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:16:42 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:16:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3250 (0.3250)	loss 1.3092 (1.3092)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1770 (0.1843)	loss 1.3186 (1.2343)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2467 (0.1846)	loss 0.9077 (1.2009)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [20/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2305 (0.2052)	loss 1.1030 (1.2027)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:49 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 20 training takes 0:00:06
[2024-12-02 13:16:50 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:16:50 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:16:50 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:16:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3517 (0.3517)	loss 1.0226 (1.0226)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1637 (0.1994)	loss 1.2127 (1.1962)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1687 (0.1859)	loss 1.6450 (1.1826)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [21/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1703 (0.1845)	loss 1.4221 (1.1872)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:16:57 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 21 training takes 0:00:06
[2024-12-02 13:16:58 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:16:58 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:16:58 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:16:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3124 (0.3124)	loss 1.4136 (1.4136)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.2546 (0.2235)	loss 1.1175 (1.1990)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:02 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2179 (0.2322)	loss 1.4164 (1.2163)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:04 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [22/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1784 (0.2206)	loss 1.3064 (1.1859)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:05 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 22 training takes 0:00:07
[2024-12-02 13:17:06 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:17:06 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:17:06 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:17:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3434 (0.3434)	loss 1.1186 (1.1186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:08 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1860 (0.2076)	loss 0.8045 (1.1530)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1706 (0.1923)	loss 1.4216 (1.1972)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:12 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [23/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1692 (0.1843)	loss 1.1113 (1.1729)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:12 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 23 training takes 0:00:06
[2024-12-02 13:17:14 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:17:14 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:17:14 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:17:14 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][0/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4310 (0.4310)	loss 1.2105 (1.2105)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1696 (0.2402)	loss 1.1162 (1.1744)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1815 (0.2111)	loss 1.2089 (1.1896)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [24/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1743 (0.1991)	loss 1.3081 (1.2048)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:20 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 24 training takes 0:00:06
[2024-12-02 13:17:21 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:17:21 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:17:21 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:17:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3488 (0.3488)	loss 1.2229 (1.2229)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1716 (0.1941)	loss 1.5144 (1.2567)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:25 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1776 (0.1873)	loss 1.1144 (1.1926)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [25/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2656 (0.2055)	loss 1.3066 (1.1866)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:29 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 25 training takes 0:00:07
[2024-12-02 13:17:30 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:17:30 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:17:30 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:17:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3514 (0.3514)	loss 1.3199 (1.3199)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1589 (0.1872)	loss 1.0294 (1.1535)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1631 (0.1851)	loss 1.2143 (1.1770)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:35 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [26/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1573 (0.1775)	loss 1.0025 (1.1751)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:36 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 26 training takes 0:00:06
[2024-12-02 13:17:37 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:17:37 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:17:37 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:17:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3371 (0.3371)	loss 1.4119 (1.4119)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1586 (0.1911)	loss 1.5333 (1.1610)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2580 (0.2125)	loss 1.4040 (1.1913)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [27/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1565 (0.2112)	loss 1.4108 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:44 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 27 training takes 0:00:07
[2024-12-02 13:17:45 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:17:45 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:17:45 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:17:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3292 (0.3292)	loss 1.3144 (1.3144)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1591 (0.1877)	loss 1.2006 (1.1132)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1643 (0.1768)	loss 1.4167 (1.1531)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [28/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1956 (0.1761)	loss 1.1021 (1.1701)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:51 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 28 training takes 0:00:06
[2024-12-02 13:17:52 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:17:52 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:17:52 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:17:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3650 (0.3650)	loss 1.3227 (1.3227)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:55 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2393 (0.2638)	loss 1.0086 (1.2451)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:57 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1812 (0.2424)	loss 1.0040 (1.2303)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:59 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [29/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1669 (0.2232)	loss 1.2243 (1.2024)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:17:59 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 29 training takes 0:00:07
[2024-12-02 13:18:00 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:18:00 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:18:00 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:18:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3748 (0.3748)	loss 1.1026 (1.1026)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.2140 (0.2174)	loss 1.1117 (1.1223)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:04 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1627 (0.1979)	loss 1.1088 (1.1668)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [30/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1827 (0.1909)	loss 1.4201 (1.1742)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:07 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 30 training takes 0:00:06
[2024-12-02 13:18:08 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:18:08 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:18:08 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:18:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/50][0/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4306 (0.4306)	loss 1.3124 (1.3124)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:11 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1817 (0.2314)	loss 1.3106 (1.2149)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1767 (0.2071)	loss 1.2093 (1.1914)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:14 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [31/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1684 (0.1936)	loss 0.7156 (1.1797)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:15 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 31 training takes 0:00:06
[2024-12-02 13:18:16 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:18:16 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:18:16 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:18:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3138 (0.3138)	loss 1.0058 (1.0058)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1795 (0.1918)	loss 1.0125 (1.2167)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2277 (0.1854)	loss 1.0123 (1.1377)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [32/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2544 (0.2078)	loss 1.4166 (1.1854)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:23 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 32 training takes 0:00:07
[2024-12-02 13:18:24 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:18:24 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:18:24 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:18:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [33/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3462 (0.3462)	loss 1.1313 (1.1313)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [33/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1618 (0.1976)	loss 0.6049 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [33/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1734 (0.1855)	loss 1.3294 (1.1954)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:29 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [33/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1740 (0.1801)	loss 1.0163 (1.1927)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:30 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 33 training takes 0:00:06
[2024-12-02 13:18:31 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:18:31 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:18:31 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:18:31 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [34/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3139 (0.3139)	loss 1.1084 (1.1084)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:33 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [34/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.2489 (0.2040)	loss 1.3212 (1.1620)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [34/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2388 (0.2250)	loss 1.3186 (1.1931)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [34/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1708 (0.2085)	loss 0.9284 (1.1845)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:38 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 34 training takes 0:00:07
[2024-12-02 13:18:39 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:18:39 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:18:39 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:18:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [35/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3530 (0.3530)	loss 1.1111 (1.1111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [35/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1608 (0.1939)	loss 0.8124 (1.1889)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [35/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1598 (0.1785)	loss 0.9057 (1.1603)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [35/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1739 (0.1772)	loss 1.6174 (1.1775)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:45 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 35 training takes 0:00:06
[2024-12-02 13:18:46 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:18:46 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:18:46 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:18:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [36/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.3867 (0.3867)	loss 1.4135 (1.4135)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [36/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2241 (0.2614)	loss 1.3019 (1.1401)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [36/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1741 (0.2280)	loss 1.1178 (1.1869)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [36/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1565 (0.2070)	loss 1.0131 (1.1773)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:53 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 36 training takes 0:00:06
[2024-12-02 13:18:54 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:18:54 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:18:54 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:18:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3275 (0.3275)	loss 1.3151 (1.3151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1702 (0.1947)	loss 1.1040 (1.2517)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:57 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1637 (0.1800)	loss 0.7092 (1.2056)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:18:59 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [37/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1750 (0.1744)	loss 1.1129 (1.1746)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:00 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 37 training takes 0:00:06
[2024-12-02 13:19:01 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:19:01 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:19:01 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:19:02 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [38/50][0/34]	eta 0:00:16 lr 0.000003	 wd 0.0500	time 0.4940 (0.4940)	loss 0.9028 (0.9028)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:04 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [38/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1749 (0.2350)	loss 1.2352 (1.1704)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [38/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1706 (0.2082)	loss 1.4207 (1.1830)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [38/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1797 (0.1984)	loss 1.0141 (1.1747)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:08 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 38 training takes 0:00:06
[2024-12-02 13:19:09 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:19:09 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:19:09 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:19:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [39/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3104 (0.3104)	loss 0.9233 (0.9233)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:11 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [39/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1621 (0.1902)	loss 1.3170 (1.2329)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [39/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1666 (0.1772)	loss 1.3231 (1.2046)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:15 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [39/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2489 (0.1929)	loss 0.9093 (1.2043)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:16 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 39 training takes 0:00:06
[2024-12-02 13:19:17 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:19:17 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:19:17 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:19:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [40/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3223 (0.3223)	loss 1.1246 (1.1246)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [40/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1768 (0.1943)	loss 1.2323 (1.1760)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:21 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [40/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1804 (0.1858)	loss 1.1203 (1.2085)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [40/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1659 (0.1821)	loss 1.0112 (1.2018)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:23 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 40 training takes 0:00:06
[2024-12-02 13:19:24 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:19:24 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:19:24 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:19:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [41/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3488 (0.3488)	loss 1.0274 (1.0274)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [41/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.2150 (0.2079)	loss 1.1096 (1.2295)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:29 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [41/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2664 (0.2265)	loss 1.1239 (1.2008)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [41/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1728 (0.2149)	loss 1.2138 (1.2016)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:31 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 41 training takes 0:00:07
[2024-12-02 13:19:32 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:19:32 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:19:32 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:19:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [42/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3030 (0.3030)	loss 0.9176 (0.9176)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [42/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1707 (0.1927)	loss 1.3111 (1.1131)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [42/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1599 (0.1816)	loss 1.1106 (1.1564)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [42/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1612 (0.1754)	loss 1.0226 (1.1715)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:38 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 42 training takes 0:00:05
[2024-12-02 13:19:39 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:19:39 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:19:39 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:19:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [43/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3377 (0.3377)	loss 1.3139 (1.3139)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:42 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [43/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2663 (0.2541)	loss 0.7032 (1.1111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [43/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1588 (0.2266)	loss 1.0167 (1.1435)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [43/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1892 (0.2096)	loss 1.3263 (1.1784)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:46 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 43 training takes 0:00:07
[2024-12-02 13:19:47 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:19:47 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:19:47 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:19:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [44/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3551 (0.3551)	loss 1.2082 (1.2082)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [44/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1669 (0.1973)	loss 1.1141 (1.1958)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [44/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1739 (0.1869)	loss 1.0141 (1.2047)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [44/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2021 (0.1855)	loss 1.4171 (1.2017)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:53 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 44 training takes 0:00:06
[2024-12-02 13:19:55 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:19:55 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:19:55 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:19:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [45/50][0/34]	eta 0:00:16 lr 0.000003	 wd 0.0500	time 0.4885 (0.4885)	loss 1.0091 (1.0091)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [45/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1762 (0.2262)	loss 1.0239 (1.1648)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:19:59 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [45/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1587 (0.1992)	loss 1.0019 (1.1559)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [45/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1689 (0.1911)	loss 1.2294 (1.1755)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:02 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 45 training takes 0:00:06
[2024-12-02 13:20:03 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:20:03 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:20:03 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:20:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [46/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3364 (0.3364)	loss 1.0175 (1.0175)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:23 swin_tiny_patch4_window7_224] (main.py 382): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 3.125e-06
  WEIGHT_DECAY: 0.05

[2024-12-02 13:20:23 swin_tiny_patch4_window7_224] (main.py 383): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 13:20:23 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:20:23 swin_tiny_patch4_window7_224] (main.py 95): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(1, 96, kernel_size=(2, 2), stride=(2, 2))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(14, 14), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(14, 14), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=192, input_resolution=(7, 7), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=192, out_features=2, bias=True)
)
[2024-12-02 13:20:23 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 13:20:23 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 13:20:23 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:20:23 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:20:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][0/34]	eta 0:00:09 lr 0.000003	 wd 0.0500	time 0.2934 (0.2934)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:25 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1582 (0.1858)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:27 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1733 (0.1815)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1675 (0.1787)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:29 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 13:20:30 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:20:30 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:20:30 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:20:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3160 (0.3160)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.2331 (0.2075)	loss 1.2106 (1.1857)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2287 (0.2193)	loss 1.3177 (1.1705)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1707 (0.2048)	loss 1.0078 (1.1956)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:37 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 1 training takes 0:00:06
[2024-12-02 13:20:38 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:20:38 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:20:38 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:20:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3552 (0.3552)	loss 0.9030 (0.9030)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1702 (0.1939)	loss 1.3133 (1.1674)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:42 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1627 (0.1846)	loss 1.1163 (1.1561)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1932 (0.1806)	loss 1.3294 (1.1946)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:20:44 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 2 training takes 0:00:06
[2024-12-02 13:20:45 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:20:45 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:20:45 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:20:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][0/34]	eta 0:00:16 lr 0.000003	 wd 0.0500	time 0.4892 (0.4892)	loss 1.2180 (1.2180)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:23 swin_tiny_patch4_window7_224] (main.py 382): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 3.125e-06
  WEIGHT_DECAY: 0.05

[2024-12-02 13:22:23 swin_tiny_patch4_window7_224] (main.py 383): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 13:22:23 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:22:23 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 13:22:23 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 13:22:23 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:22:23 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:22:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.3870 (0.3870)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:25 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1559 (0.1870)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1912 (0.1775)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1765 (0.1796)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:29 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 13:22:30 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:22:30 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:22:30 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:22:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3404 (0.3404)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1743 (0.1920)	loss 1.2106 (1.1857)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2502 (0.1908)	loss 1.3177 (1.1705)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2335 (0.2098)	loss 1.0078 (1.1956)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:37 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 1 training takes 0:00:07
[2024-12-02 13:22:38 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:22:38 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:22:38 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:22:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3178 (0.3178)	loss 0.9030 (0.9030)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1862 (0.2023)	loss 1.3133 (1.1674)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:42 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1844 (0.1897)	loss 1.1163 (1.1561)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1741 (0.1855)	loss 1.3294 (1.1946)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:44 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 2 training takes 0:00:06
[2024-12-02 13:22:45 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:22:45 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:22:45 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:22:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3158 (0.3158)	loss 1.2180 (1.2180)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.2259 (0.2072)	loss 0.8115 (1.1970)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2386 (0.2213)	loss 1.2076 (1.2151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:51 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1558 (0.2028)	loss 1.2020 (1.1984)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:52 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 3 training takes 0:00:06
[2024-12-02 13:22:53 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:22:53 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:22:53 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:22:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3458 (0.3458)	loss 1.4127 (1.4127)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:55 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1710 (0.1902)	loss 1.1205 (1.1524)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1862 (0.1835)	loss 1.4133 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1596 (0.1801)	loss 1.0023 (1.1951)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:22:59 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 4 training takes 0:00:06
[2024-12-02 13:23:00 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:23:00 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:23:00 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:23:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][0/34]	eta 0:00:15 lr 0.000003	 wd 0.0500	time 0.4617 (0.4617)	loss 1.0050 (1.0050)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2333 (0.2822)	loss 1.3082 (1.1669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1564 (0.2282)	loss 1.4345 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1676 (0.2095)	loss 1.1244 (1.1977)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:07 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 5 training takes 0:00:07
[2024-12-02 13:23:08 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:23:08 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:23:08 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:23:08 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3254 (0.3254)	loss 1.2188 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1653 (0.1905)	loss 0.8230 (1.1925)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:12 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1726 (0.1830)	loss 1.2182 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2155 (0.1792)	loss 1.2178 (1.1813)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:14 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 6 training takes 0:00:06
[2024-12-02 13:23:15 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:23:15 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:23:15 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:23:16 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][0/34]	eta 0:00:16 lr 0.000003	 wd 0.0500	time 0.4800 (0.4800)	loss 1.0111 (1.0111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:18 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1566 (0.2091)	loss 1.0072 (1.1654)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1615 (0.1861)	loss 0.9054 (1.1399)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:21 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1579 (0.1775)	loss 1.2147 (1.1798)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:21 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 7 training takes 0:00:06
[2024-12-02 13:23:22 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:23:22 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:23:22 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:23:23 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3218 (0.3218)	loss 1.1182 (1.1182)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1788 (0.1899)	loss 1.0214 (1.2186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:26 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1685 (0.1796)	loss 1.2093 (1.2085)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2387 (0.1957)	loss 1.0152 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:29 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 8 training takes 0:00:06
[2024-12-02 13:23:30 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:23:30 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:23:30 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:23:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3022 (0.3022)	loss 1.0264 (1.0264)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1594 (0.1818)	loss 1.3252 (1.1444)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1685 (0.1727)	loss 1.5173 (1.1804)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:35 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1718 (0.1710)	loss 1.5330 (1.1794)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:36 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 9 training takes 0:00:05
[2024-12-02 13:23:37 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:23:37 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:23:37 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:23:37 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3398 (0.3398)	loss 1.3284 (1.3284)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:39 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1793 (0.1941)	loss 1.1036 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:41 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2488 (0.2077)	loss 1.2124 (1.1887)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:43 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1606 (0.2061)	loss 1.1163 (1.1807)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:44 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 10 training takes 0:00:06
[2024-12-02 13:23:45 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:23:45 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:23:45 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:23:45 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3026 (0.3026)	loss 1.4163 (1.4163)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1727 (0.1905)	loss 0.8097 (1.2118)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:49 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1661 (0.1819)	loss 1.3154 (1.2331)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1848 (0.1834)	loss 0.7169 (1.1948)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:23:51 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 11 training takes 0:00:06
[2024-12-02 13:23:53 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:23:53 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:23:53 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:23:53 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [12/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.4046 (0.4046)	loss 1.1152 (1.1152)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:24:38 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:24:38 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 13:24:38 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 13:24:38 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:24:38 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:24:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][0/34]	eta 0:00:09 lr 0.000003	 wd 0.0500	time 0.2687 (0.2687)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:24:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1709 (0.1824)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:24:42 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2567 (0.1858)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:24:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2644 (0.2041)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:24:45 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 0 training takes 0:00:07
[2024-12-02 13:24:46 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:24:46 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:24:46 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:24:47 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3354 (0.3354)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:24:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1870 (0.2003)	loss 1.2106 (1.1857)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:24:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1820 (0.1899)	loss 1.3177 (1.1705)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:24:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1840 (0.1868)	loss 1.0078 (1.1956)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:24:53 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 1 training takes 0:00:06
[2024-12-02 13:24:54 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:24:54 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:24:54 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:24:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3298 (0.3298)	loss 0.9030 (0.9030)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:24:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.2138 (0.2109)	loss 1.3133 (1.1674)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:24:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2340 (0.2260)	loss 1.1163 (1.1561)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1758 (0.2134)	loss 1.3294 (1.1946)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:01 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 2 training takes 0:00:07
[2024-12-02 13:25:02 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:25:02 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:25:02 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:25:02 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3153 (0.3153)	loss 1.2180 (1.2180)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:04 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1673 (0.1879)	loss 0.8115 (1.1970)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:05 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1814 (0.1815)	loss 1.2076 (1.2151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:07 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [3/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1651 (0.1769)	loss 1.2020 (1.1984)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:08 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 3 training takes 0:00:06
[2024-12-02 13:25:09 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:25:09 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:25:09 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:25:09 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3129 (0.3129)	loss 1.4127 (1.4127)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:11 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2596 (0.2643)	loss 1.1205 (1.1524)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:13 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1794 (0.2333)	loss 1.4133 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:15 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [4/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1670 (0.2119)	loss 1.0023 (1.1951)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:16 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 4 training takes 0:00:07
[2024-12-02 13:25:17 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:25:17 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:25:17 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:25:17 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3062 (0.3062)	loss 1.0050 (1.0050)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:19 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1634 (0.1837)	loss 1.3082 (1.1669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:20 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1628 (0.1746)	loss 1.4345 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:22 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [5/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1784 (0.1739)	loss 1.1244 (1.1977)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:22 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 5 training takes 0:00:05
[2024-12-02 13:25:24 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:25:24 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:25:24 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:25:24 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][0/34]	eta 0:00:15 lr 0.000003	 wd 0.0500	time 0.4642 (0.4642)	loss 1.2188 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:27 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1740 (0.2445)	loss 0.8230 (1.1925)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:28 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1815 (0.2152)	loss 1.2182 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:30 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [6/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1709 (0.2045)	loss 1.2178 (1.1813)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:31 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 6 training takes 0:00:06
[2024-12-02 13:25:32 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:25:32 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:25:32 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:25:32 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3468 (0.3468)	loss 1.0111 (1.0111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:34 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1672 (0.1967)	loss 1.0072 (1.1654)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:36 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1775 (0.1885)	loss 0.9054 (1.1399)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:38 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [7/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2577 (0.2101)	loss 1.2147 (1.1798)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:39 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 7 training takes 0:00:07
[2024-12-02 13:25:40 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:25:40 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:25:40 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:25:40 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3538 (0.3538)	loss 1.1182 (1.1182)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:42 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1674 (0.2012)	loss 1.0214 (1.2186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:44 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1820 (0.1902)	loss 1.2093 (1.2085)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:46 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [8/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1832 (0.1889)	loss 1.0152 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:46 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 8 training takes 0:00:06
[2024-12-02 13:25:47 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:25:47 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:25:47 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:25:48 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3755 (0.3755)	loss 1.0264 (1.0264)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:50 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.2259 (0.2208)	loss 1.3252 (1.1444)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:52 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2529 (0.2310)	loss 1.5173 (1.1804)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:54 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [9/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1859 (0.2186)	loss 1.5330 (1.1794)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:55 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 9 training takes 0:00:07
[2024-12-02 13:25:56 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:25:56 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:25:56 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:25:56 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3436 (0.3436)	loss 1.3284 (1.3284)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:25:58 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1830 (0.2014)	loss 1.1036 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:26:00 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1660 (0.1898)	loss 1.2124 (1.1887)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:26:01 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [10/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1943 (0.1867)	loss 1.1163 (1.1807)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:26:02 swin_tiny_patch4_window7_224] (main.py 256): INFO EPOCH 10 training takes 0:00:06
[2024-12-02 13:26:03 swin_tiny_patch4_window7_224] (main.py 305): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:26:03 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:26:03 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:26:03 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][0/34]	eta 0:00:16 lr 0.000003	 wd 0.0500	time 0.4960 (0.4960)	loss 1.4163 (1.4163)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:26:06 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2228 (0.2891)	loss 0.8097 (1.2118)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:26:08 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1844 (0.2353)	loss 1.3154 (1.2331)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:26:10 swin_tiny_patch4_window7_224] (main.py 247): INFO Train: [11/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1683 (0.2139)	loss 0.7169 (1.1948)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:31:19 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:31:19 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 13:31:19 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 13:31:19 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:31:19 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:33:10 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:33:10 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 13:33:10 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 13:33:10 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:33:10 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:33:11 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [0/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.3889 (0.3889)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:13 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [0/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2168 (0.2603)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:15 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [0/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1752 (0.2279)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:17 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1789 (0.2100)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:17 swin_tiny_patch4_window7_224] (main.py 257): INFO EPOCH 0 training takes 0:00:07
[2024-12-02 13:33:18 swin_tiny_patch4_window7_224] (main.py 306): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:33:18 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:33:18 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:33:19 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [1/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3546 (0.3546)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:20 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [1/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1741 (0.1969)	loss 1.2106 (1.1857)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:22 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [1/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1597 (0.1852)	loss 1.3177 (1.1705)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:24 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1672 (0.1817)	loss 1.0078 (1.1956)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:25 swin_tiny_patch4_window7_224] (main.py 257): INFO EPOCH 1 training takes 0:00:06
[2024-12-02 13:33:26 swin_tiny_patch4_window7_224] (main.py 306): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:33:26 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:33:26 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:33:27 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [2/50][0/34]	eta 0:00:16 lr 0.000003	 wd 0.0500	time 0.4936 (0.4936)	loss 0.9030 (0.9030)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:29 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [2/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1680 (0.2348)	loss 1.3133 (1.1674)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:30 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [2/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1653 (0.2034)	loss 1.1163 (1.1561)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:32 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1655 (0.1943)	loss 1.3294 (1.1946)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:33 swin_tiny_patch4_window7_224] (main.py 257): INFO EPOCH 2 training takes 0:00:06
[2024-12-02 13:33:34 swin_tiny_patch4_window7_224] (main.py 306): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:33:34 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:33:34 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:33:34 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [3/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3426 (0.3426)	loss 1.2180 (1.2180)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:36 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [3/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1686 (0.2157)	loss 0.8115 (1.1970)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:38 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [3/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2353 (0.2024)	loss 1.2076 (1.2151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:40 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [3/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2237 (0.2156)	loss 1.2020 (1.1984)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:41 swin_tiny_patch4_window7_224] (main.py 257): INFO EPOCH 3 training takes 0:00:07
[2024-12-02 13:33:42 swin_tiny_patch4_window7_224] (main.py 306): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:33:42 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:33:42 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:33:42 swin_tiny_patch4_window7_224] (main.py 248): INFO Train: [4/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3715 (0.3715)	loss 1.4127 (1.4127)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:50 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:33:50 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 13:33:50 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 13:33:50 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:33:50 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:33:51 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [0/50][0/34]	eta 0:00:09 lr 0.000003	 wd 0.0500	time 0.2737 (0.2737)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:53 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [0/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.2182 (0.2387)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:55 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [0/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1783 (0.2264)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:57 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1726 (0.2112)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:33:57 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 0 training takes 0:00:07
[2024-12-02 13:33:58 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:33:58 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:33:58 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:33:59 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [1/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3098 (0.3098)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:00 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [1/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1759 (0.1892)	loss 1.2106 (1.1857)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:02 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [1/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1599 (0.1777)	loss 1.3177 (1.1705)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:04 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1616 (0.1761)	loss 1.0078 (1.1956)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:04 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 1 training takes 0:00:06
[2024-12-02 13:34:06 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:34:06 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:34:06 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:34:06 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [2/50][0/34]	eta 0:00:16 lr 0.000003	 wd 0.0500	time 0.4722 (0.4722)	loss 0.9030 (0.9030)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:08 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [2/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1695 (0.2472)	loss 1.3133 (1.1674)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:10 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [2/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1689 (0.2133)	loss 1.1163 (1.1561)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:12 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1709 (0.2012)	loss 1.3294 (1.1946)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:12 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 2 training takes 0:00:06
[2024-12-02 13:34:13 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:34:13 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:34:13 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:34:14 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [3/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3240 (0.3240)	loss 1.2180 (1.2180)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:15 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [3/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1675 (0.1919)	loss 0.8115 (1.1970)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:17 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [3/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1776 (0.1868)	loss 1.2076 (1.2151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:20 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [3/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2403 (0.2040)	loss 1.2020 (1.1984)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:20 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 3 training takes 0:00:07
[2024-12-02 13:34:21 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:34:21 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:34:21 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:34:22 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [4/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3389 (0.3389)	loss 1.4127 (1.4127)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:24 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [4/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1763 (0.1993)	loss 1.1205 (1.1524)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:25 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [4/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1864 (0.1901)	loss 1.4133 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:27 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [4/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1728 (0.1836)	loss 1.0023 (1.1951)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:28 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 4 training takes 0:00:06
[2024-12-02 13:34:29 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:34:29 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:34:29 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:34:29 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [5/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3375 (0.3375)	loss 1.0050 (1.0050)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:31 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [5/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.2148 (0.2106)	loss 1.3082 (1.1669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:34 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [5/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2552 (0.2303)	loss 1.4345 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:35 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [5/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1716 (0.2184)	loss 1.1244 (1.1977)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:36 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 5 training takes 0:00:07
[2024-12-02 13:34:37 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:34:37 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:34:37 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:34:37 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [6/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3145 (0.3145)	loss 1.2188 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:39 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [6/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1802 (0.1949)	loss 0.8230 (1.1925)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:41 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [6/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1824 (0.1875)	loss 1.2182 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:43 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [6/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1747 (0.1849)	loss 1.2178 (1.1813)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:43 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 6 training takes 0:00:06
[2024-12-02 13:34:44 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:34:44 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:34:44 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:34:45 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [7/50][0/34]	eta 0:00:16 lr 0.000003	 wd 0.0500	time 0.4918 (0.4918)	loss 1.0111 (1.0111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:47 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [7/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2446 (0.2808)	loss 1.0072 (1.1654)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:49 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [7/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1803 (0.2367)	loss 0.9054 (1.1399)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:51 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [7/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1766 (0.2177)	loss 1.2147 (1.1798)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:52 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 7 training takes 0:00:07
[2024-12-02 13:34:53 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:34:53 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:34:53 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:34:53 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [8/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3237 (0.3237)	loss 1.1182 (1.1182)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:55 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [8/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1768 (0.1885)	loss 1.0214 (1.2186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:56 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [8/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1578 (0.1813)	loss 1.2093 (1.2085)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:58 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [8/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2160 (0.1828)	loss 1.0152 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:34:59 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 8 training takes 0:00:06
[2024-12-02 13:35:00 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:35:00 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:35:00 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:35:01 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [9/50][0/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4408 (0.4408)	loss 1.0264 (1.0264)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:35:03 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [9/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1608 (0.2147)	loss 1.3252 (1.1444)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:35:04 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [9/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1757 (0.1944)	loss 1.5173 (1.1804)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:35:06 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [9/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1899 (0.1899)	loss 1.5330 (1.1794)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:35:07 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 9 training takes 0:00:06
[2024-12-02 13:35:08 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:35:08 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:35:08 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:35:08 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [10/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3159 (0.3159)	loss 1.3284 (1.3284)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:35:10 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [10/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1745 (0.1910)	loss 1.1036 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:36:04 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:36:04 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 13:36:04 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 13:36:04 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:36:04 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:36:04 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [0/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3095 (0.3095)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:36:06 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [0/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1644 (0.1904)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:37:18 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:37:18 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 13:37:18 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 13:37:18 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:37:18 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:37:19 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [0/50][0/34]	eta 0:00:25 lr 0.000003	 wd 0.0500	time 0.7443 (0.7443)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:37:25 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [0/50][10/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.6175 (0.6094)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:37:31 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [0/50][20/34]	eta 0:00:08 lr 0.000003	 wd 0.0500	time 0.5018 (0.6023)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:37:37 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [0/50][30/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.6188 (0.5961)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:37:39 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 0 training takes 0:00:20
[2024-12-02 13:37:40 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:37:40 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:37:40 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:37:41 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [1/50][0/34]	eta 0:00:28 lr 0.000003	 wd 0.0500	time 0.8325 (0.8325)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:37:47 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [1/50][10/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.6303 (0.6235)	loss 1.2106 (1.1857)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:37:53 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [1/50][20/34]	eta 0:00:08 lr 0.000003	 wd 0.0500	time 0.6245 (0.6123)	loss 1.3177 (1.1705)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:37:59 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [1/50][30/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.6150 (0.6033)	loss 1.0078 (1.1956)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:38:01 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 1 training takes 0:00:20
[2024-12-02 13:38:01 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:38:01 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:38:01 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:38:02 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [2/50][0/34]	eta 0:00:23 lr 0.000003	 wd 0.0500	time 0.6797 (0.6797)	loss 0.9030 (0.9030)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:38:08 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [2/50][10/34]	eta 0:00:15 lr 0.000003	 wd 0.0500	time 0.6137 (0.6335)	loss 1.3133 (1.1674)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:38:14 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [2/50][20/34]	eta 0:00:08 lr 0.000003	 wd 0.0500	time 0.5222 (0.6057)	loss 1.1163 (1.1561)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:38:20 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [2/50][30/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.6142 (0.6024)	loss 1.3294 (1.1946)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:38:22 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 2 training takes 0:00:20
[2024-12-02 13:38:23 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:38:23 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:38:23 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:38:24 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [3/50][0/34]	eta 0:00:24 lr 0.000003	 wd 0.0500	time 0.7196 (0.7196)	loss 1.2180 (1.2180)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:38:29 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [3/50][10/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.6168 (0.5962)	loss 0.8115 (1.1970)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:38:36 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [3/50][20/34]	eta 0:00:08 lr 0.000003	 wd 0.0500	time 0.5205 (0.6017)	loss 1.2076 (1.2151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:38:41 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [3/50][30/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.6135 (0.5895)	loss 1.2020 (1.1984)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:38:43 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 3 training takes 0:00:20
[2024-12-02 13:38:44 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:38:45 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:38:45 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:38:45 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [4/50][0/34]	eta 0:00:31 lr 0.000003	 wd 0.0500	time 0.9320 (0.9320)	loss 1.4127 (1.4127)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:38:51 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [4/50][10/34]	eta 0:00:15 lr 0.000003	 wd 0.0500	time 0.5104 (0.6318)	loss 1.1205 (1.1524)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:38:57 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [4/50][20/34]	eta 0:00:08 lr 0.000003	 wd 0.0500	time 0.6083 (0.5854)	loss 1.4133 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:39:03 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [4/50][30/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.6158 (0.5951)	loss 1.0023 (1.1951)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:39:05 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 4 training takes 0:00:20
[2024-12-02 13:39:06 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:39:06 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:39:06 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:39:06 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [5/50][0/34]	eta 0:00:22 lr 0.000003	 wd 0.0500	time 0.6740 (0.6740)	loss 1.0050 (1.0050)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:39:12 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [5/50][10/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.5145 (0.6042)	loss 1.3082 (1.1669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:39:18 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [5/50][20/34]	eta 0:00:08 lr 0.000003	 wd 0.0500	time 0.6093 (0.5993)	loss 1.4345 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:39:24 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [5/50][30/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.7147 (0.6015)	loss 1.1244 (1.1977)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:39:26 swin_tiny_patch4_window7_224] (main.py 258): INFO EPOCH 5 training takes 0:00:20
[2024-12-02 13:39:27 swin_tiny_patch4_window7_224] (main.py 307): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:39:27 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:39:27 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:39:28 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [6/50][0/34]	eta 0:00:25 lr 0.000003	 wd 0.0500	time 0.7548 (0.7548)	loss 1.2188 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:39:34 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [6/50][10/34]	eta 0:00:15 lr 0.000003	 wd 0.0500	time 0.6094 (0.6361)	loss 0.8230 (1.1925)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:39:40 swin_tiny_patch4_window7_224] (main.py 249): INFO Train: [6/50][20/34]	eta 0:00:08 lr 0.000003	 wd 0.0500	time 0.6140 (0.6222)	loss 1.2182 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:37 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:55:37 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 1192388
[2024-12-02 13:55:37 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.096084288
[2024-12-02 13:55:37 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:55:37 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:55:38 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][0/34]	eta 0:00:15 lr 0.000003	 wd 0.0500	time 0.4615 (0.4615)	loss 0.9096 (0.9096)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:40 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2632 (0.2733)	loss 1.1134 (1.1430)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:42 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1695 (0.2277)	loss 1.1165 (1.1598)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:44 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1616 (0.2075)	loss 0.9104 (1.1777)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:44 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 13:55:45 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:55:45 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:55:45 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:55:46 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3288 (0.3288)	loss 1.3204 (1.3204)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:47 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1634 (0.1855)	loss 1.2106 (1.1857)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:49 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1579 (0.1758)	loss 1.3177 (1.1705)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:51 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1860 (0.1742)	loss 1.0078 (1.1956)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:51 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 1 training takes 0:00:06
[2024-12-02 13:55:53 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:55:53 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:55:53 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:55:53 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][0/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4226 (0.4226)	loss 0.9030 (0.9030)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:55 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1749 (0.2222)	loss 1.3133 (1.1674)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:57 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1773 (0.2008)	loss 1.1163 (1.1561)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:59 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1626 (0.1948)	loss 1.3294 (1.1946)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:55:59 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 2 training takes 0:00:06
[2024-12-02 13:56:00 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:56:00 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:56:00 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:56:00 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3254 (0.3254)	loss 1.2180 (1.2180)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:02 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1776 (0.2011)	loss 0.8115 (1.1970)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:04 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2386 (0.1937)	loss 1.2076 (1.2151)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:07 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2340 (0.2105)	loss 1.2020 (1.1984)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:07 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 3 training takes 0:00:07
[2024-12-02 13:56:08 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:56:08 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:56:08 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:56:09 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3201 (0.3201)	loss 1.4127 (1.4127)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:10 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1659 (0.1869)	loss 1.1205 (1.1524)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:12 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1631 (0.1780)	loss 1.4133 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:14 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1825 (0.1752)	loss 1.0023 (1.1951)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:14 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 4 training takes 0:00:05
[2024-12-02 13:56:15 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:56:15 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:56:15 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:56:16 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3271 (0.3271)	loss 1.0050 (1.0050)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:17 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1799 (0.1881)	loss 1.3082 (1.1669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:20 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2458 (0.2077)	loss 1.4345 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:22 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1720 (0.2066)	loss 1.1244 (1.1977)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:22 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 5 training takes 0:00:06
[2024-12-02 13:56:23 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:56:23 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:56:23 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:56:24 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3445 (0.3445)	loss 1.2188 (1.2188)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:25 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1644 (0.1982)	loss 0.8230 (1.1925)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:27 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1680 (0.1829)	loss 1.2182 (1.1895)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:29 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1752 (0.1804)	loss 1.2178 (1.1813)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:29 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 6 training takes 0:00:06
[2024-12-02 13:56:30 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:56:30 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:56:30 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:56:31 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [7/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3110 (0.3110)	loss 1.0111 (1.0111)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:33 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [7/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2811 (0.2615)	loss 1.0072 (1.1654)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:35 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [7/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1616 (0.2380)	loss 0.9054 (1.1399)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:37 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [7/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1628 (0.2142)	loss 1.2147 (1.1798)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:38 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 7 training takes 0:00:07
[2024-12-02 13:56:38 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:56:38 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:56:38 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:56:39 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [8/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3519 (0.3519)	loss 1.1182 (1.1182)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:41 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [8/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1724 (0.2020)	loss 1.0214 (1.2186)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:43 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [8/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1786 (0.1945)	loss 1.2093 (1.2085)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:44 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [8/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1651 (0.1903)	loss 1.0152 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:45 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 8 training takes 0:00:06
[2024-12-02 13:56:46 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:56:46 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:56:46 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:56:47 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [9/50][0/34]	eta 0:00:16 lr 0.000003	 wd 0.0500	time 0.4733 (0.4733)	loss 1.0264 (1.0264)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:49 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [9/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1730 (0.2444)	loss 1.3252 (1.1444)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:51 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [9/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1744 (0.2105)	loss 1.5173 (1.1804)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:52 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [9/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1975 (0.1974)	loss 1.5330 (1.1794)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:53 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 9 training takes 0:00:06
[2024-12-02 13:56:54 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:56:54 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:56:54 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:56:54 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [10/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3596 (0.3596)	loss 1.3284 (1.3284)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:56 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [10/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1612 (0.2021)	loss 1.1036 (1.1933)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:56:58 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [10/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1667 (0.1925)	loss 1.2124 (1.1887)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:00 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [10/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2707 (0.2091)	loss 1.1163 (1.1807)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:01 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 10 training takes 0:00:07
[2024-12-02 13:57:02 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:57:02 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:57:02 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:57:03 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [11/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3376 (0.3376)	loss 1.4163 (1.4163)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:04 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [11/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1785 (0.1952)	loss 0.8097 (1.2118)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:06 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [11/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1807 (0.1904)	loss 1.3154 (1.2331)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:08 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [11/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1716 (0.1883)	loss 0.7169 (1.1948)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:09 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 11 training takes 0:00:06
[2024-12-02 13:57:09 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:57:09 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:57:09 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:57:10 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [12/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3064 (0.3064)	loss 1.1152 (1.1152)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:12 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [12/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1708 (0.1880)	loss 1.3062 (1.2064)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:14 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [12/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2238 (0.2175)	loss 1.0982 (1.2008)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:16 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [12/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1667 (0.2106)	loss 1.4206 (1.1763)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:17 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 12 training takes 0:00:07
[2024-12-02 13:57:17 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:57:17 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:57:17 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:57:18 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [13/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3056 (0.3056)	loss 1.2212 (1.2212)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:20 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [13/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1968 (0.1919)	loss 1.2048 (1.1112)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:21 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [13/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1855 (0.1854)	loss 1.3212 (1.1858)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:23 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [13/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1766 (0.1851)	loss 1.3129 (1.1824)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:24 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 13 training takes 0:00:06
[2024-12-02 13:57:25 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:57:25 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:57:25 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:57:25 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [14/50][0/34]	eta 0:00:11 lr 0.000003	 wd 0.0500	time 0.3514 (0.3514)	loss 1.3150 (1.3150)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:28 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [14/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2934 (0.2704)	loss 0.9079 (1.0414)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:30 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [14/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1775 (0.2465)	loss 1.5214 (1.1916)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:32 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [14/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1693 (0.2218)	loss 1.2292 (1.1842)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:32 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 14 training takes 0:00:07
[2024-12-02 13:57:33 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:57:33 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:57:33 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:57:33 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [15/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3184 (0.3184)	loss 0.8971 (0.8971)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:57:35 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [15/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1740 (0.1916)	loss 1.4212 (1.1306)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:58:02 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:58:02 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 932368
[2024-12-02 13:58:02 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.064430944
[2024-12-02 13:58:02 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:58:02 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:59:02 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 13:59:02 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 2084144
[2024-12-02 13:59:02 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.141317952
[2024-12-02 13:59:02 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 13:59:02 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 13:59:02 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][0/34]	eta 0:00:15 lr 0.000003	 wd 0.0500	time 0.4673 (0.4673)	loss 1.2547 (1.2547)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:05 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][10/34]	eta 0:00:07 lr 0.000003	 wd 0.0500	time 0.2908 (0.2917)	loss 1.0736 (1.0871)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:08 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2117 (0.2763)	loss 1.0678 (1.0528)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:10 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][30/34]	eta 0:00:01 lr 0.000003	 wd 0.0500	time 0.2140 (0.2527)	loss 1.1589 (1.0432)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:10 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 0 training takes 0:00:08
[2024-12-02 13:59:11 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:59:11 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:59:11 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:59:12 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][0/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4230 (0.4230)	loss 1.2463 (1.2463)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:14 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1957 (0.2423)	loss 1.0759 (1.1097)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:16 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2143 (0.2227)	loss 1.1593 (1.0530)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:19 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2794 (0.2338)	loss 1.0626 (1.0476)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:20 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 1 training takes 0:00:08
[2024-12-02 13:59:21 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:59:21 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:59:21 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:59:21 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3713 (0.3713)	loss 0.7966 (0.7966)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:24 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.2317 (0.2445)	loss 0.8903 (1.0130)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:26 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2164 (0.2294)	loss 0.7086 (1.0191)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:28 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1991 (0.2240)	loss 1.0663 (1.0413)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:29 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 2 training takes 0:00:07
[2024-12-02 13:59:30 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:59:30 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:59:30 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:59:30 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.3907 (0.3907)	loss 0.8912 (0.8912)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:33 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][10/34]	eta 0:00:07 lr 0.000003	 wd 0.0500	time 0.2964 (0.3091)	loss 0.9796 (1.0458)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:36 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1976 (0.2799)	loss 1.1585 (1.0320)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:38 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][30/34]	eta 0:00:01 lr 0.000003	 wd 0.0500	time 0.2308 (0.2561)	loss 0.8080 (1.0410)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 13:59:38 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 3 training takes 0:00:08
[2024-12-02 13:59:39 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 13:59:39 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 13:59:39 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 13:59:40 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3726 (0.3726)	loss 1.1704 (1.1704)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:00:54 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:02:16 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:02:16 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 2087504
[2024-12-02 14:02:16 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.15238176
[2024-12-02 14:02:16 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:02:16 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:02:16 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3140 (0.3140)	loss 1.1433 (1.1433)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:18 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1936 (0.1927)	loss 0.8821 (1.0330)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:20 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2467 (0.2083)	loss 1.2331 (1.0198)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:23 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1613 (0.2178)	loss 0.9722 (1.0234)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:23 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 0 training takes 0:00:07
[2024-12-02 14:02:24 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:02:24 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:02:24 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:02:25 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.4007 (0.4007)	loss 0.7903 (0.7903)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:27 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1782 (0.2275)	loss 0.9707 (1.0090)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:29 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1580 (0.1994)	loss 0.7930 (1.0609)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:30 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1902 (0.1917)	loss 0.8810 (1.0397)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:31 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 1 training takes 0:00:06
[2024-12-02 14:02:32 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:02:32 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:02:32 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:02:32 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][0/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4170 (0.4170)	loss 1.0604 (1.0604)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:35 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.3004 (0.2907)	loss 0.9719 (1.0647)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:37 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1909 (0.2614)	loss 1.1456 (1.0404)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:39 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1621 (0.2319)	loss 1.1440 (1.0395)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:40 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 2 training takes 0:00:07
[2024-12-02 14:02:41 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:02:41 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:02:41 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:02:41 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3612 (0.3612)	loss 1.0531 (1.0531)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:43 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1591 (0.1950)	loss 1.2340 (0.9926)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:44 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1609 (0.1798)	loss 1.1475 (1.0145)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:46 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1767 (0.1800)	loss 0.8800 (1.0370)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:47 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 3 training takes 0:00:06
[2024-12-02 14:02:48 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:02:48 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:02:48 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:02:49 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][0/34]	eta 0:00:18 lr 0.000003	 wd 0.0500	time 0.5482 (0.5482)	loss 0.7950 (0.7950)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:51 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.1826 (0.2511)	loss 1.0584 (1.0254)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:53 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1736 (0.2216)	loss 0.9674 (1.0320)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:55 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1815 (0.2064)	loss 0.8863 (1.0265)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:55 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 4 training takes 0:00:06
[2024-12-02 14:02:56 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:02:56 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:02:56 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:02:57 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][0/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4143 (0.4143)	loss 1.2266 (1.2266)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:02:58 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1594 (0.2026)	loss 1.0533 (1.0571)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:00 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2848 (0.1946)	loss 1.1440 (1.0492)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:03 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2593 (0.2178)	loss 0.9711 (1.0345)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:04 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 5 training takes 0:00:07
[2024-12-02 14:03:05 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:03:05 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:03:05 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:03:05 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.4111 (0.4111)	loss 1.0567 (1.0567)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:07 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1995 (0.2251)	loss 1.4112 (1.0577)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:09 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1802 (0.2074)	loss 0.9705 (1.0447)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:11 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1830 (0.2004)	loss 1.0579 (1.0343)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:11 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 6 training takes 0:00:06
[2024-12-02 14:03:31 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:03:31 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 2087504
[2024-12-02 14:03:31 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.15238176
[2024-12-02 14:03:31 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:03:31 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:03:32 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3620 (0.3620)	loss 1.1433 (1.1433)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:34 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1715 (0.2071)	loss 0.8821 (1.0330)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:35 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1619 (0.1875)	loss 1.2331 (1.0198)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:37 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1635 (0.1828)	loss 0.9722 (1.0234)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:38 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 14:03:39 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:03:39 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:03:39 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:03:40 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][0/34]	eta 0:00:17 lr 0.000003	 wd 0.0500	time 0.5015 (0.5015)	loss 0.7903 (0.7903)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:42 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1799 (0.2342)	loss 0.9707 (1.0090)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:44 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1624 (0.2040)	loss 0.7930 (1.0609)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:45 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1747 (0.1927)	loss 0.8810 (1.0397)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:46 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 1 training takes 0:00:06
[2024-12-02 14:03:47 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:03:47 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:03:47 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:03:47 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.3847 (0.3847)	loss 1.0604 (1.0604)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:49 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1778 (0.2138)	loss 0.9719 (1.0647)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:51 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2652 (0.2050)	loss 1.1456 (1.0404)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:03:54 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2542 (0.2291)	loss 1.1440 (1.0395)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:20 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:04:20 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 2087504
[2024-12-02 14:04:20 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.15238176
[2024-12-02 14:04:20 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:04:20 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:04:21 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][0/34]	eta 0:00:10 lr 0.000003	 wd 0.0500	time 0.3231 (0.3231)	loss 1.1433 (1.1433)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:22 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][10/34]	eta 0:00:04 lr 0.000003	 wd 0.0500	time 0.1788 (0.1900)	loss 0.8821 (1.0330)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:24 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1885 (0.1886)	loss 1.2331 (1.0198)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:26 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1790 (0.1881)	loss 0.9722 (1.0234)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:27 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 0 training takes 0:00:06
[2024-12-02 14:04:28 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:04:28 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:04:28 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:04:28 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][0/34]	eta 0:00:12 lr 0.000003	 wd 0.0500	time 0.3730 (0.3730)	loss 0.7903 (0.7903)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:30 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.2478 (0.2333)	loss 0.9707 (1.0090)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:33 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2854 (0.2539)	loss 0.7930 (1.0609)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:35 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1839 (0.2337)	loss 0.8810 (1.0397)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:36 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 1 training takes 0:00:07
[2024-12-02 14:04:37 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:04:37 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:04:37 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:04:37 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.3999 (0.3999)	loss 1.0604 (1.0604)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:39 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1969 (0.2255)	loss 0.9719 (1.0647)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:41 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2035 (0.2118)	loss 1.1456 (1.0404)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:43 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1742 (0.2057)	loss 1.1440 (1.0395)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:44 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 2 training takes 0:00:07
[2024-12-02 14:04:45 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:04:45 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:04:45 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:04:46 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][0/34]	eta 0:00:20 lr 0.000003	 wd 0.0500	time 0.5893 (0.5893)	loss 1.0531 (1.0531)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:48 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1641 (0.2448)	loss 1.2340 (0.9926)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:50 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.1980 (0.2168)	loss 1.1475 (1.0145)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:52 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1818 (0.2057)	loss 0.8800 (1.0370)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:52 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 3 training takes 0:00:06
[2024-12-02 14:04:53 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:04:53 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:04:53 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:04:54 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.4072 (0.4072)	loss 0.7950 (0.7950)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:56 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1671 (0.2161)	loss 1.0584 (1.0254)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:04:58 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.2495 (0.2106)	loss 0.9674 (1.0320)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:00 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.2688 (0.2287)	loss 0.8863 (1.0265)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:01 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 4 training takes 0:00:07
[2024-12-02 14:05:02 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:05:02 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:05:02 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:05:02 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][0/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4236 (0.4236)	loss 1.2266 (1.2266)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:04 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.1887 (0.2129)	loss 1.0533 (1.0571)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:06 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1806 (0.1940)	loss 1.1440 (1.0492)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:08 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1817 (0.1935)	loss 0.9711 (1.0345)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:09 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 5 training takes 0:00:06
[2024-12-02 14:05:10 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:05:10 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:05:10 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:05:10 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][0/34]	eta 0:00:14 lr 0.000003	 wd 0.0500	time 0.4137 (0.4137)	loss 1.0567 (1.0567)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:13 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][10/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 0.2525 (0.2787)	loss 1.4112 (1.0577)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:15 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][20/34]	eta 0:00:03 lr 0.000003	 wd 0.0500	time 0.2222 (0.2531)	loss 0.9705 (1.0447)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:17 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [6/50][30/34]	eta 0:00:00 lr 0.000003	 wd 0.0500	time 0.1934 (0.2306)	loss 1.0579 (1.0343)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:17 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 6 training takes 0:00:07
[2024-12-02 14:05:19 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 26.923 Acc@5 26.923
[2024-12-02 14:05:19 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 26.9%
[2024-12-02 14:05:19 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 26.92%
[2024-12-02 14:05:19 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [7/50][0/34]	eta 0:00:13 lr 0.000003	 wd 0.0500	time 0.3943 (0.3943)	loss 0.9673 (0.9673)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:21 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [7/50][10/34]	eta 0:00:05 lr 0.000003	 wd 0.0500	time 0.2088 (0.2191)	loss 1.0532 (1.0878)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:05:23 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [7/50][20/34]	eta 0:00:02 lr 0.000003	 wd 0.0500	time 0.1753 (0.1983)	loss 1.0546 (1.0612)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:12:42 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:12:43 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 33097328
[2024-12-02 14:12:43 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 2.213553408
[2024-12-02 14:12:43 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:12:43 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:12:45 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][0/34]	eta 0:01:28 lr 0.000003	 wd 0.0500	time 2.5953 (2.5953)	loss 1.0855 (1.0855)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:13:01 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][10/34]	eta 0:00:40 lr 0.000003	 wd 0.0500	time 1.3936 (1.6810)	loss 1.1843 (1.1228)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:13:16 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][20/34]	eta 0:00:22 lr 0.000003	 wd 0.0500	time 1.3147 (1.5902)	loss 0.9865 (1.0646)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:13:31 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][30/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 1.3608 (1.5549)	loss 0.9035 (1.0670)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:13:35 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 0 training takes 0:00:52
[2024-12-02 14:13:43 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:13:43 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:13:43 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:13:45 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][0/34]	eta 0:01:08 lr 0.000003	 wd 0.0500	time 2.0192 (2.0192)	loss 0.9955 (0.9955)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:14:01 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][10/34]	eta 0:00:38 lr 0.000003	 wd 0.0500	time 1.4162 (1.5969)	loss 1.0919 (1.0669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:14:16 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][20/34]	eta 0:00:21 lr 0.000003	 wd 0.0500	time 1.3667 (1.5489)	loss 1.1782 (1.0572)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:14:31 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][30/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 1.2971 (1.5331)	loss 1.0761 (1.0571)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:14:36 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 1 training takes 0:00:52
[2024-12-02 14:14:43 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:14:43 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:14:43 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:14:45 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][0/34]	eta 0:01:05 lr 0.000003	 wd 0.0500	time 1.9126 (1.9126)	loss 0.6413 (0.6413)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:15:01 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][10/34]	eta 0:00:39 lr 0.000003	 wd 0.0500	time 2.1980 (1.6515)	loss 1.1778 (1.0326)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:15:54 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:15:54 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 33093968
[2024-12-02 14:15:54 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 2.169298176
[2024-12-02 14:15:54 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:15:54 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:15:56 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][0/34]	eta 0:01:03 lr 0.000003	 wd 0.0500	time 1.8636 (1.8636)	loss 1.0172 (1.0172)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:16:13 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][10/34]	eta 0:00:41 lr 0.000003	 wd 0.0500	time 1.4495 (1.7265)	loss 0.7282 (1.0100)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:16:30 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][20/34]	eta 0:00:23 lr 0.000003	 wd 0.0500	time 1.6189 (1.6855)	loss 1.3203 (1.0919)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:16:48 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][30/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 1.8877 (1.7118)	loss 1.0182 (1.0872)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:16:52 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 0 training takes 0:00:57
[2024-12-02 14:17:01 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:17:01 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:17:01 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:17:03 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][0/34]	eta 0:01:08 lr 0.000003	 wd 0.0500	time 2.0139 (2.0139)	loss 1.0932 (1.0932)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:17:19 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][10/34]	eta 0:00:40 lr 0.000003	 wd 0.0500	time 1.4603 (1.6868)	loss 0.9209 (1.0959)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:17:36 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][20/34]	eta 0:00:23 lr 0.000003	 wd 0.0500	time 1.5230 (1.6666)	loss 0.7312 (1.1031)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:17:53 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][30/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 2.2995 (1.6854)	loss 0.9296 (1.0890)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:17:58 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 1 training takes 0:00:57
[2024-12-02 14:18:06 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:18:06 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:18:06 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:18:09 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][0/34]	eta 0:01:27 lr 0.000003	 wd 0.0500	time 2.5799 (2.5799)	loss 1.1311 (1.1311)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:18:25 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][10/34]	eta 0:00:41 lr 0.000003	 wd 0.0500	time 1.4599 (1.7352)	loss 0.8617 (1.0170)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:18:42 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][20/34]	eta 0:00:23 lr 0.000003	 wd 0.0500	time 1.5391 (1.6746)	loss 1.1192 (1.0790)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:18:58 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][30/34]	eta 0:00:06 lr 0.000003	 wd 0.0500	time 1.5188 (1.6676)	loss 0.9964 (1.0860)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:19:04 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 2 training takes 0:00:57
[2024-12-02 14:19:11 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:19:11 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:19:11 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:19:14 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][0/34]	eta 0:01:40 lr 0.000003	 wd 0.0500	time 2.9573 (2.9573)	loss 1.2001 (1.2001)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:19:31 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][10/34]	eta 0:00:43 lr 0.000003	 wd 0.0500	time 1.5469 (1.7997)	loss 0.9975 (1.0888)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:19:48 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][20/34]	eta 0:00:24 lr 0.000003	 wd 0.0500	time 1.5525 (1.7323)	loss 1.2027 (1.1058)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:20:22 swin_tiny_patch4_window7_224] (main.py 387): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 384
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 14:20:22 swin_tiny_patch4_window7_224] (main.py 388): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 14:20:22 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:20:23 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 33093968
[2024-12-02 14:20:23 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 2.169298176
[2024-12-02 14:20:23 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:20:23 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:20:25 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][0/34]	eta 0:01:04 lr 0.000004	 wd 0.0001	time 1.8863 (1.8863)	loss 1.0172 (1.0172)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:20:41 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][10/34]	eta 0:00:40 lr 0.000004	 wd 0.0001	time 1.5662 (1.6819)	loss 0.7282 (1.0100)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:20:58 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][20/34]	eta 0:00:23 lr 0.000004	 wd 0.0001	time 1.5246 (1.6580)	loss 1.3203 (1.0919)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:21:15 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 2.0374 (1.6975)	loss 1.0182 (1.0872)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:21:20 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 0 training takes 0:00:57
[2024-12-02 14:21:29 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:21:29 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:21:29 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:21:31 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][0/34]	eta 0:01:13 lr 0.000004	 wd 0.0001	time 2.1631 (2.1631)	loss 1.0932 (1.0932)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:21:47 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][10/34]	eta 0:00:40 lr 0.000004	 wd 0.0001	time 1.5409 (1.6963)	loss 0.9209 (1.0959)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:22:07 swin_tiny_patch4_window7_224] (main.py 387): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 384
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 14
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 14:22:07 swin_tiny_patch4_window7_224] (main.py 388): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 14:22:07 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:22:08 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 33097328
[2024-12-02 14:22:08 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 2.213553408
[2024-12-02 14:22:08 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:22:08 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:22:10 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][0/34]	eta 0:01:10 lr 0.000004	 wd 0.0001	time 2.0774 (2.0774)	loss 1.0855 (1.0855)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:22:25 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][10/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.3279 (1.5678)	loss 1.1843 (1.1228)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:22:40 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.4116 (1.5179)	loss 0.9865 (1.0646)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:22:54 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3579 (1.5069)	loss 0.9035 (1.0670)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:22:58 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 0 training takes 0:00:50
[2024-12-02 14:23:06 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:23:06 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:23:06 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:23:08 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][0/34]	eta 0:01:04 lr 0.000004	 wd 0.0001	time 1.8869 (1.8869)	loss 0.9955 (0.9955)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:23:24 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][10/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.2967 (1.5572)	loss 1.0919 (1.0669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:23:38 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.3497 (1.5043)	loss 1.1782 (1.0572)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:23:53 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][30/34]	eta 0:00:05 lr 0.000004	 wd 0.0001	time 1.3750 (1.4949)	loss 1.0761 (1.0571)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:23:58 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 1 training takes 0:00:51
[2024-12-02 14:24:05 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:24:05 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:24:05 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:24:07 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][0/34]	eta 0:01:03 lr 0.000004	 wd 0.0001	time 1.8703 (1.8703)	loss 0.6413 (0.6413)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:24:23 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][10/34]	eta 0:00:38 lr 0.000004	 wd 0.0001	time 2.0407 (1.6169)	loss 1.1778 (1.0326)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:24:38 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][20/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 1.8845 (1.5806)	loss 1.2703 (1.0401)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:24:53 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3588 (1.5479)	loss 0.9743 (1.0522)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:24:57 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 2 training takes 0:00:52
[2024-12-02 14:25:05 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:25:05 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:25:05 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:25:07 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][0/34]	eta 0:01:05 lr 0.000004	 wd 0.0001	time 1.9355 (1.9355)	loss 1.0090 (1.0090)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:25:22 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][10/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.2839 (1.5582)	loss 0.8220 (0.9971)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:25:37 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.3366 (1.5168)	loss 1.3722 (1.0442)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:25:52 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [3/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3962 (1.5012)	loss 1.1834 (1.0703)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:25:56 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 3 training takes 0:00:50
[2024-12-02 14:26:04 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:26:04 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:26:04 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:26:06 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][0/34]	eta 0:01:02 lr 0.000004	 wd 0.0001	time 1.8411 (1.8411)	loss 0.9931 (0.9931)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:26:21 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][10/34]	eta 0:00:38 lr 0.000004	 wd 0.0001	time 1.3022 (1.5847)	loss 0.8166 (1.0769)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:26:37 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.3689 (1.5538)	loss 1.0840 (1.0796)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:26:53 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [4/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 2.2055 (1.5746)	loss 0.7354 (1.0622)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:26:57 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 4 training takes 0:00:53
[2024-12-02 14:27:05 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:27:05 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:27:05 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:27:07 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][0/34]	eta 0:01:37 lr 0.000004	 wd 0.0001	time 2.8764 (2.8764)	loss 1.1726 (1.1726)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:27:23 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][10/34]	eta 0:00:39 lr 0.000004	 wd 0.0001	time 1.4300 (1.6663)	loss 1.0808 (1.0423)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:27:38 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [5/50][20/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 1.3167 (1.5742)	loss 1.0906 (1.0516)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:27:49 swin_tiny_patch4_window7_224] (main.py 387): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 8
    EMBED_DIM: 128
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 4
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 14
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 14
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 14:27:49 swin_tiny_patch4_window7_224] (main.py 388): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 14:27:49 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:27:49 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 7264962
[2024-12-02 14:27:49 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.518428352
[2024-12-02 14:27:49 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:27:49 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:29:28 swin_tiny_patch4_window7_224] (main.py 387): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 4
    - 8
    EMBED_DIM: 128
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 14
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 14
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 14:29:28 swin_tiny_patch4_window7_224] (main.py 388): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 14:29:28 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:29:29 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 7262046
[2024-12-02 14:29:29 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.517813696
[2024-12-02 14:29:29 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:29:29 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:29:49 swin_tiny_patch4_window7_224] (main.py 387): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 128
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 14
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 14
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 14:29:49 swin_tiny_patch4_window7_224] (main.py 388): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 14:29:49 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:29:49 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 3698032
[2024-12-02 14:29:49 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.262199904
[2024-12-02 14:29:49 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:29:49 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:30:10 swin_tiny_patch4_window7_224] (main.py 387): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 128
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 14
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 14:30:10 swin_tiny_patch4_window7_224] (main.py 388): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 14:30:10 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:30:10 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 3698032
[2024-12-02 14:30:10 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 0.262199904
[2024-12-02 14:30:10 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:30:10 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:30:32 swin_tiny_patch4_window7_224] (main.py 387): INFO AMP_ENABLE: false
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 16
  CACHE_MODE: 'no'
  DATASET: imagenet
  DATA_PATH: data/ImageNet-Zip
  IMG_SIZE: 28
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 1
  PIN_MEMORY: true
  ZIP_MODE: true
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.0
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: ''
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 4
    EMBED_DIM: 384
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 14
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 1
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 2
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 1
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 2
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 4.348145121276739e-06
  CLIP_GRAD: 5.0
  EPOCHS: 50
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 4.348145121276739e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 4.348145121276739e-06
  WEIGHT_DECAY: 0.0001

[2024-12-02 14:30:32 swin_tiny_patch4_window7_224] (main.py 388): INFO {"cfg": "configs/swin/swin_tiny_patch4_window7_224.yaml", "opts": null, "batch_size": 16, "data_path": "data/ImageNet-Zip", "zip": true, "cache_mode": "no", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-12-02 14:30:32 swin_tiny_patch4_window7_224] (main.py 93): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2024-12-02 14:30:32 swin_tiny_patch4_window7_224] (main.py 98): INFO number of params: 33097328
[2024-12-02 14:30:32 swin_tiny_patch4_window7_224] (main.py 101): INFO number of GFLOPs: 2.213553408
[2024-12-02 14:30:32 swin_tiny_patch4_window7_224] (main.py 138): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2024-12-02 14:30:32 swin_tiny_patch4_window7_224] (main.py 156): INFO Start training
[2024-12-02 14:30:34 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][0/34]	eta 0:01:02 lr 0.000004	 wd 0.0001	time 1.8303 (1.8303)	loss 1.0855 (1.0855)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:30:51 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][10/34]	eta 0:00:39 lr 0.000004	 wd 0.0001	time 2.1992 (1.6582)	loss 1.1843 (1.1228)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:31:06 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][20/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 1.6966 (1.6097)	loss 0.9865 (1.0646)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:31:21 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [0/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.4004 (1.5774)	loss 0.9035 (1.0670)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:31:25 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 0 training takes 0:00:53
[2024-12-02 14:31:34 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:31:34 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:31:34 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:31:36 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][0/34]	eta 0:01:06 lr 0.000004	 wd 0.0001	time 1.9683 (1.9683)	loss 0.9955 (0.9955)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:31:51 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][10/34]	eta 0:00:37 lr 0.000004	 wd 0.0001	time 1.3759 (1.5720)	loss 1.0919 (1.0669)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:32:06 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][20/34]	eta 0:00:21 lr 0.000004	 wd 0.0001	time 1.3470 (1.5326)	loss 1.1782 (1.0572)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:32:21 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [1/50][30/34]	eta 0:00:06 lr 0.000004	 wd 0.0001	time 1.3113 (1.5205)	loss 1.0761 (1.0571)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:32:26 swin_tiny_patch4_window7_224] (main.py 261): INFO EPOCH 1 training takes 0:00:52
[2024-12-02 14:32:33 swin_tiny_patch4_window7_224] (main.py 310): INFO  * Acc@1 73.077 Acc@5 73.077
[2024-12-02 14:32:33 swin_tiny_patch4_window7_224] (main.py 169): INFO Accuracy of the network on the 78 test images: 73.1%
[2024-12-02 14:32:33 swin_tiny_patch4_window7_224] (main.py 171): INFO Max accuracy: 73.08%
[2024-12-02 14:32:35 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][0/34]	eta 0:01:08 lr 0.000004	 wd 0.0001	time 2.0122 (2.0122)	loss 0.6413 (0.6413)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:32:51 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][10/34]	eta 0:00:38 lr 0.000004	 wd 0.0001	time 1.4149 (1.5850)	loss 1.1778 (1.0326)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
[2024-12-02 14:33:06 swin_tiny_patch4_window7_224] (main.py 252): INFO Train: [2/50][20/34]	eta 0:00:22 lr 0.000004	 wd 0.0001	time 2.0865 (1.5838)	loss 1.2703 (1.0401)	grad_norm 0.0000 (0.0000)	loss_scale 0.0000 (0.0000)	mem 0MB
